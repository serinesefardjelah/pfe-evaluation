Repo Name,Function Name,original_code,Description,Mutant Index,Mutant Code,Test Case,Test Result,Passed Count,Failed Count,Failed Tests,Failure Reasons,Function ID,Method
datefinder,_find_and_replace,"def _find_and_replace(self, date_string, captures):
    """"""
        :warning: when multiple tz matches exist the last sorted capture will trump
        :param date_string:
        :return: date_string, tz_string
        """"""
    cloned_replacements = copy.copy(REPLACEMENTS)
    for tz_string in captures.get('timezones', []):
        cloned_replacements.update({tz_string: ' '})
    date_string = date_string.lower()
    for key, replacement in cloned_replacements.items():
        full_match_pattern = '(^|{delimiters_pattern}){key}($|{delimiters_pattern})'.format(delimiters_pattern=DELIMITERS_PATTERN, key=key)
        date_string = re.sub(full_match_pattern, replacement, date_string, flags=re.IGNORECASE)
    return (date_string, self._pop_tz_string(sorted(captures.get('timezones', []))))","The goal of the `_find_and_replace` function is to search a given `date_string` for specific patterns and replace them based on a set of predefined replacements. It also looks for timezones in the `captures` dictionary and updates the replacements accordingly. The function returns the modified `date_string` and the timezone string. If multiple timezones are found, it selects the last sorted timezone as the final timezone string. This function is designed to clean and manipulate date strings by replacing specific patterns with predefined values.",3,"def _find_and_replace(self, date_string, captures):
    new_date_string = date_string.replace('pattern1', 'replacement1').replace('pattern2', 'replacement2')
    
    for key, value in captures.items():
        if key == 'timezone':
            new_date_string = new_date_string.replace(key, value)
    
    timezone_strings = [captures[key] for key in captures if key == 'timezone']
    timezone_string = sorted(timezone_strings)[-1] if timezone_strings else None
    
    return new_date_string, timezone_string","['./repos/datefinder\\tests', './repos/datefinder\\tests\\test_add_tzinfo.py::test_add_tzinfo', './repos/datefinder\\tests\\test_extract_date_strings.py::test_extract_date_strings', './repos/datefinder\\tests\\test_extract_date_strings.py::test_extract_date_strings_with_strict_option', './repos/datefinder\\tests\\test_find_and_replace.py::test_find_and_replace', './repos/datefinder\\tests\\test_find_dates.py::test_find_date_strings', './repos/datefinder\\tests\\test_find_dates_strict.py::test_find_date_strings_strict', './repos/datefinder\\tests\\test_simple.py::test_success', './repos/datefinder\\tests\\test_tz_gettz.py::test_tz_gettz_for_all_patterns']","50 Passed, 4 Failed",50,4,"['tests/test_find_and_replace.py::test_find_and_replace[due on Tuesday Jul 22, 2014 eastern standard time- tuesday jul 22, 2014 eastern -captures0-EST]', 'tests/test_find_dates.py::test_find_date_strings[i am looking for a date june 4th 1996 to july 3rd 2013-expected_date15-month]', 'tests/test_find_dates.py::test_find_date_strings[12th day of December, 2001-expected_date24-month]', 'tests/test_find_dates_strict.py::test_find_date_strings_strict[19th day of May, 2015-expected_date4]']","[""date_string = 'due on Tuesday Jul 22, 2014 eastern standard time'\nexpected_replaced_string = ' tuesday jul 22, 2014 eastern '\ncaptures = {'timezones': ['EST']}, expected_tz_string = 'EST'\n\n    @pytest.mark.parametrize('date_string, expected_replaced_string, captures, expected_tz_string', [\n        ('due on Tuesday Jul 22, 2014 eastern standard time',\n        ' tuesday jul 22, 2014 eastern ',\n         {'timezones':['EST']},\n         'EST',\n        )\n    ])\n    def test_find_and_replace(date_string, expected_replaced_string, captures, expected_tz_string):\n        dt = datefinder.DateFinder()\n        expected_replacements = copy.copy(REPLACEMENTS)\n        actual_date_string, actual_tz_string = dt._find_and_replace(date_string, captures)\n    \n        # assert that dt._find_and_replace did not mutate dt.REPLACEMENTS\n        assert REPLACEMENTS == expected_replacements\n    \n        # assert the return values of dt._find_and_replace\n>       assert actual_date_string == expected_replaced_string\nE       AssertionError: assert 'due on Tuesd...standard time' == ' tuesday jul...2014 eastern '\nE         \nE         -  tuesday jul 22, 2014 eastern \nE         + due on Tuesday Jul 22, 2014 eastern standard time\n\nrepos\\datefinder\\tests\\test_find_and_replace.py:27: AssertionError"", 'input_text = \'i am looking for a date june 4th 1996 to july 3rd 2013\'\nexpected_date = [datetime.datetime(1996, 6, 4, 0, 0), datetime.datetime(2013, 7, 3, 0, 0)]\nfirst = \'month\'\n\n    @pytest.mark.parametrize(\n        (""input_text"", ""expected_date"", ""first""),\n        [\n            ## English Dates\n            # (\'[Sept] 04, 2014.\', datetime(2014, 9, 4), ""month""),\n            (""Tuesday Jul 22, 2014"", datetime(2014, 7, 22), ""month""),\n            # (\'10:04am EDT\', datetime(2012, 11, 13, 14, 4), ""month""),\n            # (\'Friday\', datetime(2012, 11, 9), ""month""),\n            # (\'November 19, 2014 at noon\', datetime(2014, 11, 19, 12, 0), ""month""),\n            (""December 13, 2014 at midnight"", datetime(2014, 12, 13, 0, 0), ""month""),\n            # (\'Nov 25 2014 10:17 pm EST\', datetime(2014, 11, 26, 3, 17), ""month""),\n            # (\'Wed Aug 05 12:00:00 EDT 2015\', datetime(2015, 8, 5, 16, 0), ""month""),\n            (""April 9, 2013 at 6:11 a.m."", datetime(2013, 4, 9, 6, 11), ""month""),\n            (""Aug. 9, 2012 at 2:57 p.m."", datetime(2012, 8, 9, 14, 57), ""month""),\n            (""December 10, 2014, 11:02:21 pm"", datetime(2014, 12, 10, 23, 2, 21), ""month""),\n            (""8:25 a.m. Dec. 12, 2014"", datetime(2014, 12, 12, 8, 25), ""month""),\n            (""2:21 p.m., December 11, 2014"", datetime(2014, 12, 11, 14, 21), ""month""),\n            (""Fri, 12 Dec 2014 10:55:50"", datetime(2014, 12, 12, 10, 55, 50), ""month""),\n            # (\'20 Mar 2013 10h11\', datetime(2013, 3, 20, 10, 11), ""month""),\n            (""10:06am Dec 11, 2014"", datetime(2014, 12, 11, 10, 6), ""month""),\n            (""September 2nd, 1998"", datetime(1998, 9, 2), ""month""),\n            (\n                ""May 5, 2010 to July 10, 2011"",\n                [datetime(2010, 5, 5), datetime(2011, 7, 10)],\n                ""month"",\n            ),\n            # (\'19 February 2013 year 09:10\', datetime(2013, 2, 19, 9, 10), ""month""),\n            # Numeric dates\n            (""06-17-2014"", datetime(2014, 6, 17), ""month""),\n            (""13/03/2014"", datetime(2014, 3, 13), ""month""),\n            (\n                ""2016-02-04T20:16:26+00:00"",\n                datetime(2016, 2, 4, 20, 16, 26, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            # (\'11. 12. 2014, 08:45:39\', datetime(2014, 11, 12, 8, 45, 39)),\n            (\n                ""2017-02-03T09:04:08Z to 2017-02-03T09:04:09Z"",\n                [\n                    datetime(2017, 2, 3, 9, 4, 8, tzinfo=pytz.utc),\n                    datetime(2017, 2, 3, 9, 4, 9, tzinfo=pytz.utc),\n                ],\n                ""month"",\n            ),\n            # dates from issue https://github.com/akoumjian/datefinder/issues/14\n            (\n                ""i am looking for a date june 4th 1996 to july 3rd 2013"",\n                [datetime(1996, 6, 4), datetime(2013, 7, 3)],\n                ""month"",\n            ),\n            (\n                ""october 27 1994 to be put into effect on june 1 1995"",\n                [datetime(1994, 10, 27), datetime(1995, 6, 1)],\n                ""month"",\n            ),\n            # Simple date range\n            (\n                ""31/08/2012 to 30/08/2013"",\n                [datetime(2012, 8, 31), datetime(2013, 8, 30)],\n                ""month"",\n            ),\n            (\n                ""31 Oct 2021 - 28 Nov 2021"",\n                [datetime(2021, 10, 31), datetime(2021, 11, 28)],\n                ""day""\n            ),\n            # Z dates with and without millis, from https://github.com/akoumjian/datefinder/issues/37\n            (\n                ""2017-02-03T09:04:08.001Z"",\n                datetime(2017, 2, 3, 9, 4, 8, 1000, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            (\n                ""2017-02-03T09:04:08,00123Z"",\n                datetime(2017, 2, 3, 9, 4, 8, 1230, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            (\n                ""2017-02-03T09:04:08Z"",\n                datetime(2017, 2, 3, 9, 4, 8, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            # Year only strings, from https://github.com/akoumjian/datefinder/issues/96\n            (\n                ""Dutta is the recipient of Femina Miss India Universe title in 2004."",\n                datetime(2004, today.month, today.day),\n                ""month"",\n            ),\n            (\n                \'she said that she hit depression after being traumatized on the sets of ""Horn OK"" in 2008.\',\n                datetime(2008, today.month, today.day),\n                ""month"",\n            ),\n            # https://github.com/akoumjian/datefinder/issues/63\n            (""12th day of December, 2001"", datetime(2001, 12, 12), ""month""),\n            (""01/02/03"", datetime(2003, 1, 2, 0, 0, 0, 0), ""month""),\n            (""01/02/03"", datetime(2003, 2, 1, 0, 0, 0, 0), ""day""),\n            (""01/02/03"", datetime(2001, 2, 3, 0, 0, 0, 0), ""year""),\n            (""02/05/2020"", datetime(2020, 2, 5, 0, 0, 0, 0), ""month""),\n            (""02/05/2020"", datetime(2020, 5, 2, 0, 0, 0, 0), ""day""),\n        ],\n    )\n    def test_find_date_strings(input_text, expected_date, first):\n        if isinstance(expected_date, list):\n            matches = list(datefinder.find_dates(input_text, first=first))\n>           assert matches == expected_date\nE           assert [datetime.dat..., 7, 3, 0, 0)] == [datetime.dat..., 7, 3, 0, 0)]\nE             \nE             At index 0 diff: datetime.datetime(2013, 7, 3, 0, 0) != datetime.datetime(1996, 6, 4, 0, 0)\nE             Right contains one more item: datetime.datetime(2013, 7, 3, 0, 0)\nE             \nE             Full diff:\nE               [\nE             -     datetime.datetime(1996, 6, 4, 0, 0),\nE                   datetime.datetime(2013, 7, 3, 0, 0),\nE               ]\n\nrepos\\datefinder\\tests\\test_find_dates.py:119: AssertionError', 'input_text = \'12th day of December, 2001\'\nexpected_date = datetime.datetime(2001, 12, 12, 0, 0), first = \'month\'\n\n    @pytest.mark.parametrize(\n        (""input_text"", ""expected_date"", ""first""),\n        [\n            ## English Dates\n            # (\'[Sept] 04, 2014.\', datetime(2014, 9, 4), ""month""),\n            (""Tuesday Jul 22, 2014"", datetime(2014, 7, 22), ""month""),\n            # (\'10:04am EDT\', datetime(2012, 11, 13, 14, 4), ""month""),\n            # (\'Friday\', datetime(2012, 11, 9), ""month""),\n            # (\'November 19, 2014 at noon\', datetime(2014, 11, 19, 12, 0), ""month""),\n            (""December 13, 2014 at midnight"", datetime(2014, 12, 13, 0, 0), ""month""),\n            # (\'Nov 25 2014 10:17 pm EST\', datetime(2014, 11, 26, 3, 17), ""month""),\n            # (\'Wed Aug 05 12:00:00 EDT 2015\', datetime(2015, 8, 5, 16, 0), ""month""),\n            (""April 9, 2013 at 6:11 a.m."", datetime(2013, 4, 9, 6, 11), ""month""),\n            (""Aug. 9, 2012 at 2:57 p.m."", datetime(2012, 8, 9, 14, 57), ""month""),\n            (""December 10, 2014, 11:02:21 pm"", datetime(2014, 12, 10, 23, 2, 21), ""month""),\n            (""8:25 a.m. Dec. 12, 2014"", datetime(2014, 12, 12, 8, 25), ""month""),\n            (""2:21 p.m., December 11, 2014"", datetime(2014, 12, 11, 14, 21), ""month""),\n            (""Fri, 12 Dec 2014 10:55:50"", datetime(2014, 12, 12, 10, 55, 50), ""month""),\n            # (\'20 Mar 2013 10h11\', datetime(2013, 3, 20, 10, 11), ""month""),\n            (""10:06am Dec 11, 2014"", datetime(2014, 12, 11, 10, 6), ""month""),\n            (""September 2nd, 1998"", datetime(1998, 9, 2), ""month""),\n            (\n                ""May 5, 2010 to July 10, 2011"",\n                [datetime(2010, 5, 5), datetime(2011, 7, 10)],\n                ""month"",\n            ),\n            # (\'19 February 2013 year 09:10\', datetime(2013, 2, 19, 9, 10), ""month""),\n            # Numeric dates\n            (""06-17-2014"", datetime(2014, 6, 17), ""month""),\n            (""13/03/2014"", datetime(2014, 3, 13), ""month""),\n            (\n                ""2016-02-04T20:16:26+00:00"",\n                datetime(2016, 2, 4, 20, 16, 26, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            # (\'11. 12. 2014, 08:45:39\', datetime(2014, 11, 12, 8, 45, 39)),\n            (\n                ""2017-02-03T09:04:08Z to 2017-02-03T09:04:09Z"",\n                [\n                    datetime(2017, 2, 3, 9, 4, 8, tzinfo=pytz.utc),\n                    datetime(2017, 2, 3, 9, 4, 9, tzinfo=pytz.utc),\n                ],\n                ""month"",\n            ),\n            # dates from issue https://github.com/akoumjian/datefinder/issues/14\n            (\n                ""i am looking for a date june 4th 1996 to july 3rd 2013"",\n                [datetime(1996, 6, 4), datetime(2013, 7, 3)],\n                ""month"",\n            ),\n            (\n                ""october 27 1994 to be put into effect on june 1 1995"",\n                [datetime(1994, 10, 27), datetime(1995, 6, 1)],\n                ""month"",\n            ),\n            # Simple date range\n            (\n                ""31/08/2012 to 30/08/2013"",\n                [datetime(2012, 8, 31), datetime(2013, 8, 30)],\n                ""month"",\n            ),\n            (\n                ""31 Oct 2021 - 28 Nov 2021"",\n                [datetime(2021, 10, 31), datetime(2021, 11, 28)],\n                ""day""\n            ),\n            # Z dates with and without millis, from https://github.com/akoumjian/datefinder/issues/37\n            (\n                ""2017-02-03T09:04:08.001Z"",\n                datetime(2017, 2, 3, 9, 4, 8, 1000, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            (\n                ""2017-02-03T09:04:08,00123Z"",\n                datetime(2017, 2, 3, 9, 4, 8, 1230, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            (\n                ""2017-02-03T09:04:08Z"",\n                datetime(2017, 2, 3, 9, 4, 8, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            # Year only strings, from https://github.com/akoumjian/datefinder/issues/96\n            (\n                ""Dutta is the recipient of Femina Miss India Universe title in 2004."",\n                datetime(2004, today.month, today.day),\n                ""month"",\n            ),\n            (\n                \'she said that she hit depression after being traumatized on the sets of ""Horn OK"" in 2008.\',\n                datetime(2008, today.month, today.day),\n                ""month"",\n            ),\n            # https://github.com/akoumjian/datefinder/issues/63\n            (""12th day of December, 2001"", datetime(2001, 12, 12), ""month""),\n            (""01/02/03"", datetime(2003, 1, 2, 0, 0, 0, 0), ""month""),\n            (""01/02/03"", datetime(2003, 2, 1, 0, 0, 0, 0), ""day""),\n            (""01/02/03"", datetime(2001, 2, 3, 0, 0, 0, 0), ""year""),\n            (""02/05/2020"", datetime(2020, 2, 5, 0, 0, 0, 0), ""month""),\n            (""02/05/2020"", datetime(2020, 5, 2, 0, 0, 0, 0), ""day""),\n        ],\n    )\n    def test_find_date_strings(input_text, expected_date, first):\n        if isinstance(expected_date, list):\n            matches = list(datefinder.find_dates(input_text, first=first))\n            assert matches == expected_date\n        else:\n            return_date = None\n            for return_date in datefinder.find_dates(input_text, first=first):\n                assert return_date == expected_date\n>           assert return_date is not None, \'Did not find date for test line: ""{}""\'.format(\n                input_text\n            )  # handles dates that were never matched\nE           AssertionError: Did not find date for test line: ""12th day of December, 2001""\nE           assert None is not None\n\nrepos\\datefinder\\tests\\test_find_dates.py:124: AssertionError', 'input_text = \'19th day of May, 2015\'\nexpected_date = datetime.datetime(2015, 5, 19, 0, 0)\n\n    @pytest.mark.parametrize(\'input_text, expected_date\', [\n    \n        (\'June 2018\', []),\n        (\'09/06/18\',  datetime(2018, 9, 6)),\n        (\'09/06/2018\', datetime(2018, 9, 6)),\n        (\'recorded: 03/14/2008\', datetime(2008, 3, 14)),\n        (\'19th day of May, 2015\', datetime(2015, 5, 19)),\n        (\'19th day of May\', [])\n    \n    ])\n    def test_find_date_strings_strict(input_text, expected_date):\n        if isinstance(expected_date,list):\n            matches = list(datefinder.find_dates(input_text, strict=True))\n            assert matches == expected_date\n    \n        else:\n            return_date = None\n            for return_date in datefinder.find_dates(input_text, strict=True):\n                assert return_date == expected_date\n>           assert return_date is not None, \'Did not find date for test line: ""{}""\'.format(input_text) # handles dates\nE           AssertionError: Did not find date for test line: ""19th day of May, 2015""\nE           assert None is not None\n\nrepos\\datefinder\\tests\\test_find_dates_strict.py:32: AssertionError']",datefinder/_find_and_replace,LLM
datefinder,extract_date_strings_inner,"def extract_date_strings_inner(self, text, text_start=0, strict=False):
    """"""
        Extends extract_date_strings by text_start parameter: used in recursive calls to
        store true text coordinates in output
        """"""
    rng = self.split_date_range(text)
    if rng and len(rng) > 1:
        range_strings = []
        for range_str in rng:
            range_strings.extend(self.extract_date_strings_inner(range_str[0], text_start=range_str[1][0], strict=strict))
        for range_string in range_strings:
            yield range_string
        return
    tokens = self.tokenize_string(text)
    items = self.merge_tokens(tokens)
    for match in items:
        match_str = match.match_str
        indices = (match.indices[0] + text_start, match.indices[1] + text_start)
        captures = match.captures
        digits = captures.get('digits')
        months = captures.get('months')
        years = captures.get('years')
        if strict:
            complete = False
            if len(digits) == 3:
                complete = True
            elif len(months) == 1 and len(digits) == 2:
                complete = True
            elif len(years) == 1 and len(digits) == 2:
                complete = True
            elif len(years) == 1 and len(months) == 1 and (len(digits) == 1):
                complete = True
            if not complete:
                continue
        match_str = re.sub('[\\n\\t\\s\\xa0]+', ' ', match_str)
        match_str = match_str.strip(STRIP_CHARS)
        yield (match_str, indices, captures)","The goal of the `extract_date_strings_inner` function is to extract date strings from a given text, taking into account the starting position of the text within a larger context. The function tokenizes the text, merges tokens, and then identifies date components such as digits, months, and years. It also has an option for strict processing where it checks for complete date formats before yielding the extracted date strings along with their indices and captured components.

This function is likely part of a larger class that handles text processing tasks related to date extraction. It interacts with other methods or attributes within the class to tokenize the text, merge tokens, and apply regex patterns to extract date components. The function may be called recursively in cases where the text contains date ranges or nested structures.",2,"def extract_date_strings_inner(self, text, text_start, strict):
    date_strings = []
    # Tokenize text
    tokens = text.split()
    merged_tokens = ' '.join(tokens)
    
    # Identify date components
    # Logic to extract date components goes here
    
    # Check for complete date formats if strict mode is enabled
    
    # Append extracted date strings to the list
    
    return date_strings","['./repos/datefinder\\tests', './repos/datefinder\\tests\\test_add_tzinfo.py::test_add_tzinfo', './repos/datefinder\\tests\\test_extract_date_strings.py::test_extract_date_strings', './repos/datefinder\\tests\\test_extract_date_strings.py::test_extract_date_strings_with_strict_option', './repos/datefinder\\tests\\test_find_and_replace.py::test_find_and_replace', './repos/datefinder\\tests\\test_find_dates.py::test_find_date_strings', './repos/datefinder\\tests\\test_find_dates_strict.py::test_find_date_strings_strict', './repos/datefinder\\tests\\test_simple.py::test_success', './repos/datefinder\\tests\\test_tz_gettz.py::test_tz_gettz_for_all_patterns']","20 Passed, 34 Failed",20,34,"['tests/test_find_dates.py::test_find_date_strings[Tuesday Jul 22, 2014-expected_date0-month]', 'tests/test_find_dates.py::test_find_date_strings[December 13, 2014 at midnight-expected_date1-month]', 'tests/test_find_dates.py::test_find_date_strings[April 9, 2013 at 6:11 a.m.-expected_date2-month]', 'tests/test_find_dates.py::test_find_date_strings[Aug. 9, 2012 at 2:57 p.m.-expected_date3-month]', 'tests/test_find_dates.py::test_find_date_strings[December 10, 2014, 11:02:21 pm-expected_date4-month]', 'tests/test_find_dates.py::test_find_date_strings[8:25 a.m. Dec. 12, 2014-expected_date5-month]', 'tests/test_find_dates.py::test_find_date_strings[2:21 p.m., December 11, 2014-expected_date6-month]', 'tests/test_find_dates.py::test_find_date_strings[Fri, 12 Dec 2014 10:55:50-expected_date7-month]', 'tests/test_find_dates.py::test_find_date_strings[10:06am Dec 11, 2014-expected_date8-month]', 'tests/test_find_dates.py::test_find_date_strings[September 2nd, 1998-expected_date9-month]', 'tests/test_find_dates.py::test_find_date_strings[May 5, 2010 to July 10, 2011-expected_date10-month]', 'tests/test_find_dates.py::test_find_date_strings[06-17-2014-expected_date11-month]', 'tests/test_find_dates.py::test_find_date_strings[13/03/2014-expected_date12-month]', 'tests/test_find_dates.py::test_find_date_strings[2016-02-04T20:16:26+00:00-expected_date13-month]', 'tests/test_find_dates.py::test_find_date_strings[2017-02-03T09:04:08Z to 2017-02-03T09:04:09Z-expected_date14-month]', 'tests/test_find_dates.py::test_find_date_strings[i am looking for a date june 4th 1996 to july 3rd 2013-expected_date15-month]', 'tests/test_find_dates.py::test_find_date_strings[october 27 1994 to be put into effect on june 1 1995-expected_date16-month]', 'tests/test_find_dates.py::test_find_date_strings[31/08/2012 to 30/08/2013-expected_date17-month]', 'tests/test_find_dates.py::test_find_date_strings[31 Oct 2021 - 28 Nov 2021-expected_date18-day]', 'tests/test_find_dates.py::test_find_date_strings[2017-02-03T09:04:08.001Z-expected_date19-month]', 'tests/test_find_dates.py::test_find_date_strings[2017-02-03T09:04:08,00123Z-expected_date20-month]', 'tests/test_find_dates.py::test_find_date_strings[2017-02-03T09:04:08Z-expected_date21-month]', 'tests/test_find_dates.py::test_find_date_strings[Dutta is the recipient of Femina Miss India Universe title in 2004.-expected_date22-month]', 'tests/test_find_dates.py::test_find_date_strings[she said that she hit depression after being traumatized on the sets of ""Horn OK"" in 2008.-expected_date23-month]', 'tests/test_find_dates.py::test_find_date_strings[12th day of December, 2001-expected_date24-month]', 'tests/test_find_dates.py::test_find_date_strings[01/02/03-expected_date25-month]', 'tests/test_find_dates.py::test_find_date_strings[01/02/03-expected_date26-day]', 'tests/test_find_dates.py::test_find_date_strings[01/02/03-expected_date27-year]', 'tests/test_find_dates.py::test_find_date_strings[02/05/2020-expected_date28-month]', 'tests/test_find_dates.py::test_find_date_strings[02/05/2020-expected_date29-day]', 'tests/test_find_dates_strict.py::test_find_date_strings_strict[09/06/18-expected_date1]', 'tests/test_find_dates_strict.py::test_find_date_strings_strict[09/06/2018-expected_date2]', 'tests/test_find_dates_strict.py::test_find_date_strings_strict[recorded: 03/14/2008-expected_date3]', 'tests/test_find_dates_strict.py::test_find_date_strings_strict[19th day of May, 2015-expected_date4]']","['input_text = \'Tuesday Jul 22, 2014\'\nexpected_date = datetime.datetime(2014, 7, 22, 0, 0), first = \'month\'\n\n    @pytest.mark.parametrize(\n        (""input_text"", ""expected_date"", ""first""),\n        [\n            ## English Dates\n            # (\'[Sept] 04, 2014.\', datetime(2014, 9, 4), ""month""),\n            (""Tuesday Jul 22, 2014"", datetime(2014, 7, 22), ""month""),\n            # (\'10:04am EDT\', datetime(2012, 11, 13, 14, 4), ""month""),\n            # (\'Friday\', datetime(2012, 11, 9), ""month""),\n            # (\'November 19, 2014 at noon\', datetime(2014, 11, 19, 12, 0), ""month""),\n            (""December 13, 2014 at midnight"", datetime(2014, 12, 13, 0, 0), ""month""),\n            # (\'Nov 25 2014 10:17 pm EST\', datetime(2014, 11, 26, 3, 17), ""month""),\n            # (\'Wed Aug 05 12:00:00 EDT 2015\', datetime(2015, 8, 5, 16, 0), ""month""),\n            (""April 9, 2013 at 6:11 a.m."", datetime(2013, 4, 9, 6, 11), ""month""),\n            (""Aug. 9, 2012 at 2:57 p.m."", datetime(2012, 8, 9, 14, 57), ""month""),\n            (""December 10, 2014, 11:02:21 pm"", datetime(2014, 12, 10, 23, 2, 21), ""month""),\n            (""8:25 a.m. Dec. 12, 2014"", datetime(2014, 12, 12, 8, 25), ""month""),\n            (""2:21 p.m., December 11, 2014"", datetime(2014, 12, 11, 14, 21), ""month""),\n            (""Fri, 12 Dec 2014 10:55:50"", datetime(2014, 12, 12, 10, 55, 50), ""month""),\n            # (\'20 Mar 2013 10h11\', datetime(2013, 3, 20, 10, 11), ""month""),\n            (""10:06am Dec 11, 2014"", datetime(2014, 12, 11, 10, 6), ""month""),\n            (""September 2nd, 1998"", datetime(1998, 9, 2), ""month""),\n            (\n                ""May 5, 2010 to July 10, 2011"",\n                [datetime(2010, 5, 5), datetime(2011, 7, 10)],\n                ""month"",\n            ),\n            # (\'19 February 2013 year 09:10\', datetime(2013, 2, 19, 9, 10), ""month""),\n            # Numeric dates\n            (""06-17-2014"", datetime(2014, 6, 17), ""month""),\n            (""13/03/2014"", datetime(2014, 3, 13), ""month""),\n            (\n                ""2016-02-04T20:16:26+00:00"",\n                datetime(2016, 2, 4, 20, 16, 26, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            # (\'11. 12. 2014, 08:45:39\', datetime(2014, 11, 12, 8, 45, 39)),\n            (\n                ""2017-02-03T09:04:08Z to 2017-02-03T09:04:09Z"",\n                [\n                    datetime(2017, 2, 3, 9, 4, 8, tzinfo=pytz.utc),\n                    datetime(2017, 2, 3, 9, 4, 9, tzinfo=pytz.utc),\n                ],\n                ""month"",\n            ),\n            # dates from issue https://github.com/akoumjian/datefinder/issues/14\n            (\n                ""i am looking for a date june 4th 1996 to july 3rd 2013"",\n                [datetime(1996, 6, 4), datetime(2013, 7, 3)],\n                ""month"",\n            ),\n            (\n                ""october 27 1994 to be put into effect on june 1 1995"",\n                [datetime(1994, 10, 27), datetime(1995, 6, 1)],\n                ""month"",\n            ),\n            # Simple date range\n            (\n                ""31/08/2012 to 30/08/2013"",\n                [datetime(2012, 8, 31), datetime(2013, 8, 30)],\n                ""month"",\n            ),\n            (\n                ""31 Oct 2021 - 28 Nov 2021"",\n                [datetime(2021, 10, 31), datetime(2021, 11, 28)],\n                ""day""\n            ),\n            # Z dates with and without millis, from https://github.com/akoumjian/datefinder/issues/37\n            (\n                ""2017-02-03T09:04:08.001Z"",\n                datetime(2017, 2, 3, 9, 4, 8, 1000, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            (\n                ""2017-02-03T09:04:08,00123Z"",\n                datetime(2017, 2, 3, 9, 4, 8, 1230, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            (\n                ""2017-02-03T09:04:08Z"",\n                datetime(2017, 2, 3, 9, 4, 8, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            # Year only strings, from https://github.com/akoumjian/datefinder/issues/96\n            (\n                ""Dutta is the recipient of Femina Miss India Universe title in 2004."",\n                datetime(2004, today.month, today.day),\n                ""month"",\n            ),\n            (\n                \'she said that she hit depression after being traumatized on the sets of ""Horn OK"" in 2008.\',\n                datetime(2008, today.month, today.day),\n                ""month"",\n            ),\n            # https://github.com/akoumjian/datefinder/issues/63\n            (""12th day of December, 2001"", datetime(2001, 12, 12), ""month""),\n            (""01/02/03"", datetime(2003, 1, 2, 0, 0, 0, 0), ""month""),\n            (""01/02/03"", datetime(2003, 2, 1, 0, 0, 0, 0), ""day""),\n            (""01/02/03"", datetime(2001, 2, 3, 0, 0, 0, 0), ""year""),\n            (""02/05/2020"", datetime(2020, 2, 5, 0, 0, 0, 0), ""month""),\n            (""02/05/2020"", datetime(2020, 5, 2, 0, 0, 0, 0), ""day""),\n        ],\n    )\n    def test_find_date_strings(input_text, expected_date, first):\n        if isinstance(expected_date, list):\n            matches = list(datefinder.find_dates(input_text, first=first))\n            assert matches == expected_date\n        else:\n            return_date = None\n            for return_date in datefinder.find_dates(input_text, first=first):\n                assert return_date == expected_date\n>           assert return_date is not None, \'Did not find date for test line: ""{}""\'.format(\n                input_text\n            )  # handles dates that were never matched\nE           AssertionError: Did not find date for test line: ""Tuesday Jul 22, 2014""\nE           assert None is not None\n\nrepos\\datefinder\\tests\\test_find_dates.py:124: AssertionError', 'input_text = \'December 13, 2014 at midnight\'\nexpected_date = datetime.datetime(2014, 12, 13, 0, 0), first = \'month\'\n\n    @pytest.mark.parametrize(\n        (""input_text"", ""expected_date"", ""first""),\n        [\n            ## English Dates\n            # (\'[Sept] 04, 2014.\', datetime(2014, 9, 4), ""month""),\n            (""Tuesday Jul 22, 2014"", datetime(2014, 7, 22), ""month""),\n            # (\'10:04am EDT\', datetime(2012, 11, 13, 14, 4), ""month""),\n            # (\'Friday\', datetime(2012, 11, 9), ""month""),\n            # (\'November 19, 2014 at noon\', datetime(2014, 11, 19, 12, 0), ""month""),\n            (""December 13, 2014 at midnight"", datetime(2014, 12, 13, 0, 0), ""month""),\n            # (\'Nov 25 2014 10:17 pm EST\', datetime(2014, 11, 26, 3, 17), ""month""),\n            # (\'Wed Aug 05 12:00:00 EDT 2015\', datetime(2015, 8, 5, 16, 0), ""month""),\n            (""April 9, 2013 at 6:11 a.m."", datetime(2013, 4, 9, 6, 11), ""month""),\n            (""Aug. 9, 2012 at 2:57 p.m."", datetime(2012, 8, 9, 14, 57), ""month""),\n            (""December 10, 2014, 11:02:21 pm"", datetime(2014, 12, 10, 23, 2, 21), ""month""),\n            (""8:25 a.m. Dec. 12, 2014"", datetime(2014, 12, 12, 8, 25), ""month""),\n            (""2:21 p.m., December 11, 2014"", datetime(2014, 12, 11, 14, 21), ""month""),\n            (""Fri, 12 Dec 2014 10:55:50"", datetime(2014, 12, 12, 10, 55, 50), ""month""),\n            # (\'20 Mar 2013 10h11\', datetime(2013, 3, 20, 10, 11), ""month""),\n            (""10:06am Dec 11, 2014"", datetime(2014, 12, 11, 10, 6), ""month""),\n            (""September 2nd, 1998"", datetime(1998, 9, 2), ""month""),\n            (\n                ""May 5, 2010 to July 10, 2011"",\n                [datetime(2010, 5, 5), datetime(2011, 7, 10)],\n                ""month"",\n            ),\n            # (\'19 February 2013 year 09:10\', datetime(2013, 2, 19, 9, 10), ""month""),\n            # Numeric dates\n            (""06-17-2014"", datetime(2014, 6, 17), ""month""),\n            (""13/03/2014"", datetime(2014, 3, 13), ""month""),\n            (\n                ""2016-02-04T20:16:26+00:00"",\n                datetime(2016, 2, 4, 20, 16, 26, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            # (\'11. 12. 2014, 08:45:39\', datetime(2014, 11, 12, 8, 45, 39)),\n            (\n                ""2017-02-03T09:04:08Z to 2017-02-03T09:04:09Z"",\n                [\n                    datetime(2017, 2, 3, 9, 4, 8, tzinfo=pytz.utc),\n                    datetime(2017, 2, 3, 9, 4, 9, tzinfo=pytz.utc),\n                ],\n                ""month"",\n            ),\n            # dates from issue https://github.com/akoumjian/datefinder/issues/14\n            (\n                ""i am looking for a date june 4th 1996 to july 3rd 2013"",\n                [datetime(1996, 6, 4), datetime(2013, 7, 3)],\n                ""month"",\n            ),\n            (\n                ""october 27 1994 to be put into effect on june 1 1995"",\n                [datetime(1994, 10, 27), datetime(1995, 6, 1)],\n                ""month"",\n            ),\n            # Simple date range\n            (\n                ""31/08/2012 to 30/08/2013"",\n                [datetime(2012, 8, 31), datetime(2013, 8, 30)],\n                ""month"",\n            ),\n            (\n                ""31 Oct 2021 - 28 Nov 2021"",\n                [datetime(2021, 10, 31), datetime(2021, 11, 28)],\n                ""day""\n            ),\n            # Z dates with and without millis, from https://github.com/akoumjian/datefinder/issues/37\n            (\n                ""2017-02-03T09:04:08.001Z"",\n                datetime(2017, 2, 3, 9, 4, 8, 1000, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            (\n                ""2017-02-03T09:04:08,00123Z"",\n                datetime(2017, 2, 3, 9, 4, 8, 1230, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            (\n                ""2017-02-03T09:04:08Z"",\n                datetime(2017, 2, 3, 9, 4, 8, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            # Year only strings, from https://github.com/akoumjian/datefinder/issues/96\n            (\n                ""Dutta is the recipient of Femina Miss India Universe title in 2004."",\n                datetime(2004, today.month, today.day),\n                ""month"",\n            ),\n            (\n                \'she said that she hit depression after being traumatized on the sets of ""Horn OK"" in 2008.\',\n                datetime(2008, today.month, today.day),\n                ""month"",\n            ),\n            # https://github.com/akoumjian/datefinder/issues/63\n            (""12th day of December, 2001"", datetime(2001, 12, 12), ""month""),\n            (""01/02/03"", datetime(2003, 1, 2, 0, 0, 0, 0), ""month""),\n            (""01/02/03"", datetime(2003, 2, 1, 0, 0, 0, 0), ""day""),\n            (""01/02/03"", datetime(2001, 2, 3, 0, 0, 0, 0), ""year""),\n            (""02/05/2020"", datetime(2020, 2, 5, 0, 0, 0, 0), ""month""),\n            (""02/05/2020"", datetime(2020, 5, 2, 0, 0, 0, 0), ""day""),\n        ],\n    )\n    def test_find_date_strings(input_text, expected_date, first):\n        if isinstance(expected_date, list):\n            matches = list(datefinder.find_dates(input_text, first=first))\n            assert matches == expected_date\n        else:\n            return_date = None\n            for return_date in datefinder.find_dates(input_text, first=first):\n                assert return_date == expected_date\n>           assert return_date is not None, \'Did not find date for test line: ""{}""\'.format(\n                input_text\n            )  # handles dates that were never matched\nE           AssertionError: Did not find date for test line: ""December 13, 2014 at midnight""\nE           assert None is not None\n\nrepos\\datefinder\\tests\\test_find_dates.py:124: AssertionError', 'input_text = \'April 9, 2013 at 6:11 a.m.\'\nexpected_date = datetime.datetime(2013, 4, 9, 6, 11), first = \'month\'\n\n    @pytest.mark.parametrize(\n        (""input_text"", ""expected_date"", ""first""),\n        [\n            ## English Dates\n            # (\'[Sept] 04, 2014.\', datetime(2014, 9, 4), ""month""),\n            (""Tuesday Jul 22, 2014"", datetime(2014, 7, 22), ""month""),\n            # (\'10:04am EDT\', datetime(2012, 11, 13, 14, 4), ""month""),\n            # (\'Friday\', datetime(2012, 11, 9), ""month""),\n            # (\'November 19, 2014 at noon\', datetime(2014, 11, 19, 12, 0), ""month""),\n            (""December 13, 2014 at midnight"", datetime(2014, 12, 13, 0, 0), ""month""),\n            # (\'Nov 25 2014 10:17 pm EST\', datetime(2014, 11, 26, 3, 17), ""month""),\n            # (\'Wed Aug 05 12:00:00 EDT 2015\', datetime(2015, 8, 5, 16, 0), ""month""),\n            (""April 9, 2013 at 6:11 a.m."", datetime(2013, 4, 9, 6, 11), ""month""),\n            (""Aug. 9, 2012 at 2:57 p.m."", datetime(2012, 8, 9, 14, 57), ""month""),\n            (""December 10, 2014, 11:02:21 pm"", datetime(2014, 12, 10, 23, 2, 21), ""month""),\n            (""8:25 a.m. Dec. 12, 2014"", datetime(2014, 12, 12, 8, 25), ""month""),\n            (""2:21 p.m., December 11, 2014"", datetime(2014, 12, 11, 14, 21), ""month""),\n            (""Fri, 12 Dec 2014 10:55:50"", datetime(2014, 12, 12, 10, 55, 50), ""month""),\n            # (\'20 Mar 2013 10h11\', datetime(2013, 3, 20, 10, 11), ""month""),\n            (""10:06am Dec 11, 2014"", datetime(2014, 12, 11, 10, 6), ""month""),\n            (""September 2nd, 1998"", datetime(1998, 9, 2), ""month""),\n            (\n                ""May 5, 2010 to July 10, 2011"",\n                [datetime(2010, 5, 5), datetime(2011, 7, 10)],\n                ""month"",\n            ),\n            # (\'19 February 2013 year 09:10\', datetime(2013, 2, 19, 9, 10), ""month""),\n            # Numeric dates\n            (""06-17-2014"", datetime(2014, 6, 17), ""month""),\n            (""13/03/2014"", datetime(2014, 3, 13), ""month""),\n            (\n                ""2016-02-04T20:16:26+00:00"",\n                datetime(2016, 2, 4, 20, 16, 26, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            # (\'11. 12. 2014, 08:45:39\', datetime(2014, 11, 12, 8, 45, 39)),\n            (\n                ""2017-02-03T09:04:08Z to 2017-02-03T09:04:09Z"",\n                [\n                    datetime(2017, 2, 3, 9, 4, 8, tzinfo=pytz.utc),\n                    datetime(2017, 2, 3, 9, 4, 9, tzinfo=pytz.utc),\n                ],\n                ""month"",\n            ),\n            # dates from issue https://github.com/akoumjian/datefinder/issues/14\n            (\n                ""i am looking for a date june 4th 1996 to july 3rd 2013"",\n                [datetime(1996, 6, 4), datetime(2013, 7, 3)],\n                ""month"",\n            ),\n            (\n                ""october 27 1994 to be put into effect on june 1 1995"",\n                [datetime(1994, 10, 27), datetime(1995, 6, 1)],\n                ""month"",\n            ),\n            # Simple date range\n            (\n                ""31/08/2012 to 30/08/2013"",\n                [datetime(2012, 8, 31), datetime(2013, 8, 30)],\n                ""month"",\n            ),\n            (\n                ""31 Oct 2021 - 28 Nov 2021"",\n                [datetime(2021, 10, 31), datetime(2021, 11, 28)],\n                ""day""\n            ),\n            # Z dates with and without millis, from https://github.com/akoumjian/datefinder/issues/37\n            (\n                ""2017-02-03T09:04:08.001Z"",\n                datetime(2017, 2, 3, 9, 4, 8, 1000, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            (\n                ""2017-02-03T09:04:08,00123Z"",\n                datetime(2017, 2, 3, 9, 4, 8, 1230, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            (\n                ""2017-02-03T09:04:08Z"",\n                datetime(2017, 2, 3, 9, 4, 8, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            # Year only strings, from https://github.com/akoumjian/datefinder/issues/96\n            (\n                ""Dutta is the recipient of Femina Miss India Universe title in 2004."",\n                datetime(2004, today.month, today.day),\n                ""month"",\n            ),\n            (\n                \'she said that she hit depression after being traumatized on the sets of ""Horn OK"" in 2008.\',\n                datetime(2008, today.month, today.day),\n                ""month"",\n            ),\n            # https://github.com/akoumjian/datefinder/issues/63\n            (""12th day of December, 2001"", datetime(2001, 12, 12), ""month""),\n            (""01/02/03"", datetime(2003, 1, 2, 0, 0, 0, 0), ""month""),\n            (""01/02/03"", datetime(2003, 2, 1, 0, 0, 0, 0), ""day""),\n            (""01/02/03"", datetime(2001, 2, 3, 0, 0, 0, 0), ""year""),\n            (""02/05/2020"", datetime(2020, 2, 5, 0, 0, 0, 0), ""month""),\n            (""02/05/2020"", datetime(2020, 5, 2, 0, 0, 0, 0), ""day""),\n        ],\n    )\n    def test_find_date_strings(input_text, expected_date, first):\n        if isinstance(expected_date, list):\n            matches = list(datefinder.find_dates(input_text, first=first))\n            assert matches == expected_date\n        else:\n            return_date = None\n            for return_date in datefinder.find_dates(input_text, first=first):\n                assert return_date == expected_date\n>           assert return_date is not None, \'Did not find date for test line: ""{}""\'.format(\n                input_text\n            )  # handles dates that were never matched\nE           AssertionError: Did not find date for test line: ""April 9, 2013 at 6:11 a.m.""\nE           assert None is not None\n\nrepos\\datefinder\\tests\\test_find_dates.py:124: AssertionError', 'input_text = \'Aug. 9, 2012 at 2:57 p.m.\'\nexpected_date = datetime.datetime(2012, 8, 9, 14, 57), first = \'month\'\n\n    @pytest.mark.parametrize(\n        (""input_text"", ""expected_date"", ""first""),\n        [\n            ## English Dates\n            # (\'[Sept] 04, 2014.\', datetime(2014, 9, 4), ""month""),\n            (""Tuesday Jul 22, 2014"", datetime(2014, 7, 22), ""month""),\n            # (\'10:04am EDT\', datetime(2012, 11, 13, 14, 4), ""month""),\n            # (\'Friday\', datetime(2012, 11, 9), ""month""),\n            # (\'November 19, 2014 at noon\', datetime(2014, 11, 19, 12, 0), ""month""),\n            (""December 13, 2014 at midnight"", datetime(2014, 12, 13, 0, 0), ""month""),\n            # (\'Nov 25 2014 10:17 pm EST\', datetime(2014, 11, 26, 3, 17), ""month""),\n            # (\'Wed Aug 05 12:00:00 EDT 2015\', datetime(2015, 8, 5, 16, 0), ""month""),\n            (""April 9, 2013 at 6:11 a.m."", datetime(2013, 4, 9, 6, 11), ""month""),\n            (""Aug. 9, 2012 at 2:57 p.m."", datetime(2012, 8, 9, 14, 57), ""month""),\n            (""December 10, 2014, 11:02:21 pm"", datetime(2014, 12, 10, 23, 2, 21), ""month""),\n            (""8:25 a.m. Dec. 12, 2014"", datetime(2014, 12, 12, 8, 25), ""month""),\n            (""2:21 p.m., December 11, 2014"", datetime(2014, 12, 11, 14, 21), ""month""),\n            (""Fri, 12 Dec 2014 10:55:50"", datetime(2014, 12, 12, 10, 55, 50), ""month""),\n            # (\'20 Mar 2013 10h11\', datetime(2013, 3, 20, 10, 11), ""month""),\n            (""10:06am Dec 11, 2014"", datetime(2014, 12, 11, 10, 6), ""month""),\n            (""September 2nd, 1998"", datetime(1998, 9, 2), ""month""),\n            (\n                ""May 5, 2010 to July 10, 2011"",\n                [datetime(2010, 5, 5), datetime(2011, 7, 10)],\n                ""month"",\n            ),\n            # (\'19 February 2013 year 09:10\', datetime(2013, 2, 19, 9, 10), ""month""),\n            # Numeric dates\n            (""06-17-2014"", datetime(2014, 6, 17), ""month""),\n            (""13/03/2014"", datetime(2014, 3, 13), ""month""),\n            (\n                ""2016-02-04T20:16:26+00:00"",\n                datetime(2016, 2, 4, 20, 16, 26, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            # (\'11. 12. 2014, 08:45:39\', datetime(2014, 11, 12, 8, 45, 39)),\n            (\n                ""2017-02-03T09:04:08Z to 2017-02-03T09:04:09Z"",\n                [\n                    datetime(2017, 2, 3, 9, 4, 8, tzinfo=pytz.utc),\n                    datetime(2017, 2, 3, 9, 4, 9, tzinfo=pytz.utc),\n                ],\n                ""month"",\n            ),\n            # dates from issue https://github.com/akoumjian/datefinder/issues/14\n            (\n                ""i am looking for a date june 4th 1996 to july 3rd 2013"",\n                [datetime(1996, 6, 4), datetime(2013, 7, 3)],\n                ""month"",\n            ),\n            (\n                ""october 27 1994 to be put into effect on june 1 1995"",\n                [datetime(1994, 10, 27), datetime(1995, 6, 1)],\n                ""month"",\n            ),\n            # Simple date range\n            (\n                ""31/08/2012 to 30/08/2013"",\n                [datetime(2012, 8, 31), datetime(2013, 8, 30)],\n                ""month"",\n            ),\n            (\n                ""31 Oct 2021 - 28 Nov 2021"",\n                [datetime(2021, 10, 31), datetime(2021, 11, 28)],\n                ""day""\n            ),\n            # Z dates with and without millis, from https://github.com/akoumjian/datefinder/issues/37\n            (\n                ""2017-02-03T09:04:08.001Z"",\n                datetime(2017, 2, 3, 9, 4, 8, 1000, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            (\n                ""2017-02-03T09:04:08,00123Z"",\n                datetime(2017, 2, 3, 9, 4, 8, 1230, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            (\n                ""2017-02-03T09:04:08Z"",\n                datetime(2017, 2, 3, 9, 4, 8, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            # Year only strings, from https://github.com/akoumjian/datefinder/issues/96\n            (\n                ""Dutta is the recipient of Femina Miss India Universe title in 2004."",\n                datetime(2004, today.month, today.day),\n                ""month"",\n            ),\n            (\n                \'she said that she hit depression after being traumatized on the sets of ""Horn OK"" in 2008.\',\n                datetime(2008, today.month, today.day),\n                ""month"",\n            ),\n            # https://github.com/akoumjian/datefinder/issues/63\n            (""12th day of December, 2001"", datetime(2001, 12, 12), ""month""),\n            (""01/02/03"", datetime(2003, 1, 2, 0, 0, 0, 0), ""month""),\n            (""01/02/03"", datetime(2003, 2, 1, 0, 0, 0, 0), ""day""),\n            (""01/02/03"", datetime(2001, 2, 3, 0, 0, 0, 0), ""year""),\n            (""02/05/2020"", datetime(2020, 2, 5, 0, 0, 0, 0), ""month""),\n            (""02/05/2020"", datetime(2020, 5, 2, 0, 0, 0, 0), ""day""),\n        ],\n    )\n    def test_find_date_strings(input_text, expected_date, first):\n        if isinstance(expected_date, list):\n            matches = list(datefinder.find_dates(input_text, first=first))\n            assert matches == expected_date\n        else:\n            return_date = None\n            for return_date in datefinder.find_dates(input_text, first=first):\n                assert return_date == expected_date\n>           assert return_date is not None, \'Did not find date for test line: ""{}""\'.format(\n                input_text\n            )  # handles dates that were never matched\nE           AssertionError: Did not find date for test line: ""Aug. 9, 2012 at 2:57 p.m.""\nE           assert None is not None\n\nrepos\\datefinder\\tests\\test_find_dates.py:124: AssertionError', 'input_text = \'December 10, 2014, 11:02:21 pm\'\nexpected_date = datetime.datetime(2014, 12, 10, 23, 2, 21), first = \'month\'\n\n    @pytest.mark.parametrize(\n        (""input_text"", ""expected_date"", ""first""),\n        [\n            ## English Dates\n            # (\'[Sept] 04, 2014.\', datetime(2014, 9, 4), ""month""),\n            (""Tuesday Jul 22, 2014"", datetime(2014, 7, 22), ""month""),\n            # (\'10:04am EDT\', datetime(2012, 11, 13, 14, 4), ""month""),\n            # (\'Friday\', datetime(2012, 11, 9), ""month""),\n            # (\'November 19, 2014 at noon\', datetime(2014, 11, 19, 12, 0), ""month""),\n            (""December 13, 2014 at midnight"", datetime(2014, 12, 13, 0, 0), ""month""),\n            # (\'Nov 25 2014 10:17 pm EST\', datetime(2014, 11, 26, 3, 17), ""month""),\n            # (\'Wed Aug 05 12:00:00 EDT 2015\', datetime(2015, 8, 5, 16, 0), ""month""),\n            (""April 9, 2013 at 6:11 a.m."", datetime(2013, 4, 9, 6, 11), ""month""),\n            (""Aug. 9, 2012 at 2:57 p.m."", datetime(2012, 8, 9, 14, 57), ""month""),\n            (""December 10, 2014, 11:02:21 pm"", datetime(2014, 12, 10, 23, 2, 21), ""month""),\n            (""8:25 a.m. Dec. 12, 2014"", datetime(2014, 12, 12, 8, 25), ""month""),\n            (""2:21 p.m., December 11, 2014"", datetime(2014, 12, 11, 14, 21), ""month""),\n            (""Fri, 12 Dec 2014 10:55:50"", datetime(2014, 12, 12, 10, 55, 50), ""month""),\n            # (\'20 Mar 2013 10h11\', datetime(2013, 3, 20, 10, 11), ""month""),\n            (""10:06am Dec 11, 2014"", datetime(2014, 12, 11, 10, 6), ""month""),\n            (""September 2nd, 1998"", datetime(1998, 9, 2), ""month""),\n            (\n                ""May 5, 2010 to July 10, 2011"",\n                [datetime(2010, 5, 5), datetime(2011, 7, 10)],\n                ""month"",\n            ),\n            # (\'19 February 2013 year 09:10\', datetime(2013, 2, 19, 9, 10), ""month""),\n            # Numeric dates\n            (""06-17-2014"", datetime(2014, 6, 17), ""month""),\n            (""13/03/2014"", datetime(2014, 3, 13), ""month""),\n            (\n                ""2016-02-04T20:16:26+00:00"",\n                datetime(2016, 2, 4, 20, 16, 26, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            # (\'11. 12. 2014, 08:45:39\', datetime(2014, 11, 12, 8, 45, 39)),\n            (\n                ""2017-02-03T09:04:08Z to 2017-02-03T09:04:09Z"",\n                [\n                    datetime(2017, 2, 3, 9, 4, 8, tzinfo=pytz.utc),\n                    datetime(2017, 2, 3, 9, 4, 9, tzinfo=pytz.utc),\n                ],\n                ""month"",\n            ),\n            # dates from issue https://github.com/akoumjian/datefinder/issues/14\n            (\n                ""i am looking for a date june 4th 1996 to july 3rd 2013"",\n                [datetime(1996, 6, 4), datetime(2013, 7, 3)],\n                ""month"",\n            ),\n            (\n                ""october 27 1994 to be put into effect on june 1 1995"",\n                [datetime(1994, 10, 27), datetime(1995, 6, 1)],\n                ""month"",\n            ),\n            # Simple date range\n            (\n                ""31/08/2012 to 30/08/2013"",\n                [datetime(2012, 8, 31), datetime(2013, 8, 30)],\n                ""month"",\n            ),\n            (\n                ""31 Oct 2021 - 28 Nov 2021"",\n                [datetime(2021, 10, 31), datetime(2021, 11, 28)],\n                ""day""\n            ),\n            # Z dates with and without millis, from https://github.com/akoumjian/datefinder/issues/37\n            (\n                ""2017-02-03T09:04:08.001Z"",\n                datetime(2017, 2, 3, 9, 4, 8, 1000, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            (\n                ""2017-02-03T09:04:08,00123Z"",\n                datetime(2017, 2, 3, 9, 4, 8, 1230, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            (\n                ""2017-02-03T09:04:08Z"",\n                datetime(2017, 2, 3, 9, 4, 8, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            # Year only strings, from https://github.com/akoumjian/datefinder/issues/96\n            (\n                ""Dutta is the recipient of Femina Miss India Universe title in 2004."",\n                datetime(2004, today.month, today.day),\n                ""month"",\n            ),\n            (\n                \'she said that she hit depression after being traumatized on the sets of ""Horn OK"" in 2008.\',\n                datetime(2008, today.month, today.day),\n                ""month"",\n            ),\n            # https://github.com/akoumjian/datefinder/issues/63\n            (""12th day of December, 2001"", datetime(2001, 12, 12), ""month""),\n            (""01/02/03"", datetime(2003, 1, 2, 0, 0, 0, 0), ""month""),\n            (""01/02/03"", datetime(2003, 2, 1, 0, 0, 0, 0), ""day""),\n            (""01/02/03"", datetime(2001, 2, 3, 0, 0, 0, 0), ""year""),\n            (""02/05/2020"", datetime(2020, 2, 5, 0, 0, 0, 0), ""month""),\n            (""02/05/2020"", datetime(2020, 5, 2, 0, 0, 0, 0), ""day""),\n        ],\n    )\n    def test_find_date_strings(input_text, expected_date, first):\n        if isinstance(expected_date, list):\n            matches = list(datefinder.find_dates(input_text, first=first))\n            assert matches == expected_date\n        else:\n            return_date = None\n            for return_date in datefinder.find_dates(input_text, first=first):\n                assert return_date == expected_date\n>           assert return_date is not None, \'Did not find date for test line: ""{}""\'.format(\n                input_text\n            )  # handles dates that were never matched\nE           AssertionError: Did not find date for test line: ""December 10, 2014, 11:02:21 pm""\nE           assert None is not None\n\nrepos\\datefinder\\tests\\test_find_dates.py:124: AssertionError', 'input_text = \'8:25 a.m. Dec. 12, 2014\'\nexpected_date = datetime.datetime(2014, 12, 12, 8, 25), first = \'month\'\n\n    @pytest.mark.parametrize(\n        (""input_text"", ""expected_date"", ""first""),\n        [\n            ## English Dates\n            # (\'[Sept] 04, 2014.\', datetime(2014, 9, 4), ""month""),\n            (""Tuesday Jul 22, 2014"", datetime(2014, 7, 22), ""month""),\n            # (\'10:04am EDT\', datetime(2012, 11, 13, 14, 4), ""month""),\n            # (\'Friday\', datetime(2012, 11, 9), ""month""),\n            # (\'November 19, 2014 at noon\', datetime(2014, 11, 19, 12, 0), ""month""),\n            (""December 13, 2014 at midnight"", datetime(2014, 12, 13, 0, 0), ""month""),\n            # (\'Nov 25 2014 10:17 pm EST\', datetime(2014, 11, 26, 3, 17), ""month""),\n            # (\'Wed Aug 05 12:00:00 EDT 2015\', datetime(2015, 8, 5, 16, 0), ""month""),\n            (""April 9, 2013 at 6:11 a.m."", datetime(2013, 4, 9, 6, 11), ""month""),\n            (""Aug. 9, 2012 at 2:57 p.m."", datetime(2012, 8, 9, 14, 57), ""month""),\n            (""December 10, 2014, 11:02:21 pm"", datetime(2014, 12, 10, 23, 2, 21), ""month""),\n            (""8:25 a.m. Dec. 12, 2014"", datetime(2014, 12, 12, 8, 25), ""month""),\n            (""2:21 p.m., December 11, 2014"", datetime(2014, 12, 11, 14, 21), ""month""),\n            (""Fri, 12 Dec 2014 10:55:50"", datetime(2014, 12, 12, 10, 55, 50), ""month""),\n            # (\'20 Mar 2013 10h11\', datetime(2013, 3, 20, 10, 11), ""month""),\n            (""10:06am Dec 11, 2014"", datetime(2014, 12, 11, 10, 6), ""month""),\n            (""September 2nd, 1998"", datetime(1998, 9, 2), ""month""),\n            (\n                ""May 5, 2010 to July 10, 2011"",\n                [datetime(2010, 5, 5), datetime(2011, 7, 10)],\n                ""month"",\n            ),\n            # (\'19 February 2013 year 09:10\', datetime(2013, 2, 19, 9, 10), ""month""),\n            # Numeric dates\n            (""06-17-2014"", datetime(2014, 6, 17), ""month""),\n            (""13/03/2014"", datetime(2014, 3, 13), ""month""),\n            (\n                ""2016-02-04T20:16:26+00:00"",\n                datetime(2016, 2, 4, 20, 16, 26, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            # (\'11. 12. 2014, 08:45:39\', datetime(2014, 11, 12, 8, 45, 39)),\n            (\n                ""2017-02-03T09:04:08Z to 2017-02-03T09:04:09Z"",\n                [\n                    datetime(2017, 2, 3, 9, 4, 8, tzinfo=pytz.utc),\n                    datetime(2017, 2, 3, 9, 4, 9, tzinfo=pytz.utc),\n                ],\n                ""month"",\n            ),\n            # dates from issue https://github.com/akoumjian/datefinder/issues/14\n            (\n                ""i am looking for a date june 4th 1996 to july 3rd 2013"",\n                [datetime(1996, 6, 4), datetime(2013, 7, 3)],\n                ""month"",\n            ),\n            (\n                ""october 27 1994 to be put into effect on june 1 1995"",\n                [datetime(1994, 10, 27), datetime(1995, 6, 1)],\n                ""month"",\n            ),\n            # Simple date range\n            (\n                ""31/08/2012 to 30/08/2013"",\n                [datetime(2012, 8, 31), datetime(2013, 8, 30)],\n                ""month"",\n            ),\n            (\n                ""31 Oct 2021 - 28 Nov 2021"",\n                [datetime(2021, 10, 31), datetime(2021, 11, 28)],\n                ""day""\n            ),\n            # Z dates with and without millis, from https://github.com/akoumjian/datefinder/issues/37\n            (\n                ""2017-02-03T09:04:08.001Z"",\n                datetime(2017, 2, 3, 9, 4, 8, 1000, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            (\n                ""2017-02-03T09:04:08,00123Z"",\n                datetime(2017, 2, 3, 9, 4, 8, 1230, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            (\n                ""2017-02-03T09:04:08Z"",\n                datetime(2017, 2, 3, 9, 4, 8, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            # Year only strings, from https://github.com/akoumjian/datefinder/issues/96\n            (\n                ""Dutta is the recipient of Femina Miss India Universe title in 2004."",\n                datetime(2004, today.month, today.day),\n                ""month"",\n            ),\n            (\n                \'she said that she hit depression after being traumatized on the sets of ""Horn OK"" in 2008.\',\n                datetime(2008, today.month, today.day),\n                ""month"",\n            ),\n            # https://github.com/akoumjian/datefinder/issues/63\n            (""12th day of December, 2001"", datetime(2001, 12, 12), ""month""),\n            (""01/02/03"", datetime(2003, 1, 2, 0, 0, 0, 0), ""month""),\n            (""01/02/03"", datetime(2003, 2, 1, 0, 0, 0, 0), ""day""),\n            (""01/02/03"", datetime(2001, 2, 3, 0, 0, 0, 0), ""year""),\n            (""02/05/2020"", datetime(2020, 2, 5, 0, 0, 0, 0), ""month""),\n            (""02/05/2020"", datetime(2020, 5, 2, 0, 0, 0, 0), ""day""),\n        ],\n    )\n    def test_find_date_strings(input_text, expected_date, first):\n        if isinstance(expected_date, list):\n            matches = list(datefinder.find_dates(input_text, first=first))\n            assert matches == expected_date\n        else:\n            return_date = None\n            for return_date in datefinder.find_dates(input_text, first=first):\n                assert return_date == expected_date\n>           assert return_date is not None, \'Did not find date for test line: ""{}""\'.format(\n                input_text\n            )  # handles dates that were never matched\nE           AssertionError: Did not find date for test line: ""8:25 a.m. Dec. 12, 2014""\nE           assert None is not None\n\nrepos\\datefinder\\tests\\test_find_dates.py:124: AssertionError', 'input_text = \'2:21 p.m., December 11, 2014\'\nexpected_date = datetime.datetime(2014, 12, 11, 14, 21), first = \'month\'\n\n    @pytest.mark.parametrize(\n        (""input_text"", ""expected_date"", ""first""),\n        [\n            ## English Dates\n            # (\'[Sept] 04, 2014.\', datetime(2014, 9, 4), ""month""),\n            (""Tuesday Jul 22, 2014"", datetime(2014, 7, 22), ""month""),\n            # (\'10:04am EDT\', datetime(2012, 11, 13, 14, 4), ""month""),\n            # (\'Friday\', datetime(2012, 11, 9), ""month""),\n            # (\'November 19, 2014 at noon\', datetime(2014, 11, 19, 12, 0), ""month""),\n            (""December 13, 2014 at midnight"", datetime(2014, 12, 13, 0, 0), ""month""),\n            # (\'Nov 25 2014 10:17 pm EST\', datetime(2014, 11, 26, 3, 17), ""month""),\n            # (\'Wed Aug 05 12:00:00 EDT 2015\', datetime(2015, 8, 5, 16, 0), ""month""),\n            (""April 9, 2013 at 6:11 a.m."", datetime(2013, 4, 9, 6, 11), ""month""),\n            (""Aug. 9, 2012 at 2:57 p.m."", datetime(2012, 8, 9, 14, 57), ""month""),\n            (""December 10, 2014, 11:02:21 pm"", datetime(2014, 12, 10, 23, 2, 21), ""month""),\n            (""8:25 a.m. Dec. 12, 2014"", datetime(2014, 12, 12, 8, 25), ""month""),\n            (""2:21 p.m., December 11, 2014"", datetime(2014, 12, 11, 14, 21), ""month""),\n            (""Fri, 12 Dec 2014 10:55:50"", datetime(2014, 12, 12, 10, 55, 50), ""month""),\n            # (\'20 Mar 2013 10h11\', datetime(2013, 3, 20, 10, 11), ""month""),\n            (""10:06am Dec 11, 2014"", datetime(2014, 12, 11, 10, 6), ""month""),\n            (""September 2nd, 1998"", datetime(1998, 9, 2), ""month""),\n            (\n                ""May 5, 2010 to July 10, 2011"",\n                [datetime(2010, 5, 5), datetime(2011, 7, 10)],\n                ""month"",\n            ),\n            # (\'19 February 2013 year 09:10\', datetime(2013, 2, 19, 9, 10), ""month""),\n            # Numeric dates\n            (""06-17-2014"", datetime(2014, 6, 17), ""month""),\n            (""13/03/2014"", datetime(2014, 3, 13), ""month""),\n            (\n                ""2016-02-04T20:16:26+00:00"",\n                datetime(2016, 2, 4, 20, 16, 26, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            # (\'11. 12. 2014, 08:45:39\', datetime(2014, 11, 12, 8, 45, 39)),\n            (\n                ""2017-02-03T09:04:08Z to 2017-02-03T09:04:09Z"",\n                [\n                    datetime(2017, 2, 3, 9, 4, 8, tzinfo=pytz.utc),\n                    datetime(2017, 2, 3, 9, 4, 9, tzinfo=pytz.utc),\n                ],\n                ""month"",\n            ),\n            # dates from issue https://github.com/akoumjian/datefinder/issues/14\n            (\n                ""i am looking for a date june 4th 1996 to july 3rd 2013"",\n                [datetime(1996, 6, 4), datetime(2013, 7, 3)],\n                ""month"",\n            ),\n            (\n                ""october 27 1994 to be put into effect on june 1 1995"",\n                [datetime(1994, 10, 27), datetime(1995, 6, 1)],\n                ""month"",\n            ),\n            # Simple date range\n            (\n                ""31/08/2012 to 30/08/2013"",\n                [datetime(2012, 8, 31), datetime(2013, 8, 30)],\n                ""month"",\n            ),\n            (\n                ""31 Oct 2021 - 28 Nov 2021"",\n                [datetime(2021, 10, 31), datetime(2021, 11, 28)],\n                ""day""\n            ),\n            # Z dates with and without millis, from https://github.com/akoumjian/datefinder/issues/37\n            (\n                ""2017-02-03T09:04:08.001Z"",\n                datetime(2017, 2, 3, 9, 4, 8, 1000, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            (\n                ""2017-02-03T09:04:08,00123Z"",\n                datetime(2017, 2, 3, 9, 4, 8, 1230, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            (\n                ""2017-02-03T09:04:08Z"",\n                datetime(2017, 2, 3, 9, 4, 8, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            # Year only strings, from https://github.com/akoumjian/datefinder/issues/96\n            (\n                ""Dutta is the recipient of Femina Miss India Universe title in 2004."",\n                datetime(2004, today.month, today.day),\n                ""month"",\n            ),\n            (\n                \'she said that she hit depression after being traumatized on the sets of ""Horn OK"" in 2008.\',\n                datetime(2008, today.month, today.day),\n                ""month"",\n            ),\n            # https://github.com/akoumjian/datefinder/issues/63\n            (""12th day of December, 2001"", datetime(2001, 12, 12), ""month""),\n            (""01/02/03"", datetime(2003, 1, 2, 0, 0, 0, 0), ""month""),\n            (""01/02/03"", datetime(2003, 2, 1, 0, 0, 0, 0), ""day""),\n            (""01/02/03"", datetime(2001, 2, 3, 0, 0, 0, 0), ""year""),\n            (""02/05/2020"", datetime(2020, 2, 5, 0, 0, 0, 0), ""month""),\n            (""02/05/2020"", datetime(2020, 5, 2, 0, 0, 0, 0), ""day""),\n        ],\n    )\n    def test_find_date_strings(input_text, expected_date, first):\n        if isinstance(expected_date, list):\n            matches = list(datefinder.find_dates(input_text, first=first))\n            assert matches == expected_date\n        else:\n            return_date = None\n            for return_date in datefinder.find_dates(input_text, first=first):\n                assert return_date == expected_date\n>           assert return_date is not None, \'Did not find date for test line: ""{}""\'.format(\n                input_text\n            )  # handles dates that were never matched\nE           AssertionError: Did not find date for test line: ""2:21 p.m., December 11, 2014""\nE           assert None is not None\n\nrepos\\datefinder\\tests\\test_find_dates.py:124: AssertionError', 'input_text = \'Fri, 12 Dec 2014 10:55:50\'\nexpected_date = datetime.datetime(2014, 12, 12, 10, 55, 50), first = \'month\'\n\n    @pytest.mark.parametrize(\n        (""input_text"", ""expected_date"", ""first""),\n        [\n            ## English Dates\n            # (\'[Sept] 04, 2014.\', datetime(2014, 9, 4), ""month""),\n            (""Tuesday Jul 22, 2014"", datetime(2014, 7, 22), ""month""),\n            # (\'10:04am EDT\', datetime(2012, 11, 13, 14, 4), ""month""),\n            # (\'Friday\', datetime(2012, 11, 9), ""month""),\n            # (\'November 19, 2014 at noon\', datetime(2014, 11, 19, 12, 0), ""month""),\n            (""December 13, 2014 at midnight"", datetime(2014, 12, 13, 0, 0), ""month""),\n            # (\'Nov 25 2014 10:17 pm EST\', datetime(2014, 11, 26, 3, 17), ""month""),\n            # (\'Wed Aug 05 12:00:00 EDT 2015\', datetime(2015, 8, 5, 16, 0), ""month""),\n            (""April 9, 2013 at 6:11 a.m."", datetime(2013, 4, 9, 6, 11), ""month""),\n            (""Aug. 9, 2012 at 2:57 p.m."", datetime(2012, 8, 9, 14, 57), ""month""),\n            (""December 10, 2014, 11:02:21 pm"", datetime(2014, 12, 10, 23, 2, 21), ""month""),\n            (""8:25 a.m. Dec. 12, 2014"", datetime(2014, 12, 12, 8, 25), ""month""),\n            (""2:21 p.m., December 11, 2014"", datetime(2014, 12, 11, 14, 21), ""month""),\n            (""Fri, 12 Dec 2014 10:55:50"", datetime(2014, 12, 12, 10, 55, 50), ""month""),\n            # (\'20 Mar 2013 10h11\', datetime(2013, 3, 20, 10, 11), ""month""),\n            (""10:06am Dec 11, 2014"", datetime(2014, 12, 11, 10, 6), ""month""),\n            (""September 2nd, 1998"", datetime(1998, 9, 2), ""month""),\n            (\n                ""May 5, 2010 to July 10, 2011"",\n                [datetime(2010, 5, 5), datetime(2011, 7, 10)],\n                ""month"",\n            ),\n            # (\'19 February 2013 year 09:10\', datetime(2013, 2, 19, 9, 10), ""month""),\n            # Numeric dates\n            (""06-17-2014"", datetime(2014, 6, 17), ""month""),\n            (""13/03/2014"", datetime(2014, 3, 13), ""month""),\n            (\n                ""2016-02-04T20:16:26+00:00"",\n                datetime(2016, 2, 4, 20, 16, 26, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            # (\'11. 12. 2014, 08:45:39\', datetime(2014, 11, 12, 8, 45, 39)),\n            (\n                ""2017-02-03T09:04:08Z to 2017-02-03T09:04:09Z"",\n                [\n                    datetime(2017, 2, 3, 9, 4, 8, tzinfo=pytz.utc),\n                    datetime(2017, 2, 3, 9, 4, 9, tzinfo=pytz.utc),\n                ],\n                ""month"",\n            ),\n            # dates from issue https://github.com/akoumjian/datefinder/issues/14\n            (\n                ""i am looking for a date june 4th 1996 to july 3rd 2013"",\n                [datetime(1996, 6, 4), datetime(2013, 7, 3)],\n                ""month"",\n            ),\n            (\n                ""october 27 1994 to be put into effect on june 1 1995"",\n                [datetime(1994, 10, 27), datetime(1995, 6, 1)],\n                ""month"",\n            ),\n            # Simple date range\n            (\n                ""31/08/2012 to 30/08/2013"",\n                [datetime(2012, 8, 31), datetime(2013, 8, 30)],\n                ""month"",\n            ),\n            (\n                ""31 Oct 2021 - 28 Nov 2021"",\n                [datetime(2021, 10, 31), datetime(2021, 11, 28)],\n                ""day""\n            ),\n            # Z dates with and without millis, from https://github.com/akoumjian/datefinder/issues/37\n            (\n                ""2017-02-03T09:04:08.001Z"",\n                datetime(2017, 2, 3, 9, 4, 8, 1000, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            (\n                ""2017-02-03T09:04:08,00123Z"",\n                datetime(2017, 2, 3, 9, 4, 8, 1230, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            (\n                ""2017-02-03T09:04:08Z"",\n                datetime(2017, 2, 3, 9, 4, 8, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            # Year only strings, from https://github.com/akoumjian/datefinder/issues/96\n            (\n                ""Dutta is the recipient of Femina Miss India Universe title in 2004."",\n                datetime(2004, today.month, today.day),\n                ""month"",\n            ),\n            (\n                \'she said that she hit depression after being traumatized on the sets of ""Horn OK"" in 2008.\',\n                datetime(2008, today.month, today.day),\n                ""month"",\n            ),\n            # https://github.com/akoumjian/datefinder/issues/63\n            (""12th day of December, 2001"", datetime(2001, 12, 12), ""month""),\n            (""01/02/03"", datetime(2003, 1, 2, 0, 0, 0, 0), ""month""),\n            (""01/02/03"", datetime(2003, 2, 1, 0, 0, 0, 0), ""day""),\n            (""01/02/03"", datetime(2001, 2, 3, 0, 0, 0, 0), ""year""),\n            (""02/05/2020"", datetime(2020, 2, 5, 0, 0, 0, 0), ""month""),\n            (""02/05/2020"", datetime(2020, 5, 2, 0, 0, 0, 0), ""day""),\n        ],\n    )\n    def test_find_date_strings(input_text, expected_date, first):\n        if isinstance(expected_date, list):\n            matches = list(datefinder.find_dates(input_text, first=first))\n            assert matches == expected_date\n        else:\n            return_date = None\n            for return_date in datefinder.find_dates(input_text, first=first):\n                assert return_date == expected_date\n>           assert return_date is not None, \'Did not find date for test line: ""{}""\'.format(\n                input_text\n            )  # handles dates that were never matched\nE           AssertionError: Did not find date for test line: ""Fri, 12 Dec 2014 10:55:50""\nE           assert None is not None\n\nrepos\\datefinder\\tests\\test_find_dates.py:124: AssertionError', 'input_text = \'10:06am Dec 11, 2014\'\nexpected_date = datetime.datetime(2014, 12, 11, 10, 6), first = \'month\'\n\n    @pytest.mark.parametrize(\n        (""input_text"", ""expected_date"", ""first""),\n        [\n            ## English Dates\n            # (\'[Sept] 04, 2014.\', datetime(2014, 9, 4), ""month""),\n            (""Tuesday Jul 22, 2014"", datetime(2014, 7, 22), ""month""),\n            # (\'10:04am EDT\', datetime(2012, 11, 13, 14, 4), ""month""),\n            # (\'Friday\', datetime(2012, 11, 9), ""month""),\n            # (\'November 19, 2014 at noon\', datetime(2014, 11, 19, 12, 0), ""month""),\n            (""December 13, 2014 at midnight"", datetime(2014, 12, 13, 0, 0), ""month""),\n            # (\'Nov 25 2014 10:17 pm EST\', datetime(2014, 11, 26, 3, 17), ""month""),\n            # (\'Wed Aug 05 12:00:00 EDT 2015\', datetime(2015, 8, 5, 16, 0), ""month""),\n            (""April 9, 2013 at 6:11 a.m."", datetime(2013, 4, 9, 6, 11), ""month""),\n            (""Aug. 9, 2012 at 2:57 p.m."", datetime(2012, 8, 9, 14, 57), ""month""),\n            (""December 10, 2014, 11:02:21 pm"", datetime(2014, 12, 10, 23, 2, 21), ""month""),\n            (""8:25 a.m. Dec. 12, 2014"", datetime(2014, 12, 12, 8, 25), ""month""),\n            (""2:21 p.m., December 11, 2014"", datetime(2014, 12, 11, 14, 21), ""month""),\n            (""Fri, 12 Dec 2014 10:55:50"", datetime(2014, 12, 12, 10, 55, 50), ""month""),\n            # (\'20 Mar 2013 10h11\', datetime(2013, 3, 20, 10, 11), ""month""),\n            (""10:06am Dec 11, 2014"", datetime(2014, 12, 11, 10, 6), ""month""),\n            (""September 2nd, 1998"", datetime(1998, 9, 2), ""month""),\n            (\n                ""May 5, 2010 to July 10, 2011"",\n                [datetime(2010, 5, 5), datetime(2011, 7, 10)],\n                ""month"",\n            ),\n            # (\'19 February 2013 year 09:10\', datetime(2013, 2, 19, 9, 10), ""month""),\n            # Numeric dates\n            (""06-17-2014"", datetime(2014, 6, 17), ""month""),\n            (""13/03/2014"", datetime(2014, 3, 13), ""month""),\n            (\n                ""2016-02-04T20:16:26+00:00"",\n                datetime(2016, 2, 4, 20, 16, 26, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            # (\'11. 12. 2014, 08:45:39\', datetime(2014, 11, 12, 8, 45, 39)),\n            (\n                ""2017-02-03T09:04:08Z to 2017-02-03T09:04:09Z"",\n                [\n                    datetime(2017, 2, 3, 9, 4, 8, tzinfo=pytz.utc),\n                    datetime(2017, 2, 3, 9, 4, 9, tzinfo=pytz.utc),\n                ],\n                ""month"",\n            ),\n            # dates from issue https://github.com/akoumjian/datefinder/issues/14\n            (\n                ""i am looking for a date june 4th 1996 to july 3rd 2013"",\n                [datetime(1996, 6, 4), datetime(2013, 7, 3)],\n                ""month"",\n            ),\n            (\n                ""october 27 1994 to be put into effect on june 1 1995"",\n                [datetime(1994, 10, 27), datetime(1995, 6, 1)],\n                ""month"",\n            ),\n            # Simple date range\n            (\n                ""31/08/2012 to 30/08/2013"",\n                [datetime(2012, 8, 31), datetime(2013, 8, 30)],\n                ""month"",\n            ),\n            (\n                ""31 Oct 2021 - 28 Nov 2021"",\n                [datetime(2021, 10, 31), datetime(2021, 11, 28)],\n                ""day""\n            ),\n            # Z dates with and without millis, from https://github.com/akoumjian/datefinder/issues/37\n            (\n                ""2017-02-03T09:04:08.001Z"",\n                datetime(2017, 2, 3, 9, 4, 8, 1000, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            (\n                ""2017-02-03T09:04:08,00123Z"",\n                datetime(2017, 2, 3, 9, 4, 8, 1230, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            (\n                ""2017-02-03T09:04:08Z"",\n                datetime(2017, 2, 3, 9, 4, 8, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            # Year only strings, from https://github.com/akoumjian/datefinder/issues/96\n            (\n                ""Dutta is the recipient of Femina Miss India Universe title in 2004."",\n                datetime(2004, today.month, today.day),\n                ""month"",\n            ),\n            (\n                \'she said that she hit depression after being traumatized on the sets of ""Horn OK"" in 2008.\',\n                datetime(2008, today.month, today.day),\n                ""month"",\n            ),\n            # https://github.com/akoumjian/datefinder/issues/63\n            (""12th day of December, 2001"", datetime(2001, 12, 12), ""month""),\n            (""01/02/03"", datetime(2003, 1, 2, 0, 0, 0, 0), ""month""),\n            (""01/02/03"", datetime(2003, 2, 1, 0, 0, 0, 0), ""day""),\n            (""01/02/03"", datetime(2001, 2, 3, 0, 0, 0, 0), ""year""),\n            (""02/05/2020"", datetime(2020, 2, 5, 0, 0, 0, 0), ""month""),\n            (""02/05/2020"", datetime(2020, 5, 2, 0, 0, 0, 0), ""day""),\n        ],\n    )\n    def test_find_date_strings(input_text, expected_date, first):\n        if isinstance(expected_date, list):\n            matches = list(datefinder.find_dates(input_text, first=first))\n            assert matches == expected_date\n        else:\n            return_date = None\n            for return_date in datefinder.find_dates(input_text, first=first):\n                assert return_date == expected_date\n>           assert return_date is not None, \'Did not find date for test line: ""{}""\'.format(\n                input_text\n            )  # handles dates that were never matched\nE           AssertionError: Did not find date for test line: ""10:06am Dec 11, 2014""\nE           assert None is not None\n\nrepos\\datefinder\\tests\\test_find_dates.py:124: AssertionError', 'input_text = \'September 2nd, 1998\'\nexpected_date = datetime.datetime(1998, 9, 2, 0, 0), first = \'month\'\n\n    @pytest.mark.parametrize(\n        (""input_text"", ""expected_date"", ""first""),\n        [\n            ## English Dates\n            # (\'[Sept] 04, 2014.\', datetime(2014, 9, 4), ""month""),\n            (""Tuesday Jul 22, 2014"", datetime(2014, 7, 22), ""month""),\n            # (\'10:04am EDT\', datetime(2012, 11, 13, 14, 4), ""month""),\n            # (\'Friday\', datetime(2012, 11, 9), ""month""),\n            # (\'November 19, 2014 at noon\', datetime(2014, 11, 19, 12, 0), ""month""),\n            (""December 13, 2014 at midnight"", datetime(2014, 12, 13, 0, 0), ""month""),\n            # (\'Nov 25 2014 10:17 pm EST\', datetime(2014, 11, 26, 3, 17), ""month""),\n            # (\'Wed Aug 05 12:00:00 EDT 2015\', datetime(2015, 8, 5, 16, 0), ""month""),\n            (""April 9, 2013 at 6:11 a.m."", datetime(2013, 4, 9, 6, 11), ""month""),\n            (""Aug. 9, 2012 at 2:57 p.m."", datetime(2012, 8, 9, 14, 57), ""month""),\n            (""December 10, 2014, 11:02:21 pm"", datetime(2014, 12, 10, 23, 2, 21), ""month""),\n            (""8:25 a.m. Dec. 12, 2014"", datetime(2014, 12, 12, 8, 25), ""month""),\n            (""2:21 p.m., December 11, 2014"", datetime(2014, 12, 11, 14, 21), ""month""),\n            (""Fri, 12 Dec 2014 10:55:50"", datetime(2014, 12, 12, 10, 55, 50), ""month""),\n            # (\'20 Mar 2013 10h11\', datetime(2013, 3, 20, 10, 11), ""month""),\n            (""10:06am Dec 11, 2014"", datetime(2014, 12, 11, 10, 6), ""month""),\n            (""September 2nd, 1998"", datetime(1998, 9, 2), ""month""),\n            (\n                ""May 5, 2010 to July 10, 2011"",\n                [datetime(2010, 5, 5), datetime(2011, 7, 10)],\n                ""month"",\n            ),\n            # (\'19 February 2013 year 09:10\', datetime(2013, 2, 19, 9, 10), ""month""),\n            # Numeric dates\n            (""06-17-2014"", datetime(2014, 6, 17), ""month""),\n            (""13/03/2014"", datetime(2014, 3, 13), ""month""),\n            (\n                ""2016-02-04T20:16:26+00:00"",\n                datetime(2016, 2, 4, 20, 16, 26, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            # (\'11. 12. 2014, 08:45:39\', datetime(2014, 11, 12, 8, 45, 39)),\n            (\n                ""2017-02-03T09:04:08Z to 2017-02-03T09:04:09Z"",\n                [\n                    datetime(2017, 2, 3, 9, 4, 8, tzinfo=pytz.utc),\n                    datetime(2017, 2, 3, 9, 4, 9, tzinfo=pytz.utc),\n                ],\n                ""month"",\n            ),\n            # dates from issue https://github.com/akoumjian/datefinder/issues/14\n            (\n                ""i am looking for a date june 4th 1996 to july 3rd 2013"",\n                [datetime(1996, 6, 4), datetime(2013, 7, 3)],\n                ""month"",\n            ),\n            (\n                ""october 27 1994 to be put into effect on june 1 1995"",\n                [datetime(1994, 10, 27), datetime(1995, 6, 1)],\n                ""month"",\n            ),\n            # Simple date range\n            (\n                ""31/08/2012 to 30/08/2013"",\n                [datetime(2012, 8, 31), datetime(2013, 8, 30)],\n                ""month"",\n            ),\n            (\n                ""31 Oct 2021 - 28 Nov 2021"",\n                [datetime(2021, 10, 31), datetime(2021, 11, 28)],\n                ""day""\n            ),\n            # Z dates with and without millis, from https://github.com/akoumjian/datefinder/issues/37\n            (\n                ""2017-02-03T09:04:08.001Z"",\n                datetime(2017, 2, 3, 9, 4, 8, 1000, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            (\n                ""2017-02-03T09:04:08,00123Z"",\n                datetime(2017, 2, 3, 9, 4, 8, 1230, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            (\n                ""2017-02-03T09:04:08Z"",\n                datetime(2017, 2, 3, 9, 4, 8, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            # Year only strings, from https://github.com/akoumjian/datefinder/issues/96\n            (\n                ""Dutta is the recipient of Femina Miss India Universe title in 2004."",\n                datetime(2004, today.month, today.day),\n                ""month"",\n            ),\n            (\n                \'she said that she hit depression after being traumatized on the sets of ""Horn OK"" in 2008.\',\n                datetime(2008, today.month, today.day),\n                ""month"",\n            ),\n            # https://github.com/akoumjian/datefinder/issues/63\n            (""12th day of December, 2001"", datetime(2001, 12, 12), ""month""),\n            (""01/02/03"", datetime(2003, 1, 2, 0, 0, 0, 0), ""month""),\n            (""01/02/03"", datetime(2003, 2, 1, 0, 0, 0, 0), ""day""),\n            (""01/02/03"", datetime(2001, 2, 3, 0, 0, 0, 0), ""year""),\n            (""02/05/2020"", datetime(2020, 2, 5, 0, 0, 0, 0), ""month""),\n            (""02/05/2020"", datetime(2020, 5, 2, 0, 0, 0, 0), ""day""),\n        ],\n    )\n    def test_find_date_strings(input_text, expected_date, first):\n        if isinstance(expected_date, list):\n            matches = list(datefinder.find_dates(input_text, first=first))\n            assert matches == expected_date\n        else:\n            return_date = None\n            for return_date in datefinder.find_dates(input_text, first=first):\n                assert return_date == expected_date\n>           assert return_date is not None, \'Did not find date for test line: ""{}""\'.format(\n                input_text\n            )  # handles dates that were never matched\nE           AssertionError: Did not find date for test line: ""September 2nd, 1998""\nE           assert None is not None\n\nrepos\\datefinder\\tests\\test_find_dates.py:124: AssertionError', 'input_text = \'May 5, 2010 to July 10, 2011\'\nexpected_date = [datetime.datetime(2010, 5, 5, 0, 0), datetime.datetime(2011, 7, 10, 0, 0)]\nfirst = \'month\'\n\n    @pytest.mark.parametrize(\n        (""input_text"", ""expected_date"", ""first""),\n        [\n            ## English Dates\n            # (\'[Sept] 04, 2014.\', datetime(2014, 9, 4), ""month""),\n            (""Tuesday Jul 22, 2014"", datetime(2014, 7, 22), ""month""),\n            # (\'10:04am EDT\', datetime(2012, 11, 13, 14, 4), ""month""),\n            # (\'Friday\', datetime(2012, 11, 9), ""month""),\n            # (\'November 19, 2014 at noon\', datetime(2014, 11, 19, 12, 0), ""month""),\n            (""December 13, 2014 at midnight"", datetime(2014, 12, 13, 0, 0), ""month""),\n            # (\'Nov 25 2014 10:17 pm EST\', datetime(2014, 11, 26, 3, 17), ""month""),\n            # (\'Wed Aug 05 12:00:00 EDT 2015\', datetime(2015, 8, 5, 16, 0), ""month""),\n            (""April 9, 2013 at 6:11 a.m."", datetime(2013, 4, 9, 6, 11), ""month""),\n            (""Aug. 9, 2012 at 2:57 p.m."", datetime(2012, 8, 9, 14, 57), ""month""),\n            (""December 10, 2014, 11:02:21 pm"", datetime(2014, 12, 10, 23, 2, 21), ""month""),\n            (""8:25 a.m. Dec. 12, 2014"", datetime(2014, 12, 12, 8, 25), ""month""),\n            (""2:21 p.m., December 11, 2014"", datetime(2014, 12, 11, 14, 21), ""month""),\n            (""Fri, 12 Dec 2014 10:55:50"", datetime(2014, 12, 12, 10, 55, 50), ""month""),\n            # (\'20 Mar 2013 10h11\', datetime(2013, 3, 20, 10, 11), ""month""),\n            (""10:06am Dec 11, 2014"", datetime(2014, 12, 11, 10, 6), ""month""),\n            (""September 2nd, 1998"", datetime(1998, 9, 2), ""month""),\n            (\n                ""May 5, 2010 to July 10, 2011"",\n                [datetime(2010, 5, 5), datetime(2011, 7, 10)],\n                ""month"",\n            ),\n            # (\'19 February 2013 year 09:10\', datetime(2013, 2, 19, 9, 10), ""month""),\n            # Numeric dates\n            (""06-17-2014"", datetime(2014, 6, 17), ""month""),\n            (""13/03/2014"", datetime(2014, 3, 13), ""month""),\n            (\n                ""2016-02-04T20:16:26+00:00"",\n                datetime(2016, 2, 4, 20, 16, 26, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            # (\'11. 12. 2014, 08:45:39\', datetime(2014, 11, 12, 8, 45, 39)),\n            (\n                ""2017-02-03T09:04:08Z to 2017-02-03T09:04:09Z"",\n                [\n                    datetime(2017, 2, 3, 9, 4, 8, tzinfo=pytz.utc),\n                    datetime(2017, 2, 3, 9, 4, 9, tzinfo=pytz.utc),\n                ],\n                ""month"",\n            ),\n            # dates from issue https://github.com/akoumjian/datefinder/issues/14\n            (\n                ""i am looking for a date june 4th 1996 to july 3rd 2013"",\n                [datetime(1996, 6, 4), datetime(2013, 7, 3)],\n                ""month"",\n            ),\n            (\n                ""october 27 1994 to be put into effect on june 1 1995"",\n                [datetime(1994, 10, 27), datetime(1995, 6, 1)],\n                ""month"",\n            ),\n            # Simple date range\n            (\n                ""31/08/2012 to 30/08/2013"",\n                [datetime(2012, 8, 31), datetime(2013, 8, 30)],\n                ""month"",\n            ),\n            (\n                ""31 Oct 2021 - 28 Nov 2021"",\n                [datetime(2021, 10, 31), datetime(2021, 11, 28)],\n                ""day""\n            ),\n            # Z dates with and without millis, from https://github.com/akoumjian/datefinder/issues/37\n            (\n                ""2017-02-03T09:04:08.001Z"",\n                datetime(2017, 2, 3, 9, 4, 8, 1000, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            (\n                ""2017-02-03T09:04:08,00123Z"",\n                datetime(2017, 2, 3, 9, 4, 8, 1230, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            (\n                ""2017-02-03T09:04:08Z"",\n                datetime(2017, 2, 3, 9, 4, 8, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            # Year only strings, from https://github.com/akoumjian/datefinder/issues/96\n            (\n                ""Dutta is the recipient of Femina Miss India Universe title in 2004."",\n                datetime(2004, today.month, today.day),\n                ""month"",\n            ),\n            (\n                \'she said that she hit depression after being traumatized on the sets of ""Horn OK"" in 2008.\',\n                datetime(2008, today.month, today.day),\n                ""month"",\n            ),\n            # https://github.com/akoumjian/datefinder/issues/63\n            (""12th day of December, 2001"", datetime(2001, 12, 12), ""month""),\n            (""01/02/03"", datetime(2003, 1, 2, 0, 0, 0, 0), ""month""),\n            (""01/02/03"", datetime(2003, 2, 1, 0, 0, 0, 0), ""day""),\n            (""01/02/03"", datetime(2001, 2, 3, 0, 0, 0, 0), ""year""),\n            (""02/05/2020"", datetime(2020, 2, 5, 0, 0, 0, 0), ""month""),\n            (""02/05/2020"", datetime(2020, 5, 2, 0, 0, 0, 0), ""day""),\n        ],\n    )\n    def test_find_date_strings(input_text, expected_date, first):\n        if isinstance(expected_date, list):\n            matches = list(datefinder.find_dates(input_text, first=first))\n>           assert matches == expected_date\nE           assert [] == [datetime.dat... 7, 10, 0, 0)]\nE             \nE             Right contains 2 more items, first extra item: datetime.datetime(2010, 5, 5, 0, 0)\nE             \nE             Full diff:\nE             + []\nE             - [\nE             -     datetime.datetime(2010, 5, 5, 0, 0),\nE             -     datetime.datetime(2011, 7, 10, 0, 0),\nE             - ]\n\nrepos\\datefinder\\tests\\test_find_dates.py:119: AssertionError', 'input_text = \'06-17-2014\', expected_date = datetime.datetime(2014, 6, 17, 0, 0)\nfirst = \'month\'\n\n    @pytest.mark.parametrize(\n        (""input_text"", ""expected_date"", ""first""),\n        [\n            ## English Dates\n            # (\'[Sept] 04, 2014.\', datetime(2014, 9, 4), ""month""),\n            (""Tuesday Jul 22, 2014"", datetime(2014, 7, 22), ""month""),\n            # (\'10:04am EDT\', datetime(2012, 11, 13, 14, 4), ""month""),\n            # (\'Friday\', datetime(2012, 11, 9), ""month""),\n            # (\'November 19, 2014 at noon\', datetime(2014, 11, 19, 12, 0), ""month""),\n            (""December 13, 2014 at midnight"", datetime(2014, 12, 13, 0, 0), ""month""),\n            # (\'Nov 25 2014 10:17 pm EST\', datetime(2014, 11, 26, 3, 17), ""month""),\n            # (\'Wed Aug 05 12:00:00 EDT 2015\', datetime(2015, 8, 5, 16, 0), ""month""),\n            (""April 9, 2013 at 6:11 a.m."", datetime(2013, 4, 9, 6, 11), ""month""),\n            (""Aug. 9, 2012 at 2:57 p.m."", datetime(2012, 8, 9, 14, 57), ""month""),\n            (""December 10, 2014, 11:02:21 pm"", datetime(2014, 12, 10, 23, 2, 21), ""month""),\n            (""8:25 a.m. Dec. 12, 2014"", datetime(2014, 12, 12, 8, 25), ""month""),\n            (""2:21 p.m., December 11, 2014"", datetime(2014, 12, 11, 14, 21), ""month""),\n            (""Fri, 12 Dec 2014 10:55:50"", datetime(2014, 12, 12, 10, 55, 50), ""month""),\n            # (\'20 Mar 2013 10h11\', datetime(2013, 3, 20, 10, 11), ""month""),\n            (""10:06am Dec 11, 2014"", datetime(2014, 12, 11, 10, 6), ""month""),\n            (""September 2nd, 1998"", datetime(1998, 9, 2), ""month""),\n            (\n                ""May 5, 2010 to July 10, 2011"",\n                [datetime(2010, 5, 5), datetime(2011, 7, 10)],\n                ""month"",\n            ),\n            # (\'19 February 2013 year 09:10\', datetime(2013, 2, 19, 9, 10), ""month""),\n            # Numeric dates\n            (""06-17-2014"", datetime(2014, 6, 17), ""month""),\n            (""13/03/2014"", datetime(2014, 3, 13), ""month""),\n            (\n                ""2016-02-04T20:16:26+00:00"",\n                datetime(2016, 2, 4, 20, 16, 26, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            # (\'11. 12. 2014, 08:45:39\', datetime(2014, 11, 12, 8, 45, 39)),\n            (\n                ""2017-02-03T09:04:08Z to 2017-02-03T09:04:09Z"",\n                [\n                    datetime(2017, 2, 3, 9, 4, 8, tzinfo=pytz.utc),\n                    datetime(2017, 2, 3, 9, 4, 9, tzinfo=pytz.utc),\n                ],\n                ""month"",\n            ),\n            # dates from issue https://github.com/akoumjian/datefinder/issues/14\n            (\n                ""i am looking for a date june 4th 1996 to july 3rd 2013"",\n                [datetime(1996, 6, 4), datetime(2013, 7, 3)],\n                ""month"",\n            ),\n            (\n                ""october 27 1994 to be put into effect on june 1 1995"",\n                [datetime(1994, 10, 27), datetime(1995, 6, 1)],\n                ""month"",\n            ),\n            # Simple date range\n            (\n                ""31/08/2012 to 30/08/2013"",\n                [datetime(2012, 8, 31), datetime(2013, 8, 30)],\n                ""month"",\n            ),\n            (\n                ""31 Oct 2021 - 28 Nov 2021"",\n                [datetime(2021, 10, 31), datetime(2021, 11, 28)],\n                ""day""\n            ),\n            # Z dates with and without millis, from https://github.com/akoumjian/datefinder/issues/37\n            (\n                ""2017-02-03T09:04:08.001Z"",\n                datetime(2017, 2, 3, 9, 4, 8, 1000, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            (\n                ""2017-02-03T09:04:08,00123Z"",\n                datetime(2017, 2, 3, 9, 4, 8, 1230, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            (\n                ""2017-02-03T09:04:08Z"",\n                datetime(2017, 2, 3, 9, 4, 8, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            # Year only strings, from https://github.com/akoumjian/datefinder/issues/96\n            (\n                ""Dutta is the recipient of Femina Miss India Universe title in 2004."",\n                datetime(2004, today.month, today.day),\n                ""month"",\n            ),\n            (\n                \'she said that she hit depression after being traumatized on the sets of ""Horn OK"" in 2008.\',\n                datetime(2008, today.month, today.day),\n                ""month"",\n            ),\n            # https://github.com/akoumjian/datefinder/issues/63\n            (""12th day of December, 2001"", datetime(2001, 12, 12), ""month""),\n            (""01/02/03"", datetime(2003, 1, 2, 0, 0, 0, 0), ""month""),\n            (""01/02/03"", datetime(2003, 2, 1, 0, 0, 0, 0), ""day""),\n            (""01/02/03"", datetime(2001, 2, 3, 0, 0, 0, 0), ""year""),\n            (""02/05/2020"", datetime(2020, 2, 5, 0, 0, 0, 0), ""month""),\n            (""02/05/2020"", datetime(2020, 5, 2, 0, 0, 0, 0), ""day""),\n        ],\n    )\n    def test_find_date_strings(input_text, expected_date, first):\n        if isinstance(expected_date, list):\n            matches = list(datefinder.find_dates(input_text, first=first))\n            assert matches == expected_date\n        else:\n            return_date = None\n            for return_date in datefinder.find_dates(input_text, first=first):\n                assert return_date == expected_date\n>           assert return_date is not None, \'Did not find date for test line: ""{}""\'.format(\n                input_text\n            )  # handles dates that were never matched\nE           AssertionError: Did not find date for test line: ""06-17-2014""\nE           assert None is not None\n\nrepos\\datefinder\\tests\\test_find_dates.py:124: AssertionError', 'input_text = \'13/03/2014\', expected_date = datetime.datetime(2014, 3, 13, 0, 0)\nfirst = \'month\'\n\n    @pytest.mark.parametrize(\n        (""input_text"", ""expected_date"", ""first""),\n        [\n            ## English Dates\n            # (\'[Sept] 04, 2014.\', datetime(2014, 9, 4), ""month""),\n            (""Tuesday Jul 22, 2014"", datetime(2014, 7, 22), ""month""),\n            # (\'10:04am EDT\', datetime(2012, 11, 13, 14, 4), ""month""),\n            # (\'Friday\', datetime(2012, 11, 9), ""month""),\n            # (\'November 19, 2014 at noon\', datetime(2014, 11, 19, 12, 0), ""month""),\n            (""December 13, 2014 at midnight"", datetime(2014, 12, 13, 0, 0), ""month""),\n            # (\'Nov 25 2014 10:17 pm EST\', datetime(2014, 11, 26, 3, 17), ""month""),\n            # (\'Wed Aug 05 12:00:00 EDT 2015\', datetime(2015, 8, 5, 16, 0), ""month""),\n            (""April 9, 2013 at 6:11 a.m."", datetime(2013, 4, 9, 6, 11), ""month""),\n            (""Aug. 9, 2012 at 2:57 p.m."", datetime(2012, 8, 9, 14, 57), ""month""),\n            (""December 10, 2014, 11:02:21 pm"", datetime(2014, 12, 10, 23, 2, 21), ""month""),\n            (""8:25 a.m. Dec. 12, 2014"", datetime(2014, 12, 12, 8, 25), ""month""),\n            (""2:21 p.m., December 11, 2014"", datetime(2014, 12, 11, 14, 21), ""month""),\n            (""Fri, 12 Dec 2014 10:55:50"", datetime(2014, 12, 12, 10, 55, 50), ""month""),\n            # (\'20 Mar 2013 10h11\', datetime(2013, 3, 20, 10, 11), ""month""),\n            (""10:06am Dec 11, 2014"", datetime(2014, 12, 11, 10, 6), ""month""),\n            (""September 2nd, 1998"", datetime(1998, 9, 2), ""month""),\n            (\n                ""May 5, 2010 to July 10, 2011"",\n                [datetime(2010, 5, 5), datetime(2011, 7, 10)],\n                ""month"",\n            ),\n            # (\'19 February 2013 year 09:10\', datetime(2013, 2, 19, 9, 10), ""month""),\n            # Numeric dates\n            (""06-17-2014"", datetime(2014, 6, 17), ""month""),\n            (""13/03/2014"", datetime(2014, 3, 13), ""month""),\n            (\n                ""2016-02-04T20:16:26+00:00"",\n                datetime(2016, 2, 4, 20, 16, 26, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            # (\'11. 12. 2014, 08:45:39\', datetime(2014, 11, 12, 8, 45, 39)),\n            (\n                ""2017-02-03T09:04:08Z to 2017-02-03T09:04:09Z"",\n                [\n                    datetime(2017, 2, 3, 9, 4, 8, tzinfo=pytz.utc),\n                    datetime(2017, 2, 3, 9, 4, 9, tzinfo=pytz.utc),\n                ],\n                ""month"",\n            ),\n            # dates from issue https://github.com/akoumjian/datefinder/issues/14\n            (\n                ""i am looking for a date june 4th 1996 to july 3rd 2013"",\n                [datetime(1996, 6, 4), datetime(2013, 7, 3)],\n                ""month"",\n            ),\n            (\n                ""october 27 1994 to be put into effect on june 1 1995"",\n                [datetime(1994, 10, 27), datetime(1995, 6, 1)],\n                ""month"",\n            ),\n            # Simple date range\n            (\n                ""31/08/2012 to 30/08/2013"",\n                [datetime(2012, 8, 31), datetime(2013, 8, 30)],\n                ""month"",\n            ),\n            (\n                ""31 Oct 2021 - 28 Nov 2021"",\n                [datetime(2021, 10, 31), datetime(2021, 11, 28)],\n                ""day""\n            ),\n            # Z dates with and without millis, from https://github.com/akoumjian/datefinder/issues/37\n            (\n                ""2017-02-03T09:04:08.001Z"",\n                datetime(2017, 2, 3, 9, 4, 8, 1000, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            (\n                ""2017-02-03T09:04:08,00123Z"",\n                datetime(2017, 2, 3, 9, 4, 8, 1230, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            (\n                ""2017-02-03T09:04:08Z"",\n                datetime(2017, 2, 3, 9, 4, 8, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            # Year only strings, from https://github.com/akoumjian/datefinder/issues/96\n            (\n                ""Dutta is the recipient of Femina Miss India Universe title in 2004."",\n                datetime(2004, today.month, today.day),\n                ""month"",\n            ),\n            (\n                \'she said that she hit depression after being traumatized on the sets of ""Horn OK"" in 2008.\',\n                datetime(2008, today.month, today.day),\n                ""month"",\n            ),\n            # https://github.com/akoumjian/datefinder/issues/63\n            (""12th day of December, 2001"", datetime(2001, 12, 12), ""month""),\n            (""01/02/03"", datetime(2003, 1, 2, 0, 0, 0, 0), ""month""),\n            (""01/02/03"", datetime(2003, 2, 1, 0, 0, 0, 0), ""day""),\n            (""01/02/03"", datetime(2001, 2, 3, 0, 0, 0, 0), ""year""),\n            (""02/05/2020"", datetime(2020, 2, 5, 0, 0, 0, 0), ""month""),\n            (""02/05/2020"", datetime(2020, 5, 2, 0, 0, 0, 0), ""day""),\n        ],\n    )\n    def test_find_date_strings(input_text, expected_date, first):\n        if isinstance(expected_date, list):\n            matches = list(datefinder.find_dates(input_text, first=first))\n            assert matches == expected_date\n        else:\n            return_date = None\n            for return_date in datefinder.find_dates(input_text, first=first):\n                assert return_date == expected_date\n>           assert return_date is not None, \'Did not find date for test line: ""{}""\'.format(\n                input_text\n            )  # handles dates that were never matched\nE           AssertionError: Did not find date for test line: ""13/03/2014""\nE           assert None is not None\n\nrepos\\datefinder\\tests\\test_find_dates.py:124: AssertionError', 'input_text = \'2016-02-04T20:16:26+00:00\'\nexpected_date = datetime.datetime(2016, 2, 4, 20, 16, 26, tzinfo=<UTC>)\nfirst = \'month\'\n\n    @pytest.mark.parametrize(\n        (""input_text"", ""expected_date"", ""first""),\n        [\n            ## English Dates\n            # (\'[Sept] 04, 2014.\', datetime(2014, 9, 4), ""month""),\n            (""Tuesday Jul 22, 2014"", datetime(2014, 7, 22), ""month""),\n            # (\'10:04am EDT\', datetime(2012, 11, 13, 14, 4), ""month""),\n            # (\'Friday\', datetime(2012, 11, 9), ""month""),\n            # (\'November 19, 2014 at noon\', datetime(2014, 11, 19, 12, 0), ""month""),\n            (""December 13, 2014 at midnight"", datetime(2014, 12, 13, 0, 0), ""month""),\n            # (\'Nov 25 2014 10:17 pm EST\', datetime(2014, 11, 26, 3, 17), ""month""),\n            # (\'Wed Aug 05 12:00:00 EDT 2015\', datetime(2015, 8, 5, 16, 0), ""month""),\n            (""April 9, 2013 at 6:11 a.m."", datetime(2013, 4, 9, 6, 11), ""month""),\n            (""Aug. 9, 2012 at 2:57 p.m."", datetime(2012, 8, 9, 14, 57), ""month""),\n            (""December 10, 2014, 11:02:21 pm"", datetime(2014, 12, 10, 23, 2, 21), ""month""),\n            (""8:25 a.m. Dec. 12, 2014"", datetime(2014, 12, 12, 8, 25), ""month""),\n            (""2:21 p.m., December 11, 2014"", datetime(2014, 12, 11, 14, 21), ""month""),\n            (""Fri, 12 Dec 2014 10:55:50"", datetime(2014, 12, 12, 10, 55, 50), ""month""),\n            # (\'20 Mar 2013 10h11\', datetime(2013, 3, 20, 10, 11), ""month""),\n            (""10:06am Dec 11, 2014"", datetime(2014, 12, 11, 10, 6), ""month""),\n            (""September 2nd, 1998"", datetime(1998, 9, 2), ""month""),\n            (\n                ""May 5, 2010 to July 10, 2011"",\n                [datetime(2010, 5, 5), datetime(2011, 7, 10)],\n                ""month"",\n            ),\n            # (\'19 February 2013 year 09:10\', datetime(2013, 2, 19, 9, 10), ""month""),\n            # Numeric dates\n            (""06-17-2014"", datetime(2014, 6, 17), ""month""),\n            (""13/03/2014"", datetime(2014, 3, 13), ""month""),\n            (\n                ""2016-02-04T20:16:26+00:00"",\n                datetime(2016, 2, 4, 20, 16, 26, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            # (\'11. 12. 2014, 08:45:39\', datetime(2014, 11, 12, 8, 45, 39)),\n            (\n                ""2017-02-03T09:04:08Z to 2017-02-03T09:04:09Z"",\n                [\n                    datetime(2017, 2, 3, 9, 4, 8, tzinfo=pytz.utc),\n                    datetime(2017, 2, 3, 9, 4, 9, tzinfo=pytz.utc),\n                ],\n                ""month"",\n            ),\n            # dates from issue https://github.com/akoumjian/datefinder/issues/14\n            (\n                ""i am looking for a date june 4th 1996 to july 3rd 2013"",\n                [datetime(1996, 6, 4), datetime(2013, 7, 3)],\n                ""month"",\n            ),\n            (\n                ""october 27 1994 to be put into effect on june 1 1995"",\n                [datetime(1994, 10, 27), datetime(1995, 6, 1)],\n                ""month"",\n            ),\n            # Simple date range\n            (\n                ""31/08/2012 to 30/08/2013"",\n                [datetime(2012, 8, 31), datetime(2013, 8, 30)],\n                ""month"",\n            ),\n            (\n                ""31 Oct 2021 - 28 Nov 2021"",\n                [datetime(2021, 10, 31), datetime(2021, 11, 28)],\n                ""day""\n            ),\n            # Z dates with and without millis, from https://github.com/akoumjian/datefinder/issues/37\n            (\n                ""2017-02-03T09:04:08.001Z"",\n                datetime(2017, 2, 3, 9, 4, 8, 1000, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            (\n                ""2017-02-03T09:04:08,00123Z"",\n                datetime(2017, 2, 3, 9, 4, 8, 1230, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            (\n                ""2017-02-03T09:04:08Z"",\n                datetime(2017, 2, 3, 9, 4, 8, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            # Year only strings, from https://github.com/akoumjian/datefinder/issues/96\n            (\n                ""Dutta is the recipient of Femina Miss India Universe title in 2004."",\n                datetime(2004, today.month, today.day),\n                ""month"",\n            ),\n            (\n                \'she said that she hit depression after being traumatized on the sets of ""Horn OK"" in 2008.\',\n                datetime(2008, today.month, today.day),\n                ""month"",\n            ),\n            # https://github.com/akoumjian/datefinder/issues/63\n            (""12th day of December, 2001"", datetime(2001, 12, 12), ""month""),\n            (""01/02/03"", datetime(2003, 1, 2, 0, 0, 0, 0), ""month""),\n            (""01/02/03"", datetime(2003, 2, 1, 0, 0, 0, 0), ""day""),\n            (""01/02/03"", datetime(2001, 2, 3, 0, 0, 0, 0), ""year""),\n            (""02/05/2020"", datetime(2020, 2, 5, 0, 0, 0, 0), ""month""),\n            (""02/05/2020"", datetime(2020, 5, 2, 0, 0, 0, 0), ""day""),\n        ],\n    )\n    def test_find_date_strings(input_text, expected_date, first):\n        if isinstance(expected_date, list):\n            matches = list(datefinder.find_dates(input_text, first=first))\n            assert matches == expected_date\n        else:\n            return_date = None\n            for return_date in datefinder.find_dates(input_text, first=first):\n                assert return_date == expected_date\n>           assert return_date is not None, \'Did not find date for test line: ""{}""\'.format(\n                input_text\n            )  # handles dates that were never matched\nE           AssertionError: Did not find date for test line: ""2016-02-04T20:16:26+00:00""\nE           assert None is not None\n\nrepos\\datefinder\\tests\\test_find_dates.py:124: AssertionError', 'input_text = \'2017-02-03T09:04:08Z to 2017-02-03T09:04:09Z\'\nexpected_date = [datetime.datetime(2017, 2, 3, 9, 4, 8, tzinfo=<UTC>), datetime.datetime(2017, 2, 3, 9, 4, 9, tzinfo=<UTC>)]\nfirst = \'month\'\n\n    @pytest.mark.parametrize(\n        (""input_text"", ""expected_date"", ""first""),\n        [\n            ## English Dates\n            # (\'[Sept] 04, 2014.\', datetime(2014, 9, 4), ""month""),\n            (""Tuesday Jul 22, 2014"", datetime(2014, 7, 22), ""month""),\n            # (\'10:04am EDT\', datetime(2012, 11, 13, 14, 4), ""month""),\n            # (\'Friday\', datetime(2012, 11, 9), ""month""),\n            # (\'November 19, 2014 at noon\', datetime(2014, 11, 19, 12, 0), ""month""),\n            (""December 13, 2014 at midnight"", datetime(2014, 12, 13, 0, 0), ""month""),\n            # (\'Nov 25 2014 10:17 pm EST\', datetime(2014, 11, 26, 3, 17), ""month""),\n            # (\'Wed Aug 05 12:00:00 EDT 2015\', datetime(2015, 8, 5, 16, 0), ""month""),\n            (""April 9, 2013 at 6:11 a.m."", datetime(2013, 4, 9, 6, 11), ""month""),\n            (""Aug. 9, 2012 at 2:57 p.m."", datetime(2012, 8, 9, 14, 57), ""month""),\n            (""December 10, 2014, 11:02:21 pm"", datetime(2014, 12, 10, 23, 2, 21), ""month""),\n            (""8:25 a.m. Dec. 12, 2014"", datetime(2014, 12, 12, 8, 25), ""month""),\n            (""2:21 p.m., December 11, 2014"", datetime(2014, 12, 11, 14, 21), ""month""),\n            (""Fri, 12 Dec 2014 10:55:50"", datetime(2014, 12, 12, 10, 55, 50), ""month""),\n            # (\'20 Mar 2013 10h11\', datetime(2013, 3, 20, 10, 11), ""month""),\n            (""10:06am Dec 11, 2014"", datetime(2014, 12, 11, 10, 6), ""month""),\n            (""September 2nd, 1998"", datetime(1998, 9, 2), ""month""),\n            (\n                ""May 5, 2010 to July 10, 2011"",\n                [datetime(2010, 5, 5), datetime(2011, 7, 10)],\n                ""month"",\n            ),\n            # (\'19 February 2013 year 09:10\', datetime(2013, 2, 19, 9, 10), ""month""),\n            # Numeric dates\n            (""06-17-2014"", datetime(2014, 6, 17), ""month""),\n            (""13/03/2014"", datetime(2014, 3, 13), ""month""),\n            (\n                ""2016-02-04T20:16:26+00:00"",\n                datetime(2016, 2, 4, 20, 16, 26, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            # (\'11. 12. 2014, 08:45:39\', datetime(2014, 11, 12, 8, 45, 39)),\n            (\n                ""2017-02-03T09:04:08Z to 2017-02-03T09:04:09Z"",\n                [\n                    datetime(2017, 2, 3, 9, 4, 8, tzinfo=pytz.utc),\n                    datetime(2017, 2, 3, 9, 4, 9, tzinfo=pytz.utc),\n                ],\n                ""month"",\n            ),\n            # dates from issue https://github.com/akoumjian/datefinder/issues/14\n            (\n                ""i am looking for a date june 4th 1996 to july 3rd 2013"",\n                [datetime(1996, 6, 4), datetime(2013, 7, 3)],\n                ""month"",\n            ),\n            (\n                ""october 27 1994 to be put into effect on june 1 1995"",\n                [datetime(1994, 10, 27), datetime(1995, 6, 1)],\n                ""month"",\n            ),\n            # Simple date range\n            (\n                ""31/08/2012 to 30/08/2013"",\n                [datetime(2012, 8, 31), datetime(2013, 8, 30)],\n                ""month"",\n            ),\n            (\n                ""31 Oct 2021 - 28 Nov 2021"",\n                [datetime(2021, 10, 31), datetime(2021, 11, 28)],\n                ""day""\n            ),\n            # Z dates with and without millis, from https://github.com/akoumjian/datefinder/issues/37\n            (\n                ""2017-02-03T09:04:08.001Z"",\n                datetime(2017, 2, 3, 9, 4, 8, 1000, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            (\n                ""2017-02-03T09:04:08,00123Z"",\n                datetime(2017, 2, 3, 9, 4, 8, 1230, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            (\n                ""2017-02-03T09:04:08Z"",\n                datetime(2017, 2, 3, 9, 4, 8, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            # Year only strings, from https://github.com/akoumjian/datefinder/issues/96\n            (\n                ""Dutta is the recipient of Femina Miss India Universe title in 2004."",\n                datetime(2004, today.month, today.day),\n                ""month"",\n            ),\n            (\n                \'she said that she hit depression after being traumatized on the sets of ""Horn OK"" in 2008.\',\n                datetime(2008, today.month, today.day),\n                ""month"",\n            ),\n            # https://github.com/akoumjian/datefinder/issues/63\n            (""12th day of December, 2001"", datetime(2001, 12, 12), ""month""),\n            (""01/02/03"", datetime(2003, 1, 2, 0, 0, 0, 0), ""month""),\n            (""01/02/03"", datetime(2003, 2, 1, 0, 0, 0, 0), ""day""),\n            (""01/02/03"", datetime(2001, 2, 3, 0, 0, 0, 0), ""year""),\n            (""02/05/2020"", datetime(2020, 2, 5, 0, 0, 0, 0), ""month""),\n            (""02/05/2020"", datetime(2020, 5, 2, 0, 0, 0, 0), ""day""),\n        ],\n    )\n    def test_find_date_strings(input_text, expected_date, first):\n        if isinstance(expected_date, list):\n            matches = list(datefinder.find_dates(input_text, first=first))\n>           assert matches == expected_date\nE           assert [] == [datetime.dat...tzinfo=<UTC>)]\nE             \nE             Right contains 2 more items, first extra item: datetime.datetime(2017, 2, 3, 9, 4, 8, tzinfo=<UTC>)\nE             \nE             Full diff:\nE             + []\nE             - [\nE             -     datetime.datetime(2017, 2, 3, 9, 4, 8, tzinfo=<UTC>),\nE             -     datetime.datetime(2017, 2, 3, 9, 4, 9, tzinfo=<UTC>),\nE             - ]\n\nrepos\\datefinder\\tests\\test_find_dates.py:119: AssertionError', 'input_text = \'i am looking for a date june 4th 1996 to july 3rd 2013\'\nexpected_date = [datetime.datetime(1996, 6, 4, 0, 0), datetime.datetime(2013, 7, 3, 0, 0)]\nfirst = \'month\'\n\n    @pytest.mark.parametrize(\n        (""input_text"", ""expected_date"", ""first""),\n        [\n            ## English Dates\n            # (\'[Sept] 04, 2014.\', datetime(2014, 9, 4), ""month""),\n            (""Tuesday Jul 22, 2014"", datetime(2014, 7, 22), ""month""),\n            # (\'10:04am EDT\', datetime(2012, 11, 13, 14, 4), ""month""),\n            # (\'Friday\', datetime(2012, 11, 9), ""month""),\n            # (\'November 19, 2014 at noon\', datetime(2014, 11, 19, 12, 0), ""month""),\n            (""December 13, 2014 at midnight"", datetime(2014, 12, 13, 0, 0), ""month""),\n            # (\'Nov 25 2014 10:17 pm EST\', datetime(2014, 11, 26, 3, 17), ""month""),\n            # (\'Wed Aug 05 12:00:00 EDT 2015\', datetime(2015, 8, 5, 16, 0), ""month""),\n            (""April 9, 2013 at 6:11 a.m."", datetime(2013, 4, 9, 6, 11), ""month""),\n            (""Aug. 9, 2012 at 2:57 p.m."", datetime(2012, 8, 9, 14, 57), ""month""),\n            (""December 10, 2014, 11:02:21 pm"", datetime(2014, 12, 10, 23, 2, 21), ""month""),\n            (""8:25 a.m. Dec. 12, 2014"", datetime(2014, 12, 12, 8, 25), ""month""),\n            (""2:21 p.m., December 11, 2014"", datetime(2014, 12, 11, 14, 21), ""month""),\n            (""Fri, 12 Dec 2014 10:55:50"", datetime(2014, 12, 12, 10, 55, 50), ""month""),\n            # (\'20 Mar 2013 10h11\', datetime(2013, 3, 20, 10, 11), ""month""),\n            (""10:06am Dec 11, 2014"", datetime(2014, 12, 11, 10, 6), ""month""),\n            (""September 2nd, 1998"", datetime(1998, 9, 2), ""month""),\n            (\n                ""May 5, 2010 to July 10, 2011"",\n                [datetime(2010, 5, 5), datetime(2011, 7, 10)],\n                ""month"",\n            ),\n            # (\'19 February 2013 year 09:10\', datetime(2013, 2, 19, 9, 10), ""month""),\n            # Numeric dates\n            (""06-17-2014"", datetime(2014, 6, 17), ""month""),\n            (""13/03/2014"", datetime(2014, 3, 13), ""month""),\n            (\n                ""2016-02-04T20:16:26+00:00"",\n                datetime(2016, 2, 4, 20, 16, 26, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            # (\'11. 12. 2014, 08:45:39\', datetime(2014, 11, 12, 8, 45, 39)),\n            (\n                ""2017-02-03T09:04:08Z to 2017-02-03T09:04:09Z"",\n                [\n                    datetime(2017, 2, 3, 9, 4, 8, tzinfo=pytz.utc),\n                    datetime(2017, 2, 3, 9, 4, 9, tzinfo=pytz.utc),\n                ],\n                ""month"",\n            ),\n            # dates from issue https://github.com/akoumjian/datefinder/issues/14\n            (\n                ""i am looking for a date june 4th 1996 to july 3rd 2013"",\n                [datetime(1996, 6, 4), datetime(2013, 7, 3)],\n                ""month"",\n            ),\n            (\n                ""october 27 1994 to be put into effect on june 1 1995"",\n                [datetime(1994, 10, 27), datetime(1995, 6, 1)],\n                ""month"",\n            ),\n            # Simple date range\n            (\n                ""31/08/2012 to 30/08/2013"",\n                [datetime(2012, 8, 31), datetime(2013, 8, 30)],\n                ""month"",\n            ),\n            (\n                ""31 Oct 2021 - 28 Nov 2021"",\n                [datetime(2021, 10, 31), datetime(2021, 11, 28)],\n                ""day""\n            ),\n            # Z dates with and without millis, from https://github.com/akoumjian/datefinder/issues/37\n            (\n                ""2017-02-03T09:04:08.001Z"",\n                datetime(2017, 2, 3, 9, 4, 8, 1000, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            (\n                ""2017-02-03T09:04:08,00123Z"",\n                datetime(2017, 2, 3, 9, 4, 8, 1230, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            (\n                ""2017-02-03T09:04:08Z"",\n                datetime(2017, 2, 3, 9, 4, 8, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            # Year only strings, from https://github.com/akoumjian/datefinder/issues/96\n            (\n                ""Dutta is the recipient of Femina Miss India Universe title in 2004."",\n                datetime(2004, today.month, today.day),\n                ""month"",\n            ),\n            (\n                \'she said that she hit depression after being traumatized on the sets of ""Horn OK"" in 2008.\',\n                datetime(2008, today.month, today.day),\n                ""month"",\n            ),\n            # https://github.com/akoumjian/datefinder/issues/63\n            (""12th day of December, 2001"", datetime(2001, 12, 12), ""month""),\n            (""01/02/03"", datetime(2003, 1, 2, 0, 0, 0, 0), ""month""),\n            (""01/02/03"", datetime(2003, 2, 1, 0, 0, 0, 0), ""day""),\n            (""01/02/03"", datetime(2001, 2, 3, 0, 0, 0, 0), ""year""),\n            (""02/05/2020"", datetime(2020, 2, 5, 0, 0, 0, 0), ""month""),\n            (""02/05/2020"", datetime(2020, 5, 2, 0, 0, 0, 0), ""day""),\n        ],\n    )\n    def test_find_date_strings(input_text, expected_date, first):\n        if isinstance(expected_date, list):\n            matches = list(datefinder.find_dates(input_text, first=first))\n>           assert matches == expected_date\nE           assert [] == [datetime.dat..., 7, 3, 0, 0)]\nE             \nE             Right contains 2 more items, first extra item: datetime.datetime(1996, 6, 4, 0, 0)\nE             \nE             Full diff:\nE             + []\nE             - [\nE             -     datetime.datetime(1996, 6, 4, 0, 0),\nE             -     datetime.datetime(2013, 7, 3, 0, 0),\nE             - ]\n\nrepos\\datefinder\\tests\\test_find_dates.py:119: AssertionError', 'input_text = \'october 27 1994 to be put into effect on june 1 1995\'\nexpected_date = [datetime.datetime(1994, 10, 27, 0, 0), datetime.datetime(1995, 6, 1, 0, 0)]\nfirst = \'month\'\n\n    @pytest.mark.parametrize(\n        (""input_text"", ""expected_date"", ""first""),\n        [\n            ## English Dates\n            # (\'[Sept] 04, 2014.\', datetime(2014, 9, 4), ""month""),\n            (""Tuesday Jul 22, 2014"", datetime(2014, 7, 22), ""month""),\n            # (\'10:04am EDT\', datetime(2012, 11, 13, 14, 4), ""month""),\n            # (\'Friday\', datetime(2012, 11, 9), ""month""),\n            # (\'November 19, 2014 at noon\', datetime(2014, 11, 19, 12, 0), ""month""),\n            (""December 13, 2014 at midnight"", datetime(2014, 12, 13, 0, 0), ""month""),\n            # (\'Nov 25 2014 10:17 pm EST\', datetime(2014, 11, 26, 3, 17), ""month""),\n            # (\'Wed Aug 05 12:00:00 EDT 2015\', datetime(2015, 8, 5, 16, 0), ""month""),\n            (""April 9, 2013 at 6:11 a.m."", datetime(2013, 4, 9, 6, 11), ""month""),\n            (""Aug. 9, 2012 at 2:57 p.m."", datetime(2012, 8, 9, 14, 57), ""month""),\n            (""December 10, 2014, 11:02:21 pm"", datetime(2014, 12, 10, 23, 2, 21), ""month""),\n            (""8:25 a.m. Dec. 12, 2014"", datetime(2014, 12, 12, 8, 25), ""month""),\n            (""2:21 p.m., December 11, 2014"", datetime(2014, 12, 11, 14, 21), ""month""),\n            (""Fri, 12 Dec 2014 10:55:50"", datetime(2014, 12, 12, 10, 55, 50), ""month""),\n            # (\'20 Mar 2013 10h11\', datetime(2013, 3, 20, 10, 11), ""month""),\n            (""10:06am Dec 11, 2014"", datetime(2014, 12, 11, 10, 6), ""month""),\n            (""September 2nd, 1998"", datetime(1998, 9, 2), ""month""),\n            (\n                ""May 5, 2010 to July 10, 2011"",\n                [datetime(2010, 5, 5), datetime(2011, 7, 10)],\n                ""month"",\n            ),\n            # (\'19 February 2013 year 09:10\', datetime(2013, 2, 19, 9, 10), ""month""),\n            # Numeric dates\n            (""06-17-2014"", datetime(2014, 6, 17), ""month""),\n            (""13/03/2014"", datetime(2014, 3, 13), ""month""),\n            (\n                ""2016-02-04T20:16:26+00:00"",\n                datetime(2016, 2, 4, 20, 16, 26, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            # (\'11. 12. 2014, 08:45:39\', datetime(2014, 11, 12, 8, 45, 39)),\n            (\n                ""2017-02-03T09:04:08Z to 2017-02-03T09:04:09Z"",\n                [\n                    datetime(2017, 2, 3, 9, 4, 8, tzinfo=pytz.utc),\n                    datetime(2017, 2, 3, 9, 4, 9, tzinfo=pytz.utc),\n                ],\n                ""month"",\n            ),\n            # dates from issue https://github.com/akoumjian/datefinder/issues/14\n            (\n                ""i am looking for a date june 4th 1996 to july 3rd 2013"",\n                [datetime(1996, 6, 4), datetime(2013, 7, 3)],\n                ""month"",\n            ),\n            (\n                ""october 27 1994 to be put into effect on june 1 1995"",\n                [datetime(1994, 10, 27), datetime(1995, 6, 1)],\n                ""month"",\n            ),\n            # Simple date range\n            (\n                ""31/08/2012 to 30/08/2013"",\n                [datetime(2012, 8, 31), datetime(2013, 8, 30)],\n                ""month"",\n            ),\n            (\n                ""31 Oct 2021 - 28 Nov 2021"",\n                [datetime(2021, 10, 31), datetime(2021, 11, 28)],\n                ""day""\n            ),\n            # Z dates with and without millis, from https://github.com/akoumjian/datefinder/issues/37\n            (\n                ""2017-02-03T09:04:08.001Z"",\n                datetime(2017, 2, 3, 9, 4, 8, 1000, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            (\n                ""2017-02-03T09:04:08,00123Z"",\n                datetime(2017, 2, 3, 9, 4, 8, 1230, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            (\n                ""2017-02-03T09:04:08Z"",\n                datetime(2017, 2, 3, 9, 4, 8, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            # Year only strings, from https://github.com/akoumjian/datefinder/issues/96\n            (\n                ""Dutta is the recipient of Femina Miss India Universe title in 2004."",\n                datetime(2004, today.month, today.day),\n                ""month"",\n            ),\n            (\n                \'she said that she hit depression after being traumatized on the sets of ""Horn OK"" in 2008.\',\n                datetime(2008, today.month, today.day),\n                ""month"",\n            ),\n            # https://github.com/akoumjian/datefinder/issues/63\n            (""12th day of December, 2001"", datetime(2001, 12, 12), ""month""),\n            (""01/02/03"", datetime(2003, 1, 2, 0, 0, 0, 0), ""month""),\n            (""01/02/03"", datetime(2003, 2, 1, 0, 0, 0, 0), ""day""),\n            (""01/02/03"", datetime(2001, 2, 3, 0, 0, 0, 0), ""year""),\n            (""02/05/2020"", datetime(2020, 2, 5, 0, 0, 0, 0), ""month""),\n            (""02/05/2020"", datetime(2020, 5, 2, 0, 0, 0, 0), ""day""),\n        ],\n    )\n    def test_find_date_strings(input_text, expected_date, first):\n        if isinstance(expected_date, list):\n            matches = list(datefinder.find_dates(input_text, first=first))\n>           assert matches == expected_date\nE           assert [] == [datetime.dat..., 6, 1, 0, 0)]\nE             \nE             Right contains 2 more items, first extra item: datetime.datetime(1994, 10, 27, 0, 0)\nE             \nE             Full diff:\nE             + []\nE             - [\nE             -     datetime.datetime(1994, 10, 27, 0, 0),\nE             -     datetime.datetime(1995, 6, 1, 0, 0),\nE             - ]\n\nrepos\\datefinder\\tests\\test_find_dates.py:119: AssertionError', 'input_text = \'31/08/2012 to 30/08/2013\'\nexpected_date = [datetime.datetime(2012, 8, 31, 0, 0), datetime.datetime(2013, 8, 30, 0, 0)]\nfirst = \'month\'\n\n    @pytest.mark.parametrize(\n        (""input_text"", ""expected_date"", ""first""),\n        [\n            ## English Dates\n            # (\'[Sept] 04, 2014.\', datetime(2014, 9, 4), ""month""),\n            (""Tuesday Jul 22, 2014"", datetime(2014, 7, 22), ""month""),\n            # (\'10:04am EDT\', datetime(2012, 11, 13, 14, 4), ""month""),\n            # (\'Friday\', datetime(2012, 11, 9), ""month""),\n            # (\'November 19, 2014 at noon\', datetime(2014, 11, 19, 12, 0), ""month""),\n            (""December 13, 2014 at midnight"", datetime(2014, 12, 13, 0, 0), ""month""),\n            # (\'Nov 25 2014 10:17 pm EST\', datetime(2014, 11, 26, 3, 17), ""month""),\n            # (\'Wed Aug 05 12:00:00 EDT 2015\', datetime(2015, 8, 5, 16, 0), ""month""),\n            (""April 9, 2013 at 6:11 a.m."", datetime(2013, 4, 9, 6, 11), ""month""),\n            (""Aug. 9, 2012 at 2:57 p.m."", datetime(2012, 8, 9, 14, 57), ""month""),\n            (""December 10, 2014, 11:02:21 pm"", datetime(2014, 12, 10, 23, 2, 21), ""month""),\n            (""8:25 a.m. Dec. 12, 2014"", datetime(2014, 12, 12, 8, 25), ""month""),\n            (""2:21 p.m., December 11, 2014"", datetime(2014, 12, 11, 14, 21), ""month""),\n            (""Fri, 12 Dec 2014 10:55:50"", datetime(2014, 12, 12, 10, 55, 50), ""month""),\n            # (\'20 Mar 2013 10h11\', datetime(2013, 3, 20, 10, 11), ""month""),\n            (""10:06am Dec 11, 2014"", datetime(2014, 12, 11, 10, 6), ""month""),\n            (""September 2nd, 1998"", datetime(1998, 9, 2), ""month""),\n            (\n                ""May 5, 2010 to July 10, 2011"",\n                [datetime(2010, 5, 5), datetime(2011, 7, 10)],\n                ""month"",\n            ),\n            # (\'19 February 2013 year 09:10\', datetime(2013, 2, 19, 9, 10), ""month""),\n            # Numeric dates\n            (""06-17-2014"", datetime(2014, 6, 17), ""month""),\n            (""13/03/2014"", datetime(2014, 3, 13), ""month""),\n            (\n                ""2016-02-04T20:16:26+00:00"",\n                datetime(2016, 2, 4, 20, 16, 26, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            # (\'11. 12. 2014, 08:45:39\', datetime(2014, 11, 12, 8, 45, 39)),\n            (\n                ""2017-02-03T09:04:08Z to 2017-02-03T09:04:09Z"",\n                [\n                    datetime(2017, 2, 3, 9, 4, 8, tzinfo=pytz.utc),\n                    datetime(2017, 2, 3, 9, 4, 9, tzinfo=pytz.utc),\n                ],\n                ""month"",\n            ),\n            # dates from issue https://github.com/akoumjian/datefinder/issues/14\n            (\n                ""i am looking for a date june 4th 1996 to july 3rd 2013"",\n                [datetime(1996, 6, 4), datetime(2013, 7, 3)],\n                ""month"",\n            ),\n            (\n                ""october 27 1994 to be put into effect on june 1 1995"",\n                [datetime(1994, 10, 27), datetime(1995, 6, 1)],\n                ""month"",\n            ),\n            # Simple date range\n            (\n                ""31/08/2012 to 30/08/2013"",\n                [datetime(2012, 8, 31), datetime(2013, 8, 30)],\n                ""month"",\n            ),\n            (\n                ""31 Oct 2021 - 28 Nov 2021"",\n                [datetime(2021, 10, 31), datetime(2021, 11, 28)],\n                ""day""\n            ),\n            # Z dates with and without millis, from https://github.com/akoumjian/datefinder/issues/37\n            (\n                ""2017-02-03T09:04:08.001Z"",\n                datetime(2017, 2, 3, 9, 4, 8, 1000, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            (\n                ""2017-02-03T09:04:08,00123Z"",\n                datetime(2017, 2, 3, 9, 4, 8, 1230, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            (\n                ""2017-02-03T09:04:08Z"",\n                datetime(2017, 2, 3, 9, 4, 8, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            # Year only strings, from https://github.com/akoumjian/datefinder/issues/96\n            (\n                ""Dutta is the recipient of Femina Miss India Universe title in 2004."",\n                datetime(2004, today.month, today.day),\n                ""month"",\n            ),\n            (\n                \'she said that she hit depression after being traumatized on the sets of ""Horn OK"" in 2008.\',\n                datetime(2008, today.month, today.day),\n                ""month"",\n            ),\n            # https://github.com/akoumjian/datefinder/issues/63\n            (""12th day of December, 2001"", datetime(2001, 12, 12), ""month""),\n            (""01/02/03"", datetime(2003, 1, 2, 0, 0, 0, 0), ""month""),\n            (""01/02/03"", datetime(2003, 2, 1, 0, 0, 0, 0), ""day""),\n            (""01/02/03"", datetime(2001, 2, 3, 0, 0, 0, 0), ""year""),\n            (""02/05/2020"", datetime(2020, 2, 5, 0, 0, 0, 0), ""month""),\n            (""02/05/2020"", datetime(2020, 5, 2, 0, 0, 0, 0), ""day""),\n        ],\n    )\n    def test_find_date_strings(input_text, expected_date, first):\n        if isinstance(expected_date, list):\n            matches = list(datefinder.find_dates(input_text, first=first))\n>           assert matches == expected_date\nE           assert [] == [datetime.dat... 8, 30, 0, 0)]\nE             \nE             Right contains 2 more items, first extra item: datetime.datetime(2012, 8, 31, 0, 0)\nE             \nE             Full diff:\nE             + []\nE             - [\nE             -     datetime.datetime(2012, 8, 31, 0, 0),\nE             -     datetime.datetime(2013, 8, 30, 0, 0),\nE             - ]\n\nrepos\\datefinder\\tests\\test_find_dates.py:119: AssertionError', 'input_text = \'31 Oct 2021 - 28 Nov 2021\'\nexpected_date = [datetime.datetime(2021, 10, 31, 0, 0), datetime.datetime(2021, 11, 28, 0, 0)]\nfirst = \'day\'\n\n    @pytest.mark.parametrize(\n        (""input_text"", ""expected_date"", ""first""),\n        [\n            ## English Dates\n            # (\'[Sept] 04, 2014.\', datetime(2014, 9, 4), ""month""),\n            (""Tuesday Jul 22, 2014"", datetime(2014, 7, 22), ""month""),\n            # (\'10:04am EDT\', datetime(2012, 11, 13, 14, 4), ""month""),\n            # (\'Friday\', datetime(2012, 11, 9), ""month""),\n            # (\'November 19, 2014 at noon\', datetime(2014, 11, 19, 12, 0), ""month""),\n            (""December 13, 2014 at midnight"", datetime(2014, 12, 13, 0, 0), ""month""),\n            # (\'Nov 25 2014 10:17 pm EST\', datetime(2014, 11, 26, 3, 17), ""month""),\n            # (\'Wed Aug 05 12:00:00 EDT 2015\', datetime(2015, 8, 5, 16, 0), ""month""),\n            (""April 9, 2013 at 6:11 a.m."", datetime(2013, 4, 9, 6, 11), ""month""),\n            (""Aug. 9, 2012 at 2:57 p.m."", datetime(2012, 8, 9, 14, 57), ""month""),\n            (""December 10, 2014, 11:02:21 pm"", datetime(2014, 12, 10, 23, 2, 21), ""month""),\n            (""8:25 a.m. Dec. 12, 2014"", datetime(2014, 12, 12, 8, 25), ""month""),\n            (""2:21 p.m., December 11, 2014"", datetime(2014, 12, 11, 14, 21), ""month""),\n            (""Fri, 12 Dec 2014 10:55:50"", datetime(2014, 12, 12, 10, 55, 50), ""month""),\n            # (\'20 Mar 2013 10h11\', datetime(2013, 3, 20, 10, 11), ""month""),\n            (""10:06am Dec 11, 2014"", datetime(2014, 12, 11, 10, 6), ""month""),\n            (""September 2nd, 1998"", datetime(1998, 9, 2), ""month""),\n            (\n                ""May 5, 2010 to July 10, 2011"",\n                [datetime(2010, 5, 5), datetime(2011, 7, 10)],\n                ""month"",\n            ),\n            # (\'19 February 2013 year 09:10\', datetime(2013, 2, 19, 9, 10), ""month""),\n            # Numeric dates\n            (""06-17-2014"", datetime(2014, 6, 17), ""month""),\n            (""13/03/2014"", datetime(2014, 3, 13), ""month""),\n            (\n                ""2016-02-04T20:16:26+00:00"",\n                datetime(2016, 2, 4, 20, 16, 26, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            # (\'11. 12. 2014, 08:45:39\', datetime(2014, 11, 12, 8, 45, 39)),\n            (\n                ""2017-02-03T09:04:08Z to 2017-02-03T09:04:09Z"",\n                [\n                    datetime(2017, 2, 3, 9, 4, 8, tzinfo=pytz.utc),\n                    datetime(2017, 2, 3, 9, 4, 9, tzinfo=pytz.utc),\n                ],\n                ""month"",\n            ),\n            # dates from issue https://github.com/akoumjian/datefinder/issues/14\n            (\n                ""i am looking for a date june 4th 1996 to july 3rd 2013"",\n                [datetime(1996, 6, 4), datetime(2013, 7, 3)],\n                ""month"",\n            ),\n            (\n                ""october 27 1994 to be put into effect on june 1 1995"",\n                [datetime(1994, 10, 27), datetime(1995, 6, 1)],\n                ""month"",\n            ),\n            # Simple date range\n            (\n                ""31/08/2012 to 30/08/2013"",\n                [datetime(2012, 8, 31), datetime(2013, 8, 30)],\n                ""month"",\n            ),\n            (\n                ""31 Oct 2021 - 28 Nov 2021"",\n                [datetime(2021, 10, 31), datetime(2021, 11, 28)],\n                ""day""\n            ),\n            # Z dates with and without millis, from https://github.com/akoumjian/datefinder/issues/37\n            (\n                ""2017-02-03T09:04:08.001Z"",\n                datetime(2017, 2, 3, 9, 4, 8, 1000, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            (\n                ""2017-02-03T09:04:08,00123Z"",\n                datetime(2017, 2, 3, 9, 4, 8, 1230, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            (\n                ""2017-02-03T09:04:08Z"",\n                datetime(2017, 2, 3, 9, 4, 8, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            # Year only strings, from https://github.com/akoumjian/datefinder/issues/96\n            (\n                ""Dutta is the recipient of Femina Miss India Universe title in 2004."",\n                datetime(2004, today.month, today.day),\n                ""month"",\n            ),\n            (\n                \'she said that she hit depression after being traumatized on the sets of ""Horn OK"" in 2008.\',\n                datetime(2008, today.month, today.day),\n                ""month"",\n            ),\n            # https://github.com/akoumjian/datefinder/issues/63\n            (""12th day of December, 2001"", datetime(2001, 12, 12), ""month""),\n            (""01/02/03"", datetime(2003, 1, 2, 0, 0, 0, 0), ""month""),\n            (""01/02/03"", datetime(2003, 2, 1, 0, 0, 0, 0), ""day""),\n            (""01/02/03"", datetime(2001, 2, 3, 0, 0, 0, 0), ""year""),\n            (""02/05/2020"", datetime(2020, 2, 5, 0, 0, 0, 0), ""month""),\n            (""02/05/2020"", datetime(2020, 5, 2, 0, 0, 0, 0), ""day""),\n        ],\n    )\n    def test_find_date_strings(input_text, expected_date, first):\n        if isinstance(expected_date, list):\n            matches = list(datefinder.find_dates(input_text, first=first))\n>           assert matches == expected_date\nE           assert [] == [datetime.dat...11, 28, 0, 0)]\nE             \nE             Right contains 2 more items, first extra item: datetime.datetime(2021, 10, 31, 0, 0)\nE             \nE             Full diff:\nE             + []\nE             - [\nE             -     datetime.datetime(2021, 10, 31, 0, 0),\nE             -     datetime.datetime(2021, 11, 28, 0, 0),\nE             - ]\n\nrepos\\datefinder\\tests\\test_find_dates.py:119: AssertionError', 'input_text = \'2017-02-03T09:04:08.001Z\'\nexpected_date = datetime.datetime(2017, 2, 3, 9, 4, 8, 1000, tzinfo=<UTC>)\nfirst = \'month\'\n\n    @pytest.mark.parametrize(\n        (""input_text"", ""expected_date"", ""first""),\n        [\n            ## English Dates\n            # (\'[Sept] 04, 2014.\', datetime(2014, 9, 4), ""month""),\n            (""Tuesday Jul 22, 2014"", datetime(2014, 7, 22), ""month""),\n            # (\'10:04am EDT\', datetime(2012, 11, 13, 14, 4), ""month""),\n            # (\'Friday\', datetime(2012, 11, 9), ""month""),\n            # (\'November 19, 2014 at noon\', datetime(2014, 11, 19, 12, 0), ""month""),\n            (""December 13, 2014 at midnight"", datetime(2014, 12, 13, 0, 0), ""month""),\n            # (\'Nov 25 2014 10:17 pm EST\', datetime(2014, 11, 26, 3, 17), ""month""),\n            # (\'Wed Aug 05 12:00:00 EDT 2015\', datetime(2015, 8, 5, 16, 0), ""month""),\n            (""April 9, 2013 at 6:11 a.m."", datetime(2013, 4, 9, 6, 11), ""month""),\n            (""Aug. 9, 2012 at 2:57 p.m."", datetime(2012, 8, 9, 14, 57), ""month""),\n            (""December 10, 2014, 11:02:21 pm"", datetime(2014, 12, 10, 23, 2, 21), ""month""),\n            (""8:25 a.m. Dec. 12, 2014"", datetime(2014, 12, 12, 8, 25), ""month""),\n            (""2:21 p.m., December 11, 2014"", datetime(2014, 12, 11, 14, 21), ""month""),\n            (""Fri, 12 Dec 2014 10:55:50"", datetime(2014, 12, 12, 10, 55, 50), ""month""),\n            # (\'20 Mar 2013 10h11\', datetime(2013, 3, 20, 10, 11), ""month""),\n            (""10:06am Dec 11, 2014"", datetime(2014, 12, 11, 10, 6), ""month""),\n            (""September 2nd, 1998"", datetime(1998, 9, 2), ""month""),\n            (\n                ""May 5, 2010 to July 10, 2011"",\n                [datetime(2010, 5, 5), datetime(2011, 7, 10)],\n                ""month"",\n            ),\n            # (\'19 February 2013 year 09:10\', datetime(2013, 2, 19, 9, 10), ""month""),\n            # Numeric dates\n            (""06-17-2014"", datetime(2014, 6, 17), ""month""),\n            (""13/03/2014"", datetime(2014, 3, 13), ""month""),\n            (\n                ""2016-02-04T20:16:26+00:00"",\n                datetime(2016, 2, 4, 20, 16, 26, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            # (\'11. 12. 2014, 08:45:39\', datetime(2014, 11, 12, 8, 45, 39)),\n            (\n                ""2017-02-03T09:04:08Z to 2017-02-03T09:04:09Z"",\n                [\n                    datetime(2017, 2, 3, 9, 4, 8, tzinfo=pytz.utc),\n                    datetime(2017, 2, 3, 9, 4, 9, tzinfo=pytz.utc),\n                ],\n                ""month"",\n            ),\n            # dates from issue https://github.com/akoumjian/datefinder/issues/14\n            (\n                ""i am looking for a date june 4th 1996 to july 3rd 2013"",\n                [datetime(1996, 6, 4), datetime(2013, 7, 3)],\n                ""month"",\n            ),\n            (\n                ""october 27 1994 to be put into effect on june 1 1995"",\n                [datetime(1994, 10, 27), datetime(1995, 6, 1)],\n                ""month"",\n            ),\n            # Simple date range\n            (\n                ""31/08/2012 to 30/08/2013"",\n                [datetime(2012, 8, 31), datetime(2013, 8, 30)],\n                ""month"",\n            ),\n            (\n                ""31 Oct 2021 - 28 Nov 2021"",\n                [datetime(2021, 10, 31), datetime(2021, 11, 28)],\n                ""day""\n            ),\n            # Z dates with and without millis, from https://github.com/akoumjian/datefinder/issues/37\n            (\n                ""2017-02-03T09:04:08.001Z"",\n                datetime(2017, 2, 3, 9, 4, 8, 1000, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            (\n                ""2017-02-03T09:04:08,00123Z"",\n                datetime(2017, 2, 3, 9, 4, 8, 1230, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            (\n                ""2017-02-03T09:04:08Z"",\n                datetime(2017, 2, 3, 9, 4, 8, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            # Year only strings, from https://github.com/akoumjian/datefinder/issues/96\n            (\n                ""Dutta is the recipient of Femina Miss India Universe title in 2004."",\n                datetime(2004, today.month, today.day),\n                ""month"",\n            ),\n            (\n                \'she said that she hit depression after being traumatized on the sets of ""Horn OK"" in 2008.\',\n                datetime(2008, today.month, today.day),\n                ""month"",\n            ),\n            # https://github.com/akoumjian/datefinder/issues/63\n            (""12th day of December, 2001"", datetime(2001, 12, 12), ""month""),\n            (""01/02/03"", datetime(2003, 1, 2, 0, 0, 0, 0), ""month""),\n            (""01/02/03"", datetime(2003, 2, 1, 0, 0, 0, 0), ""day""),\n            (""01/02/03"", datetime(2001, 2, 3, 0, 0, 0, 0), ""year""),\n            (""02/05/2020"", datetime(2020, 2, 5, 0, 0, 0, 0), ""month""),\n            (""02/05/2020"", datetime(2020, 5, 2, 0, 0, 0, 0), ""day""),\n        ],\n    )\n    def test_find_date_strings(input_text, expected_date, first):\n        if isinstance(expected_date, list):\n            matches = list(datefinder.find_dates(input_text, first=first))\n            assert matches == expected_date\n        else:\n            return_date = None\n            for return_date in datefinder.find_dates(input_text, first=first):\n                assert return_date == expected_date\n>           assert return_date is not None, \'Did not find date for test line: ""{}""\'.format(\n                input_text\n            )  # handles dates that were never matched\nE           AssertionError: Did not find date for test line: ""2017-02-03T09:04:08.001Z""\nE           assert None is not None\n\nrepos\\datefinder\\tests\\test_find_dates.py:124: AssertionError', 'input_text = \'2017-02-03T09:04:08,00123Z\'\nexpected_date = datetime.datetime(2017, 2, 3, 9, 4, 8, 1230, tzinfo=<UTC>)\nfirst = \'month\'\n\n    @pytest.mark.parametrize(\n        (""input_text"", ""expected_date"", ""first""),\n        [\n            ## English Dates\n            # (\'[Sept] 04, 2014.\', datetime(2014, 9, 4), ""month""),\n            (""Tuesday Jul 22, 2014"", datetime(2014, 7, 22), ""month""),\n            # (\'10:04am EDT\', datetime(2012, 11, 13, 14, 4), ""month""),\n            # (\'Friday\', datetime(2012, 11, 9), ""month""),\n            # (\'November 19, 2014 at noon\', datetime(2014, 11, 19, 12, 0), ""month""),\n            (""December 13, 2014 at midnight"", datetime(2014, 12, 13, 0, 0), ""month""),\n            # (\'Nov 25 2014 10:17 pm EST\', datetime(2014, 11, 26, 3, 17), ""month""),\n            # (\'Wed Aug 05 12:00:00 EDT 2015\', datetime(2015, 8, 5, 16, 0), ""month""),\n            (""April 9, 2013 at 6:11 a.m."", datetime(2013, 4, 9, 6, 11), ""month""),\n            (""Aug. 9, 2012 at 2:57 p.m."", datetime(2012, 8, 9, 14, 57), ""month""),\n            (""December 10, 2014, 11:02:21 pm"", datetime(2014, 12, 10, 23, 2, 21), ""month""),\n            (""8:25 a.m. Dec. 12, 2014"", datetime(2014, 12, 12, 8, 25), ""month""),\n            (""2:21 p.m., December 11, 2014"", datetime(2014, 12, 11, 14, 21), ""month""),\n            (""Fri, 12 Dec 2014 10:55:50"", datetime(2014, 12, 12, 10, 55, 50), ""month""),\n            # (\'20 Mar 2013 10h11\', datetime(2013, 3, 20, 10, 11), ""month""),\n            (""10:06am Dec 11, 2014"", datetime(2014, 12, 11, 10, 6), ""month""),\n            (""September 2nd, 1998"", datetime(1998, 9, 2), ""month""),\n            (\n                ""May 5, 2010 to July 10, 2011"",\n                [datetime(2010, 5, 5), datetime(2011, 7, 10)],\n                ""month"",\n            ),\n            # (\'19 February 2013 year 09:10\', datetime(2013, 2, 19, 9, 10), ""month""),\n            # Numeric dates\n            (""06-17-2014"", datetime(2014, 6, 17), ""month""),\n            (""13/03/2014"", datetime(2014, 3, 13), ""month""),\n            (\n                ""2016-02-04T20:16:26+00:00"",\n                datetime(2016, 2, 4, 20, 16, 26, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            # (\'11. 12. 2014, 08:45:39\', datetime(2014, 11, 12, 8, 45, 39)),\n            (\n                ""2017-02-03T09:04:08Z to 2017-02-03T09:04:09Z"",\n                [\n                    datetime(2017, 2, 3, 9, 4, 8, tzinfo=pytz.utc),\n                    datetime(2017, 2, 3, 9, 4, 9, tzinfo=pytz.utc),\n                ],\n                ""month"",\n            ),\n            # dates from issue https://github.com/akoumjian/datefinder/issues/14\n            (\n                ""i am looking for a date june 4th 1996 to july 3rd 2013"",\n                [datetime(1996, 6, 4), datetime(2013, 7, 3)],\n                ""month"",\n            ),\n            (\n                ""october 27 1994 to be put into effect on june 1 1995"",\n                [datetime(1994, 10, 27), datetime(1995, 6, 1)],\n                ""month"",\n            ),\n            # Simple date range\n            (\n                ""31/08/2012 to 30/08/2013"",\n                [datetime(2012, 8, 31), datetime(2013, 8, 30)],\n                ""month"",\n            ),\n            (\n                ""31 Oct 2021 - 28 Nov 2021"",\n                [datetime(2021, 10, 31), datetime(2021, 11, 28)],\n                ""day""\n            ),\n            # Z dates with and without millis, from https://github.com/akoumjian/datefinder/issues/37\n            (\n                ""2017-02-03T09:04:08.001Z"",\n                datetime(2017, 2, 3, 9, 4, 8, 1000, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            (\n                ""2017-02-03T09:04:08,00123Z"",\n                datetime(2017, 2, 3, 9, 4, 8, 1230, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            (\n                ""2017-02-03T09:04:08Z"",\n                datetime(2017, 2, 3, 9, 4, 8, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            # Year only strings, from https://github.com/akoumjian/datefinder/issues/96\n            (\n                ""Dutta is the recipient of Femina Miss India Universe title in 2004."",\n                datetime(2004, today.month, today.day),\n                ""month"",\n            ),\n            (\n                \'she said that she hit depression after being traumatized on the sets of ""Horn OK"" in 2008.\',\n                datetime(2008, today.month, today.day),\n                ""month"",\n            ),\n            # https://github.com/akoumjian/datefinder/issues/63\n            (""12th day of December, 2001"", datetime(2001, 12, 12), ""month""),\n            (""01/02/03"", datetime(2003, 1, 2, 0, 0, 0, 0), ""month""),\n            (""01/02/03"", datetime(2003, 2, 1, 0, 0, 0, 0), ""day""),\n            (""01/02/03"", datetime(2001, 2, 3, 0, 0, 0, 0), ""year""),\n            (""02/05/2020"", datetime(2020, 2, 5, 0, 0, 0, 0), ""month""),\n            (""02/05/2020"", datetime(2020, 5, 2, 0, 0, 0, 0), ""day""),\n        ],\n    )\n    def test_find_date_strings(input_text, expected_date, first):\n        if isinstance(expected_date, list):\n            matches = list(datefinder.find_dates(input_text, first=first))\n            assert matches == expected_date\n        else:\n            return_date = None\n            for return_date in datefinder.find_dates(input_text, first=first):\n                assert return_date == expected_date\n>           assert return_date is not None, \'Did not find date for test line: ""{}""\'.format(\n                input_text\n            )  # handles dates that were never matched\nE           AssertionError: Did not find date for test line: ""2017-02-03T09:04:08,00123Z""\nE           assert None is not None\n\nrepos\\datefinder\\tests\\test_find_dates.py:124: AssertionError', 'input_text = \'2017-02-03T09:04:08Z\'\nexpected_date = datetime.datetime(2017, 2, 3, 9, 4, 8, tzinfo=<UTC>)\nfirst = \'month\'\n\n    @pytest.mark.parametrize(\n        (""input_text"", ""expected_date"", ""first""),\n        [\n            ## English Dates\n            # (\'[Sept] 04, 2014.\', datetime(2014, 9, 4), ""month""),\n            (""Tuesday Jul 22, 2014"", datetime(2014, 7, 22), ""month""),\n            # (\'10:04am EDT\', datetime(2012, 11, 13, 14, 4), ""month""),\n            # (\'Friday\', datetime(2012, 11, 9), ""month""),\n            # (\'November 19, 2014 at noon\', datetime(2014, 11, 19, 12, 0), ""month""),\n            (""December 13, 2014 at midnight"", datetime(2014, 12, 13, 0, 0), ""month""),\n            # (\'Nov 25 2014 10:17 pm EST\', datetime(2014, 11, 26, 3, 17), ""month""),\n            # (\'Wed Aug 05 12:00:00 EDT 2015\', datetime(2015, 8, 5, 16, 0), ""month""),\n            (""April 9, 2013 at 6:11 a.m."", datetime(2013, 4, 9, 6, 11), ""month""),\n            (""Aug. 9, 2012 at 2:57 p.m."", datetime(2012, 8, 9, 14, 57), ""month""),\n            (""December 10, 2014, 11:02:21 pm"", datetime(2014, 12, 10, 23, 2, 21), ""month""),\n            (""8:25 a.m. Dec. 12, 2014"", datetime(2014, 12, 12, 8, 25), ""month""),\n            (""2:21 p.m., December 11, 2014"", datetime(2014, 12, 11, 14, 21), ""month""),\n            (""Fri, 12 Dec 2014 10:55:50"", datetime(2014, 12, 12, 10, 55, 50), ""month""),\n            # (\'20 Mar 2013 10h11\', datetime(2013, 3, 20, 10, 11), ""month""),\n            (""10:06am Dec 11, 2014"", datetime(2014, 12, 11, 10, 6), ""month""),\n            (""September 2nd, 1998"", datetime(1998, 9, 2), ""month""),\n            (\n                ""May 5, 2010 to July 10, 2011"",\n                [datetime(2010, 5, 5), datetime(2011, 7, 10)],\n                ""month"",\n            ),\n            # (\'19 February 2013 year 09:10\', datetime(2013, 2, 19, 9, 10), ""month""),\n            # Numeric dates\n            (""06-17-2014"", datetime(2014, 6, 17), ""month""),\n            (""13/03/2014"", datetime(2014, 3, 13), ""month""),\n            (\n                ""2016-02-04T20:16:26+00:00"",\n                datetime(2016, 2, 4, 20, 16, 26, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            # (\'11. 12. 2014, 08:45:39\', datetime(2014, 11, 12, 8, 45, 39)),\n            (\n                ""2017-02-03T09:04:08Z to 2017-02-03T09:04:09Z"",\n                [\n                    datetime(2017, 2, 3, 9, 4, 8, tzinfo=pytz.utc),\n                    datetime(2017, 2, 3, 9, 4, 9, tzinfo=pytz.utc),\n                ],\n                ""month"",\n            ),\n            # dates from issue https://github.com/akoumjian/datefinder/issues/14\n            (\n                ""i am looking for a date june 4th 1996 to july 3rd 2013"",\n                [datetime(1996, 6, 4), datetime(2013, 7, 3)],\n                ""month"",\n            ),\n            (\n                ""october 27 1994 to be put into effect on june 1 1995"",\n                [datetime(1994, 10, 27), datetime(1995, 6, 1)],\n                ""month"",\n            ),\n            # Simple date range\n            (\n                ""31/08/2012 to 30/08/2013"",\n                [datetime(2012, 8, 31), datetime(2013, 8, 30)],\n                ""month"",\n            ),\n            (\n                ""31 Oct 2021 - 28 Nov 2021"",\n                [datetime(2021, 10, 31), datetime(2021, 11, 28)],\n                ""day""\n            ),\n            # Z dates with and without millis, from https://github.com/akoumjian/datefinder/issues/37\n            (\n                ""2017-02-03T09:04:08.001Z"",\n                datetime(2017, 2, 3, 9, 4, 8, 1000, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            (\n                ""2017-02-03T09:04:08,00123Z"",\n                datetime(2017, 2, 3, 9, 4, 8, 1230, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            (\n                ""2017-02-03T09:04:08Z"",\n                datetime(2017, 2, 3, 9, 4, 8, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            # Year only strings, from https://github.com/akoumjian/datefinder/issues/96\n            (\n                ""Dutta is the recipient of Femina Miss India Universe title in 2004."",\n                datetime(2004, today.month, today.day),\n                ""month"",\n            ),\n            (\n                \'she said that she hit depression after being traumatized on the sets of ""Horn OK"" in 2008.\',\n                datetime(2008, today.month, today.day),\n                ""month"",\n            ),\n            # https://github.com/akoumjian/datefinder/issues/63\n            (""12th day of December, 2001"", datetime(2001, 12, 12), ""month""),\n            (""01/02/03"", datetime(2003, 1, 2, 0, 0, 0, 0), ""month""),\n            (""01/02/03"", datetime(2003, 2, 1, 0, 0, 0, 0), ""day""),\n            (""01/02/03"", datetime(2001, 2, 3, 0, 0, 0, 0), ""year""),\n            (""02/05/2020"", datetime(2020, 2, 5, 0, 0, 0, 0), ""month""),\n            (""02/05/2020"", datetime(2020, 5, 2, 0, 0, 0, 0), ""day""),\n        ],\n    )\n    def test_find_date_strings(input_text, expected_date, first):\n        if isinstance(expected_date, list):\n            matches = list(datefinder.find_dates(input_text, first=first))\n            assert matches == expected_date\n        else:\n            return_date = None\n            for return_date in datefinder.find_dates(input_text, first=first):\n                assert return_date == expected_date\n>           assert return_date is not None, \'Did not find date for test line: ""{}""\'.format(\n                input_text\n            )  # handles dates that were never matched\nE           AssertionError: Did not find date for test line: ""2017-02-03T09:04:08Z""\nE           assert None is not None\n\nrepos\\datefinder\\tests\\test_find_dates.py:124: AssertionError', 'input_text = \'Dutta is the recipient of Femina Miss India Universe title in 2004.\'\nexpected_date = datetime.datetime(2004, 4, 14, 0, 0), first = \'month\'\n\n    @pytest.mark.parametrize(\n        (""input_text"", ""expected_date"", ""first""),\n        [\n            ## English Dates\n            # (\'[Sept] 04, 2014.\', datetime(2014, 9, 4), ""month""),\n            (""Tuesday Jul 22, 2014"", datetime(2014, 7, 22), ""month""),\n            # (\'10:04am EDT\', datetime(2012, 11, 13, 14, 4), ""month""),\n            # (\'Friday\', datetime(2012, 11, 9), ""month""),\n            # (\'November 19, 2014 at noon\', datetime(2014, 11, 19, 12, 0), ""month""),\n            (""December 13, 2014 at midnight"", datetime(2014, 12, 13, 0, 0), ""month""),\n            # (\'Nov 25 2014 10:17 pm EST\', datetime(2014, 11, 26, 3, 17), ""month""),\n            # (\'Wed Aug 05 12:00:00 EDT 2015\', datetime(2015, 8, 5, 16, 0), ""month""),\n            (""April 9, 2013 at 6:11 a.m."", datetime(2013, 4, 9, 6, 11), ""month""),\n            (""Aug. 9, 2012 at 2:57 p.m."", datetime(2012, 8, 9, 14, 57), ""month""),\n            (""December 10, 2014, 11:02:21 pm"", datetime(2014, 12, 10, 23, 2, 21), ""month""),\n            (""8:25 a.m. Dec. 12, 2014"", datetime(2014, 12, 12, 8, 25), ""month""),\n            (""2:21 p.m., December 11, 2014"", datetime(2014, 12, 11, 14, 21), ""month""),\n            (""Fri, 12 Dec 2014 10:55:50"", datetime(2014, 12, 12, 10, 55, 50), ""month""),\n            # (\'20 Mar 2013 10h11\', datetime(2013, 3, 20, 10, 11), ""month""),\n            (""10:06am Dec 11, 2014"", datetime(2014, 12, 11, 10, 6), ""month""),\n            (""September 2nd, 1998"", datetime(1998, 9, 2), ""month""),\n            (\n                ""May 5, 2010 to July 10, 2011"",\n                [datetime(2010, 5, 5), datetime(2011, 7, 10)],\n                ""month"",\n            ),\n            # (\'19 February 2013 year 09:10\', datetime(2013, 2, 19, 9, 10), ""month""),\n            # Numeric dates\n            (""06-17-2014"", datetime(2014, 6, 17), ""month""),\n            (""13/03/2014"", datetime(2014, 3, 13), ""month""),\n            (\n                ""2016-02-04T20:16:26+00:00"",\n                datetime(2016, 2, 4, 20, 16, 26, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            # (\'11. 12. 2014, 08:45:39\', datetime(2014, 11, 12, 8, 45, 39)),\n            (\n                ""2017-02-03T09:04:08Z to 2017-02-03T09:04:09Z"",\n                [\n                    datetime(2017, 2, 3, 9, 4, 8, tzinfo=pytz.utc),\n                    datetime(2017, 2, 3, 9, 4, 9, tzinfo=pytz.utc),\n                ],\n                ""month"",\n            ),\n            # dates from issue https://github.com/akoumjian/datefinder/issues/14\n            (\n                ""i am looking for a date june 4th 1996 to july 3rd 2013"",\n                [datetime(1996, 6, 4), datetime(2013, 7, 3)],\n                ""month"",\n            ),\n            (\n                ""october 27 1994 to be put into effect on june 1 1995"",\n                [datetime(1994, 10, 27), datetime(1995, 6, 1)],\n                ""month"",\n            ),\n            # Simple date range\n            (\n                ""31/08/2012 to 30/08/2013"",\n                [datetime(2012, 8, 31), datetime(2013, 8, 30)],\n                ""month"",\n            ),\n            (\n                ""31 Oct 2021 - 28 Nov 2021"",\n                [datetime(2021, 10, 31), datetime(2021, 11, 28)],\n                ""day""\n            ),\n            # Z dates with and without millis, from https://github.com/akoumjian/datefinder/issues/37\n            (\n                ""2017-02-03T09:04:08.001Z"",\n                datetime(2017, 2, 3, 9, 4, 8, 1000, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            (\n                ""2017-02-03T09:04:08,00123Z"",\n                datetime(2017, 2, 3, 9, 4, 8, 1230, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            (\n                ""2017-02-03T09:04:08Z"",\n                datetime(2017, 2, 3, 9, 4, 8, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            # Year only strings, from https://github.com/akoumjian/datefinder/issues/96\n            (\n                ""Dutta is the recipient of Femina Miss India Universe title in 2004."",\n                datetime(2004, today.month, today.day),\n                ""month"",\n            ),\n            (\n                \'she said that she hit depression after being traumatized on the sets of ""Horn OK"" in 2008.\',\n                datetime(2008, today.month, today.day),\n                ""month"",\n            ),\n            # https://github.com/akoumjian/datefinder/issues/63\n            (""12th day of December, 2001"", datetime(2001, 12, 12), ""month""),\n            (""01/02/03"", datetime(2003, 1, 2, 0, 0, 0, 0), ""month""),\n            (""01/02/03"", datetime(2003, 2, 1, 0, 0, 0, 0), ""day""),\n            (""01/02/03"", datetime(2001, 2, 3, 0, 0, 0, 0), ""year""),\n            (""02/05/2020"", datetime(2020, 2, 5, 0, 0, 0, 0), ""month""),\n            (""02/05/2020"", datetime(2020, 5, 2, 0, 0, 0, 0), ""day""),\n        ],\n    )\n    def test_find_date_strings(input_text, expected_date, first):\n        if isinstance(expected_date, list):\n            matches = list(datefinder.find_dates(input_text, first=first))\n            assert matches == expected_date\n        else:\n            return_date = None\n            for return_date in datefinder.find_dates(input_text, first=first):\n                assert return_date == expected_date\n>           assert return_date is not None, \'Did not find date for test line: ""{}""\'.format(\n                input_text\n            )  # handles dates that were never matched\nE           AssertionError: Did not find date for test line: ""Dutta is the recipient of Femina Miss India Universe title in 2004.""\nE           assert None is not None\n\nrepos\\datefinder\\tests\\test_find_dates.py:124: AssertionError', 'input_text = \'she said that she hit depression after being traumatized on the sets of ""Horn OK"" in 2008.\'\nexpected_date = datetime.datetime(2008, 4, 14, 0, 0), first = \'month\'\n\n    @pytest.mark.parametrize(\n        (""input_text"", ""expected_date"", ""first""),\n        [\n            ## English Dates\n            # (\'[Sept] 04, 2014.\', datetime(2014, 9, 4), ""month""),\n            (""Tuesday Jul 22, 2014"", datetime(2014, 7, 22), ""month""),\n            # (\'10:04am EDT\', datetime(2012, 11, 13, 14, 4), ""month""),\n            # (\'Friday\', datetime(2012, 11, 9), ""month""),\n            # (\'November 19, 2014 at noon\', datetime(2014, 11, 19, 12, 0), ""month""),\n            (""December 13, 2014 at midnight"", datetime(2014, 12, 13, 0, 0), ""month""),\n            # (\'Nov 25 2014 10:17 pm EST\', datetime(2014, 11, 26, 3, 17), ""month""),\n            # (\'Wed Aug 05 12:00:00 EDT 2015\', datetime(2015, 8, 5, 16, 0), ""month""),\n            (""April 9, 2013 at 6:11 a.m."", datetime(2013, 4, 9, 6, 11), ""month""),\n            (""Aug. 9, 2012 at 2:57 p.m."", datetime(2012, 8, 9, 14, 57), ""month""),\n            (""December 10, 2014, 11:02:21 pm"", datetime(2014, 12, 10, 23, 2, 21), ""month""),\n            (""8:25 a.m. Dec. 12, 2014"", datetime(2014, 12, 12, 8, 25), ""month""),\n            (""2:21 p.m., December 11, 2014"", datetime(2014, 12, 11, 14, 21), ""month""),\n            (""Fri, 12 Dec 2014 10:55:50"", datetime(2014, 12, 12, 10, 55, 50), ""month""),\n            # (\'20 Mar 2013 10h11\', datetime(2013, 3, 20, 10, 11), ""month""),\n            (""10:06am Dec 11, 2014"", datetime(2014, 12, 11, 10, 6), ""month""),\n            (""September 2nd, 1998"", datetime(1998, 9, 2), ""month""),\n            (\n                ""May 5, 2010 to July 10, 2011"",\n                [datetime(2010, 5, 5), datetime(2011, 7, 10)],\n                ""month"",\n            ),\n            # (\'19 February 2013 year 09:10\', datetime(2013, 2, 19, 9, 10), ""month""),\n            # Numeric dates\n            (""06-17-2014"", datetime(2014, 6, 17), ""month""),\n            (""13/03/2014"", datetime(2014, 3, 13), ""month""),\n            (\n                ""2016-02-04T20:16:26+00:00"",\n                datetime(2016, 2, 4, 20, 16, 26, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            # (\'11. 12. 2014, 08:45:39\', datetime(2014, 11, 12, 8, 45, 39)),\n            (\n                ""2017-02-03T09:04:08Z to 2017-02-03T09:04:09Z"",\n                [\n                    datetime(2017, 2, 3, 9, 4, 8, tzinfo=pytz.utc),\n                    datetime(2017, 2, 3, 9, 4, 9, tzinfo=pytz.utc),\n                ],\n                ""month"",\n            ),\n            # dates from issue https://github.com/akoumjian/datefinder/issues/14\n            (\n                ""i am looking for a date june 4th 1996 to july 3rd 2013"",\n                [datetime(1996, 6, 4), datetime(2013, 7, 3)],\n                ""month"",\n            ),\n            (\n                ""october 27 1994 to be put into effect on june 1 1995"",\n                [datetime(1994, 10, 27), datetime(1995, 6, 1)],\n                ""month"",\n            ),\n            # Simple date range\n            (\n                ""31/08/2012 to 30/08/2013"",\n                [datetime(2012, 8, 31), datetime(2013, 8, 30)],\n                ""month"",\n            ),\n            (\n                ""31 Oct 2021 - 28 Nov 2021"",\n                [datetime(2021, 10, 31), datetime(2021, 11, 28)],\n                ""day""\n            ),\n            # Z dates with and without millis, from https://github.com/akoumjian/datefinder/issues/37\n            (\n                ""2017-02-03T09:04:08.001Z"",\n                datetime(2017, 2, 3, 9, 4, 8, 1000, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            (\n                ""2017-02-03T09:04:08,00123Z"",\n                datetime(2017, 2, 3, 9, 4, 8, 1230, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            (\n                ""2017-02-03T09:04:08Z"",\n                datetime(2017, 2, 3, 9, 4, 8, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            # Year only strings, from https://github.com/akoumjian/datefinder/issues/96\n            (\n                ""Dutta is the recipient of Femina Miss India Universe title in 2004."",\n                datetime(2004, today.month, today.day),\n                ""month"",\n            ),\n            (\n                \'she said that she hit depression after being traumatized on the sets of ""Horn OK"" in 2008.\',\n                datetime(2008, today.month, today.day),\n                ""month"",\n            ),\n            # https://github.com/akoumjian/datefinder/issues/63\n            (""12th day of December, 2001"", datetime(2001, 12, 12), ""month""),\n            (""01/02/03"", datetime(2003, 1, 2, 0, 0, 0, 0), ""month""),\n            (""01/02/03"", datetime(2003, 2, 1, 0, 0, 0, 0), ""day""),\n            (""01/02/03"", datetime(2001, 2, 3, 0, 0, 0, 0), ""year""),\n            (""02/05/2020"", datetime(2020, 2, 5, 0, 0, 0, 0), ""month""),\n            (""02/05/2020"", datetime(2020, 5, 2, 0, 0, 0, 0), ""day""),\n        ],\n    )\n    def test_find_date_strings(input_text, expected_date, first):\n        if isinstance(expected_date, list):\n            matches = list(datefinder.find_dates(input_text, first=first))\n            assert matches == expected_date\n        else:\n            return_date = None\n            for return_date in datefinder.find_dates(input_text, first=first):\n                assert return_date == expected_date\n>           assert return_date is not None, \'Did not find date for test line: ""{}""\'.format(\n                input_text\n            )  # handles dates that were never matched\nE           AssertionError: Did not find date for test line: ""she said that she hit depression after being traumatized on the sets of ""Horn OK"" in 2008.""\nE           assert None is not None\n\nrepos\\datefinder\\tests\\test_find_dates.py:124: AssertionError', 'input_text = \'12th day of December, 2001\'\nexpected_date = datetime.datetime(2001, 12, 12, 0, 0), first = \'month\'\n\n    @pytest.mark.parametrize(\n        (""input_text"", ""expected_date"", ""first""),\n        [\n            ## English Dates\n            # (\'[Sept] 04, 2014.\', datetime(2014, 9, 4), ""month""),\n            (""Tuesday Jul 22, 2014"", datetime(2014, 7, 22), ""month""),\n            # (\'10:04am EDT\', datetime(2012, 11, 13, 14, 4), ""month""),\n            # (\'Friday\', datetime(2012, 11, 9), ""month""),\n            # (\'November 19, 2014 at noon\', datetime(2014, 11, 19, 12, 0), ""month""),\n            (""December 13, 2014 at midnight"", datetime(2014, 12, 13, 0, 0), ""month""),\n            # (\'Nov 25 2014 10:17 pm EST\', datetime(2014, 11, 26, 3, 17), ""month""),\n            # (\'Wed Aug 05 12:00:00 EDT 2015\', datetime(2015, 8, 5, 16, 0), ""month""),\n            (""April 9, 2013 at 6:11 a.m."", datetime(2013, 4, 9, 6, 11), ""month""),\n            (""Aug. 9, 2012 at 2:57 p.m."", datetime(2012, 8, 9, 14, 57), ""month""),\n            (""December 10, 2014, 11:02:21 pm"", datetime(2014, 12, 10, 23, 2, 21), ""month""),\n            (""8:25 a.m. Dec. 12, 2014"", datetime(2014, 12, 12, 8, 25), ""month""),\n            (""2:21 p.m., December 11, 2014"", datetime(2014, 12, 11, 14, 21), ""month""),\n            (""Fri, 12 Dec 2014 10:55:50"", datetime(2014, 12, 12, 10, 55, 50), ""month""),\n            # (\'20 Mar 2013 10h11\', datetime(2013, 3, 20, 10, 11), ""month""),\n            (""10:06am Dec 11, 2014"", datetime(2014, 12, 11, 10, 6), ""month""),\n            (""September 2nd, 1998"", datetime(1998, 9, 2), ""month""),\n            (\n                ""May 5, 2010 to July 10, 2011"",\n                [datetime(2010, 5, 5), datetime(2011, 7, 10)],\n                ""month"",\n            ),\n            # (\'19 February 2013 year 09:10\', datetime(2013, 2, 19, 9, 10), ""month""),\n            # Numeric dates\n            (""06-17-2014"", datetime(2014, 6, 17), ""month""),\n            (""13/03/2014"", datetime(2014, 3, 13), ""month""),\n            (\n                ""2016-02-04T20:16:26+00:00"",\n                datetime(2016, 2, 4, 20, 16, 26, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            # (\'11. 12. 2014, 08:45:39\', datetime(2014, 11, 12, 8, 45, 39)),\n            (\n                ""2017-02-03T09:04:08Z to 2017-02-03T09:04:09Z"",\n                [\n                    datetime(2017, 2, 3, 9, 4, 8, tzinfo=pytz.utc),\n                    datetime(2017, 2, 3, 9, 4, 9, tzinfo=pytz.utc),\n                ],\n                ""month"",\n            ),\n            # dates from issue https://github.com/akoumjian/datefinder/issues/14\n            (\n                ""i am looking for a date june 4th 1996 to july 3rd 2013"",\n                [datetime(1996, 6, 4), datetime(2013, 7, 3)],\n                ""month"",\n            ),\n            (\n                ""october 27 1994 to be put into effect on june 1 1995"",\n                [datetime(1994, 10, 27), datetime(1995, 6, 1)],\n                ""month"",\n            ),\n            # Simple date range\n            (\n                ""31/08/2012 to 30/08/2013"",\n                [datetime(2012, 8, 31), datetime(2013, 8, 30)],\n                ""month"",\n            ),\n            (\n                ""31 Oct 2021 - 28 Nov 2021"",\n                [datetime(2021, 10, 31), datetime(2021, 11, 28)],\n                ""day""\n            ),\n            # Z dates with and without millis, from https://github.com/akoumjian/datefinder/issues/37\n            (\n                ""2017-02-03T09:04:08.001Z"",\n                datetime(2017, 2, 3, 9, 4, 8, 1000, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            (\n                ""2017-02-03T09:04:08,00123Z"",\n                datetime(2017, 2, 3, 9, 4, 8, 1230, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            (\n                ""2017-02-03T09:04:08Z"",\n                datetime(2017, 2, 3, 9, 4, 8, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            # Year only strings, from https://github.com/akoumjian/datefinder/issues/96\n            (\n                ""Dutta is the recipient of Femina Miss India Universe title in 2004."",\n                datetime(2004, today.month, today.day),\n                ""month"",\n            ),\n            (\n                \'she said that she hit depression after being traumatized on the sets of ""Horn OK"" in 2008.\',\n                datetime(2008, today.month, today.day),\n                ""month"",\n            ),\n            # https://github.com/akoumjian/datefinder/issues/63\n            (""12th day of December, 2001"", datetime(2001, 12, 12), ""month""),\n            (""01/02/03"", datetime(2003, 1, 2, 0, 0, 0, 0), ""month""),\n            (""01/02/03"", datetime(2003, 2, 1, 0, 0, 0, 0), ""day""),\n            (""01/02/03"", datetime(2001, 2, 3, 0, 0, 0, 0), ""year""),\n            (""02/05/2020"", datetime(2020, 2, 5, 0, 0, 0, 0), ""month""),\n            (""02/05/2020"", datetime(2020, 5, 2, 0, 0, 0, 0), ""day""),\n        ],\n    )\n    def test_find_date_strings(input_text, expected_date, first):\n        if isinstance(expected_date, list):\n            matches = list(datefinder.find_dates(input_text, first=first))\n            assert matches == expected_date\n        else:\n            return_date = None\n            for return_date in datefinder.find_dates(input_text, first=first):\n                assert return_date == expected_date\n>           assert return_date is not None, \'Did not find date for test line: ""{}""\'.format(\n                input_text\n            )  # handles dates that were never matched\nE           AssertionError: Did not find date for test line: ""12th day of December, 2001""\nE           assert None is not None\n\nrepos\\datefinder\\tests\\test_find_dates.py:124: AssertionError', 'input_text = \'01/02/03\', expected_date = datetime.datetime(2003, 1, 2, 0, 0)\nfirst = \'month\'\n\n    @pytest.mark.parametrize(\n        (""input_text"", ""expected_date"", ""first""),\n        [\n            ## English Dates\n            # (\'[Sept] 04, 2014.\', datetime(2014, 9, 4), ""month""),\n            (""Tuesday Jul 22, 2014"", datetime(2014, 7, 22), ""month""),\n            # (\'10:04am EDT\', datetime(2012, 11, 13, 14, 4), ""month""),\n            # (\'Friday\', datetime(2012, 11, 9), ""month""),\n            # (\'November 19, 2014 at noon\', datetime(2014, 11, 19, 12, 0), ""month""),\n            (""December 13, 2014 at midnight"", datetime(2014, 12, 13, 0, 0), ""month""),\n            # (\'Nov 25 2014 10:17 pm EST\', datetime(2014, 11, 26, 3, 17), ""month""),\n            # (\'Wed Aug 05 12:00:00 EDT 2015\', datetime(2015, 8, 5, 16, 0), ""month""),\n            (""April 9, 2013 at 6:11 a.m."", datetime(2013, 4, 9, 6, 11), ""month""),\n            (""Aug. 9, 2012 at 2:57 p.m."", datetime(2012, 8, 9, 14, 57), ""month""),\n            (""December 10, 2014, 11:02:21 pm"", datetime(2014, 12, 10, 23, 2, 21), ""month""),\n            (""8:25 a.m. Dec. 12, 2014"", datetime(2014, 12, 12, 8, 25), ""month""),\n            (""2:21 p.m., December 11, 2014"", datetime(2014, 12, 11, 14, 21), ""month""),\n            (""Fri, 12 Dec 2014 10:55:50"", datetime(2014, 12, 12, 10, 55, 50), ""month""),\n            # (\'20 Mar 2013 10h11\', datetime(2013, 3, 20, 10, 11), ""month""),\n            (""10:06am Dec 11, 2014"", datetime(2014, 12, 11, 10, 6), ""month""),\n            (""September 2nd, 1998"", datetime(1998, 9, 2), ""month""),\n            (\n                ""May 5, 2010 to July 10, 2011"",\n                [datetime(2010, 5, 5), datetime(2011, 7, 10)],\n                ""month"",\n            ),\n            # (\'19 February 2013 year 09:10\', datetime(2013, 2, 19, 9, 10), ""month""),\n            # Numeric dates\n            (""06-17-2014"", datetime(2014, 6, 17), ""month""),\n            (""13/03/2014"", datetime(2014, 3, 13), ""month""),\n            (\n                ""2016-02-04T20:16:26+00:00"",\n                datetime(2016, 2, 4, 20, 16, 26, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            # (\'11. 12. 2014, 08:45:39\', datetime(2014, 11, 12, 8, 45, 39)),\n            (\n                ""2017-02-03T09:04:08Z to 2017-02-03T09:04:09Z"",\n                [\n                    datetime(2017, 2, 3, 9, 4, 8, tzinfo=pytz.utc),\n                    datetime(2017, 2, 3, 9, 4, 9, tzinfo=pytz.utc),\n                ],\n                ""month"",\n            ),\n            # dates from issue https://github.com/akoumjian/datefinder/issues/14\n            (\n                ""i am looking for a date june 4th 1996 to july 3rd 2013"",\n                [datetime(1996, 6, 4), datetime(2013, 7, 3)],\n                ""month"",\n            ),\n            (\n                ""october 27 1994 to be put into effect on june 1 1995"",\n                [datetime(1994, 10, 27), datetime(1995, 6, 1)],\n                ""month"",\n            ),\n            # Simple date range\n            (\n                ""31/08/2012 to 30/08/2013"",\n                [datetime(2012, 8, 31), datetime(2013, 8, 30)],\n                ""month"",\n            ),\n            (\n                ""31 Oct 2021 - 28 Nov 2021"",\n                [datetime(2021, 10, 31), datetime(2021, 11, 28)],\n                ""day""\n            ),\n            # Z dates with and without millis, from https://github.com/akoumjian/datefinder/issues/37\n            (\n                ""2017-02-03T09:04:08.001Z"",\n                datetime(2017, 2, 3, 9, 4, 8, 1000, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            (\n                ""2017-02-03T09:04:08,00123Z"",\n                datetime(2017, 2, 3, 9, 4, 8, 1230, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            (\n                ""2017-02-03T09:04:08Z"",\n                datetime(2017, 2, 3, 9, 4, 8, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            # Year only strings, from https://github.com/akoumjian/datefinder/issues/96\n            (\n                ""Dutta is the recipient of Femina Miss India Universe title in 2004."",\n                datetime(2004, today.month, today.day),\n                ""month"",\n            ),\n            (\n                \'she said that she hit depression after being traumatized on the sets of ""Horn OK"" in 2008.\',\n                datetime(2008, today.month, today.day),\n                ""month"",\n            ),\n            # https://github.com/akoumjian/datefinder/issues/63\n            (""12th day of December, 2001"", datetime(2001, 12, 12), ""month""),\n            (""01/02/03"", datetime(2003, 1, 2, 0, 0, 0, 0), ""month""),\n            (""01/02/03"", datetime(2003, 2, 1, 0, 0, 0, 0), ""day""),\n            (""01/02/03"", datetime(2001, 2, 3, 0, 0, 0, 0), ""year""),\n            (""02/05/2020"", datetime(2020, 2, 5, 0, 0, 0, 0), ""month""),\n            (""02/05/2020"", datetime(2020, 5, 2, 0, 0, 0, 0), ""day""),\n        ],\n    )\n    def test_find_date_strings(input_text, expected_date, first):\n        if isinstance(expected_date, list):\n            matches = list(datefinder.find_dates(input_text, first=first))\n            assert matches == expected_date\n        else:\n            return_date = None\n            for return_date in datefinder.find_dates(input_text, first=first):\n                assert return_date == expected_date\n>           assert return_date is not None, \'Did not find date for test line: ""{}""\'.format(\n                input_text\n            )  # handles dates that were never matched\nE           AssertionError: Did not find date for test line: ""01/02/03""\nE           assert None is not None\n\nrepos\\datefinder\\tests\\test_find_dates.py:124: AssertionError', 'input_text = \'01/02/03\', expected_date = datetime.datetime(2003, 2, 1, 0, 0)\nfirst = \'day\'\n\n    @pytest.mark.parametrize(\n        (""input_text"", ""expected_date"", ""first""),\n        [\n            ## English Dates\n            # (\'[Sept] 04, 2014.\', datetime(2014, 9, 4), ""month""),\n            (""Tuesday Jul 22, 2014"", datetime(2014, 7, 22), ""month""),\n            # (\'10:04am EDT\', datetime(2012, 11, 13, 14, 4), ""month""),\n            # (\'Friday\', datetime(2012, 11, 9), ""month""),\n            # (\'November 19, 2014 at noon\', datetime(2014, 11, 19, 12, 0), ""month""),\n            (""December 13, 2014 at midnight"", datetime(2014, 12, 13, 0, 0), ""month""),\n            # (\'Nov 25 2014 10:17 pm EST\', datetime(2014, 11, 26, 3, 17), ""month""),\n            # (\'Wed Aug 05 12:00:00 EDT 2015\', datetime(2015, 8, 5, 16, 0), ""month""),\n            (""April 9, 2013 at 6:11 a.m."", datetime(2013, 4, 9, 6, 11), ""month""),\n            (""Aug. 9, 2012 at 2:57 p.m."", datetime(2012, 8, 9, 14, 57), ""month""),\n            (""December 10, 2014, 11:02:21 pm"", datetime(2014, 12, 10, 23, 2, 21), ""month""),\n            (""8:25 a.m. Dec. 12, 2014"", datetime(2014, 12, 12, 8, 25), ""month""),\n            (""2:21 p.m., December 11, 2014"", datetime(2014, 12, 11, 14, 21), ""month""),\n            (""Fri, 12 Dec 2014 10:55:50"", datetime(2014, 12, 12, 10, 55, 50), ""month""),\n            # (\'20 Mar 2013 10h11\', datetime(2013, 3, 20, 10, 11), ""month""),\n            (""10:06am Dec 11, 2014"", datetime(2014, 12, 11, 10, 6), ""month""),\n            (""September 2nd, 1998"", datetime(1998, 9, 2), ""month""),\n            (\n                ""May 5, 2010 to July 10, 2011"",\n                [datetime(2010, 5, 5), datetime(2011, 7, 10)],\n                ""month"",\n            ),\n            # (\'19 February 2013 year 09:10\', datetime(2013, 2, 19, 9, 10), ""month""),\n            # Numeric dates\n            (""06-17-2014"", datetime(2014, 6, 17), ""month""),\n            (""13/03/2014"", datetime(2014, 3, 13), ""month""),\n            (\n                ""2016-02-04T20:16:26+00:00"",\n                datetime(2016, 2, 4, 20, 16, 26, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            # (\'11. 12. 2014, 08:45:39\', datetime(2014, 11, 12, 8, 45, 39)),\n            (\n                ""2017-02-03T09:04:08Z to 2017-02-03T09:04:09Z"",\n                [\n                    datetime(2017, 2, 3, 9, 4, 8, tzinfo=pytz.utc),\n                    datetime(2017, 2, 3, 9, 4, 9, tzinfo=pytz.utc),\n                ],\n                ""month"",\n            ),\n            # dates from issue https://github.com/akoumjian/datefinder/issues/14\n            (\n                ""i am looking for a date june 4th 1996 to july 3rd 2013"",\n                [datetime(1996, 6, 4), datetime(2013, 7, 3)],\n                ""month"",\n            ),\n            (\n                ""october 27 1994 to be put into effect on june 1 1995"",\n                [datetime(1994, 10, 27), datetime(1995, 6, 1)],\n                ""month"",\n            ),\n            # Simple date range\n            (\n                ""31/08/2012 to 30/08/2013"",\n                [datetime(2012, 8, 31), datetime(2013, 8, 30)],\n                ""month"",\n            ),\n            (\n                ""31 Oct 2021 - 28 Nov 2021"",\n                [datetime(2021, 10, 31), datetime(2021, 11, 28)],\n                ""day""\n            ),\n            # Z dates with and without millis, from https://github.com/akoumjian/datefinder/issues/37\n            (\n                ""2017-02-03T09:04:08.001Z"",\n                datetime(2017, 2, 3, 9, 4, 8, 1000, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            (\n                ""2017-02-03T09:04:08,00123Z"",\n                datetime(2017, 2, 3, 9, 4, 8, 1230, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            (\n                ""2017-02-03T09:04:08Z"",\n                datetime(2017, 2, 3, 9, 4, 8, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            # Year only strings, from https://github.com/akoumjian/datefinder/issues/96\n            (\n                ""Dutta is the recipient of Femina Miss India Universe title in 2004."",\n                datetime(2004, today.month, today.day),\n                ""month"",\n            ),\n            (\n                \'she said that she hit depression after being traumatized on the sets of ""Horn OK"" in 2008.\',\n                datetime(2008, today.month, today.day),\n                ""month"",\n            ),\n            # https://github.com/akoumjian/datefinder/issues/63\n            (""12th day of December, 2001"", datetime(2001, 12, 12), ""month""),\n            (""01/02/03"", datetime(2003, 1, 2, 0, 0, 0, 0), ""month""),\n            (""01/02/03"", datetime(2003, 2, 1, 0, 0, 0, 0), ""day""),\n            (""01/02/03"", datetime(2001, 2, 3, 0, 0, 0, 0), ""year""),\n            (""02/05/2020"", datetime(2020, 2, 5, 0, 0, 0, 0), ""month""),\n            (""02/05/2020"", datetime(2020, 5, 2, 0, 0, 0, 0), ""day""),\n        ],\n    )\n    def test_find_date_strings(input_text, expected_date, first):\n        if isinstance(expected_date, list):\n            matches = list(datefinder.find_dates(input_text, first=first))\n            assert matches == expected_date\n        else:\n            return_date = None\n            for return_date in datefinder.find_dates(input_text, first=first):\n                assert return_date == expected_date\n>           assert return_date is not None, \'Did not find date for test line: ""{}""\'.format(\n                input_text\n            )  # handles dates that were never matched\nE           AssertionError: Did not find date for test line: ""01/02/03""\nE           assert None is not None\n\nrepos\\datefinder\\tests\\test_find_dates.py:124: AssertionError', 'input_text = \'01/02/03\', expected_date = datetime.datetime(2001, 2, 3, 0, 0)\nfirst = \'year\'\n\n    @pytest.mark.parametrize(\n        (""input_text"", ""expected_date"", ""first""),\n        [\n            ## English Dates\n            # (\'[Sept] 04, 2014.\', datetime(2014, 9, 4), ""month""),\n            (""Tuesday Jul 22, 2014"", datetime(2014, 7, 22), ""month""),\n            # (\'10:04am EDT\', datetime(2012, 11, 13, 14, 4), ""month""),\n            # (\'Friday\', datetime(2012, 11, 9), ""month""),\n            # (\'November 19, 2014 at noon\', datetime(2014, 11, 19, 12, 0), ""month""),\n            (""December 13, 2014 at midnight"", datetime(2014, 12, 13, 0, 0), ""month""),\n            # (\'Nov 25 2014 10:17 pm EST\', datetime(2014, 11, 26, 3, 17), ""month""),\n            # (\'Wed Aug 05 12:00:00 EDT 2015\', datetime(2015, 8, 5, 16, 0), ""month""),\n            (""April 9, 2013 at 6:11 a.m."", datetime(2013, 4, 9, 6, 11), ""month""),\n            (""Aug. 9, 2012 at 2:57 p.m."", datetime(2012, 8, 9, 14, 57), ""month""),\n            (""December 10, 2014, 11:02:21 pm"", datetime(2014, 12, 10, 23, 2, 21), ""month""),\n            (""8:25 a.m. Dec. 12, 2014"", datetime(2014, 12, 12, 8, 25), ""month""),\n            (""2:21 p.m., December 11, 2014"", datetime(2014, 12, 11, 14, 21), ""month""),\n            (""Fri, 12 Dec 2014 10:55:50"", datetime(2014, 12, 12, 10, 55, 50), ""month""),\n            # (\'20 Mar 2013 10h11\', datetime(2013, 3, 20, 10, 11), ""month""),\n            (""10:06am Dec 11, 2014"", datetime(2014, 12, 11, 10, 6), ""month""),\n            (""September 2nd, 1998"", datetime(1998, 9, 2), ""month""),\n            (\n                ""May 5, 2010 to July 10, 2011"",\n                [datetime(2010, 5, 5), datetime(2011, 7, 10)],\n                ""month"",\n            ),\n            # (\'19 February 2013 year 09:10\', datetime(2013, 2, 19, 9, 10), ""month""),\n            # Numeric dates\n            (""06-17-2014"", datetime(2014, 6, 17), ""month""),\n            (""13/03/2014"", datetime(2014, 3, 13), ""month""),\n            (\n                ""2016-02-04T20:16:26+00:00"",\n                datetime(2016, 2, 4, 20, 16, 26, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            # (\'11. 12. 2014, 08:45:39\', datetime(2014, 11, 12, 8, 45, 39)),\n            (\n                ""2017-02-03T09:04:08Z to 2017-02-03T09:04:09Z"",\n                [\n                    datetime(2017, 2, 3, 9, 4, 8, tzinfo=pytz.utc),\n                    datetime(2017, 2, 3, 9, 4, 9, tzinfo=pytz.utc),\n                ],\n                ""month"",\n            ),\n            # dates from issue https://github.com/akoumjian/datefinder/issues/14\n            (\n                ""i am looking for a date june 4th 1996 to july 3rd 2013"",\n                [datetime(1996, 6, 4), datetime(2013, 7, 3)],\n                ""month"",\n            ),\n            (\n                ""october 27 1994 to be put into effect on june 1 1995"",\n                [datetime(1994, 10, 27), datetime(1995, 6, 1)],\n                ""month"",\n            ),\n            # Simple date range\n            (\n                ""31/08/2012 to 30/08/2013"",\n                [datetime(2012, 8, 31), datetime(2013, 8, 30)],\n                ""month"",\n            ),\n            (\n                ""31 Oct 2021 - 28 Nov 2021"",\n                [datetime(2021, 10, 31), datetime(2021, 11, 28)],\n                ""day""\n            ),\n            # Z dates with and without millis, from https://github.com/akoumjian/datefinder/issues/37\n            (\n                ""2017-02-03T09:04:08.001Z"",\n                datetime(2017, 2, 3, 9, 4, 8, 1000, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            (\n                ""2017-02-03T09:04:08,00123Z"",\n                datetime(2017, 2, 3, 9, 4, 8, 1230, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            (\n                ""2017-02-03T09:04:08Z"",\n                datetime(2017, 2, 3, 9, 4, 8, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            # Year only strings, from https://github.com/akoumjian/datefinder/issues/96\n            (\n                ""Dutta is the recipient of Femina Miss India Universe title in 2004."",\n                datetime(2004, today.month, today.day),\n                ""month"",\n            ),\n            (\n                \'she said that she hit depression after being traumatized on the sets of ""Horn OK"" in 2008.\',\n                datetime(2008, today.month, today.day),\n                ""month"",\n            ),\n            # https://github.com/akoumjian/datefinder/issues/63\n            (""12th day of December, 2001"", datetime(2001, 12, 12), ""month""),\n            (""01/02/03"", datetime(2003, 1, 2, 0, 0, 0, 0), ""month""),\n            (""01/02/03"", datetime(2003, 2, 1, 0, 0, 0, 0), ""day""),\n            (""01/02/03"", datetime(2001, 2, 3, 0, 0, 0, 0), ""year""),\n            (""02/05/2020"", datetime(2020, 2, 5, 0, 0, 0, 0), ""month""),\n            (""02/05/2020"", datetime(2020, 5, 2, 0, 0, 0, 0), ""day""),\n        ],\n    )\n    def test_find_date_strings(input_text, expected_date, first):\n        if isinstance(expected_date, list):\n            matches = list(datefinder.find_dates(input_text, first=first))\n            assert matches == expected_date\n        else:\n            return_date = None\n            for return_date in datefinder.find_dates(input_text, first=first):\n                assert return_date == expected_date\n>           assert return_date is not None, \'Did not find date for test line: ""{}""\'.format(\n                input_text\n            )  # handles dates that were never matched\nE           AssertionError: Did not find date for test line: ""01/02/03""\nE           assert None is not None\n\nrepos\\datefinder\\tests\\test_find_dates.py:124: AssertionError', 'input_text = \'02/05/2020\', expected_date = datetime.datetime(2020, 2, 5, 0, 0)\nfirst = \'month\'\n\n    @pytest.mark.parametrize(\n        (""input_text"", ""expected_date"", ""first""),\n        [\n            ## English Dates\n            # (\'[Sept] 04, 2014.\', datetime(2014, 9, 4), ""month""),\n            (""Tuesday Jul 22, 2014"", datetime(2014, 7, 22), ""month""),\n            # (\'10:04am EDT\', datetime(2012, 11, 13, 14, 4), ""month""),\n            # (\'Friday\', datetime(2012, 11, 9), ""month""),\n            # (\'November 19, 2014 at noon\', datetime(2014, 11, 19, 12, 0), ""month""),\n            (""December 13, 2014 at midnight"", datetime(2014, 12, 13, 0, 0), ""month""),\n            # (\'Nov 25 2014 10:17 pm EST\', datetime(2014, 11, 26, 3, 17), ""month""),\n            # (\'Wed Aug 05 12:00:00 EDT 2015\', datetime(2015, 8, 5, 16, 0), ""month""),\n            (""April 9, 2013 at 6:11 a.m."", datetime(2013, 4, 9, 6, 11), ""month""),\n            (""Aug. 9, 2012 at 2:57 p.m."", datetime(2012, 8, 9, 14, 57), ""month""),\n            (""December 10, 2014, 11:02:21 pm"", datetime(2014, 12, 10, 23, 2, 21), ""month""),\n            (""8:25 a.m. Dec. 12, 2014"", datetime(2014, 12, 12, 8, 25), ""month""),\n            (""2:21 p.m., December 11, 2014"", datetime(2014, 12, 11, 14, 21), ""month""),\n            (""Fri, 12 Dec 2014 10:55:50"", datetime(2014, 12, 12, 10, 55, 50), ""month""),\n            # (\'20 Mar 2013 10h11\', datetime(2013, 3, 20, 10, 11), ""month""),\n            (""10:06am Dec 11, 2014"", datetime(2014, 12, 11, 10, 6), ""month""),\n            (""September 2nd, 1998"", datetime(1998, 9, 2), ""month""),\n            (\n                ""May 5, 2010 to July 10, 2011"",\n                [datetime(2010, 5, 5), datetime(2011, 7, 10)],\n                ""month"",\n            ),\n            # (\'19 February 2013 year 09:10\', datetime(2013, 2, 19, 9, 10), ""month""),\n            # Numeric dates\n            (""06-17-2014"", datetime(2014, 6, 17), ""month""),\n            (""13/03/2014"", datetime(2014, 3, 13), ""month""),\n            (\n                ""2016-02-04T20:16:26+00:00"",\n                datetime(2016, 2, 4, 20, 16, 26, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            # (\'11. 12. 2014, 08:45:39\', datetime(2014, 11, 12, 8, 45, 39)),\n            (\n                ""2017-02-03T09:04:08Z to 2017-02-03T09:04:09Z"",\n                [\n                    datetime(2017, 2, 3, 9, 4, 8, tzinfo=pytz.utc),\n                    datetime(2017, 2, 3, 9, 4, 9, tzinfo=pytz.utc),\n                ],\n                ""month"",\n            ),\n            # dates from issue https://github.com/akoumjian/datefinder/issues/14\n            (\n                ""i am looking for a date june 4th 1996 to july 3rd 2013"",\n                [datetime(1996, 6, 4), datetime(2013, 7, 3)],\n                ""month"",\n            ),\n            (\n                ""october 27 1994 to be put into effect on june 1 1995"",\n                [datetime(1994, 10, 27), datetime(1995, 6, 1)],\n                ""month"",\n            ),\n            # Simple date range\n            (\n                ""31/08/2012 to 30/08/2013"",\n                [datetime(2012, 8, 31), datetime(2013, 8, 30)],\n                ""month"",\n            ),\n            (\n                ""31 Oct 2021 - 28 Nov 2021"",\n                [datetime(2021, 10, 31), datetime(2021, 11, 28)],\n                ""day""\n            ),\n            # Z dates with and without millis, from https://github.com/akoumjian/datefinder/issues/37\n            (\n                ""2017-02-03T09:04:08.001Z"",\n                datetime(2017, 2, 3, 9, 4, 8, 1000, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            (\n                ""2017-02-03T09:04:08,00123Z"",\n                datetime(2017, 2, 3, 9, 4, 8, 1230, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            (\n                ""2017-02-03T09:04:08Z"",\n                datetime(2017, 2, 3, 9, 4, 8, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            # Year only strings, from https://github.com/akoumjian/datefinder/issues/96\n            (\n                ""Dutta is the recipient of Femina Miss India Universe title in 2004."",\n                datetime(2004, today.month, today.day),\n                ""month"",\n            ),\n            (\n                \'she said that she hit depression after being traumatized on the sets of ""Horn OK"" in 2008.\',\n                datetime(2008, today.month, today.day),\n                ""month"",\n            ),\n            # https://github.com/akoumjian/datefinder/issues/63\n            (""12th day of December, 2001"", datetime(2001, 12, 12), ""month""),\n            (""01/02/03"", datetime(2003, 1, 2, 0, 0, 0, 0), ""month""),\n            (""01/02/03"", datetime(2003, 2, 1, 0, 0, 0, 0), ""day""),\n            (""01/02/03"", datetime(2001, 2, 3, 0, 0, 0, 0), ""year""),\n            (""02/05/2020"", datetime(2020, 2, 5, 0, 0, 0, 0), ""month""),\n            (""02/05/2020"", datetime(2020, 5, 2, 0, 0, 0, 0), ""day""),\n        ],\n    )\n    def test_find_date_strings(input_text, expected_date, first):\n        if isinstance(expected_date, list):\n            matches = list(datefinder.find_dates(input_text, first=first))\n            assert matches == expected_date\n        else:\n            return_date = None\n            for return_date in datefinder.find_dates(input_text, first=first):\n                assert return_date == expected_date\n>           assert return_date is not None, \'Did not find date for test line: ""{}""\'.format(\n                input_text\n            )  # handles dates that were never matched\nE           AssertionError: Did not find date for test line: ""02/05/2020""\nE           assert None is not None\n\nrepos\\datefinder\\tests\\test_find_dates.py:124: AssertionError', 'input_text = \'02/05/2020\', expected_date = datetime.datetime(2020, 5, 2, 0, 0)\nfirst = \'day\'\n\n    @pytest.mark.parametrize(\n        (""input_text"", ""expected_date"", ""first""),\n        [\n            ## English Dates\n            # (\'[Sept] 04, 2014.\', datetime(2014, 9, 4), ""month""),\n            (""Tuesday Jul 22, 2014"", datetime(2014, 7, 22), ""month""),\n            # (\'10:04am EDT\', datetime(2012, 11, 13, 14, 4), ""month""),\n            # (\'Friday\', datetime(2012, 11, 9), ""month""),\n            # (\'November 19, 2014 at noon\', datetime(2014, 11, 19, 12, 0), ""month""),\n            (""December 13, 2014 at midnight"", datetime(2014, 12, 13, 0, 0), ""month""),\n            # (\'Nov 25 2014 10:17 pm EST\', datetime(2014, 11, 26, 3, 17), ""month""),\n            # (\'Wed Aug 05 12:00:00 EDT 2015\', datetime(2015, 8, 5, 16, 0), ""month""),\n            (""April 9, 2013 at 6:11 a.m."", datetime(2013, 4, 9, 6, 11), ""month""),\n            (""Aug. 9, 2012 at 2:57 p.m."", datetime(2012, 8, 9, 14, 57), ""month""),\n            (""December 10, 2014, 11:02:21 pm"", datetime(2014, 12, 10, 23, 2, 21), ""month""),\n            (""8:25 a.m. Dec. 12, 2014"", datetime(2014, 12, 12, 8, 25), ""month""),\n            (""2:21 p.m., December 11, 2014"", datetime(2014, 12, 11, 14, 21), ""month""),\n            (""Fri, 12 Dec 2014 10:55:50"", datetime(2014, 12, 12, 10, 55, 50), ""month""),\n            # (\'20 Mar 2013 10h11\', datetime(2013, 3, 20, 10, 11), ""month""),\n            (""10:06am Dec 11, 2014"", datetime(2014, 12, 11, 10, 6), ""month""),\n            (""September 2nd, 1998"", datetime(1998, 9, 2), ""month""),\n            (\n                ""May 5, 2010 to July 10, 2011"",\n                [datetime(2010, 5, 5), datetime(2011, 7, 10)],\n                ""month"",\n            ),\n            # (\'19 February 2013 year 09:10\', datetime(2013, 2, 19, 9, 10), ""month""),\n            # Numeric dates\n            (""06-17-2014"", datetime(2014, 6, 17), ""month""),\n            (""13/03/2014"", datetime(2014, 3, 13), ""month""),\n            (\n                ""2016-02-04T20:16:26+00:00"",\n                datetime(2016, 2, 4, 20, 16, 26, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            # (\'11. 12. 2014, 08:45:39\', datetime(2014, 11, 12, 8, 45, 39)),\n            (\n                ""2017-02-03T09:04:08Z to 2017-02-03T09:04:09Z"",\n                [\n                    datetime(2017, 2, 3, 9, 4, 8, tzinfo=pytz.utc),\n                    datetime(2017, 2, 3, 9, 4, 9, tzinfo=pytz.utc),\n                ],\n                ""month"",\n            ),\n            # dates from issue https://github.com/akoumjian/datefinder/issues/14\n            (\n                ""i am looking for a date june 4th 1996 to july 3rd 2013"",\n                [datetime(1996, 6, 4), datetime(2013, 7, 3)],\n                ""month"",\n            ),\n            (\n                ""october 27 1994 to be put into effect on june 1 1995"",\n                [datetime(1994, 10, 27), datetime(1995, 6, 1)],\n                ""month"",\n            ),\n            # Simple date range\n            (\n                ""31/08/2012 to 30/08/2013"",\n                [datetime(2012, 8, 31), datetime(2013, 8, 30)],\n                ""month"",\n            ),\n            (\n                ""31 Oct 2021 - 28 Nov 2021"",\n                [datetime(2021, 10, 31), datetime(2021, 11, 28)],\n                ""day""\n            ),\n            # Z dates with and without millis, from https://github.com/akoumjian/datefinder/issues/37\n            (\n                ""2017-02-03T09:04:08.001Z"",\n                datetime(2017, 2, 3, 9, 4, 8, 1000, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            (\n                ""2017-02-03T09:04:08,00123Z"",\n                datetime(2017, 2, 3, 9, 4, 8, 1230, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            (\n                ""2017-02-03T09:04:08Z"",\n                datetime(2017, 2, 3, 9, 4, 8, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            # Year only strings, from https://github.com/akoumjian/datefinder/issues/96\n            (\n                ""Dutta is the recipient of Femina Miss India Universe title in 2004."",\n                datetime(2004, today.month, today.day),\n                ""month"",\n            ),\n            (\n                \'she said that she hit depression after being traumatized on the sets of ""Horn OK"" in 2008.\',\n                datetime(2008, today.month, today.day),\n                ""month"",\n            ),\n            # https://github.com/akoumjian/datefinder/issues/63\n            (""12th day of December, 2001"", datetime(2001, 12, 12), ""month""),\n            (""01/02/03"", datetime(2003, 1, 2, 0, 0, 0, 0), ""month""),\n            (""01/02/03"", datetime(2003, 2, 1, 0, 0, 0, 0), ""day""),\n            (""01/02/03"", datetime(2001, 2, 3, 0, 0, 0, 0), ""year""),\n            (""02/05/2020"", datetime(2020, 2, 5, 0, 0, 0, 0), ""month""),\n            (""02/05/2020"", datetime(2020, 5, 2, 0, 0, 0, 0), ""day""),\n        ],\n    )\n    def test_find_date_strings(input_text, expected_date, first):\n        if isinstance(expected_date, list):\n            matches = list(datefinder.find_dates(input_text, first=first))\n            assert matches == expected_date\n        else:\n            return_date = None\n            for return_date in datefinder.find_dates(input_text, first=first):\n                assert return_date == expected_date\n>           assert return_date is not None, \'Did not find date for test line: ""{}""\'.format(\n                input_text\n            )  # handles dates that were never matched\nE           AssertionError: Did not find date for test line: ""02/05/2020""\nE           assert None is not None\n\nrepos\\datefinder\\tests\\test_find_dates.py:124: AssertionError', 'input_text = \'09/06/18\', expected_date = datetime.datetime(2018, 9, 6, 0, 0)\n\n    @pytest.mark.parametrize(\'input_text, expected_date\', [\n    \n        (\'June 2018\', []),\n        (\'09/06/18\',  datetime(2018, 9, 6)),\n        (\'09/06/2018\', datetime(2018, 9, 6)),\n        (\'recorded: 03/14/2008\', datetime(2008, 3, 14)),\n        (\'19th day of May, 2015\', datetime(2015, 5, 19)),\n        (\'19th day of May\', [])\n    \n    ])\n    def test_find_date_strings_strict(input_text, expected_date):\n        if isinstance(expected_date,list):\n            matches = list(datefinder.find_dates(input_text, strict=True))\n            assert matches == expected_date\n    \n        else:\n            return_date = None\n            for return_date in datefinder.find_dates(input_text, strict=True):\n                assert return_date == expected_date\n>           assert return_date is not None, \'Did not find date for test line: ""{}""\'.format(input_text) # handles dates\nE           AssertionError: Did not find date for test line: ""09/06/18""\nE           assert None is not None\n\nrepos\\datefinder\\tests\\test_find_dates_strict.py:32: AssertionError', 'input_text = \'09/06/2018\', expected_date = datetime.datetime(2018, 9, 6, 0, 0)\n\n    @pytest.mark.parametrize(\'input_text, expected_date\', [\n    \n        (\'June 2018\', []),\n        (\'09/06/18\',  datetime(2018, 9, 6)),\n        (\'09/06/2018\', datetime(2018, 9, 6)),\n        (\'recorded: 03/14/2008\', datetime(2008, 3, 14)),\n        (\'19th day of May, 2015\', datetime(2015, 5, 19)),\n        (\'19th day of May\', [])\n    \n    ])\n    def test_find_date_strings_strict(input_text, expected_date):\n        if isinstance(expected_date,list):\n            matches = list(datefinder.find_dates(input_text, strict=True))\n            assert matches == expected_date\n    \n        else:\n            return_date = None\n            for return_date in datefinder.find_dates(input_text, strict=True):\n                assert return_date == expected_date\n>           assert return_date is not None, \'Did not find date for test line: ""{}""\'.format(input_text) # handles dates\nE           AssertionError: Did not find date for test line: ""09/06/2018""\nE           assert None is not None\n\nrepos\\datefinder\\tests\\test_find_dates_strict.py:32: AssertionError', 'input_text = \'recorded: 03/14/2008\'\nexpected_date = datetime.datetime(2008, 3, 14, 0, 0)\n\n    @pytest.mark.parametrize(\'input_text, expected_date\', [\n    \n        (\'June 2018\', []),\n        (\'09/06/18\',  datetime(2018, 9, 6)),\n        (\'09/06/2018\', datetime(2018, 9, 6)),\n        (\'recorded: 03/14/2008\', datetime(2008, 3, 14)),\n        (\'19th day of May, 2015\', datetime(2015, 5, 19)),\n        (\'19th day of May\', [])\n    \n    ])\n    def test_find_date_strings_strict(input_text, expected_date):\n        if isinstance(expected_date,list):\n            matches = list(datefinder.find_dates(input_text, strict=True))\n            assert matches == expected_date\n    \n        else:\n            return_date = None\n            for return_date in datefinder.find_dates(input_text, strict=True):\n                assert return_date == expected_date\n>           assert return_date is not None, \'Did not find date for test line: ""{}""\'.format(input_text) # handles dates\nE           AssertionError: Did not find date for test line: ""recorded: 03/14/2008""\nE           assert None is not None\n\nrepos\\datefinder\\tests\\test_find_dates_strict.py:32: AssertionError', 'input_text = \'19th day of May, 2015\'\nexpected_date = datetime.datetime(2015, 5, 19, 0, 0)\n\n    @pytest.mark.parametrize(\'input_text, expected_date\', [\n    \n        (\'June 2018\', []),\n        (\'09/06/18\',  datetime(2018, 9, 6)),\n        (\'09/06/2018\', datetime(2018, 9, 6)),\n        (\'recorded: 03/14/2008\', datetime(2008, 3, 14)),\n        (\'19th day of May, 2015\', datetime(2015, 5, 19)),\n        (\'19th day of May\', [])\n    \n    ])\n    def test_find_date_strings_strict(input_text, expected_date):\n        if isinstance(expected_date,list):\n            matches = list(datefinder.find_dates(input_text, strict=True))\n            assert matches == expected_date\n    \n        else:\n            return_date = None\n            for return_date in datefinder.find_dates(input_text, strict=True):\n                assert return_date == expected_date\n>           assert return_date is not None, \'Did not find date for test line: ""{}""\'.format(input_text) # handles dates\nE           AssertionError: Did not find date for test line: ""19th day of May, 2015""\nE           assert None is not None\n\nrepos\\datefinder\\tests\\test_find_dates_strict.py:32: AssertionError']",datefinder/extract_date_strings_inner,LLM
datefinder,tokenize_string,"def tokenize_string(self, text):
    """"""
        Get matches from source text. Method merge_tokens will later compose
        potential date strings out of these matches.
        :param text: source text like 'the big fight at 2p.m. mountain standard time on ufc.com'
        :return: [(match_text, match_group, {match.capturesdict()}), ...]
        """"""
    items = []
    last_index = 0
    for match in DATE_REGEX.finditer(text):
        match_str = match.group(0)
        indices = match.span(0)
        captures = match.capturesdict()
        group = self.get_token_group(captures)
        if indices[0] > last_index:
            items.append((text[last_index:indices[0]], '', {}))
        items.append((match_str, group, captures))
        last_index = indices[1]
    if last_index < len(text):
        items.append((text[last_index:len(text)], '', {}))
    return items","The `tokenize_string` function aims to extract matches of a specific regex pattern from a given text. It iterates through the text, identifies matches, and groups them based on certain criteria. The function returns a list of tuples containing the extracted match, its group, and any additional captures associated with the match. This process allows for further composition of potential date strings from the extracted matches.",1,"def tokenize_string(self, text):
    import re
    
    pattern = r'(\d{1,2})[/.-](\d{1,2})[/.-](\d{2,4})'
    matches = re.finditer(pattern, text)
    
    extracted = []
    for match in matches:
        extracted.append((match.group(0), match.group(1), match.group(2), match.group(3)))
    
    return extracted","['./repos/datefinder\\tests', './repos/datefinder\\tests\\test_add_tzinfo.py::test_add_tzinfo', './repos/datefinder\\tests\\test_extract_date_strings.py::test_extract_date_strings', './repos/datefinder\\tests\\test_extract_date_strings.py::test_extract_date_strings_with_strict_option', './repos/datefinder\\tests\\test_find_and_replace.py::test_find_and_replace', './repos/datefinder\\tests\\test_find_dates.py::test_find_date_strings', './repos/datefinder\\tests\\test_find_dates_strict.py::test_find_date_strings_strict', './repos/datefinder\\tests\\test_simple.py::test_success', './repos/datefinder\\tests\\test_tz_gettz.py::test_tz_gettz_for_all_patterns']","17 Passed, 37 Failed",17,37,"['tests/test_extract_date_strings.py::test_extract_date_strings[starting Thursday 2020-11-05 13:50 GMT-Thursday 2020-11-05 13:50 GMT]', 'tests/test_extract_date_strings.py::test_extract_date_strings[starting Thu 2020-11-05 13:50 GMT-Thu 2020-11-05 13:50 GMT]', 'tests/test_extract_date_strings.py::test_extract_date_strings_with_strict_option[They said it was on 01-03-2015-on 01-03-2015]', 'tests/test_find_dates.py::test_find_date_strings[Tuesday Jul 22, 2014-expected_date0-month]', 'tests/test_find_dates.py::test_find_date_strings[December 13, 2014 at midnight-expected_date1-month]', 'tests/test_find_dates.py::test_find_date_strings[April 9, 2013 at 6:11 a.m.-expected_date2-month]', 'tests/test_find_dates.py::test_find_date_strings[Aug. 9, 2012 at 2:57 p.m.-expected_date3-month]', 'tests/test_find_dates.py::test_find_date_strings[December 10, 2014, 11:02:21 pm-expected_date4-month]', 'tests/test_find_dates.py::test_find_date_strings[8:25 a.m. Dec. 12, 2014-expected_date5-month]', 'tests/test_find_dates.py::test_find_date_strings[2:21 p.m., December 11, 2014-expected_date6-month]', 'tests/test_find_dates.py::test_find_date_strings[Fri, 12 Dec 2014 10:55:50-expected_date7-month]', 'tests/test_find_dates.py::test_find_date_strings[10:06am Dec 11, 2014-expected_date8-month]', 'tests/test_find_dates.py::test_find_date_strings[September 2nd, 1998-expected_date9-month]', 'tests/test_find_dates.py::test_find_date_strings[May 5, 2010 to July 10, 2011-expected_date10-month]', 'tests/test_find_dates.py::test_find_date_strings[06-17-2014-expected_date11-month]', 'tests/test_find_dates.py::test_find_date_strings[13/03/2014-expected_date12-month]', 'tests/test_find_dates.py::test_find_date_strings[2016-02-04T20:16:26+00:00-expected_date13-month]', 'tests/test_find_dates.py::test_find_date_strings[2017-02-03T09:04:08Z to 2017-02-03T09:04:09Z-expected_date14-month]', 'tests/test_find_dates.py::test_find_date_strings[i am looking for a date june 4th 1996 to july 3rd 2013-expected_date15-month]', 'tests/test_find_dates.py::test_find_date_strings[october 27 1994 to be put into effect on june 1 1995-expected_date16-month]', 'tests/test_find_dates.py::test_find_date_strings[31/08/2012 to 30/08/2013-expected_date17-month]', 'tests/test_find_dates.py::test_find_date_strings[31 Oct 2021 - 28 Nov 2021-expected_date18-day]', 'tests/test_find_dates.py::test_find_date_strings[2017-02-03T09:04:08.001Z-expected_date19-month]', 'tests/test_find_dates.py::test_find_date_strings[2017-02-03T09:04:08,00123Z-expected_date20-month]', 'tests/test_find_dates.py::test_find_date_strings[2017-02-03T09:04:08Z-expected_date21-month]', 'tests/test_find_dates.py::test_find_date_strings[Dutta is the recipient of Femina Miss India Universe title in 2004.-expected_date22-month]', 'tests/test_find_dates.py::test_find_date_strings[she said that she hit depression after being traumatized on the sets of ""Horn OK"" in 2008.-expected_date23-month]', 'tests/test_find_dates.py::test_find_date_strings[12th day of December, 2001-expected_date24-month]', 'tests/test_find_dates.py::test_find_date_strings[01/02/03-expected_date25-month]', 'tests/test_find_dates.py::test_find_date_strings[01/02/03-expected_date26-day]', 'tests/test_find_dates.py::test_find_date_strings[01/02/03-expected_date27-year]', 'tests/test_find_dates.py::test_find_date_strings[02/05/2020-expected_date28-month]', 'tests/test_find_dates.py::test_find_date_strings[02/05/2020-expected_date29-day]', 'tests/test_find_dates_strict.py::test_find_date_strings_strict[09/06/18-expected_date1]', 'tests/test_find_dates_strict.py::test_find_date_strings_strict[09/06/2018-expected_date2]', 'tests/test_find_dates_strict.py::test_find_date_strings_strict[recorded: 03/14/2008-expected_date3]', 'tests/test_find_dates_strict.py::test_find_date_strings_strict[19th day of May, 2015-expected_date4]']","['date_string = \'starting Thursday 2020-11-05 13:50 GMT\'\nexpected_match_date_string = \'Thursday 2020-11-05 13:50 GMT\'\n\n    @pytest.mark.parametrize(\'date_string, expected_match_date_string\', [\n        [\'March 20, 2015 3:30 pm GMT \', \'March 20, 2015 3:30 pm GMT\'],\n        [\'March 20, 2015 3:30 pm ACWDT in the parking lot\', \'March 20, 2015 3:30 pm ACWDT\'],\n        [\'blah blah March 20, 2015 3pm MADMT for some thing\', \'March 20, 2015 3pm MADMT\'],\n        [\'we need it back on Friday 2p.m. central standard time\', \'on Friday 2p.m. central standard time\'],\n        [\'the big fight at 2p.m. mountain standard time on ufc.com\', \'at 2p.m. mountain standard time on\'],\n    \n        # issue: Thu not recognised by regex #138\n        [\'starting Thursday 2020-11-05 13:50 GMT\', \'Thursday 2020-11-05 13:50 GMT\'],\n        [\'starting Thu 2020-11-05 13:50 GMT\', \'Thu 2020-11-05 13:50 GMT\'],\n    ])\n    def test_extract_date_strings(date_string, expected_match_date_string):\n        dt = datefinder.DateFinder()\n>       for actual_date_string, indexes, captures in dt.extract_date_strings(date_string):\n\nrepos\\datefinder\\tests\\test_extract_date_strings.py:22: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\datefinder\\datefinder\\__init__.py:110: in extract_date_strings_inner\n    items = self.merge_tokens(tokens)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <datefinder.DateFinder object at 0x000002AC9D936E50>\ntokens = [(\'20-11-05\', \'20\', \'11\', \'05\')]\n\n    def merge_tokens(self, tokens):\n        """"""\n        Makes potential date strings out of matches, got from tokenize_string method.\n        :param tokens: [(match_text, match_group, {match.capturesdict()}), ...]\n        :return: potential date strings\n        """"""\n        MIN_MATCHES = 3\n        fragments = []\n        frag = DateFragment()\n        start_char, total_chars = (0, 0)\n        for token in tokens:\n            total_chars += len(token[0])\n            tok_text, group, tok_capts = (token[0], token[1], token[2])\n            if not group:\n                if frag.indices[1] > 0:\n                    if frag.get_captures_count() >= MIN_MATCHES:\n                        fragments.append(frag)\n                frag = DateFragment()\n                start_char = total_chars\n                continue\n            if frag.indices[1] == 0:\n                frag.indices = (start_char, total_chars)\n            else:\n                frag.indices = (frag.indices[0], total_chars)\n            frag.match_str += tok_text\n            for capt in tok_capts:\n                if capt in frag.captures:\n                    frag.captures[capt] += tok_capts[capt]\n                else:\n>                   frag.captures[capt] = tok_capts[capt]\nE                   TypeError: string indices must be integers, not \'str\'\n\nrepos\\datefinder\\datefinder\\__init__.py:172: TypeError', 'date_string = \'starting Thu 2020-11-05 13:50 GMT\'\nexpected_match_date_string = \'Thu 2020-11-05 13:50 GMT\'\n\n    @pytest.mark.parametrize(\'date_string, expected_match_date_string\', [\n        [\'March 20, 2015 3:30 pm GMT \', \'March 20, 2015 3:30 pm GMT\'],\n        [\'March 20, 2015 3:30 pm ACWDT in the parking lot\', \'March 20, 2015 3:30 pm ACWDT\'],\n        [\'blah blah March 20, 2015 3pm MADMT for some thing\', \'March 20, 2015 3pm MADMT\'],\n        [\'we need it back on Friday 2p.m. central standard time\', \'on Friday 2p.m. central standard time\'],\n        [\'the big fight at 2p.m. mountain standard time on ufc.com\', \'at 2p.m. mountain standard time on\'],\n    \n        # issue: Thu not recognised by regex #138\n        [\'starting Thursday 2020-11-05 13:50 GMT\', \'Thursday 2020-11-05 13:50 GMT\'],\n        [\'starting Thu 2020-11-05 13:50 GMT\', \'Thu 2020-11-05 13:50 GMT\'],\n    ])\n    def test_extract_date_strings(date_string, expected_match_date_string):\n        dt = datefinder.DateFinder()\n>       for actual_date_string, indexes, captures in dt.extract_date_strings(date_string):\n\nrepos\\datefinder\\tests\\test_extract_date_strings.py:22: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\datefinder\\datefinder\\__init__.py:110: in extract_date_strings_inner\n    items = self.merge_tokens(tokens)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <datefinder.DateFinder object at 0x000002AC9DC9EC60>\ntokens = [(\'20-11-05\', \'20\', \'11\', \'05\')]\n\n    def merge_tokens(self, tokens):\n        """"""\n        Makes potential date strings out of matches, got from tokenize_string method.\n        :param tokens: [(match_text, match_group, {match.capturesdict()}), ...]\n        :return: potential date strings\n        """"""\n        MIN_MATCHES = 3\n        fragments = []\n        frag = DateFragment()\n        start_char, total_chars = (0, 0)\n        for token in tokens:\n            total_chars += len(token[0])\n            tok_text, group, tok_capts = (token[0], token[1], token[2])\n            if not group:\n                if frag.indices[1] > 0:\n                    if frag.get_captures_count() >= MIN_MATCHES:\n                        fragments.append(frag)\n                frag = DateFragment()\n                start_char = total_chars\n                continue\n            if frag.indices[1] == 0:\n                frag.indices = (start_char, total_chars)\n            else:\n                frag.indices = (frag.indices[0], total_chars)\n            frag.match_str += tok_text\n            for capt in tok_capts:\n                if capt in frag.captures:\n                    frag.captures[capt] += tok_capts[capt]\n                else:\n>                   frag.captures[capt] = tok_capts[capt]\nE                   TypeError: string indices must be integers, not \'str\'\n\nrepos\\datefinder\\datefinder\\__init__.py:172: TypeError', 'date_string = \'They said it was on 01-03-2015\'\nexpected_match_date_string = \'on 01-03-2015\'\n\n    @pytest.mark.parametrize(\'date_string, expected_match_date_string\', [\n        [\'the Friday after next Tuesday the 20th\', \'\'], # no matches\n        [\'This Tuesday March 2015 in the evening\', \'\'], # no matches\n        [\'They said it was on 01-03-2015\', \'on 01-03-2015\'], # 3 digits strict match\n        [\'May 20 2015 is nowhere near the other date\', \'May 20 2015\'], # one month two digit match\n    ])\n    def test_extract_date_strings_with_strict_option(date_string, expected_match_date_string):\n        """"""\n        make sure that `strict` mode works for the dates we care about\n        and doesn\'t work for others\n    \n        :param date_string:\n        :param expected_match_date_string:\n        :return:\n        """"""\n        dt = datefinder.DateFinder()\n>       for actual_date_string, indexes, captures in dt.extract_date_strings(date_string,strict=True):\n\nrepos\\datefinder\\tests\\test_extract_date_strings.py:47: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\datefinder\\datefinder\\__init__.py:110: in extract_date_strings_inner\n    items = self.merge_tokens(tokens)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <datefinder.DateFinder object at 0x000002AC9DCCEA50>\ntokens = [(\'01-03-2015\', \'01\', \'03\', \'2015\')]\n\n    def merge_tokens(self, tokens):\n        """"""\n        Makes potential date strings out of matches, got from tokenize_string method.\n        :param tokens: [(match_text, match_group, {match.capturesdict()}), ...]\n        :return: potential date strings\n        """"""\n        MIN_MATCHES = 3\n        fragments = []\n        frag = DateFragment()\n        start_char, total_chars = (0, 0)\n        for token in tokens:\n            total_chars += len(token[0])\n            tok_text, group, tok_capts = (token[0], token[1], token[2])\n            if not group:\n                if frag.indices[1] > 0:\n                    if frag.get_captures_count() >= MIN_MATCHES:\n                        fragments.append(frag)\n                frag = DateFragment()\n                start_char = total_chars\n                continue\n            if frag.indices[1] == 0:\n                frag.indices = (start_char, total_chars)\n            else:\n                frag.indices = (frag.indices[0], total_chars)\n            frag.match_str += tok_text\n            for capt in tok_capts:\n                if capt in frag.captures:\n                    frag.captures[capt] += tok_capts[capt]\n                else:\n>                   frag.captures[capt] = tok_capts[capt]\nE                   TypeError: string indices must be integers, not \'str\'\n\nrepos\\datefinder\\datefinder\\__init__.py:172: TypeError', 'input_text = \'Tuesday Jul 22, 2014\'\nexpected_date = datetime.datetime(2014, 7, 22, 0, 0), first = \'month\'\n\n    @pytest.mark.parametrize(\n        (""input_text"", ""expected_date"", ""first""),\n        [\n            ## English Dates\n            # (\'[Sept] 04, 2014.\', datetime(2014, 9, 4), ""month""),\n            (""Tuesday Jul 22, 2014"", datetime(2014, 7, 22), ""month""),\n            # (\'10:04am EDT\', datetime(2012, 11, 13, 14, 4), ""month""),\n            # (\'Friday\', datetime(2012, 11, 9), ""month""),\n            # (\'November 19, 2014 at noon\', datetime(2014, 11, 19, 12, 0), ""month""),\n            (""December 13, 2014 at midnight"", datetime(2014, 12, 13, 0, 0), ""month""),\n            # (\'Nov 25 2014 10:17 pm EST\', datetime(2014, 11, 26, 3, 17), ""month""),\n            # (\'Wed Aug 05 12:00:00 EDT 2015\', datetime(2015, 8, 5, 16, 0), ""month""),\n            (""April 9, 2013 at 6:11 a.m."", datetime(2013, 4, 9, 6, 11), ""month""),\n            (""Aug. 9, 2012 at 2:57 p.m."", datetime(2012, 8, 9, 14, 57), ""month""),\n            (""December 10, 2014, 11:02:21 pm"", datetime(2014, 12, 10, 23, 2, 21), ""month""),\n            (""8:25 a.m. Dec. 12, 2014"", datetime(2014, 12, 12, 8, 25), ""month""),\n            (""2:21 p.m., December 11, 2014"", datetime(2014, 12, 11, 14, 21), ""month""),\n            (""Fri, 12 Dec 2014 10:55:50"", datetime(2014, 12, 12, 10, 55, 50), ""month""),\n            # (\'20 Mar 2013 10h11\', datetime(2013, 3, 20, 10, 11), ""month""),\n            (""10:06am Dec 11, 2014"", datetime(2014, 12, 11, 10, 6), ""month""),\n            (""September 2nd, 1998"", datetime(1998, 9, 2), ""month""),\n            (\n                ""May 5, 2010 to July 10, 2011"",\n                [datetime(2010, 5, 5), datetime(2011, 7, 10)],\n                ""month"",\n            ),\n            # (\'19 February 2013 year 09:10\', datetime(2013, 2, 19, 9, 10), ""month""),\n            # Numeric dates\n            (""06-17-2014"", datetime(2014, 6, 17), ""month""),\n            (""13/03/2014"", datetime(2014, 3, 13), ""month""),\n            (\n                ""2016-02-04T20:16:26+00:00"",\n                datetime(2016, 2, 4, 20, 16, 26, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            # (\'11. 12. 2014, 08:45:39\', datetime(2014, 11, 12, 8, 45, 39)),\n            (\n                ""2017-02-03T09:04:08Z to 2017-02-03T09:04:09Z"",\n                [\n                    datetime(2017, 2, 3, 9, 4, 8, tzinfo=pytz.utc),\n                    datetime(2017, 2, 3, 9, 4, 9, tzinfo=pytz.utc),\n                ],\n                ""month"",\n            ),\n            # dates from issue https://github.com/akoumjian/datefinder/issues/14\n            (\n                ""i am looking for a date june 4th 1996 to july 3rd 2013"",\n                [datetime(1996, 6, 4), datetime(2013, 7, 3)],\n                ""month"",\n            ),\n            (\n                ""october 27 1994 to be put into effect on june 1 1995"",\n                [datetime(1994, 10, 27), datetime(1995, 6, 1)],\n                ""month"",\n            ),\n            # Simple date range\n            (\n                ""31/08/2012 to 30/08/2013"",\n                [datetime(2012, 8, 31), datetime(2013, 8, 30)],\n                ""month"",\n            ),\n            (\n                ""31 Oct 2021 - 28 Nov 2021"",\n                [datetime(2021, 10, 31), datetime(2021, 11, 28)],\n                ""day""\n            ),\n            # Z dates with and without millis, from https://github.com/akoumjian/datefinder/issues/37\n            (\n                ""2017-02-03T09:04:08.001Z"",\n                datetime(2017, 2, 3, 9, 4, 8, 1000, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            (\n                ""2017-02-03T09:04:08,00123Z"",\n                datetime(2017, 2, 3, 9, 4, 8, 1230, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            (\n                ""2017-02-03T09:04:08Z"",\n                datetime(2017, 2, 3, 9, 4, 8, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            # Year only strings, from https://github.com/akoumjian/datefinder/issues/96\n            (\n                ""Dutta is the recipient of Femina Miss India Universe title in 2004."",\n                datetime(2004, today.month, today.day),\n                ""month"",\n            ),\n            (\n                \'she said that she hit depression after being traumatized on the sets of ""Horn OK"" in 2008.\',\n                datetime(2008, today.month, today.day),\n                ""month"",\n            ),\n            # https://github.com/akoumjian/datefinder/issues/63\n            (""12th day of December, 2001"", datetime(2001, 12, 12), ""month""),\n            (""01/02/03"", datetime(2003, 1, 2, 0, 0, 0, 0), ""month""),\n            (""01/02/03"", datetime(2003, 2, 1, 0, 0, 0, 0), ""day""),\n            (""01/02/03"", datetime(2001, 2, 3, 0, 0, 0, 0), ""year""),\n            (""02/05/2020"", datetime(2020, 2, 5, 0, 0, 0, 0), ""month""),\n            (""02/05/2020"", datetime(2020, 5, 2, 0, 0, 0, 0), ""day""),\n        ],\n    )\n    def test_find_date_strings(input_text, expected_date, first):\n        if isinstance(expected_date, list):\n            matches = list(datefinder.find_dates(input_text, first=first))\n            assert matches == expected_date\n        else:\n            return_date = None\n            for return_date in datefinder.find_dates(input_text, first=first):\n                assert return_date == expected_date\n>           assert return_date is not None, \'Did not find date for test line: ""{}""\'.format(\n                input_text\n            )  # handles dates that were never matched\nE           AssertionError: Did not find date for test line: ""Tuesday Jul 22, 2014""\nE           assert None is not None\n\nrepos\\datefinder\\tests\\test_find_dates.py:124: AssertionError', 'input_text = \'December 13, 2014 at midnight\'\nexpected_date = datetime.datetime(2014, 12, 13, 0, 0), first = \'month\'\n\n    @pytest.mark.parametrize(\n        (""input_text"", ""expected_date"", ""first""),\n        [\n            ## English Dates\n            # (\'[Sept] 04, 2014.\', datetime(2014, 9, 4), ""month""),\n            (""Tuesday Jul 22, 2014"", datetime(2014, 7, 22), ""month""),\n            # (\'10:04am EDT\', datetime(2012, 11, 13, 14, 4), ""month""),\n            # (\'Friday\', datetime(2012, 11, 9), ""month""),\n            # (\'November 19, 2014 at noon\', datetime(2014, 11, 19, 12, 0), ""month""),\n            (""December 13, 2014 at midnight"", datetime(2014, 12, 13, 0, 0), ""month""),\n            # (\'Nov 25 2014 10:17 pm EST\', datetime(2014, 11, 26, 3, 17), ""month""),\n            # (\'Wed Aug 05 12:00:00 EDT 2015\', datetime(2015, 8, 5, 16, 0), ""month""),\n            (""April 9, 2013 at 6:11 a.m."", datetime(2013, 4, 9, 6, 11), ""month""),\n            (""Aug. 9, 2012 at 2:57 p.m."", datetime(2012, 8, 9, 14, 57), ""month""),\n            (""December 10, 2014, 11:02:21 pm"", datetime(2014, 12, 10, 23, 2, 21), ""month""),\n            (""8:25 a.m. Dec. 12, 2014"", datetime(2014, 12, 12, 8, 25), ""month""),\n            (""2:21 p.m., December 11, 2014"", datetime(2014, 12, 11, 14, 21), ""month""),\n            (""Fri, 12 Dec 2014 10:55:50"", datetime(2014, 12, 12, 10, 55, 50), ""month""),\n            # (\'20 Mar 2013 10h11\', datetime(2013, 3, 20, 10, 11), ""month""),\n            (""10:06am Dec 11, 2014"", datetime(2014, 12, 11, 10, 6), ""month""),\n            (""September 2nd, 1998"", datetime(1998, 9, 2), ""month""),\n            (\n                ""May 5, 2010 to July 10, 2011"",\n                [datetime(2010, 5, 5), datetime(2011, 7, 10)],\n                ""month"",\n            ),\n            # (\'19 February 2013 year 09:10\', datetime(2013, 2, 19, 9, 10), ""month""),\n            # Numeric dates\n            (""06-17-2014"", datetime(2014, 6, 17), ""month""),\n            (""13/03/2014"", datetime(2014, 3, 13), ""month""),\n            (\n                ""2016-02-04T20:16:26+00:00"",\n                datetime(2016, 2, 4, 20, 16, 26, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            # (\'11. 12. 2014, 08:45:39\', datetime(2014, 11, 12, 8, 45, 39)),\n            (\n                ""2017-02-03T09:04:08Z to 2017-02-03T09:04:09Z"",\n                [\n                    datetime(2017, 2, 3, 9, 4, 8, tzinfo=pytz.utc),\n                    datetime(2017, 2, 3, 9, 4, 9, tzinfo=pytz.utc),\n                ],\n                ""month"",\n            ),\n            # dates from issue https://github.com/akoumjian/datefinder/issues/14\n            (\n                ""i am looking for a date june 4th 1996 to july 3rd 2013"",\n                [datetime(1996, 6, 4), datetime(2013, 7, 3)],\n                ""month"",\n            ),\n            (\n                ""october 27 1994 to be put into effect on june 1 1995"",\n                [datetime(1994, 10, 27), datetime(1995, 6, 1)],\n                ""month"",\n            ),\n            # Simple date range\n            (\n                ""31/08/2012 to 30/08/2013"",\n                [datetime(2012, 8, 31), datetime(2013, 8, 30)],\n                ""month"",\n            ),\n            (\n                ""31 Oct 2021 - 28 Nov 2021"",\n                [datetime(2021, 10, 31), datetime(2021, 11, 28)],\n                ""day""\n            ),\n            # Z dates with and without millis, from https://github.com/akoumjian/datefinder/issues/37\n            (\n                ""2017-02-03T09:04:08.001Z"",\n                datetime(2017, 2, 3, 9, 4, 8, 1000, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            (\n                ""2017-02-03T09:04:08,00123Z"",\n                datetime(2017, 2, 3, 9, 4, 8, 1230, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            (\n                ""2017-02-03T09:04:08Z"",\n                datetime(2017, 2, 3, 9, 4, 8, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            # Year only strings, from https://github.com/akoumjian/datefinder/issues/96\n            (\n                ""Dutta is the recipient of Femina Miss India Universe title in 2004."",\n                datetime(2004, today.month, today.day),\n                ""month"",\n            ),\n            (\n                \'she said that she hit depression after being traumatized on the sets of ""Horn OK"" in 2008.\',\n                datetime(2008, today.month, today.day),\n                ""month"",\n            ),\n            # https://github.com/akoumjian/datefinder/issues/63\n            (""12th day of December, 2001"", datetime(2001, 12, 12), ""month""),\n            (""01/02/03"", datetime(2003, 1, 2, 0, 0, 0, 0), ""month""),\n            (""01/02/03"", datetime(2003, 2, 1, 0, 0, 0, 0), ""day""),\n            (""01/02/03"", datetime(2001, 2, 3, 0, 0, 0, 0), ""year""),\n            (""02/05/2020"", datetime(2020, 2, 5, 0, 0, 0, 0), ""month""),\n            (""02/05/2020"", datetime(2020, 5, 2, 0, 0, 0, 0), ""day""),\n        ],\n    )\n    def test_find_date_strings(input_text, expected_date, first):\n        if isinstance(expected_date, list):\n            matches = list(datefinder.find_dates(input_text, first=first))\n            assert matches == expected_date\n        else:\n            return_date = None\n            for return_date in datefinder.find_dates(input_text, first=first):\n                assert return_date == expected_date\n>           assert return_date is not None, \'Did not find date for test line: ""{}""\'.format(\n                input_text\n            )  # handles dates that were never matched\nE           AssertionError: Did not find date for test line: ""December 13, 2014 at midnight""\nE           assert None is not None\n\nrepos\\datefinder\\tests\\test_find_dates.py:124: AssertionError', 'input_text = \'April 9, 2013 at 6:11 a.m.\'\nexpected_date = datetime.datetime(2013, 4, 9, 6, 11), first = \'month\'\n\n    @pytest.mark.parametrize(\n        (""input_text"", ""expected_date"", ""first""),\n        [\n            ## English Dates\n            # (\'[Sept] 04, 2014.\', datetime(2014, 9, 4), ""month""),\n            (""Tuesday Jul 22, 2014"", datetime(2014, 7, 22), ""month""),\n            # (\'10:04am EDT\', datetime(2012, 11, 13, 14, 4), ""month""),\n            # (\'Friday\', datetime(2012, 11, 9), ""month""),\n            # (\'November 19, 2014 at noon\', datetime(2014, 11, 19, 12, 0), ""month""),\n            (""December 13, 2014 at midnight"", datetime(2014, 12, 13, 0, 0), ""month""),\n            # (\'Nov 25 2014 10:17 pm EST\', datetime(2014, 11, 26, 3, 17), ""month""),\n            # (\'Wed Aug 05 12:00:00 EDT 2015\', datetime(2015, 8, 5, 16, 0), ""month""),\n            (""April 9, 2013 at 6:11 a.m."", datetime(2013, 4, 9, 6, 11), ""month""),\n            (""Aug. 9, 2012 at 2:57 p.m."", datetime(2012, 8, 9, 14, 57), ""month""),\n            (""December 10, 2014, 11:02:21 pm"", datetime(2014, 12, 10, 23, 2, 21), ""month""),\n            (""8:25 a.m. Dec. 12, 2014"", datetime(2014, 12, 12, 8, 25), ""month""),\n            (""2:21 p.m., December 11, 2014"", datetime(2014, 12, 11, 14, 21), ""month""),\n            (""Fri, 12 Dec 2014 10:55:50"", datetime(2014, 12, 12, 10, 55, 50), ""month""),\n            # (\'20 Mar 2013 10h11\', datetime(2013, 3, 20, 10, 11), ""month""),\n            (""10:06am Dec 11, 2014"", datetime(2014, 12, 11, 10, 6), ""month""),\n            (""September 2nd, 1998"", datetime(1998, 9, 2), ""month""),\n            (\n                ""May 5, 2010 to July 10, 2011"",\n                [datetime(2010, 5, 5), datetime(2011, 7, 10)],\n                ""month"",\n            ),\n            # (\'19 February 2013 year 09:10\', datetime(2013, 2, 19, 9, 10), ""month""),\n            # Numeric dates\n            (""06-17-2014"", datetime(2014, 6, 17), ""month""),\n            (""13/03/2014"", datetime(2014, 3, 13), ""month""),\n            (\n                ""2016-02-04T20:16:26+00:00"",\n                datetime(2016, 2, 4, 20, 16, 26, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            # (\'11. 12. 2014, 08:45:39\', datetime(2014, 11, 12, 8, 45, 39)),\n            (\n                ""2017-02-03T09:04:08Z to 2017-02-03T09:04:09Z"",\n                [\n                    datetime(2017, 2, 3, 9, 4, 8, tzinfo=pytz.utc),\n                    datetime(2017, 2, 3, 9, 4, 9, tzinfo=pytz.utc),\n                ],\n                ""month"",\n            ),\n            # dates from issue https://github.com/akoumjian/datefinder/issues/14\n            (\n                ""i am looking for a date june 4th 1996 to july 3rd 2013"",\n                [datetime(1996, 6, 4), datetime(2013, 7, 3)],\n                ""month"",\n            ),\n            (\n                ""october 27 1994 to be put into effect on june 1 1995"",\n                [datetime(1994, 10, 27), datetime(1995, 6, 1)],\n                ""month"",\n            ),\n            # Simple date range\n            (\n                ""31/08/2012 to 30/08/2013"",\n                [datetime(2012, 8, 31), datetime(2013, 8, 30)],\n                ""month"",\n            ),\n            (\n                ""31 Oct 2021 - 28 Nov 2021"",\n                [datetime(2021, 10, 31), datetime(2021, 11, 28)],\n                ""day""\n            ),\n            # Z dates with and without millis, from https://github.com/akoumjian/datefinder/issues/37\n            (\n                ""2017-02-03T09:04:08.001Z"",\n                datetime(2017, 2, 3, 9, 4, 8, 1000, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            (\n                ""2017-02-03T09:04:08,00123Z"",\n                datetime(2017, 2, 3, 9, 4, 8, 1230, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            (\n                ""2017-02-03T09:04:08Z"",\n                datetime(2017, 2, 3, 9, 4, 8, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            # Year only strings, from https://github.com/akoumjian/datefinder/issues/96\n            (\n                ""Dutta is the recipient of Femina Miss India Universe title in 2004."",\n                datetime(2004, today.month, today.day),\n                ""month"",\n            ),\n            (\n                \'she said that she hit depression after being traumatized on the sets of ""Horn OK"" in 2008.\',\n                datetime(2008, today.month, today.day),\n                ""month"",\n            ),\n            # https://github.com/akoumjian/datefinder/issues/63\n            (""12th day of December, 2001"", datetime(2001, 12, 12), ""month""),\n            (""01/02/03"", datetime(2003, 1, 2, 0, 0, 0, 0), ""month""),\n            (""01/02/03"", datetime(2003, 2, 1, 0, 0, 0, 0), ""day""),\n            (""01/02/03"", datetime(2001, 2, 3, 0, 0, 0, 0), ""year""),\n            (""02/05/2020"", datetime(2020, 2, 5, 0, 0, 0, 0), ""month""),\n            (""02/05/2020"", datetime(2020, 5, 2, 0, 0, 0, 0), ""day""),\n        ],\n    )\n    def test_find_date_strings(input_text, expected_date, first):\n        if isinstance(expected_date, list):\n            matches = list(datefinder.find_dates(input_text, first=first))\n            assert matches == expected_date\n        else:\n            return_date = None\n            for return_date in datefinder.find_dates(input_text, first=first):\n                assert return_date == expected_date\n>           assert return_date is not None, \'Did not find date for test line: ""{}""\'.format(\n                input_text\n            )  # handles dates that were never matched\nE           AssertionError: Did not find date for test line: ""April 9, 2013 at 6:11 a.m.""\nE           assert None is not None\n\nrepos\\datefinder\\tests\\test_find_dates.py:124: AssertionError', 'input_text = \'Aug. 9, 2012 at 2:57 p.m.\'\nexpected_date = datetime.datetime(2012, 8, 9, 14, 57), first = \'month\'\n\n    @pytest.mark.parametrize(\n        (""input_text"", ""expected_date"", ""first""),\n        [\n            ## English Dates\n            # (\'[Sept] 04, 2014.\', datetime(2014, 9, 4), ""month""),\n            (""Tuesday Jul 22, 2014"", datetime(2014, 7, 22), ""month""),\n            # (\'10:04am EDT\', datetime(2012, 11, 13, 14, 4), ""month""),\n            # (\'Friday\', datetime(2012, 11, 9), ""month""),\n            # (\'November 19, 2014 at noon\', datetime(2014, 11, 19, 12, 0), ""month""),\n            (""December 13, 2014 at midnight"", datetime(2014, 12, 13, 0, 0), ""month""),\n            # (\'Nov 25 2014 10:17 pm EST\', datetime(2014, 11, 26, 3, 17), ""month""),\n            # (\'Wed Aug 05 12:00:00 EDT 2015\', datetime(2015, 8, 5, 16, 0), ""month""),\n            (""April 9, 2013 at 6:11 a.m."", datetime(2013, 4, 9, 6, 11), ""month""),\n            (""Aug. 9, 2012 at 2:57 p.m."", datetime(2012, 8, 9, 14, 57), ""month""),\n            (""December 10, 2014, 11:02:21 pm"", datetime(2014, 12, 10, 23, 2, 21), ""month""),\n            (""8:25 a.m. Dec. 12, 2014"", datetime(2014, 12, 12, 8, 25), ""month""),\n            (""2:21 p.m., December 11, 2014"", datetime(2014, 12, 11, 14, 21), ""month""),\n            (""Fri, 12 Dec 2014 10:55:50"", datetime(2014, 12, 12, 10, 55, 50), ""month""),\n            # (\'20 Mar 2013 10h11\', datetime(2013, 3, 20, 10, 11), ""month""),\n            (""10:06am Dec 11, 2014"", datetime(2014, 12, 11, 10, 6), ""month""),\n            (""September 2nd, 1998"", datetime(1998, 9, 2), ""month""),\n            (\n                ""May 5, 2010 to July 10, 2011"",\n                [datetime(2010, 5, 5), datetime(2011, 7, 10)],\n                ""month"",\n            ),\n            # (\'19 February 2013 year 09:10\', datetime(2013, 2, 19, 9, 10), ""month""),\n            # Numeric dates\n            (""06-17-2014"", datetime(2014, 6, 17), ""month""),\n            (""13/03/2014"", datetime(2014, 3, 13), ""month""),\n            (\n                ""2016-02-04T20:16:26+00:00"",\n                datetime(2016, 2, 4, 20, 16, 26, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            # (\'11. 12. 2014, 08:45:39\', datetime(2014, 11, 12, 8, 45, 39)),\n            (\n                ""2017-02-03T09:04:08Z to 2017-02-03T09:04:09Z"",\n                [\n                    datetime(2017, 2, 3, 9, 4, 8, tzinfo=pytz.utc),\n                    datetime(2017, 2, 3, 9, 4, 9, tzinfo=pytz.utc),\n                ],\n                ""month"",\n            ),\n            # dates from issue https://github.com/akoumjian/datefinder/issues/14\n            (\n                ""i am looking for a date june 4th 1996 to july 3rd 2013"",\n                [datetime(1996, 6, 4), datetime(2013, 7, 3)],\n                ""month"",\n            ),\n            (\n                ""october 27 1994 to be put into effect on june 1 1995"",\n                [datetime(1994, 10, 27), datetime(1995, 6, 1)],\n                ""month"",\n            ),\n            # Simple date range\n            (\n                ""31/08/2012 to 30/08/2013"",\n                [datetime(2012, 8, 31), datetime(2013, 8, 30)],\n                ""month"",\n            ),\n            (\n                ""31 Oct 2021 - 28 Nov 2021"",\n                [datetime(2021, 10, 31), datetime(2021, 11, 28)],\n                ""day""\n            ),\n            # Z dates with and without millis, from https://github.com/akoumjian/datefinder/issues/37\n            (\n                ""2017-02-03T09:04:08.001Z"",\n                datetime(2017, 2, 3, 9, 4, 8, 1000, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            (\n                ""2017-02-03T09:04:08,00123Z"",\n                datetime(2017, 2, 3, 9, 4, 8, 1230, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            (\n                ""2017-02-03T09:04:08Z"",\n                datetime(2017, 2, 3, 9, 4, 8, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            # Year only strings, from https://github.com/akoumjian/datefinder/issues/96\n            (\n                ""Dutta is the recipient of Femina Miss India Universe title in 2004."",\n                datetime(2004, today.month, today.day),\n                ""month"",\n            ),\n            (\n                \'she said that she hit depression after being traumatized on the sets of ""Horn OK"" in 2008.\',\n                datetime(2008, today.month, today.day),\n                ""month"",\n            ),\n            # https://github.com/akoumjian/datefinder/issues/63\n            (""12th day of December, 2001"", datetime(2001, 12, 12), ""month""),\n            (""01/02/03"", datetime(2003, 1, 2, 0, 0, 0, 0), ""month""),\n            (""01/02/03"", datetime(2003, 2, 1, 0, 0, 0, 0), ""day""),\n            (""01/02/03"", datetime(2001, 2, 3, 0, 0, 0, 0), ""year""),\n            (""02/05/2020"", datetime(2020, 2, 5, 0, 0, 0, 0), ""month""),\n            (""02/05/2020"", datetime(2020, 5, 2, 0, 0, 0, 0), ""day""),\n        ],\n    )\n    def test_find_date_strings(input_text, expected_date, first):\n        if isinstance(expected_date, list):\n            matches = list(datefinder.find_dates(input_text, first=first))\n            assert matches == expected_date\n        else:\n            return_date = None\n            for return_date in datefinder.find_dates(input_text, first=first):\n                assert return_date == expected_date\n>           assert return_date is not None, \'Did not find date for test line: ""{}""\'.format(\n                input_text\n            )  # handles dates that were never matched\nE           AssertionError: Did not find date for test line: ""Aug. 9, 2012 at 2:57 p.m.""\nE           assert None is not None\n\nrepos\\datefinder\\tests\\test_find_dates.py:124: AssertionError', 'input_text = \'December 10, 2014, 11:02:21 pm\'\nexpected_date = datetime.datetime(2014, 12, 10, 23, 2, 21), first = \'month\'\n\n    @pytest.mark.parametrize(\n        (""input_text"", ""expected_date"", ""first""),\n        [\n            ## English Dates\n            # (\'[Sept] 04, 2014.\', datetime(2014, 9, 4), ""month""),\n            (""Tuesday Jul 22, 2014"", datetime(2014, 7, 22), ""month""),\n            # (\'10:04am EDT\', datetime(2012, 11, 13, 14, 4), ""month""),\n            # (\'Friday\', datetime(2012, 11, 9), ""month""),\n            # (\'November 19, 2014 at noon\', datetime(2014, 11, 19, 12, 0), ""month""),\n            (""December 13, 2014 at midnight"", datetime(2014, 12, 13, 0, 0), ""month""),\n            # (\'Nov 25 2014 10:17 pm EST\', datetime(2014, 11, 26, 3, 17), ""month""),\n            # (\'Wed Aug 05 12:00:00 EDT 2015\', datetime(2015, 8, 5, 16, 0), ""month""),\n            (""April 9, 2013 at 6:11 a.m."", datetime(2013, 4, 9, 6, 11), ""month""),\n            (""Aug. 9, 2012 at 2:57 p.m."", datetime(2012, 8, 9, 14, 57), ""month""),\n            (""December 10, 2014, 11:02:21 pm"", datetime(2014, 12, 10, 23, 2, 21), ""month""),\n            (""8:25 a.m. Dec. 12, 2014"", datetime(2014, 12, 12, 8, 25), ""month""),\n            (""2:21 p.m., December 11, 2014"", datetime(2014, 12, 11, 14, 21), ""month""),\n            (""Fri, 12 Dec 2014 10:55:50"", datetime(2014, 12, 12, 10, 55, 50), ""month""),\n            # (\'20 Mar 2013 10h11\', datetime(2013, 3, 20, 10, 11), ""month""),\n            (""10:06am Dec 11, 2014"", datetime(2014, 12, 11, 10, 6), ""month""),\n            (""September 2nd, 1998"", datetime(1998, 9, 2), ""month""),\n            (\n                ""May 5, 2010 to July 10, 2011"",\n                [datetime(2010, 5, 5), datetime(2011, 7, 10)],\n                ""month"",\n            ),\n            # (\'19 February 2013 year 09:10\', datetime(2013, 2, 19, 9, 10), ""month""),\n            # Numeric dates\n            (""06-17-2014"", datetime(2014, 6, 17), ""month""),\n            (""13/03/2014"", datetime(2014, 3, 13), ""month""),\n            (\n                ""2016-02-04T20:16:26+00:00"",\n                datetime(2016, 2, 4, 20, 16, 26, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            # (\'11. 12. 2014, 08:45:39\', datetime(2014, 11, 12, 8, 45, 39)),\n            (\n                ""2017-02-03T09:04:08Z to 2017-02-03T09:04:09Z"",\n                [\n                    datetime(2017, 2, 3, 9, 4, 8, tzinfo=pytz.utc),\n                    datetime(2017, 2, 3, 9, 4, 9, tzinfo=pytz.utc),\n                ],\n                ""month"",\n            ),\n            # dates from issue https://github.com/akoumjian/datefinder/issues/14\n            (\n                ""i am looking for a date june 4th 1996 to july 3rd 2013"",\n                [datetime(1996, 6, 4), datetime(2013, 7, 3)],\n                ""month"",\n            ),\n            (\n                ""october 27 1994 to be put into effect on june 1 1995"",\n                [datetime(1994, 10, 27), datetime(1995, 6, 1)],\n                ""month"",\n            ),\n            # Simple date range\n            (\n                ""31/08/2012 to 30/08/2013"",\n                [datetime(2012, 8, 31), datetime(2013, 8, 30)],\n                ""month"",\n            ),\n            (\n                ""31 Oct 2021 - 28 Nov 2021"",\n                [datetime(2021, 10, 31), datetime(2021, 11, 28)],\n                ""day""\n            ),\n            # Z dates with and without millis, from https://github.com/akoumjian/datefinder/issues/37\n            (\n                ""2017-02-03T09:04:08.001Z"",\n                datetime(2017, 2, 3, 9, 4, 8, 1000, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            (\n                ""2017-02-03T09:04:08,00123Z"",\n                datetime(2017, 2, 3, 9, 4, 8, 1230, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            (\n                ""2017-02-03T09:04:08Z"",\n                datetime(2017, 2, 3, 9, 4, 8, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            # Year only strings, from https://github.com/akoumjian/datefinder/issues/96\n            (\n                ""Dutta is the recipient of Femina Miss India Universe title in 2004."",\n                datetime(2004, today.month, today.day),\n                ""month"",\n            ),\n            (\n                \'she said that she hit depression after being traumatized on the sets of ""Horn OK"" in 2008.\',\n                datetime(2008, today.month, today.day),\n                ""month"",\n            ),\n            # https://github.com/akoumjian/datefinder/issues/63\n            (""12th day of December, 2001"", datetime(2001, 12, 12), ""month""),\n            (""01/02/03"", datetime(2003, 1, 2, 0, 0, 0, 0), ""month""),\n            (""01/02/03"", datetime(2003, 2, 1, 0, 0, 0, 0), ""day""),\n            (""01/02/03"", datetime(2001, 2, 3, 0, 0, 0, 0), ""year""),\n            (""02/05/2020"", datetime(2020, 2, 5, 0, 0, 0, 0), ""month""),\n            (""02/05/2020"", datetime(2020, 5, 2, 0, 0, 0, 0), ""day""),\n        ],\n    )\n    def test_find_date_strings(input_text, expected_date, first):\n        if isinstance(expected_date, list):\n            matches = list(datefinder.find_dates(input_text, first=first))\n            assert matches == expected_date\n        else:\n            return_date = None\n            for return_date in datefinder.find_dates(input_text, first=first):\n                assert return_date == expected_date\n>           assert return_date is not None, \'Did not find date for test line: ""{}""\'.format(\n                input_text\n            )  # handles dates that were never matched\nE           AssertionError: Did not find date for test line: ""December 10, 2014, 11:02:21 pm""\nE           assert None is not None\n\nrepos\\datefinder\\tests\\test_find_dates.py:124: AssertionError', 'input_text = \'8:25 a.m. Dec. 12, 2014\'\nexpected_date = datetime.datetime(2014, 12, 12, 8, 25), first = \'month\'\n\n    @pytest.mark.parametrize(\n        (""input_text"", ""expected_date"", ""first""),\n        [\n            ## English Dates\n            # (\'[Sept] 04, 2014.\', datetime(2014, 9, 4), ""month""),\n            (""Tuesday Jul 22, 2014"", datetime(2014, 7, 22), ""month""),\n            # (\'10:04am EDT\', datetime(2012, 11, 13, 14, 4), ""month""),\n            # (\'Friday\', datetime(2012, 11, 9), ""month""),\n            # (\'November 19, 2014 at noon\', datetime(2014, 11, 19, 12, 0), ""month""),\n            (""December 13, 2014 at midnight"", datetime(2014, 12, 13, 0, 0), ""month""),\n            # (\'Nov 25 2014 10:17 pm EST\', datetime(2014, 11, 26, 3, 17), ""month""),\n            # (\'Wed Aug 05 12:00:00 EDT 2015\', datetime(2015, 8, 5, 16, 0), ""month""),\n            (""April 9, 2013 at 6:11 a.m."", datetime(2013, 4, 9, 6, 11), ""month""),\n            (""Aug. 9, 2012 at 2:57 p.m."", datetime(2012, 8, 9, 14, 57), ""month""),\n            (""December 10, 2014, 11:02:21 pm"", datetime(2014, 12, 10, 23, 2, 21), ""month""),\n            (""8:25 a.m. Dec. 12, 2014"", datetime(2014, 12, 12, 8, 25), ""month""),\n            (""2:21 p.m., December 11, 2014"", datetime(2014, 12, 11, 14, 21), ""month""),\n            (""Fri, 12 Dec 2014 10:55:50"", datetime(2014, 12, 12, 10, 55, 50), ""month""),\n            # (\'20 Mar 2013 10h11\', datetime(2013, 3, 20, 10, 11), ""month""),\n            (""10:06am Dec 11, 2014"", datetime(2014, 12, 11, 10, 6), ""month""),\n            (""September 2nd, 1998"", datetime(1998, 9, 2), ""month""),\n            (\n                ""May 5, 2010 to July 10, 2011"",\n                [datetime(2010, 5, 5), datetime(2011, 7, 10)],\n                ""month"",\n            ),\n            # (\'19 February 2013 year 09:10\', datetime(2013, 2, 19, 9, 10), ""month""),\n            # Numeric dates\n            (""06-17-2014"", datetime(2014, 6, 17), ""month""),\n            (""13/03/2014"", datetime(2014, 3, 13), ""month""),\n            (\n                ""2016-02-04T20:16:26+00:00"",\n                datetime(2016, 2, 4, 20, 16, 26, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            # (\'11. 12. 2014, 08:45:39\', datetime(2014, 11, 12, 8, 45, 39)),\n            (\n                ""2017-02-03T09:04:08Z to 2017-02-03T09:04:09Z"",\n                [\n                    datetime(2017, 2, 3, 9, 4, 8, tzinfo=pytz.utc),\n                    datetime(2017, 2, 3, 9, 4, 9, tzinfo=pytz.utc),\n                ],\n                ""month"",\n            ),\n            # dates from issue https://github.com/akoumjian/datefinder/issues/14\n            (\n                ""i am looking for a date june 4th 1996 to july 3rd 2013"",\n                [datetime(1996, 6, 4), datetime(2013, 7, 3)],\n                ""month"",\n            ),\n            (\n                ""october 27 1994 to be put into effect on june 1 1995"",\n                [datetime(1994, 10, 27), datetime(1995, 6, 1)],\n                ""month"",\n            ),\n            # Simple date range\n            (\n                ""31/08/2012 to 30/08/2013"",\n                [datetime(2012, 8, 31), datetime(2013, 8, 30)],\n                ""month"",\n            ),\n            (\n                ""31 Oct 2021 - 28 Nov 2021"",\n                [datetime(2021, 10, 31), datetime(2021, 11, 28)],\n                ""day""\n            ),\n            # Z dates with and without millis, from https://github.com/akoumjian/datefinder/issues/37\n            (\n                ""2017-02-03T09:04:08.001Z"",\n                datetime(2017, 2, 3, 9, 4, 8, 1000, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            (\n                ""2017-02-03T09:04:08,00123Z"",\n                datetime(2017, 2, 3, 9, 4, 8, 1230, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            (\n                ""2017-02-03T09:04:08Z"",\n                datetime(2017, 2, 3, 9, 4, 8, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            # Year only strings, from https://github.com/akoumjian/datefinder/issues/96\n            (\n                ""Dutta is the recipient of Femina Miss India Universe title in 2004."",\n                datetime(2004, today.month, today.day),\n                ""month"",\n            ),\n            (\n                \'she said that she hit depression after being traumatized on the sets of ""Horn OK"" in 2008.\',\n                datetime(2008, today.month, today.day),\n                ""month"",\n            ),\n            # https://github.com/akoumjian/datefinder/issues/63\n            (""12th day of December, 2001"", datetime(2001, 12, 12), ""month""),\n            (""01/02/03"", datetime(2003, 1, 2, 0, 0, 0, 0), ""month""),\n            (""01/02/03"", datetime(2003, 2, 1, 0, 0, 0, 0), ""day""),\n            (""01/02/03"", datetime(2001, 2, 3, 0, 0, 0, 0), ""year""),\n            (""02/05/2020"", datetime(2020, 2, 5, 0, 0, 0, 0), ""month""),\n            (""02/05/2020"", datetime(2020, 5, 2, 0, 0, 0, 0), ""day""),\n        ],\n    )\n    def test_find_date_strings(input_text, expected_date, first):\n        if isinstance(expected_date, list):\n            matches = list(datefinder.find_dates(input_text, first=first))\n            assert matches == expected_date\n        else:\n            return_date = None\n            for return_date in datefinder.find_dates(input_text, first=first):\n                assert return_date == expected_date\n>           assert return_date is not None, \'Did not find date for test line: ""{}""\'.format(\n                input_text\n            )  # handles dates that were never matched\nE           AssertionError: Did not find date for test line: ""8:25 a.m. Dec. 12, 2014""\nE           assert None is not None\n\nrepos\\datefinder\\tests\\test_find_dates.py:124: AssertionError', 'input_text = \'2:21 p.m., December 11, 2014\'\nexpected_date = datetime.datetime(2014, 12, 11, 14, 21), first = \'month\'\n\n    @pytest.mark.parametrize(\n        (""input_text"", ""expected_date"", ""first""),\n        [\n            ## English Dates\n            # (\'[Sept] 04, 2014.\', datetime(2014, 9, 4), ""month""),\n            (""Tuesday Jul 22, 2014"", datetime(2014, 7, 22), ""month""),\n            # (\'10:04am EDT\', datetime(2012, 11, 13, 14, 4), ""month""),\n            # (\'Friday\', datetime(2012, 11, 9), ""month""),\n            # (\'November 19, 2014 at noon\', datetime(2014, 11, 19, 12, 0), ""month""),\n            (""December 13, 2014 at midnight"", datetime(2014, 12, 13, 0, 0), ""month""),\n            # (\'Nov 25 2014 10:17 pm EST\', datetime(2014, 11, 26, 3, 17), ""month""),\n            # (\'Wed Aug 05 12:00:00 EDT 2015\', datetime(2015, 8, 5, 16, 0), ""month""),\n            (""April 9, 2013 at 6:11 a.m."", datetime(2013, 4, 9, 6, 11), ""month""),\n            (""Aug. 9, 2012 at 2:57 p.m."", datetime(2012, 8, 9, 14, 57), ""month""),\n            (""December 10, 2014, 11:02:21 pm"", datetime(2014, 12, 10, 23, 2, 21), ""month""),\n            (""8:25 a.m. Dec. 12, 2014"", datetime(2014, 12, 12, 8, 25), ""month""),\n            (""2:21 p.m., December 11, 2014"", datetime(2014, 12, 11, 14, 21), ""month""),\n            (""Fri, 12 Dec 2014 10:55:50"", datetime(2014, 12, 12, 10, 55, 50), ""month""),\n            # (\'20 Mar 2013 10h11\', datetime(2013, 3, 20, 10, 11), ""month""),\n            (""10:06am Dec 11, 2014"", datetime(2014, 12, 11, 10, 6), ""month""),\n            (""September 2nd, 1998"", datetime(1998, 9, 2), ""month""),\n            (\n                ""May 5, 2010 to July 10, 2011"",\n                [datetime(2010, 5, 5), datetime(2011, 7, 10)],\n                ""month"",\n            ),\n            # (\'19 February 2013 year 09:10\', datetime(2013, 2, 19, 9, 10), ""month""),\n            # Numeric dates\n            (""06-17-2014"", datetime(2014, 6, 17), ""month""),\n            (""13/03/2014"", datetime(2014, 3, 13), ""month""),\n            (\n                ""2016-02-04T20:16:26+00:00"",\n                datetime(2016, 2, 4, 20, 16, 26, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            # (\'11. 12. 2014, 08:45:39\', datetime(2014, 11, 12, 8, 45, 39)),\n            (\n                ""2017-02-03T09:04:08Z to 2017-02-03T09:04:09Z"",\n                [\n                    datetime(2017, 2, 3, 9, 4, 8, tzinfo=pytz.utc),\n                    datetime(2017, 2, 3, 9, 4, 9, tzinfo=pytz.utc),\n                ],\n                ""month"",\n            ),\n            # dates from issue https://github.com/akoumjian/datefinder/issues/14\n            (\n                ""i am looking for a date june 4th 1996 to july 3rd 2013"",\n                [datetime(1996, 6, 4), datetime(2013, 7, 3)],\n                ""month"",\n            ),\n            (\n                ""october 27 1994 to be put into effect on june 1 1995"",\n                [datetime(1994, 10, 27), datetime(1995, 6, 1)],\n                ""month"",\n            ),\n            # Simple date range\n            (\n                ""31/08/2012 to 30/08/2013"",\n                [datetime(2012, 8, 31), datetime(2013, 8, 30)],\n                ""month"",\n            ),\n            (\n                ""31 Oct 2021 - 28 Nov 2021"",\n                [datetime(2021, 10, 31), datetime(2021, 11, 28)],\n                ""day""\n            ),\n            # Z dates with and without millis, from https://github.com/akoumjian/datefinder/issues/37\n            (\n                ""2017-02-03T09:04:08.001Z"",\n                datetime(2017, 2, 3, 9, 4, 8, 1000, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            (\n                ""2017-02-03T09:04:08,00123Z"",\n                datetime(2017, 2, 3, 9, 4, 8, 1230, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            (\n                ""2017-02-03T09:04:08Z"",\n                datetime(2017, 2, 3, 9, 4, 8, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            # Year only strings, from https://github.com/akoumjian/datefinder/issues/96\n            (\n                ""Dutta is the recipient of Femina Miss India Universe title in 2004."",\n                datetime(2004, today.month, today.day),\n                ""month"",\n            ),\n            (\n                \'she said that she hit depression after being traumatized on the sets of ""Horn OK"" in 2008.\',\n                datetime(2008, today.month, today.day),\n                ""month"",\n            ),\n            # https://github.com/akoumjian/datefinder/issues/63\n            (""12th day of December, 2001"", datetime(2001, 12, 12), ""month""),\n            (""01/02/03"", datetime(2003, 1, 2, 0, 0, 0, 0), ""month""),\n            (""01/02/03"", datetime(2003, 2, 1, 0, 0, 0, 0), ""day""),\n            (""01/02/03"", datetime(2001, 2, 3, 0, 0, 0, 0), ""year""),\n            (""02/05/2020"", datetime(2020, 2, 5, 0, 0, 0, 0), ""month""),\n            (""02/05/2020"", datetime(2020, 5, 2, 0, 0, 0, 0), ""day""),\n        ],\n    )\n    def test_find_date_strings(input_text, expected_date, first):\n        if isinstance(expected_date, list):\n            matches = list(datefinder.find_dates(input_text, first=first))\n            assert matches == expected_date\n        else:\n            return_date = None\n            for return_date in datefinder.find_dates(input_text, first=first):\n                assert return_date == expected_date\n>           assert return_date is not None, \'Did not find date for test line: ""{}""\'.format(\n                input_text\n            )  # handles dates that were never matched\nE           AssertionError: Did not find date for test line: ""2:21 p.m., December 11, 2014""\nE           assert None is not None\n\nrepos\\datefinder\\tests\\test_find_dates.py:124: AssertionError', 'input_text = \'Fri, 12 Dec 2014 10:55:50\'\nexpected_date = datetime.datetime(2014, 12, 12, 10, 55, 50), first = \'month\'\n\n    @pytest.mark.parametrize(\n        (""input_text"", ""expected_date"", ""first""),\n        [\n            ## English Dates\n            # (\'[Sept] 04, 2014.\', datetime(2014, 9, 4), ""month""),\n            (""Tuesday Jul 22, 2014"", datetime(2014, 7, 22), ""month""),\n            # (\'10:04am EDT\', datetime(2012, 11, 13, 14, 4), ""month""),\n            # (\'Friday\', datetime(2012, 11, 9), ""month""),\n            # (\'November 19, 2014 at noon\', datetime(2014, 11, 19, 12, 0), ""month""),\n            (""December 13, 2014 at midnight"", datetime(2014, 12, 13, 0, 0), ""month""),\n            # (\'Nov 25 2014 10:17 pm EST\', datetime(2014, 11, 26, 3, 17), ""month""),\n            # (\'Wed Aug 05 12:00:00 EDT 2015\', datetime(2015, 8, 5, 16, 0), ""month""),\n            (""April 9, 2013 at 6:11 a.m."", datetime(2013, 4, 9, 6, 11), ""month""),\n            (""Aug. 9, 2012 at 2:57 p.m."", datetime(2012, 8, 9, 14, 57), ""month""),\n            (""December 10, 2014, 11:02:21 pm"", datetime(2014, 12, 10, 23, 2, 21), ""month""),\n            (""8:25 a.m. Dec. 12, 2014"", datetime(2014, 12, 12, 8, 25), ""month""),\n            (""2:21 p.m., December 11, 2014"", datetime(2014, 12, 11, 14, 21), ""month""),\n            (""Fri, 12 Dec 2014 10:55:50"", datetime(2014, 12, 12, 10, 55, 50), ""month""),\n            # (\'20 Mar 2013 10h11\', datetime(2013, 3, 20, 10, 11), ""month""),\n            (""10:06am Dec 11, 2014"", datetime(2014, 12, 11, 10, 6), ""month""),\n            (""September 2nd, 1998"", datetime(1998, 9, 2), ""month""),\n            (\n                ""May 5, 2010 to July 10, 2011"",\n                [datetime(2010, 5, 5), datetime(2011, 7, 10)],\n                ""month"",\n            ),\n            # (\'19 February 2013 year 09:10\', datetime(2013, 2, 19, 9, 10), ""month""),\n            # Numeric dates\n            (""06-17-2014"", datetime(2014, 6, 17), ""month""),\n            (""13/03/2014"", datetime(2014, 3, 13), ""month""),\n            (\n                ""2016-02-04T20:16:26+00:00"",\n                datetime(2016, 2, 4, 20, 16, 26, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            # (\'11. 12. 2014, 08:45:39\', datetime(2014, 11, 12, 8, 45, 39)),\n            (\n                ""2017-02-03T09:04:08Z to 2017-02-03T09:04:09Z"",\n                [\n                    datetime(2017, 2, 3, 9, 4, 8, tzinfo=pytz.utc),\n                    datetime(2017, 2, 3, 9, 4, 9, tzinfo=pytz.utc),\n                ],\n                ""month"",\n            ),\n            # dates from issue https://github.com/akoumjian/datefinder/issues/14\n            (\n                ""i am looking for a date june 4th 1996 to july 3rd 2013"",\n                [datetime(1996, 6, 4), datetime(2013, 7, 3)],\n                ""month"",\n            ),\n            (\n                ""october 27 1994 to be put into effect on june 1 1995"",\n                [datetime(1994, 10, 27), datetime(1995, 6, 1)],\n                ""month"",\n            ),\n            # Simple date range\n            (\n                ""31/08/2012 to 30/08/2013"",\n                [datetime(2012, 8, 31), datetime(2013, 8, 30)],\n                ""month"",\n            ),\n            (\n                ""31 Oct 2021 - 28 Nov 2021"",\n                [datetime(2021, 10, 31), datetime(2021, 11, 28)],\n                ""day""\n            ),\n            # Z dates with and without millis, from https://github.com/akoumjian/datefinder/issues/37\n            (\n                ""2017-02-03T09:04:08.001Z"",\n                datetime(2017, 2, 3, 9, 4, 8, 1000, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            (\n                ""2017-02-03T09:04:08,00123Z"",\n                datetime(2017, 2, 3, 9, 4, 8, 1230, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            (\n                ""2017-02-03T09:04:08Z"",\n                datetime(2017, 2, 3, 9, 4, 8, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            # Year only strings, from https://github.com/akoumjian/datefinder/issues/96\n            (\n                ""Dutta is the recipient of Femina Miss India Universe title in 2004."",\n                datetime(2004, today.month, today.day),\n                ""month"",\n            ),\n            (\n                \'she said that she hit depression after being traumatized on the sets of ""Horn OK"" in 2008.\',\n                datetime(2008, today.month, today.day),\n                ""month"",\n            ),\n            # https://github.com/akoumjian/datefinder/issues/63\n            (""12th day of December, 2001"", datetime(2001, 12, 12), ""month""),\n            (""01/02/03"", datetime(2003, 1, 2, 0, 0, 0, 0), ""month""),\n            (""01/02/03"", datetime(2003, 2, 1, 0, 0, 0, 0), ""day""),\n            (""01/02/03"", datetime(2001, 2, 3, 0, 0, 0, 0), ""year""),\n            (""02/05/2020"", datetime(2020, 2, 5, 0, 0, 0, 0), ""month""),\n            (""02/05/2020"", datetime(2020, 5, 2, 0, 0, 0, 0), ""day""),\n        ],\n    )\n    def test_find_date_strings(input_text, expected_date, first):\n        if isinstance(expected_date, list):\n            matches = list(datefinder.find_dates(input_text, first=first))\n            assert matches == expected_date\n        else:\n            return_date = None\n            for return_date in datefinder.find_dates(input_text, first=first):\n                assert return_date == expected_date\n>           assert return_date is not None, \'Did not find date for test line: ""{}""\'.format(\n                input_text\n            )  # handles dates that were never matched\nE           AssertionError: Did not find date for test line: ""Fri, 12 Dec 2014 10:55:50""\nE           assert None is not None\n\nrepos\\datefinder\\tests\\test_find_dates.py:124: AssertionError', 'input_text = \'10:06am Dec 11, 2014\'\nexpected_date = datetime.datetime(2014, 12, 11, 10, 6), first = \'month\'\n\n    @pytest.mark.parametrize(\n        (""input_text"", ""expected_date"", ""first""),\n        [\n            ## English Dates\n            # (\'[Sept] 04, 2014.\', datetime(2014, 9, 4), ""month""),\n            (""Tuesday Jul 22, 2014"", datetime(2014, 7, 22), ""month""),\n            # (\'10:04am EDT\', datetime(2012, 11, 13, 14, 4), ""month""),\n            # (\'Friday\', datetime(2012, 11, 9), ""month""),\n            # (\'November 19, 2014 at noon\', datetime(2014, 11, 19, 12, 0), ""month""),\n            (""December 13, 2014 at midnight"", datetime(2014, 12, 13, 0, 0), ""month""),\n            # (\'Nov 25 2014 10:17 pm EST\', datetime(2014, 11, 26, 3, 17), ""month""),\n            # (\'Wed Aug 05 12:00:00 EDT 2015\', datetime(2015, 8, 5, 16, 0), ""month""),\n            (""April 9, 2013 at 6:11 a.m."", datetime(2013, 4, 9, 6, 11), ""month""),\n            (""Aug. 9, 2012 at 2:57 p.m."", datetime(2012, 8, 9, 14, 57), ""month""),\n            (""December 10, 2014, 11:02:21 pm"", datetime(2014, 12, 10, 23, 2, 21), ""month""),\n            (""8:25 a.m. Dec. 12, 2014"", datetime(2014, 12, 12, 8, 25), ""month""),\n            (""2:21 p.m., December 11, 2014"", datetime(2014, 12, 11, 14, 21), ""month""),\n            (""Fri, 12 Dec 2014 10:55:50"", datetime(2014, 12, 12, 10, 55, 50), ""month""),\n            # (\'20 Mar 2013 10h11\', datetime(2013, 3, 20, 10, 11), ""month""),\n            (""10:06am Dec 11, 2014"", datetime(2014, 12, 11, 10, 6), ""month""),\n            (""September 2nd, 1998"", datetime(1998, 9, 2), ""month""),\n            (\n                ""May 5, 2010 to July 10, 2011"",\n                [datetime(2010, 5, 5), datetime(2011, 7, 10)],\n                ""month"",\n            ),\n            # (\'19 February 2013 year 09:10\', datetime(2013, 2, 19, 9, 10), ""month""),\n            # Numeric dates\n            (""06-17-2014"", datetime(2014, 6, 17), ""month""),\n            (""13/03/2014"", datetime(2014, 3, 13), ""month""),\n            (\n                ""2016-02-04T20:16:26+00:00"",\n                datetime(2016, 2, 4, 20, 16, 26, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            # (\'11. 12. 2014, 08:45:39\', datetime(2014, 11, 12, 8, 45, 39)),\n            (\n                ""2017-02-03T09:04:08Z to 2017-02-03T09:04:09Z"",\n                [\n                    datetime(2017, 2, 3, 9, 4, 8, tzinfo=pytz.utc),\n                    datetime(2017, 2, 3, 9, 4, 9, tzinfo=pytz.utc),\n                ],\n                ""month"",\n            ),\n            # dates from issue https://github.com/akoumjian/datefinder/issues/14\n            (\n                ""i am looking for a date june 4th 1996 to july 3rd 2013"",\n                [datetime(1996, 6, 4), datetime(2013, 7, 3)],\n                ""month"",\n            ),\n            (\n                ""october 27 1994 to be put into effect on june 1 1995"",\n                [datetime(1994, 10, 27), datetime(1995, 6, 1)],\n                ""month"",\n            ),\n            # Simple date range\n            (\n                ""31/08/2012 to 30/08/2013"",\n                [datetime(2012, 8, 31), datetime(2013, 8, 30)],\n                ""month"",\n            ),\n            (\n                ""31 Oct 2021 - 28 Nov 2021"",\n                [datetime(2021, 10, 31), datetime(2021, 11, 28)],\n                ""day""\n            ),\n            # Z dates with and without millis, from https://github.com/akoumjian/datefinder/issues/37\n            (\n                ""2017-02-03T09:04:08.001Z"",\n                datetime(2017, 2, 3, 9, 4, 8, 1000, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            (\n                ""2017-02-03T09:04:08,00123Z"",\n                datetime(2017, 2, 3, 9, 4, 8, 1230, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            (\n                ""2017-02-03T09:04:08Z"",\n                datetime(2017, 2, 3, 9, 4, 8, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            # Year only strings, from https://github.com/akoumjian/datefinder/issues/96\n            (\n                ""Dutta is the recipient of Femina Miss India Universe title in 2004."",\n                datetime(2004, today.month, today.day),\n                ""month"",\n            ),\n            (\n                \'she said that she hit depression after being traumatized on the sets of ""Horn OK"" in 2008.\',\n                datetime(2008, today.month, today.day),\n                ""month"",\n            ),\n            # https://github.com/akoumjian/datefinder/issues/63\n            (""12th day of December, 2001"", datetime(2001, 12, 12), ""month""),\n            (""01/02/03"", datetime(2003, 1, 2, 0, 0, 0, 0), ""month""),\n            (""01/02/03"", datetime(2003, 2, 1, 0, 0, 0, 0), ""day""),\n            (""01/02/03"", datetime(2001, 2, 3, 0, 0, 0, 0), ""year""),\n            (""02/05/2020"", datetime(2020, 2, 5, 0, 0, 0, 0), ""month""),\n            (""02/05/2020"", datetime(2020, 5, 2, 0, 0, 0, 0), ""day""),\n        ],\n    )\n    def test_find_date_strings(input_text, expected_date, first):\n        if isinstance(expected_date, list):\n            matches = list(datefinder.find_dates(input_text, first=first))\n            assert matches == expected_date\n        else:\n            return_date = None\n            for return_date in datefinder.find_dates(input_text, first=first):\n                assert return_date == expected_date\n>           assert return_date is not None, \'Did not find date for test line: ""{}""\'.format(\n                input_text\n            )  # handles dates that were never matched\nE           AssertionError: Did not find date for test line: ""10:06am Dec 11, 2014""\nE           assert None is not None\n\nrepos\\datefinder\\tests\\test_find_dates.py:124: AssertionError', 'input_text = \'September 2nd, 1998\'\nexpected_date = datetime.datetime(1998, 9, 2, 0, 0), first = \'month\'\n\n    @pytest.mark.parametrize(\n        (""input_text"", ""expected_date"", ""first""),\n        [\n            ## English Dates\n            # (\'[Sept] 04, 2014.\', datetime(2014, 9, 4), ""month""),\n            (""Tuesday Jul 22, 2014"", datetime(2014, 7, 22), ""month""),\n            # (\'10:04am EDT\', datetime(2012, 11, 13, 14, 4), ""month""),\n            # (\'Friday\', datetime(2012, 11, 9), ""month""),\n            # (\'November 19, 2014 at noon\', datetime(2014, 11, 19, 12, 0), ""month""),\n            (""December 13, 2014 at midnight"", datetime(2014, 12, 13, 0, 0), ""month""),\n            # (\'Nov 25 2014 10:17 pm EST\', datetime(2014, 11, 26, 3, 17), ""month""),\n            # (\'Wed Aug 05 12:00:00 EDT 2015\', datetime(2015, 8, 5, 16, 0), ""month""),\n            (""April 9, 2013 at 6:11 a.m."", datetime(2013, 4, 9, 6, 11), ""month""),\n            (""Aug. 9, 2012 at 2:57 p.m."", datetime(2012, 8, 9, 14, 57), ""month""),\n            (""December 10, 2014, 11:02:21 pm"", datetime(2014, 12, 10, 23, 2, 21), ""month""),\n            (""8:25 a.m. Dec. 12, 2014"", datetime(2014, 12, 12, 8, 25), ""month""),\n            (""2:21 p.m., December 11, 2014"", datetime(2014, 12, 11, 14, 21), ""month""),\n            (""Fri, 12 Dec 2014 10:55:50"", datetime(2014, 12, 12, 10, 55, 50), ""month""),\n            # (\'20 Mar 2013 10h11\', datetime(2013, 3, 20, 10, 11), ""month""),\n            (""10:06am Dec 11, 2014"", datetime(2014, 12, 11, 10, 6), ""month""),\n            (""September 2nd, 1998"", datetime(1998, 9, 2), ""month""),\n            (\n                ""May 5, 2010 to July 10, 2011"",\n                [datetime(2010, 5, 5), datetime(2011, 7, 10)],\n                ""month"",\n            ),\n            # (\'19 February 2013 year 09:10\', datetime(2013, 2, 19, 9, 10), ""month""),\n            # Numeric dates\n            (""06-17-2014"", datetime(2014, 6, 17), ""month""),\n            (""13/03/2014"", datetime(2014, 3, 13), ""month""),\n            (\n                ""2016-02-04T20:16:26+00:00"",\n                datetime(2016, 2, 4, 20, 16, 26, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            # (\'11. 12. 2014, 08:45:39\', datetime(2014, 11, 12, 8, 45, 39)),\n            (\n                ""2017-02-03T09:04:08Z to 2017-02-03T09:04:09Z"",\n                [\n                    datetime(2017, 2, 3, 9, 4, 8, tzinfo=pytz.utc),\n                    datetime(2017, 2, 3, 9, 4, 9, tzinfo=pytz.utc),\n                ],\n                ""month"",\n            ),\n            # dates from issue https://github.com/akoumjian/datefinder/issues/14\n            (\n                ""i am looking for a date june 4th 1996 to july 3rd 2013"",\n                [datetime(1996, 6, 4), datetime(2013, 7, 3)],\n                ""month"",\n            ),\n            (\n                ""october 27 1994 to be put into effect on june 1 1995"",\n                [datetime(1994, 10, 27), datetime(1995, 6, 1)],\n                ""month"",\n            ),\n            # Simple date range\n            (\n                ""31/08/2012 to 30/08/2013"",\n                [datetime(2012, 8, 31), datetime(2013, 8, 30)],\n                ""month"",\n            ),\n            (\n                ""31 Oct 2021 - 28 Nov 2021"",\n                [datetime(2021, 10, 31), datetime(2021, 11, 28)],\n                ""day""\n            ),\n            # Z dates with and without millis, from https://github.com/akoumjian/datefinder/issues/37\n            (\n                ""2017-02-03T09:04:08.001Z"",\n                datetime(2017, 2, 3, 9, 4, 8, 1000, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            (\n                ""2017-02-03T09:04:08,00123Z"",\n                datetime(2017, 2, 3, 9, 4, 8, 1230, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            (\n                ""2017-02-03T09:04:08Z"",\n                datetime(2017, 2, 3, 9, 4, 8, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            # Year only strings, from https://github.com/akoumjian/datefinder/issues/96\n            (\n                ""Dutta is the recipient of Femina Miss India Universe title in 2004."",\n                datetime(2004, today.month, today.day),\n                ""month"",\n            ),\n            (\n                \'she said that she hit depression after being traumatized on the sets of ""Horn OK"" in 2008.\',\n                datetime(2008, today.month, today.day),\n                ""month"",\n            ),\n            # https://github.com/akoumjian/datefinder/issues/63\n            (""12th day of December, 2001"", datetime(2001, 12, 12), ""month""),\n            (""01/02/03"", datetime(2003, 1, 2, 0, 0, 0, 0), ""month""),\n            (""01/02/03"", datetime(2003, 2, 1, 0, 0, 0, 0), ""day""),\n            (""01/02/03"", datetime(2001, 2, 3, 0, 0, 0, 0), ""year""),\n            (""02/05/2020"", datetime(2020, 2, 5, 0, 0, 0, 0), ""month""),\n            (""02/05/2020"", datetime(2020, 5, 2, 0, 0, 0, 0), ""day""),\n        ],\n    )\n    def test_find_date_strings(input_text, expected_date, first):\n        if isinstance(expected_date, list):\n            matches = list(datefinder.find_dates(input_text, first=first))\n            assert matches == expected_date\n        else:\n            return_date = None\n            for return_date in datefinder.find_dates(input_text, first=first):\n                assert return_date == expected_date\n>           assert return_date is not None, \'Did not find date for test line: ""{}""\'.format(\n                input_text\n            )  # handles dates that were never matched\nE           AssertionError: Did not find date for test line: ""September 2nd, 1998""\nE           assert None is not None\n\nrepos\\datefinder\\tests\\test_find_dates.py:124: AssertionError', 'input_text = \'May 5, 2010 to July 10, 2011\'\nexpected_date = [datetime.datetime(2010, 5, 5, 0, 0), datetime.datetime(2011, 7, 10, 0, 0)]\nfirst = \'month\'\n\n    @pytest.mark.parametrize(\n        (""input_text"", ""expected_date"", ""first""),\n        [\n            ## English Dates\n            # (\'[Sept] 04, 2014.\', datetime(2014, 9, 4), ""month""),\n            (""Tuesday Jul 22, 2014"", datetime(2014, 7, 22), ""month""),\n            # (\'10:04am EDT\', datetime(2012, 11, 13, 14, 4), ""month""),\n            # (\'Friday\', datetime(2012, 11, 9), ""month""),\n            # (\'November 19, 2014 at noon\', datetime(2014, 11, 19, 12, 0), ""month""),\n            (""December 13, 2014 at midnight"", datetime(2014, 12, 13, 0, 0), ""month""),\n            # (\'Nov 25 2014 10:17 pm EST\', datetime(2014, 11, 26, 3, 17), ""month""),\n            # (\'Wed Aug 05 12:00:00 EDT 2015\', datetime(2015, 8, 5, 16, 0), ""month""),\n            (""April 9, 2013 at 6:11 a.m."", datetime(2013, 4, 9, 6, 11), ""month""),\n            (""Aug. 9, 2012 at 2:57 p.m."", datetime(2012, 8, 9, 14, 57), ""month""),\n            (""December 10, 2014, 11:02:21 pm"", datetime(2014, 12, 10, 23, 2, 21), ""month""),\n            (""8:25 a.m. Dec. 12, 2014"", datetime(2014, 12, 12, 8, 25), ""month""),\n            (""2:21 p.m., December 11, 2014"", datetime(2014, 12, 11, 14, 21), ""month""),\n            (""Fri, 12 Dec 2014 10:55:50"", datetime(2014, 12, 12, 10, 55, 50), ""month""),\n            # (\'20 Mar 2013 10h11\', datetime(2013, 3, 20, 10, 11), ""month""),\n            (""10:06am Dec 11, 2014"", datetime(2014, 12, 11, 10, 6), ""month""),\n            (""September 2nd, 1998"", datetime(1998, 9, 2), ""month""),\n            (\n                ""May 5, 2010 to July 10, 2011"",\n                [datetime(2010, 5, 5), datetime(2011, 7, 10)],\n                ""month"",\n            ),\n            # (\'19 February 2013 year 09:10\', datetime(2013, 2, 19, 9, 10), ""month""),\n            # Numeric dates\n            (""06-17-2014"", datetime(2014, 6, 17), ""month""),\n            (""13/03/2014"", datetime(2014, 3, 13), ""month""),\n            (\n                ""2016-02-04T20:16:26+00:00"",\n                datetime(2016, 2, 4, 20, 16, 26, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            # (\'11. 12. 2014, 08:45:39\', datetime(2014, 11, 12, 8, 45, 39)),\n            (\n                ""2017-02-03T09:04:08Z to 2017-02-03T09:04:09Z"",\n                [\n                    datetime(2017, 2, 3, 9, 4, 8, tzinfo=pytz.utc),\n                    datetime(2017, 2, 3, 9, 4, 9, tzinfo=pytz.utc),\n                ],\n                ""month"",\n            ),\n            # dates from issue https://github.com/akoumjian/datefinder/issues/14\n            (\n                ""i am looking for a date june 4th 1996 to july 3rd 2013"",\n                [datetime(1996, 6, 4), datetime(2013, 7, 3)],\n                ""month"",\n            ),\n            (\n                ""october 27 1994 to be put into effect on june 1 1995"",\n                [datetime(1994, 10, 27), datetime(1995, 6, 1)],\n                ""month"",\n            ),\n            # Simple date range\n            (\n                ""31/08/2012 to 30/08/2013"",\n                [datetime(2012, 8, 31), datetime(2013, 8, 30)],\n                ""month"",\n            ),\n            (\n                ""31 Oct 2021 - 28 Nov 2021"",\n                [datetime(2021, 10, 31), datetime(2021, 11, 28)],\n                ""day""\n            ),\n            # Z dates with and without millis, from https://github.com/akoumjian/datefinder/issues/37\n            (\n                ""2017-02-03T09:04:08.001Z"",\n                datetime(2017, 2, 3, 9, 4, 8, 1000, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            (\n                ""2017-02-03T09:04:08,00123Z"",\n                datetime(2017, 2, 3, 9, 4, 8, 1230, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            (\n                ""2017-02-03T09:04:08Z"",\n                datetime(2017, 2, 3, 9, 4, 8, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            # Year only strings, from https://github.com/akoumjian/datefinder/issues/96\n            (\n                ""Dutta is the recipient of Femina Miss India Universe title in 2004."",\n                datetime(2004, today.month, today.day),\n                ""month"",\n            ),\n            (\n                \'she said that she hit depression after being traumatized on the sets of ""Horn OK"" in 2008.\',\n                datetime(2008, today.month, today.day),\n                ""month"",\n            ),\n            # https://github.com/akoumjian/datefinder/issues/63\n            (""12th day of December, 2001"", datetime(2001, 12, 12), ""month""),\n            (""01/02/03"", datetime(2003, 1, 2, 0, 0, 0, 0), ""month""),\n            (""01/02/03"", datetime(2003, 2, 1, 0, 0, 0, 0), ""day""),\n            (""01/02/03"", datetime(2001, 2, 3, 0, 0, 0, 0), ""year""),\n            (""02/05/2020"", datetime(2020, 2, 5, 0, 0, 0, 0), ""month""),\n            (""02/05/2020"", datetime(2020, 5, 2, 0, 0, 0, 0), ""day""),\n        ],\n    )\n    def test_find_date_strings(input_text, expected_date, first):\n        if isinstance(expected_date, list):\n            matches = list(datefinder.find_dates(input_text, first=first))\n>           assert matches == expected_date\nE           assert [] == [datetime.dat... 7, 10, 0, 0)]\nE             \nE             Right contains 2 more items, first extra item: datetime.datetime(2010, 5, 5, 0, 0)\nE             \nE             Full diff:\nE             + []\nE             - [\nE             -     datetime.datetime(2010, 5, 5, 0, 0),\nE             -     datetime.datetime(2011, 7, 10, 0, 0),\nE             - ]\n\nrepos\\datefinder\\tests\\test_find_dates.py:119: AssertionError', 'input_text = \'06-17-2014\', expected_date = datetime.datetime(2014, 6, 17, 0, 0)\nfirst = \'month\'\n\n    @pytest.mark.parametrize(\n        (""input_text"", ""expected_date"", ""first""),\n        [\n            ## English Dates\n            # (\'[Sept] 04, 2014.\', datetime(2014, 9, 4), ""month""),\n            (""Tuesday Jul 22, 2014"", datetime(2014, 7, 22), ""month""),\n            # (\'10:04am EDT\', datetime(2012, 11, 13, 14, 4), ""month""),\n            # (\'Friday\', datetime(2012, 11, 9), ""month""),\n            # (\'November 19, 2014 at noon\', datetime(2014, 11, 19, 12, 0), ""month""),\n            (""December 13, 2014 at midnight"", datetime(2014, 12, 13, 0, 0), ""month""),\n            # (\'Nov 25 2014 10:17 pm EST\', datetime(2014, 11, 26, 3, 17), ""month""),\n            # (\'Wed Aug 05 12:00:00 EDT 2015\', datetime(2015, 8, 5, 16, 0), ""month""),\n            (""April 9, 2013 at 6:11 a.m."", datetime(2013, 4, 9, 6, 11), ""month""),\n            (""Aug. 9, 2012 at 2:57 p.m."", datetime(2012, 8, 9, 14, 57), ""month""),\n            (""December 10, 2014, 11:02:21 pm"", datetime(2014, 12, 10, 23, 2, 21), ""month""),\n            (""8:25 a.m. Dec. 12, 2014"", datetime(2014, 12, 12, 8, 25), ""month""),\n            (""2:21 p.m., December 11, 2014"", datetime(2014, 12, 11, 14, 21), ""month""),\n            (""Fri, 12 Dec 2014 10:55:50"", datetime(2014, 12, 12, 10, 55, 50), ""month""),\n            # (\'20 Mar 2013 10h11\', datetime(2013, 3, 20, 10, 11), ""month""),\n            (""10:06am Dec 11, 2014"", datetime(2014, 12, 11, 10, 6), ""month""),\n            (""September 2nd, 1998"", datetime(1998, 9, 2), ""month""),\n            (\n                ""May 5, 2010 to July 10, 2011"",\n                [datetime(2010, 5, 5), datetime(2011, 7, 10)],\n                ""month"",\n            ),\n            # (\'19 February 2013 year 09:10\', datetime(2013, 2, 19, 9, 10), ""month""),\n            # Numeric dates\n            (""06-17-2014"", datetime(2014, 6, 17), ""month""),\n            (""13/03/2014"", datetime(2014, 3, 13), ""month""),\n            (\n                ""2016-02-04T20:16:26+00:00"",\n                datetime(2016, 2, 4, 20, 16, 26, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            # (\'11. 12. 2014, 08:45:39\', datetime(2014, 11, 12, 8, 45, 39)),\n            (\n                ""2017-02-03T09:04:08Z to 2017-02-03T09:04:09Z"",\n                [\n                    datetime(2017, 2, 3, 9, 4, 8, tzinfo=pytz.utc),\n                    datetime(2017, 2, 3, 9, 4, 9, tzinfo=pytz.utc),\n                ],\n                ""month"",\n            ),\n            # dates from issue https://github.com/akoumjian/datefinder/issues/14\n            (\n                ""i am looking for a date june 4th 1996 to july 3rd 2013"",\n                [datetime(1996, 6, 4), datetime(2013, 7, 3)],\n                ""month"",\n            ),\n            (\n                ""october 27 1994 to be put into effect on june 1 1995"",\n                [datetime(1994, 10, 27), datetime(1995, 6, 1)],\n                ""month"",\n            ),\n            # Simple date range\n            (\n                ""31/08/2012 to 30/08/2013"",\n                [datetime(2012, 8, 31), datetime(2013, 8, 30)],\n                ""month"",\n            ),\n            (\n                ""31 Oct 2021 - 28 Nov 2021"",\n                [datetime(2021, 10, 31), datetime(2021, 11, 28)],\n                ""day""\n            ),\n            # Z dates with and without millis, from https://github.com/akoumjian/datefinder/issues/37\n            (\n                ""2017-02-03T09:04:08.001Z"",\n                datetime(2017, 2, 3, 9, 4, 8, 1000, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            (\n                ""2017-02-03T09:04:08,00123Z"",\n                datetime(2017, 2, 3, 9, 4, 8, 1230, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            (\n                ""2017-02-03T09:04:08Z"",\n                datetime(2017, 2, 3, 9, 4, 8, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            # Year only strings, from https://github.com/akoumjian/datefinder/issues/96\n            (\n                ""Dutta is the recipient of Femina Miss India Universe title in 2004."",\n                datetime(2004, today.month, today.day),\n                ""month"",\n            ),\n            (\n                \'she said that she hit depression after being traumatized on the sets of ""Horn OK"" in 2008.\',\n                datetime(2008, today.month, today.day),\n                ""month"",\n            ),\n            # https://github.com/akoumjian/datefinder/issues/63\n            (""12th day of December, 2001"", datetime(2001, 12, 12), ""month""),\n            (""01/02/03"", datetime(2003, 1, 2, 0, 0, 0, 0), ""month""),\n            (""01/02/03"", datetime(2003, 2, 1, 0, 0, 0, 0), ""day""),\n            (""01/02/03"", datetime(2001, 2, 3, 0, 0, 0, 0), ""year""),\n            (""02/05/2020"", datetime(2020, 2, 5, 0, 0, 0, 0), ""month""),\n            (""02/05/2020"", datetime(2020, 5, 2, 0, 0, 0, 0), ""day""),\n        ],\n    )\n    def test_find_date_strings(input_text, expected_date, first):\n        if isinstance(expected_date, list):\n            matches = list(datefinder.find_dates(input_text, first=first))\n            assert matches == expected_date\n        else:\n            return_date = None\n>           for return_date in datefinder.find_dates(input_text, first=first):\n\nrepos\\datefinder\\tests\\test_find_dates.py:122: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\datefinder\\datefinder\\__init__.py:24: in find_dates\n    for date_string, indices, captures in self.extract_date_strings(text, strict=strict):\nrepos\\datefinder\\datefinder\\__init__.py:110: in extract_date_strings_inner\n    items = self.merge_tokens(tokens)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <datefinder.DateFinder object at 0x000002AC9DACB770>\ntokens = [(\'06-17-2014\', \'06\', \'17\', \'2014\')]\n\n    def merge_tokens(self, tokens):\n        """"""\n        Makes potential date strings out of matches, got from tokenize_string method.\n        :param tokens: [(match_text, match_group, {match.capturesdict()}), ...]\n        :return: potential date strings\n        """"""\n        MIN_MATCHES = 3\n        fragments = []\n        frag = DateFragment()\n        start_char, total_chars = (0, 0)\n        for token in tokens:\n            total_chars += len(token[0])\n            tok_text, group, tok_capts = (token[0], token[1], token[2])\n            if not group:\n                if frag.indices[1] > 0:\n                    if frag.get_captures_count() >= MIN_MATCHES:\n                        fragments.append(frag)\n                frag = DateFragment()\n                start_char = total_chars\n                continue\n            if frag.indices[1] == 0:\n                frag.indices = (start_char, total_chars)\n            else:\n                frag.indices = (frag.indices[0], total_chars)\n            frag.match_str += tok_text\n            for capt in tok_capts:\n                if capt in frag.captures:\n                    frag.captures[capt] += tok_capts[capt]\n                else:\n>                   frag.captures[capt] = tok_capts[capt]\nE                   TypeError: string indices must be integers, not \'str\'\n\nrepos\\datefinder\\datefinder\\__init__.py:172: TypeError', 'input_text = \'13/03/2014\', expected_date = datetime.datetime(2014, 3, 13, 0, 0)\nfirst = \'month\'\n\n    @pytest.mark.parametrize(\n        (""input_text"", ""expected_date"", ""first""),\n        [\n            ## English Dates\n            # (\'[Sept] 04, 2014.\', datetime(2014, 9, 4), ""month""),\n            (""Tuesday Jul 22, 2014"", datetime(2014, 7, 22), ""month""),\n            # (\'10:04am EDT\', datetime(2012, 11, 13, 14, 4), ""month""),\n            # (\'Friday\', datetime(2012, 11, 9), ""month""),\n            # (\'November 19, 2014 at noon\', datetime(2014, 11, 19, 12, 0), ""month""),\n            (""December 13, 2014 at midnight"", datetime(2014, 12, 13, 0, 0), ""month""),\n            # (\'Nov 25 2014 10:17 pm EST\', datetime(2014, 11, 26, 3, 17), ""month""),\n            # (\'Wed Aug 05 12:00:00 EDT 2015\', datetime(2015, 8, 5, 16, 0), ""month""),\n            (""April 9, 2013 at 6:11 a.m."", datetime(2013, 4, 9, 6, 11), ""month""),\n            (""Aug. 9, 2012 at 2:57 p.m."", datetime(2012, 8, 9, 14, 57), ""month""),\n            (""December 10, 2014, 11:02:21 pm"", datetime(2014, 12, 10, 23, 2, 21), ""month""),\n            (""8:25 a.m. Dec. 12, 2014"", datetime(2014, 12, 12, 8, 25), ""month""),\n            (""2:21 p.m., December 11, 2014"", datetime(2014, 12, 11, 14, 21), ""month""),\n            (""Fri, 12 Dec 2014 10:55:50"", datetime(2014, 12, 12, 10, 55, 50), ""month""),\n            # (\'20 Mar 2013 10h11\', datetime(2013, 3, 20, 10, 11), ""month""),\n            (""10:06am Dec 11, 2014"", datetime(2014, 12, 11, 10, 6), ""month""),\n            (""September 2nd, 1998"", datetime(1998, 9, 2), ""month""),\n            (\n                ""May 5, 2010 to July 10, 2011"",\n                [datetime(2010, 5, 5), datetime(2011, 7, 10)],\n                ""month"",\n            ),\n            # (\'19 February 2013 year 09:10\', datetime(2013, 2, 19, 9, 10), ""month""),\n            # Numeric dates\n            (""06-17-2014"", datetime(2014, 6, 17), ""month""),\n            (""13/03/2014"", datetime(2014, 3, 13), ""month""),\n            (\n                ""2016-02-04T20:16:26+00:00"",\n                datetime(2016, 2, 4, 20, 16, 26, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            # (\'11. 12. 2014, 08:45:39\', datetime(2014, 11, 12, 8, 45, 39)),\n            (\n                ""2017-02-03T09:04:08Z to 2017-02-03T09:04:09Z"",\n                [\n                    datetime(2017, 2, 3, 9, 4, 8, tzinfo=pytz.utc),\n                    datetime(2017, 2, 3, 9, 4, 9, tzinfo=pytz.utc),\n                ],\n                ""month"",\n            ),\n            # dates from issue https://github.com/akoumjian/datefinder/issues/14\n            (\n                ""i am looking for a date june 4th 1996 to july 3rd 2013"",\n                [datetime(1996, 6, 4), datetime(2013, 7, 3)],\n                ""month"",\n            ),\n            (\n                ""october 27 1994 to be put into effect on june 1 1995"",\n                [datetime(1994, 10, 27), datetime(1995, 6, 1)],\n                ""month"",\n            ),\n            # Simple date range\n            (\n                ""31/08/2012 to 30/08/2013"",\n                [datetime(2012, 8, 31), datetime(2013, 8, 30)],\n                ""month"",\n            ),\n            (\n                ""31 Oct 2021 - 28 Nov 2021"",\n                [datetime(2021, 10, 31), datetime(2021, 11, 28)],\n                ""day""\n            ),\n            # Z dates with and without millis, from https://github.com/akoumjian/datefinder/issues/37\n            (\n                ""2017-02-03T09:04:08.001Z"",\n                datetime(2017, 2, 3, 9, 4, 8, 1000, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            (\n                ""2017-02-03T09:04:08,00123Z"",\n                datetime(2017, 2, 3, 9, 4, 8, 1230, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            (\n                ""2017-02-03T09:04:08Z"",\n                datetime(2017, 2, 3, 9, 4, 8, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            # Year only strings, from https://github.com/akoumjian/datefinder/issues/96\n            (\n                ""Dutta is the recipient of Femina Miss India Universe title in 2004."",\n                datetime(2004, today.month, today.day),\n                ""month"",\n            ),\n            (\n                \'she said that she hit depression after being traumatized on the sets of ""Horn OK"" in 2008.\',\n                datetime(2008, today.month, today.day),\n                ""month"",\n            ),\n            # https://github.com/akoumjian/datefinder/issues/63\n            (""12th day of December, 2001"", datetime(2001, 12, 12), ""month""),\n            (""01/02/03"", datetime(2003, 1, 2, 0, 0, 0, 0), ""month""),\n            (""01/02/03"", datetime(2003, 2, 1, 0, 0, 0, 0), ""day""),\n            (""01/02/03"", datetime(2001, 2, 3, 0, 0, 0, 0), ""year""),\n            (""02/05/2020"", datetime(2020, 2, 5, 0, 0, 0, 0), ""month""),\n            (""02/05/2020"", datetime(2020, 5, 2, 0, 0, 0, 0), ""day""),\n        ],\n    )\n    def test_find_date_strings(input_text, expected_date, first):\n        if isinstance(expected_date, list):\n            matches = list(datefinder.find_dates(input_text, first=first))\n            assert matches == expected_date\n        else:\n            return_date = None\n>           for return_date in datefinder.find_dates(input_text, first=first):\n\nrepos\\datefinder\\tests\\test_find_dates.py:122: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\datefinder\\datefinder\\__init__.py:24: in find_dates\n    for date_string, indices, captures in self.extract_date_strings(text, strict=strict):\nrepos\\datefinder\\datefinder\\__init__.py:110: in extract_date_strings_inner\n    items = self.merge_tokens(tokens)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <datefinder.DateFinder object at 0x000002AC9DACBC50>\ntokens = [(\'13/03/2014\', \'13\', \'03\', \'2014\')]\n\n    def merge_tokens(self, tokens):\n        """"""\n        Makes potential date strings out of matches, got from tokenize_string method.\n        :param tokens: [(match_text, match_group, {match.capturesdict()}), ...]\n        :return: potential date strings\n        """"""\n        MIN_MATCHES = 3\n        fragments = []\n        frag = DateFragment()\n        start_char, total_chars = (0, 0)\n        for token in tokens:\n            total_chars += len(token[0])\n            tok_text, group, tok_capts = (token[0], token[1], token[2])\n            if not group:\n                if frag.indices[1] > 0:\n                    if frag.get_captures_count() >= MIN_MATCHES:\n                        fragments.append(frag)\n                frag = DateFragment()\n                start_char = total_chars\n                continue\n            if frag.indices[1] == 0:\n                frag.indices = (start_char, total_chars)\n            else:\n                frag.indices = (frag.indices[0], total_chars)\n            frag.match_str += tok_text\n            for capt in tok_capts:\n                if capt in frag.captures:\n                    frag.captures[capt] += tok_capts[capt]\n                else:\n>                   frag.captures[capt] = tok_capts[capt]\nE                   TypeError: string indices must be integers, not \'str\'\n\nrepos\\datefinder\\datefinder\\__init__.py:172: TypeError', 'input_text = \'2016-02-04T20:16:26+00:00\'\nexpected_date = datetime.datetime(2016, 2, 4, 20, 16, 26, tzinfo=<UTC>)\nfirst = \'month\'\n\n    @pytest.mark.parametrize(\n        (""input_text"", ""expected_date"", ""first""),\n        [\n            ## English Dates\n            # (\'[Sept] 04, 2014.\', datetime(2014, 9, 4), ""month""),\n            (""Tuesday Jul 22, 2014"", datetime(2014, 7, 22), ""month""),\n            # (\'10:04am EDT\', datetime(2012, 11, 13, 14, 4), ""month""),\n            # (\'Friday\', datetime(2012, 11, 9), ""month""),\n            # (\'November 19, 2014 at noon\', datetime(2014, 11, 19, 12, 0), ""month""),\n            (""December 13, 2014 at midnight"", datetime(2014, 12, 13, 0, 0), ""month""),\n            # (\'Nov 25 2014 10:17 pm EST\', datetime(2014, 11, 26, 3, 17), ""month""),\n            # (\'Wed Aug 05 12:00:00 EDT 2015\', datetime(2015, 8, 5, 16, 0), ""month""),\n            (""April 9, 2013 at 6:11 a.m."", datetime(2013, 4, 9, 6, 11), ""month""),\n            (""Aug. 9, 2012 at 2:57 p.m."", datetime(2012, 8, 9, 14, 57), ""month""),\n            (""December 10, 2014, 11:02:21 pm"", datetime(2014, 12, 10, 23, 2, 21), ""month""),\n            (""8:25 a.m. Dec. 12, 2014"", datetime(2014, 12, 12, 8, 25), ""month""),\n            (""2:21 p.m., December 11, 2014"", datetime(2014, 12, 11, 14, 21), ""month""),\n            (""Fri, 12 Dec 2014 10:55:50"", datetime(2014, 12, 12, 10, 55, 50), ""month""),\n            # (\'20 Mar 2013 10h11\', datetime(2013, 3, 20, 10, 11), ""month""),\n            (""10:06am Dec 11, 2014"", datetime(2014, 12, 11, 10, 6), ""month""),\n            (""September 2nd, 1998"", datetime(1998, 9, 2), ""month""),\n            (\n                ""May 5, 2010 to July 10, 2011"",\n                [datetime(2010, 5, 5), datetime(2011, 7, 10)],\n                ""month"",\n            ),\n            # (\'19 February 2013 year 09:10\', datetime(2013, 2, 19, 9, 10), ""month""),\n            # Numeric dates\n            (""06-17-2014"", datetime(2014, 6, 17), ""month""),\n            (""13/03/2014"", datetime(2014, 3, 13), ""month""),\n            (\n                ""2016-02-04T20:16:26+00:00"",\n                datetime(2016, 2, 4, 20, 16, 26, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            # (\'11. 12. 2014, 08:45:39\', datetime(2014, 11, 12, 8, 45, 39)),\n            (\n                ""2017-02-03T09:04:08Z to 2017-02-03T09:04:09Z"",\n                [\n                    datetime(2017, 2, 3, 9, 4, 8, tzinfo=pytz.utc),\n                    datetime(2017, 2, 3, 9, 4, 9, tzinfo=pytz.utc),\n                ],\n                ""month"",\n            ),\n            # dates from issue https://github.com/akoumjian/datefinder/issues/14\n            (\n                ""i am looking for a date june 4th 1996 to july 3rd 2013"",\n                [datetime(1996, 6, 4), datetime(2013, 7, 3)],\n                ""month"",\n            ),\n            (\n                ""october 27 1994 to be put into effect on june 1 1995"",\n                [datetime(1994, 10, 27), datetime(1995, 6, 1)],\n                ""month"",\n            ),\n            # Simple date range\n            (\n                ""31/08/2012 to 30/08/2013"",\n                [datetime(2012, 8, 31), datetime(2013, 8, 30)],\n                ""month"",\n            ),\n            (\n                ""31 Oct 2021 - 28 Nov 2021"",\n                [datetime(2021, 10, 31), datetime(2021, 11, 28)],\n                ""day""\n            ),\n            # Z dates with and without millis, from https://github.com/akoumjian/datefinder/issues/37\n            (\n                ""2017-02-03T09:04:08.001Z"",\n                datetime(2017, 2, 3, 9, 4, 8, 1000, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            (\n                ""2017-02-03T09:04:08,00123Z"",\n                datetime(2017, 2, 3, 9, 4, 8, 1230, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            (\n                ""2017-02-03T09:04:08Z"",\n                datetime(2017, 2, 3, 9, 4, 8, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            # Year only strings, from https://github.com/akoumjian/datefinder/issues/96\n            (\n                ""Dutta is the recipient of Femina Miss India Universe title in 2004."",\n                datetime(2004, today.month, today.day),\n                ""month"",\n            ),\n            (\n                \'she said that she hit depression after being traumatized on the sets of ""Horn OK"" in 2008.\',\n                datetime(2008, today.month, today.day),\n                ""month"",\n            ),\n            # https://github.com/akoumjian/datefinder/issues/63\n            (""12th day of December, 2001"", datetime(2001, 12, 12), ""month""),\n            (""01/02/03"", datetime(2003, 1, 2, 0, 0, 0, 0), ""month""),\n            (""01/02/03"", datetime(2003, 2, 1, 0, 0, 0, 0), ""day""),\n            (""01/02/03"", datetime(2001, 2, 3, 0, 0, 0, 0), ""year""),\n            (""02/05/2020"", datetime(2020, 2, 5, 0, 0, 0, 0), ""month""),\n            (""02/05/2020"", datetime(2020, 5, 2, 0, 0, 0, 0), ""day""),\n        ],\n    )\n    def test_find_date_strings(input_text, expected_date, first):\n        if isinstance(expected_date, list):\n            matches = list(datefinder.find_dates(input_text, first=first))\n            assert matches == expected_date\n        else:\n            return_date = None\n>           for return_date in datefinder.find_dates(input_text, first=first):\n\nrepos\\datefinder\\tests\\test_find_dates.py:122: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\datefinder\\datefinder\\__init__.py:24: in find_dates\n    for date_string, indices, captures in self.extract_date_strings(text, strict=strict):\nrepos\\datefinder\\datefinder\\__init__.py:110: in extract_date_strings_inner\n    items = self.merge_tokens(tokens)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <datefinder.DateFinder object at 0x000002AC9DADF9B0>\ntokens = [(\'16-02-04\', \'16\', \'02\', \'04\')]\n\n    def merge_tokens(self, tokens):\n        """"""\n        Makes potential date strings out of matches, got from tokenize_string method.\n        :param tokens: [(match_text, match_group, {match.capturesdict()}), ...]\n        :return: potential date strings\n        """"""\n        MIN_MATCHES = 3\n        fragments = []\n        frag = DateFragment()\n        start_char, total_chars = (0, 0)\n        for token in tokens:\n            total_chars += len(token[0])\n            tok_text, group, tok_capts = (token[0], token[1], token[2])\n            if not group:\n                if frag.indices[1] > 0:\n                    if frag.get_captures_count() >= MIN_MATCHES:\n                        fragments.append(frag)\n                frag = DateFragment()\n                start_char = total_chars\n                continue\n            if frag.indices[1] == 0:\n                frag.indices = (start_char, total_chars)\n            else:\n                frag.indices = (frag.indices[0], total_chars)\n            frag.match_str += tok_text\n            for capt in tok_capts:\n                if capt in frag.captures:\n                    frag.captures[capt] += tok_capts[capt]\n                else:\n>                   frag.captures[capt] = tok_capts[capt]\nE                   TypeError: string indices must be integers, not \'str\'\n\nrepos\\datefinder\\datefinder\\__init__.py:172: TypeError', 'input_text = \'2017-02-03T09:04:08Z to 2017-02-03T09:04:09Z\'\nexpected_date = [datetime.datetime(2017, 2, 3, 9, 4, 8, tzinfo=<UTC>), datetime.datetime(2017, 2, 3, 9, 4, 9, tzinfo=<UTC>)]\nfirst = \'month\'\n\n    @pytest.mark.parametrize(\n        (""input_text"", ""expected_date"", ""first""),\n        [\n            ## English Dates\n            # (\'[Sept] 04, 2014.\', datetime(2014, 9, 4), ""month""),\n            (""Tuesday Jul 22, 2014"", datetime(2014, 7, 22), ""month""),\n            # (\'10:04am EDT\', datetime(2012, 11, 13, 14, 4), ""month""),\n            # (\'Friday\', datetime(2012, 11, 9), ""month""),\n            # (\'November 19, 2014 at noon\', datetime(2014, 11, 19, 12, 0), ""month""),\n            (""December 13, 2014 at midnight"", datetime(2014, 12, 13, 0, 0), ""month""),\n            # (\'Nov 25 2014 10:17 pm EST\', datetime(2014, 11, 26, 3, 17), ""month""),\n            # (\'Wed Aug 05 12:00:00 EDT 2015\', datetime(2015, 8, 5, 16, 0), ""month""),\n            (""April 9, 2013 at 6:11 a.m."", datetime(2013, 4, 9, 6, 11), ""month""),\n            (""Aug. 9, 2012 at 2:57 p.m."", datetime(2012, 8, 9, 14, 57), ""month""),\n            (""December 10, 2014, 11:02:21 pm"", datetime(2014, 12, 10, 23, 2, 21), ""month""),\n            (""8:25 a.m. Dec. 12, 2014"", datetime(2014, 12, 12, 8, 25), ""month""),\n            (""2:21 p.m., December 11, 2014"", datetime(2014, 12, 11, 14, 21), ""month""),\n            (""Fri, 12 Dec 2014 10:55:50"", datetime(2014, 12, 12, 10, 55, 50), ""month""),\n            # (\'20 Mar 2013 10h11\', datetime(2013, 3, 20, 10, 11), ""month""),\n            (""10:06am Dec 11, 2014"", datetime(2014, 12, 11, 10, 6), ""month""),\n            (""September 2nd, 1998"", datetime(1998, 9, 2), ""month""),\n            (\n                ""May 5, 2010 to July 10, 2011"",\n                [datetime(2010, 5, 5), datetime(2011, 7, 10)],\n                ""month"",\n            ),\n            # (\'19 February 2013 year 09:10\', datetime(2013, 2, 19, 9, 10), ""month""),\n            # Numeric dates\n            (""06-17-2014"", datetime(2014, 6, 17), ""month""),\n            (""13/03/2014"", datetime(2014, 3, 13), ""month""),\n            (\n                ""2016-02-04T20:16:26+00:00"",\n                datetime(2016, 2, 4, 20, 16, 26, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            # (\'11. 12. 2014, 08:45:39\', datetime(2014, 11, 12, 8, 45, 39)),\n            (\n                ""2017-02-03T09:04:08Z to 2017-02-03T09:04:09Z"",\n                [\n                    datetime(2017, 2, 3, 9, 4, 8, tzinfo=pytz.utc),\n                    datetime(2017, 2, 3, 9, 4, 9, tzinfo=pytz.utc),\n                ],\n                ""month"",\n            ),\n            # dates from issue https://github.com/akoumjian/datefinder/issues/14\n            (\n                ""i am looking for a date june 4th 1996 to july 3rd 2013"",\n                [datetime(1996, 6, 4), datetime(2013, 7, 3)],\n                ""month"",\n            ),\n            (\n                ""october 27 1994 to be put into effect on june 1 1995"",\n                [datetime(1994, 10, 27), datetime(1995, 6, 1)],\n                ""month"",\n            ),\n            # Simple date range\n            (\n                ""31/08/2012 to 30/08/2013"",\n                [datetime(2012, 8, 31), datetime(2013, 8, 30)],\n                ""month"",\n            ),\n            (\n                ""31 Oct 2021 - 28 Nov 2021"",\n                [datetime(2021, 10, 31), datetime(2021, 11, 28)],\n                ""day""\n            ),\n            # Z dates with and without millis, from https://github.com/akoumjian/datefinder/issues/37\n            (\n                ""2017-02-03T09:04:08.001Z"",\n                datetime(2017, 2, 3, 9, 4, 8, 1000, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            (\n                ""2017-02-03T09:04:08,00123Z"",\n                datetime(2017, 2, 3, 9, 4, 8, 1230, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            (\n                ""2017-02-03T09:04:08Z"",\n                datetime(2017, 2, 3, 9, 4, 8, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            # Year only strings, from https://github.com/akoumjian/datefinder/issues/96\n            (\n                ""Dutta is the recipient of Femina Miss India Universe title in 2004."",\n                datetime(2004, today.month, today.day),\n                ""month"",\n            ),\n            (\n                \'she said that she hit depression after being traumatized on the sets of ""Horn OK"" in 2008.\',\n                datetime(2008, today.month, today.day),\n                ""month"",\n            ),\n            # https://github.com/akoumjian/datefinder/issues/63\n            (""12th day of December, 2001"", datetime(2001, 12, 12), ""month""),\n            (""01/02/03"", datetime(2003, 1, 2, 0, 0, 0, 0), ""month""),\n            (""01/02/03"", datetime(2003, 2, 1, 0, 0, 0, 0), ""day""),\n            (""01/02/03"", datetime(2001, 2, 3, 0, 0, 0, 0), ""year""),\n            (""02/05/2020"", datetime(2020, 2, 5, 0, 0, 0, 0), ""month""),\n            (""02/05/2020"", datetime(2020, 5, 2, 0, 0, 0, 0), ""day""),\n        ],\n    )\n    def test_find_date_strings(input_text, expected_date, first):\n        if isinstance(expected_date, list):\n>           matches = list(datefinder.find_dates(input_text, first=first))\n\nrepos\\datefinder\\tests\\test_find_dates.py:118: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\datefinder\\datefinder\\__init__.py:24: in find_dates\n    for date_string, indices, captures in self.extract_date_strings(text, strict=strict):\nrepos\\datefinder\\datefinder\\__init__.py:105: in extract_date_strings_inner\n    range_strings.extend(self.extract_date_strings_inner(range_str[0], text_start=range_str[1][0], strict=strict))\nrepos\\datefinder\\datefinder\\__init__.py:110: in extract_date_strings_inner\n    items = self.merge_tokens(tokens)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <datefinder.DateFinder object at 0x000002AC9DACB770>\ntokens = [(\'17-02-03\', \'17\', \'02\', \'03\')]\n\n    def merge_tokens(self, tokens):\n        """"""\n        Makes potential date strings out of matches, got from tokenize_string method.\n        :param tokens: [(match_text, match_group, {match.capturesdict()}), ...]\n        :return: potential date strings\n        """"""\n        MIN_MATCHES = 3\n        fragments = []\n        frag = DateFragment()\n        start_char, total_chars = (0, 0)\n        for token in tokens:\n            total_chars += len(token[0])\n            tok_text, group, tok_capts = (token[0], token[1], token[2])\n            if not group:\n                if frag.indices[1] > 0:\n                    if frag.get_captures_count() >= MIN_MATCHES:\n                        fragments.append(frag)\n                frag = DateFragment()\n                start_char = total_chars\n                continue\n            if frag.indices[1] == 0:\n                frag.indices = (start_char, total_chars)\n            else:\n                frag.indices = (frag.indices[0], total_chars)\n            frag.match_str += tok_text\n            for capt in tok_capts:\n                if capt in frag.captures:\n                    frag.captures[capt] += tok_capts[capt]\n                else:\n>                   frag.captures[capt] = tok_capts[capt]\nE                   TypeError: string indices must be integers, not \'str\'\n\nrepos\\datefinder\\datefinder\\__init__.py:172: TypeError', 'input_text = \'i am looking for a date june 4th 1996 to july 3rd 2013\'\nexpected_date = [datetime.datetime(1996, 6, 4, 0, 0), datetime.datetime(2013, 7, 3, 0, 0)]\nfirst = \'month\'\n\n    @pytest.mark.parametrize(\n        (""input_text"", ""expected_date"", ""first""),\n        [\n            ## English Dates\n            # (\'[Sept] 04, 2014.\', datetime(2014, 9, 4), ""month""),\n            (""Tuesday Jul 22, 2014"", datetime(2014, 7, 22), ""month""),\n            # (\'10:04am EDT\', datetime(2012, 11, 13, 14, 4), ""month""),\n            # (\'Friday\', datetime(2012, 11, 9), ""month""),\n            # (\'November 19, 2014 at noon\', datetime(2014, 11, 19, 12, 0), ""month""),\n            (""December 13, 2014 at midnight"", datetime(2014, 12, 13, 0, 0), ""month""),\n            # (\'Nov 25 2014 10:17 pm EST\', datetime(2014, 11, 26, 3, 17), ""month""),\n            # (\'Wed Aug 05 12:00:00 EDT 2015\', datetime(2015, 8, 5, 16, 0), ""month""),\n            (""April 9, 2013 at 6:11 a.m."", datetime(2013, 4, 9, 6, 11), ""month""),\n            (""Aug. 9, 2012 at 2:57 p.m."", datetime(2012, 8, 9, 14, 57), ""month""),\n            (""December 10, 2014, 11:02:21 pm"", datetime(2014, 12, 10, 23, 2, 21), ""month""),\n            (""8:25 a.m. Dec. 12, 2014"", datetime(2014, 12, 12, 8, 25), ""month""),\n            (""2:21 p.m., December 11, 2014"", datetime(2014, 12, 11, 14, 21), ""month""),\n            (""Fri, 12 Dec 2014 10:55:50"", datetime(2014, 12, 12, 10, 55, 50), ""month""),\n            # (\'20 Mar 2013 10h11\', datetime(2013, 3, 20, 10, 11), ""month""),\n            (""10:06am Dec 11, 2014"", datetime(2014, 12, 11, 10, 6), ""month""),\n            (""September 2nd, 1998"", datetime(1998, 9, 2), ""month""),\n            (\n                ""May 5, 2010 to July 10, 2011"",\n                [datetime(2010, 5, 5), datetime(2011, 7, 10)],\n                ""month"",\n            ),\n            # (\'19 February 2013 year 09:10\', datetime(2013, 2, 19, 9, 10), ""month""),\n            # Numeric dates\n            (""06-17-2014"", datetime(2014, 6, 17), ""month""),\n            (""13/03/2014"", datetime(2014, 3, 13), ""month""),\n            (\n                ""2016-02-04T20:16:26+00:00"",\n                datetime(2016, 2, 4, 20, 16, 26, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            # (\'11. 12. 2014, 08:45:39\', datetime(2014, 11, 12, 8, 45, 39)),\n            (\n                ""2017-02-03T09:04:08Z to 2017-02-03T09:04:09Z"",\n                [\n                    datetime(2017, 2, 3, 9, 4, 8, tzinfo=pytz.utc),\n                    datetime(2017, 2, 3, 9, 4, 9, tzinfo=pytz.utc),\n                ],\n                ""month"",\n            ),\n            # dates from issue https://github.com/akoumjian/datefinder/issues/14\n            (\n                ""i am looking for a date june 4th 1996 to july 3rd 2013"",\n                [datetime(1996, 6, 4), datetime(2013, 7, 3)],\n                ""month"",\n            ),\n            (\n                ""october 27 1994 to be put into effect on june 1 1995"",\n                [datetime(1994, 10, 27), datetime(1995, 6, 1)],\n                ""month"",\n            ),\n            # Simple date range\n            (\n                ""31/08/2012 to 30/08/2013"",\n                [datetime(2012, 8, 31), datetime(2013, 8, 30)],\n                ""month"",\n            ),\n            (\n                ""31 Oct 2021 - 28 Nov 2021"",\n                [datetime(2021, 10, 31), datetime(2021, 11, 28)],\n                ""day""\n            ),\n            # Z dates with and without millis, from https://github.com/akoumjian/datefinder/issues/37\n            (\n                ""2017-02-03T09:04:08.001Z"",\n                datetime(2017, 2, 3, 9, 4, 8, 1000, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            (\n                ""2017-02-03T09:04:08,00123Z"",\n                datetime(2017, 2, 3, 9, 4, 8, 1230, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            (\n                ""2017-02-03T09:04:08Z"",\n                datetime(2017, 2, 3, 9, 4, 8, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            # Year only strings, from https://github.com/akoumjian/datefinder/issues/96\n            (\n                ""Dutta is the recipient of Femina Miss India Universe title in 2004."",\n                datetime(2004, today.month, today.day),\n                ""month"",\n            ),\n            (\n                \'she said that she hit depression after being traumatized on the sets of ""Horn OK"" in 2008.\',\n                datetime(2008, today.month, today.day),\n                ""month"",\n            ),\n            # https://github.com/akoumjian/datefinder/issues/63\n            (""12th day of December, 2001"", datetime(2001, 12, 12), ""month""),\n            (""01/02/03"", datetime(2003, 1, 2, 0, 0, 0, 0), ""month""),\n            (""01/02/03"", datetime(2003, 2, 1, 0, 0, 0, 0), ""day""),\n            (""01/02/03"", datetime(2001, 2, 3, 0, 0, 0, 0), ""year""),\n            (""02/05/2020"", datetime(2020, 2, 5, 0, 0, 0, 0), ""month""),\n            (""02/05/2020"", datetime(2020, 5, 2, 0, 0, 0, 0), ""day""),\n        ],\n    )\n    def test_find_date_strings(input_text, expected_date, first):\n        if isinstance(expected_date, list):\n            matches = list(datefinder.find_dates(input_text, first=first))\n>           assert matches == expected_date\nE           assert [] == [datetime.dat..., 7, 3, 0, 0)]\nE             \nE             Right contains 2 more items, first extra item: datetime.datetime(1996, 6, 4, 0, 0)\nE             \nE             Full diff:\nE             + []\nE             - [\nE             -     datetime.datetime(1996, 6, 4, 0, 0),\nE             -     datetime.datetime(2013, 7, 3, 0, 0),\nE             - ]\n\nrepos\\datefinder\\tests\\test_find_dates.py:119: AssertionError', 'input_text = \'october 27 1994 to be put into effect on june 1 1995\'\nexpected_date = [datetime.datetime(1994, 10, 27, 0, 0), datetime.datetime(1995, 6, 1, 0, 0)]\nfirst = \'month\'\n\n    @pytest.mark.parametrize(\n        (""input_text"", ""expected_date"", ""first""),\n        [\n            ## English Dates\n            # (\'[Sept] 04, 2014.\', datetime(2014, 9, 4), ""month""),\n            (""Tuesday Jul 22, 2014"", datetime(2014, 7, 22), ""month""),\n            # (\'10:04am EDT\', datetime(2012, 11, 13, 14, 4), ""month""),\n            # (\'Friday\', datetime(2012, 11, 9), ""month""),\n            # (\'November 19, 2014 at noon\', datetime(2014, 11, 19, 12, 0), ""month""),\n            (""December 13, 2014 at midnight"", datetime(2014, 12, 13, 0, 0), ""month""),\n            # (\'Nov 25 2014 10:17 pm EST\', datetime(2014, 11, 26, 3, 17), ""month""),\n            # (\'Wed Aug 05 12:00:00 EDT 2015\', datetime(2015, 8, 5, 16, 0), ""month""),\n            (""April 9, 2013 at 6:11 a.m."", datetime(2013, 4, 9, 6, 11), ""month""),\n            (""Aug. 9, 2012 at 2:57 p.m."", datetime(2012, 8, 9, 14, 57), ""month""),\n            (""December 10, 2014, 11:02:21 pm"", datetime(2014, 12, 10, 23, 2, 21), ""month""),\n            (""8:25 a.m. Dec. 12, 2014"", datetime(2014, 12, 12, 8, 25), ""month""),\n            (""2:21 p.m., December 11, 2014"", datetime(2014, 12, 11, 14, 21), ""month""),\n            (""Fri, 12 Dec 2014 10:55:50"", datetime(2014, 12, 12, 10, 55, 50), ""month""),\n            # (\'20 Mar 2013 10h11\', datetime(2013, 3, 20, 10, 11), ""month""),\n            (""10:06am Dec 11, 2014"", datetime(2014, 12, 11, 10, 6), ""month""),\n            (""September 2nd, 1998"", datetime(1998, 9, 2), ""month""),\n            (\n                ""May 5, 2010 to July 10, 2011"",\n                [datetime(2010, 5, 5), datetime(2011, 7, 10)],\n                ""month"",\n            ),\n            # (\'19 February 2013 year 09:10\', datetime(2013, 2, 19, 9, 10), ""month""),\n            # Numeric dates\n            (""06-17-2014"", datetime(2014, 6, 17), ""month""),\n            (""13/03/2014"", datetime(2014, 3, 13), ""month""),\n            (\n                ""2016-02-04T20:16:26+00:00"",\n                datetime(2016, 2, 4, 20, 16, 26, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            # (\'11. 12. 2014, 08:45:39\', datetime(2014, 11, 12, 8, 45, 39)),\n            (\n                ""2017-02-03T09:04:08Z to 2017-02-03T09:04:09Z"",\n                [\n                    datetime(2017, 2, 3, 9, 4, 8, tzinfo=pytz.utc),\n                    datetime(2017, 2, 3, 9, 4, 9, tzinfo=pytz.utc),\n                ],\n                ""month"",\n            ),\n            # dates from issue https://github.com/akoumjian/datefinder/issues/14\n            (\n                ""i am looking for a date june 4th 1996 to july 3rd 2013"",\n                [datetime(1996, 6, 4), datetime(2013, 7, 3)],\n                ""month"",\n            ),\n            (\n                ""october 27 1994 to be put into effect on june 1 1995"",\n                [datetime(1994, 10, 27), datetime(1995, 6, 1)],\n                ""month"",\n            ),\n            # Simple date range\n            (\n                ""31/08/2012 to 30/08/2013"",\n                [datetime(2012, 8, 31), datetime(2013, 8, 30)],\n                ""month"",\n            ),\n            (\n                ""31 Oct 2021 - 28 Nov 2021"",\n                [datetime(2021, 10, 31), datetime(2021, 11, 28)],\n                ""day""\n            ),\n            # Z dates with and without millis, from https://github.com/akoumjian/datefinder/issues/37\n            (\n                ""2017-02-03T09:04:08.001Z"",\n                datetime(2017, 2, 3, 9, 4, 8, 1000, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            (\n                ""2017-02-03T09:04:08,00123Z"",\n                datetime(2017, 2, 3, 9, 4, 8, 1230, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            (\n                ""2017-02-03T09:04:08Z"",\n                datetime(2017, 2, 3, 9, 4, 8, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            # Year only strings, from https://github.com/akoumjian/datefinder/issues/96\n            (\n                ""Dutta is the recipient of Femina Miss India Universe title in 2004."",\n                datetime(2004, today.month, today.day),\n                ""month"",\n            ),\n            (\n                \'she said that she hit depression after being traumatized on the sets of ""Horn OK"" in 2008.\',\n                datetime(2008, today.month, today.day),\n                ""month"",\n            ),\n            # https://github.com/akoumjian/datefinder/issues/63\n            (""12th day of December, 2001"", datetime(2001, 12, 12), ""month""),\n            (""01/02/03"", datetime(2003, 1, 2, 0, 0, 0, 0), ""month""),\n            (""01/02/03"", datetime(2003, 2, 1, 0, 0, 0, 0), ""day""),\n            (""01/02/03"", datetime(2001, 2, 3, 0, 0, 0, 0), ""year""),\n            (""02/05/2020"", datetime(2020, 2, 5, 0, 0, 0, 0), ""month""),\n            (""02/05/2020"", datetime(2020, 5, 2, 0, 0, 0, 0), ""day""),\n        ],\n    )\n    def test_find_date_strings(input_text, expected_date, first):\n        if isinstance(expected_date, list):\n            matches = list(datefinder.find_dates(input_text, first=first))\n>           assert matches == expected_date\nE           assert [] == [datetime.dat..., 6, 1, 0, 0)]\nE             \nE             Right contains 2 more items, first extra item: datetime.datetime(1994, 10, 27, 0, 0)\nE             \nE             Full diff:\nE             + []\nE             - [\nE             -     datetime.datetime(1994, 10, 27, 0, 0),\nE             -     datetime.datetime(1995, 6, 1, 0, 0),\nE             - ]\n\nrepos\\datefinder\\tests\\test_find_dates.py:119: AssertionError', 'input_text = \'31/08/2012 to 30/08/2013\'\nexpected_date = [datetime.datetime(2012, 8, 31, 0, 0), datetime.datetime(2013, 8, 30, 0, 0)]\nfirst = \'month\'\n\n    @pytest.mark.parametrize(\n        (""input_text"", ""expected_date"", ""first""),\n        [\n            ## English Dates\n            # (\'[Sept] 04, 2014.\', datetime(2014, 9, 4), ""month""),\n            (""Tuesday Jul 22, 2014"", datetime(2014, 7, 22), ""month""),\n            # (\'10:04am EDT\', datetime(2012, 11, 13, 14, 4), ""month""),\n            # (\'Friday\', datetime(2012, 11, 9), ""month""),\n            # (\'November 19, 2014 at noon\', datetime(2014, 11, 19, 12, 0), ""month""),\n            (""December 13, 2014 at midnight"", datetime(2014, 12, 13, 0, 0), ""month""),\n            # (\'Nov 25 2014 10:17 pm EST\', datetime(2014, 11, 26, 3, 17), ""month""),\n            # (\'Wed Aug 05 12:00:00 EDT 2015\', datetime(2015, 8, 5, 16, 0), ""month""),\n            (""April 9, 2013 at 6:11 a.m."", datetime(2013, 4, 9, 6, 11), ""month""),\n            (""Aug. 9, 2012 at 2:57 p.m."", datetime(2012, 8, 9, 14, 57), ""month""),\n            (""December 10, 2014, 11:02:21 pm"", datetime(2014, 12, 10, 23, 2, 21), ""month""),\n            (""8:25 a.m. Dec. 12, 2014"", datetime(2014, 12, 12, 8, 25), ""month""),\n            (""2:21 p.m., December 11, 2014"", datetime(2014, 12, 11, 14, 21), ""month""),\n            (""Fri, 12 Dec 2014 10:55:50"", datetime(2014, 12, 12, 10, 55, 50), ""month""),\n            # (\'20 Mar 2013 10h11\', datetime(2013, 3, 20, 10, 11), ""month""),\n            (""10:06am Dec 11, 2014"", datetime(2014, 12, 11, 10, 6), ""month""),\n            (""September 2nd, 1998"", datetime(1998, 9, 2), ""month""),\n            (\n                ""May 5, 2010 to July 10, 2011"",\n                [datetime(2010, 5, 5), datetime(2011, 7, 10)],\n                ""month"",\n            ),\n            # (\'19 February 2013 year 09:10\', datetime(2013, 2, 19, 9, 10), ""month""),\n            # Numeric dates\n            (""06-17-2014"", datetime(2014, 6, 17), ""month""),\n            (""13/03/2014"", datetime(2014, 3, 13), ""month""),\n            (\n                ""2016-02-04T20:16:26+00:00"",\n                datetime(2016, 2, 4, 20, 16, 26, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            # (\'11. 12. 2014, 08:45:39\', datetime(2014, 11, 12, 8, 45, 39)),\n            (\n                ""2017-02-03T09:04:08Z to 2017-02-03T09:04:09Z"",\n                [\n                    datetime(2017, 2, 3, 9, 4, 8, tzinfo=pytz.utc),\n                    datetime(2017, 2, 3, 9, 4, 9, tzinfo=pytz.utc),\n                ],\n                ""month"",\n            ),\n            # dates from issue https://github.com/akoumjian/datefinder/issues/14\n            (\n                ""i am looking for a date june 4th 1996 to july 3rd 2013"",\n                [datetime(1996, 6, 4), datetime(2013, 7, 3)],\n                ""month"",\n            ),\n            (\n                ""october 27 1994 to be put into effect on june 1 1995"",\n                [datetime(1994, 10, 27), datetime(1995, 6, 1)],\n                ""month"",\n            ),\n            # Simple date range\n            (\n                ""31/08/2012 to 30/08/2013"",\n                [datetime(2012, 8, 31), datetime(2013, 8, 30)],\n                ""month"",\n            ),\n            (\n                ""31 Oct 2021 - 28 Nov 2021"",\n                [datetime(2021, 10, 31), datetime(2021, 11, 28)],\n                ""day""\n            ),\n            # Z dates with and without millis, from https://github.com/akoumjian/datefinder/issues/37\n            (\n                ""2017-02-03T09:04:08.001Z"",\n                datetime(2017, 2, 3, 9, 4, 8, 1000, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            (\n                ""2017-02-03T09:04:08,00123Z"",\n                datetime(2017, 2, 3, 9, 4, 8, 1230, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            (\n                ""2017-02-03T09:04:08Z"",\n                datetime(2017, 2, 3, 9, 4, 8, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            # Year only strings, from https://github.com/akoumjian/datefinder/issues/96\n            (\n                ""Dutta is the recipient of Femina Miss India Universe title in 2004."",\n                datetime(2004, today.month, today.day),\n                ""month"",\n            ),\n            (\n                \'she said that she hit depression after being traumatized on the sets of ""Horn OK"" in 2008.\',\n                datetime(2008, today.month, today.day),\n                ""month"",\n            ),\n            # https://github.com/akoumjian/datefinder/issues/63\n            (""12th day of December, 2001"", datetime(2001, 12, 12), ""month""),\n            (""01/02/03"", datetime(2003, 1, 2, 0, 0, 0, 0), ""month""),\n            (""01/02/03"", datetime(2003, 2, 1, 0, 0, 0, 0), ""day""),\n            (""01/02/03"", datetime(2001, 2, 3, 0, 0, 0, 0), ""year""),\n            (""02/05/2020"", datetime(2020, 2, 5, 0, 0, 0, 0), ""month""),\n            (""02/05/2020"", datetime(2020, 5, 2, 0, 0, 0, 0), ""day""),\n        ],\n    )\n    def test_find_date_strings(input_text, expected_date, first):\n        if isinstance(expected_date, list):\n>           matches = list(datefinder.find_dates(input_text, first=first))\n\nrepos\\datefinder\\tests\\test_find_dates.py:118: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\datefinder\\datefinder\\__init__.py:24: in find_dates\n    for date_string, indices, captures in self.extract_date_strings(text, strict=strict):\nrepos\\datefinder\\datefinder\\__init__.py:105: in extract_date_strings_inner\n    range_strings.extend(self.extract_date_strings_inner(range_str[0], text_start=range_str[1][0], strict=strict))\nrepos\\datefinder\\datefinder\\__init__.py:110: in extract_date_strings_inner\n    items = self.merge_tokens(tokens)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <datefinder.DateFinder object at 0x000002AC9DAC9F10>\ntokens = [(\'31/08/2012\', \'31\', \'08\', \'2012\')]\n\n    def merge_tokens(self, tokens):\n        """"""\n        Makes potential date strings out of matches, got from tokenize_string method.\n        :param tokens: [(match_text, match_group, {match.capturesdict()}), ...]\n        :return: potential date strings\n        """"""\n        MIN_MATCHES = 3\n        fragments = []\n        frag = DateFragment()\n        start_char, total_chars = (0, 0)\n        for token in tokens:\n            total_chars += len(token[0])\n            tok_text, group, tok_capts = (token[0], token[1], token[2])\n            if not group:\n                if frag.indices[1] > 0:\n                    if frag.get_captures_count() >= MIN_MATCHES:\n                        fragments.append(frag)\n                frag = DateFragment()\n                start_char = total_chars\n                continue\n            if frag.indices[1] == 0:\n                frag.indices = (start_char, total_chars)\n            else:\n                frag.indices = (frag.indices[0], total_chars)\n            frag.match_str += tok_text\n            for capt in tok_capts:\n                if capt in frag.captures:\n                    frag.captures[capt] += tok_capts[capt]\n                else:\n>                   frag.captures[capt] = tok_capts[capt]\nE                   TypeError: string indices must be integers, not \'str\'\n\nrepos\\datefinder\\datefinder\\__init__.py:172: TypeError', 'input_text = \'31 Oct 2021 - 28 Nov 2021\'\nexpected_date = [datetime.datetime(2021, 10, 31, 0, 0), datetime.datetime(2021, 11, 28, 0, 0)]\nfirst = \'day\'\n\n    @pytest.mark.parametrize(\n        (""input_text"", ""expected_date"", ""first""),\n        [\n            ## English Dates\n            # (\'[Sept] 04, 2014.\', datetime(2014, 9, 4), ""month""),\n            (""Tuesday Jul 22, 2014"", datetime(2014, 7, 22), ""month""),\n            # (\'10:04am EDT\', datetime(2012, 11, 13, 14, 4), ""month""),\n            # (\'Friday\', datetime(2012, 11, 9), ""month""),\n            # (\'November 19, 2014 at noon\', datetime(2014, 11, 19, 12, 0), ""month""),\n            (""December 13, 2014 at midnight"", datetime(2014, 12, 13, 0, 0), ""month""),\n            # (\'Nov 25 2014 10:17 pm EST\', datetime(2014, 11, 26, 3, 17), ""month""),\n            # (\'Wed Aug 05 12:00:00 EDT 2015\', datetime(2015, 8, 5, 16, 0), ""month""),\n            (""April 9, 2013 at 6:11 a.m."", datetime(2013, 4, 9, 6, 11), ""month""),\n            (""Aug. 9, 2012 at 2:57 p.m."", datetime(2012, 8, 9, 14, 57), ""month""),\n            (""December 10, 2014, 11:02:21 pm"", datetime(2014, 12, 10, 23, 2, 21), ""month""),\n            (""8:25 a.m. Dec. 12, 2014"", datetime(2014, 12, 12, 8, 25), ""month""),\n            (""2:21 p.m., December 11, 2014"", datetime(2014, 12, 11, 14, 21), ""month""),\n            (""Fri, 12 Dec 2014 10:55:50"", datetime(2014, 12, 12, 10, 55, 50), ""month""),\n            # (\'20 Mar 2013 10h11\', datetime(2013, 3, 20, 10, 11), ""month""),\n            (""10:06am Dec 11, 2014"", datetime(2014, 12, 11, 10, 6), ""month""),\n            (""September 2nd, 1998"", datetime(1998, 9, 2), ""month""),\n            (\n                ""May 5, 2010 to July 10, 2011"",\n                [datetime(2010, 5, 5), datetime(2011, 7, 10)],\n                ""month"",\n            ),\n            # (\'19 February 2013 year 09:10\', datetime(2013, 2, 19, 9, 10), ""month""),\n            # Numeric dates\n            (""06-17-2014"", datetime(2014, 6, 17), ""month""),\n            (""13/03/2014"", datetime(2014, 3, 13), ""month""),\n            (\n                ""2016-02-04T20:16:26+00:00"",\n                datetime(2016, 2, 4, 20, 16, 26, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            # (\'11. 12. 2014, 08:45:39\', datetime(2014, 11, 12, 8, 45, 39)),\n            (\n                ""2017-02-03T09:04:08Z to 2017-02-03T09:04:09Z"",\n                [\n                    datetime(2017, 2, 3, 9, 4, 8, tzinfo=pytz.utc),\n                    datetime(2017, 2, 3, 9, 4, 9, tzinfo=pytz.utc),\n                ],\n                ""month"",\n            ),\n            # dates from issue https://github.com/akoumjian/datefinder/issues/14\n            (\n                ""i am looking for a date june 4th 1996 to july 3rd 2013"",\n                [datetime(1996, 6, 4), datetime(2013, 7, 3)],\n                ""month"",\n            ),\n            (\n                ""october 27 1994 to be put into effect on june 1 1995"",\n                [datetime(1994, 10, 27), datetime(1995, 6, 1)],\n                ""month"",\n            ),\n            # Simple date range\n            (\n                ""31/08/2012 to 30/08/2013"",\n                [datetime(2012, 8, 31), datetime(2013, 8, 30)],\n                ""month"",\n            ),\n            (\n                ""31 Oct 2021 - 28 Nov 2021"",\n                [datetime(2021, 10, 31), datetime(2021, 11, 28)],\n                ""day""\n            ),\n            # Z dates with and without millis, from https://github.com/akoumjian/datefinder/issues/37\n            (\n                ""2017-02-03T09:04:08.001Z"",\n                datetime(2017, 2, 3, 9, 4, 8, 1000, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            (\n                ""2017-02-03T09:04:08,00123Z"",\n                datetime(2017, 2, 3, 9, 4, 8, 1230, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            (\n                ""2017-02-03T09:04:08Z"",\n                datetime(2017, 2, 3, 9, 4, 8, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            # Year only strings, from https://github.com/akoumjian/datefinder/issues/96\n            (\n                ""Dutta is the recipient of Femina Miss India Universe title in 2004."",\n                datetime(2004, today.month, today.day),\n                ""month"",\n            ),\n            (\n                \'she said that she hit depression after being traumatized on the sets of ""Horn OK"" in 2008.\',\n                datetime(2008, today.month, today.day),\n                ""month"",\n            ),\n            # https://github.com/akoumjian/datefinder/issues/63\n            (""12th day of December, 2001"", datetime(2001, 12, 12), ""month""),\n            (""01/02/03"", datetime(2003, 1, 2, 0, 0, 0, 0), ""month""),\n            (""01/02/03"", datetime(2003, 2, 1, 0, 0, 0, 0), ""day""),\n            (""01/02/03"", datetime(2001, 2, 3, 0, 0, 0, 0), ""year""),\n            (""02/05/2020"", datetime(2020, 2, 5, 0, 0, 0, 0), ""month""),\n            (""02/05/2020"", datetime(2020, 5, 2, 0, 0, 0, 0), ""day""),\n        ],\n    )\n    def test_find_date_strings(input_text, expected_date, first):\n        if isinstance(expected_date, list):\n            matches = list(datefinder.find_dates(input_text, first=first))\n>           assert matches == expected_date\nE           assert [] == [datetime.dat...11, 28, 0, 0)]\nE             \nE             Right contains 2 more items, first extra item: datetime.datetime(2021, 10, 31, 0, 0)\nE             \nE             Full diff:\nE             + []\nE             - [\nE             -     datetime.datetime(2021, 10, 31, 0, 0),\nE             -     datetime.datetime(2021, 11, 28, 0, 0),\nE             - ]\n\nrepos\\datefinder\\tests\\test_find_dates.py:119: AssertionError', 'input_text = \'2017-02-03T09:04:08.001Z\'\nexpected_date = datetime.datetime(2017, 2, 3, 9, 4, 8, 1000, tzinfo=<UTC>)\nfirst = \'month\'\n\n    @pytest.mark.parametrize(\n        (""input_text"", ""expected_date"", ""first""),\n        [\n            ## English Dates\n            # (\'[Sept] 04, 2014.\', datetime(2014, 9, 4), ""month""),\n            (""Tuesday Jul 22, 2014"", datetime(2014, 7, 22), ""month""),\n            # (\'10:04am EDT\', datetime(2012, 11, 13, 14, 4), ""month""),\n            # (\'Friday\', datetime(2012, 11, 9), ""month""),\n            # (\'November 19, 2014 at noon\', datetime(2014, 11, 19, 12, 0), ""month""),\n            (""December 13, 2014 at midnight"", datetime(2014, 12, 13, 0, 0), ""month""),\n            # (\'Nov 25 2014 10:17 pm EST\', datetime(2014, 11, 26, 3, 17), ""month""),\n            # (\'Wed Aug 05 12:00:00 EDT 2015\', datetime(2015, 8, 5, 16, 0), ""month""),\n            (""April 9, 2013 at 6:11 a.m."", datetime(2013, 4, 9, 6, 11), ""month""),\n            (""Aug. 9, 2012 at 2:57 p.m."", datetime(2012, 8, 9, 14, 57), ""month""),\n            (""December 10, 2014, 11:02:21 pm"", datetime(2014, 12, 10, 23, 2, 21), ""month""),\n            (""8:25 a.m. Dec. 12, 2014"", datetime(2014, 12, 12, 8, 25), ""month""),\n            (""2:21 p.m., December 11, 2014"", datetime(2014, 12, 11, 14, 21), ""month""),\n            (""Fri, 12 Dec 2014 10:55:50"", datetime(2014, 12, 12, 10, 55, 50), ""month""),\n            # (\'20 Mar 2013 10h11\', datetime(2013, 3, 20, 10, 11), ""month""),\n            (""10:06am Dec 11, 2014"", datetime(2014, 12, 11, 10, 6), ""month""),\n            (""September 2nd, 1998"", datetime(1998, 9, 2), ""month""),\n            (\n                ""May 5, 2010 to July 10, 2011"",\n                [datetime(2010, 5, 5), datetime(2011, 7, 10)],\n                ""month"",\n            ),\n            # (\'19 February 2013 year 09:10\', datetime(2013, 2, 19, 9, 10), ""month""),\n            # Numeric dates\n            (""06-17-2014"", datetime(2014, 6, 17), ""month""),\n            (""13/03/2014"", datetime(2014, 3, 13), ""month""),\n            (\n                ""2016-02-04T20:16:26+00:00"",\n                datetime(2016, 2, 4, 20, 16, 26, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            # (\'11. 12. 2014, 08:45:39\', datetime(2014, 11, 12, 8, 45, 39)),\n            (\n                ""2017-02-03T09:04:08Z to 2017-02-03T09:04:09Z"",\n                [\n                    datetime(2017, 2, 3, 9, 4, 8, tzinfo=pytz.utc),\n                    datetime(2017, 2, 3, 9, 4, 9, tzinfo=pytz.utc),\n                ],\n                ""month"",\n            ),\n            # dates from issue https://github.com/akoumjian/datefinder/issues/14\n            (\n                ""i am looking for a date june 4th 1996 to july 3rd 2013"",\n                [datetime(1996, 6, 4), datetime(2013, 7, 3)],\n                ""month"",\n            ),\n            (\n                ""october 27 1994 to be put into effect on june 1 1995"",\n                [datetime(1994, 10, 27), datetime(1995, 6, 1)],\n                ""month"",\n            ),\n            # Simple date range\n            (\n                ""31/08/2012 to 30/08/2013"",\n                [datetime(2012, 8, 31), datetime(2013, 8, 30)],\n                ""month"",\n            ),\n            (\n                ""31 Oct 2021 - 28 Nov 2021"",\n                [datetime(2021, 10, 31), datetime(2021, 11, 28)],\n                ""day""\n            ),\n            # Z dates with and without millis, from https://github.com/akoumjian/datefinder/issues/37\n            (\n                ""2017-02-03T09:04:08.001Z"",\n                datetime(2017, 2, 3, 9, 4, 8, 1000, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            (\n                ""2017-02-03T09:04:08,00123Z"",\n                datetime(2017, 2, 3, 9, 4, 8, 1230, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            (\n                ""2017-02-03T09:04:08Z"",\n                datetime(2017, 2, 3, 9, 4, 8, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            # Year only strings, from https://github.com/akoumjian/datefinder/issues/96\n            (\n                ""Dutta is the recipient of Femina Miss India Universe title in 2004."",\n                datetime(2004, today.month, today.day),\n                ""month"",\n            ),\n            (\n                \'she said that she hit depression after being traumatized on the sets of ""Horn OK"" in 2008.\',\n                datetime(2008, today.month, today.day),\n                ""month"",\n            ),\n            # https://github.com/akoumjian/datefinder/issues/63\n            (""12th day of December, 2001"", datetime(2001, 12, 12), ""month""),\n            (""01/02/03"", datetime(2003, 1, 2, 0, 0, 0, 0), ""month""),\n            (""01/02/03"", datetime(2003, 2, 1, 0, 0, 0, 0), ""day""),\n            (""01/02/03"", datetime(2001, 2, 3, 0, 0, 0, 0), ""year""),\n            (""02/05/2020"", datetime(2020, 2, 5, 0, 0, 0, 0), ""month""),\n            (""02/05/2020"", datetime(2020, 5, 2, 0, 0, 0, 0), ""day""),\n        ],\n    )\n    def test_find_date_strings(input_text, expected_date, first):\n        if isinstance(expected_date, list):\n            matches = list(datefinder.find_dates(input_text, first=first))\n            assert matches == expected_date\n        else:\n            return_date = None\n>           for return_date in datefinder.find_dates(input_text, first=first):\n\nrepos\\datefinder\\tests\\test_find_dates.py:122: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\datefinder\\datefinder\\__init__.py:24: in find_dates\n    for date_string, indices, captures in self.extract_date_strings(text, strict=strict):\nrepos\\datefinder\\datefinder\\__init__.py:110: in extract_date_strings_inner\n    items = self.merge_tokens(tokens)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <datefinder.DateFinder object at 0x000002AC9DAAE330>\ntokens = [(\'17-02-03\', \'17\', \'02\', \'03\')]\n\n    def merge_tokens(self, tokens):\n        """"""\n        Makes potential date strings out of matches, got from tokenize_string method.\n        :param tokens: [(match_text, match_group, {match.capturesdict()}), ...]\n        :return: potential date strings\n        """"""\n        MIN_MATCHES = 3\n        fragments = []\n        frag = DateFragment()\n        start_char, total_chars = (0, 0)\n        for token in tokens:\n            total_chars += len(token[0])\n            tok_text, group, tok_capts = (token[0], token[1], token[2])\n            if not group:\n                if frag.indices[1] > 0:\n                    if frag.get_captures_count() >= MIN_MATCHES:\n                        fragments.append(frag)\n                frag = DateFragment()\n                start_char = total_chars\n                continue\n            if frag.indices[1] == 0:\n                frag.indices = (start_char, total_chars)\n            else:\n                frag.indices = (frag.indices[0], total_chars)\n            frag.match_str += tok_text\n            for capt in tok_capts:\n                if capt in frag.captures:\n                    frag.captures[capt] += tok_capts[capt]\n                else:\n>                   frag.captures[capt] = tok_capts[capt]\nE                   TypeError: string indices must be integers, not \'str\'\n\nrepos\\datefinder\\datefinder\\__init__.py:172: TypeError', 'input_text = \'2017-02-03T09:04:08,00123Z\'\nexpected_date = datetime.datetime(2017, 2, 3, 9, 4, 8, 1230, tzinfo=<UTC>)\nfirst = \'month\'\n\n    @pytest.mark.parametrize(\n        (""input_text"", ""expected_date"", ""first""),\n        [\n            ## English Dates\n            # (\'[Sept] 04, 2014.\', datetime(2014, 9, 4), ""month""),\n            (""Tuesday Jul 22, 2014"", datetime(2014, 7, 22), ""month""),\n            # (\'10:04am EDT\', datetime(2012, 11, 13, 14, 4), ""month""),\n            # (\'Friday\', datetime(2012, 11, 9), ""month""),\n            # (\'November 19, 2014 at noon\', datetime(2014, 11, 19, 12, 0), ""month""),\n            (""December 13, 2014 at midnight"", datetime(2014, 12, 13, 0, 0), ""month""),\n            # (\'Nov 25 2014 10:17 pm EST\', datetime(2014, 11, 26, 3, 17), ""month""),\n            # (\'Wed Aug 05 12:00:00 EDT 2015\', datetime(2015, 8, 5, 16, 0), ""month""),\n            (""April 9, 2013 at 6:11 a.m."", datetime(2013, 4, 9, 6, 11), ""month""),\n            (""Aug. 9, 2012 at 2:57 p.m."", datetime(2012, 8, 9, 14, 57), ""month""),\n            (""December 10, 2014, 11:02:21 pm"", datetime(2014, 12, 10, 23, 2, 21), ""month""),\n            (""8:25 a.m. Dec. 12, 2014"", datetime(2014, 12, 12, 8, 25), ""month""),\n            (""2:21 p.m., December 11, 2014"", datetime(2014, 12, 11, 14, 21), ""month""),\n            (""Fri, 12 Dec 2014 10:55:50"", datetime(2014, 12, 12, 10, 55, 50), ""month""),\n            # (\'20 Mar 2013 10h11\', datetime(2013, 3, 20, 10, 11), ""month""),\n            (""10:06am Dec 11, 2014"", datetime(2014, 12, 11, 10, 6), ""month""),\n            (""September 2nd, 1998"", datetime(1998, 9, 2), ""month""),\n            (\n                ""May 5, 2010 to July 10, 2011"",\n                [datetime(2010, 5, 5), datetime(2011, 7, 10)],\n                ""month"",\n            ),\n            # (\'19 February 2013 year 09:10\', datetime(2013, 2, 19, 9, 10), ""month""),\n            # Numeric dates\n            (""06-17-2014"", datetime(2014, 6, 17), ""month""),\n            (""13/03/2014"", datetime(2014, 3, 13), ""month""),\n            (\n                ""2016-02-04T20:16:26+00:00"",\n                datetime(2016, 2, 4, 20, 16, 26, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            # (\'11. 12. 2014, 08:45:39\', datetime(2014, 11, 12, 8, 45, 39)),\n            (\n                ""2017-02-03T09:04:08Z to 2017-02-03T09:04:09Z"",\n                [\n                    datetime(2017, 2, 3, 9, 4, 8, tzinfo=pytz.utc),\n                    datetime(2017, 2, 3, 9, 4, 9, tzinfo=pytz.utc),\n                ],\n                ""month"",\n            ),\n            # dates from issue https://github.com/akoumjian/datefinder/issues/14\n            (\n                ""i am looking for a date june 4th 1996 to july 3rd 2013"",\n                [datetime(1996, 6, 4), datetime(2013, 7, 3)],\n                ""month"",\n            ),\n            (\n                ""october 27 1994 to be put into effect on june 1 1995"",\n                [datetime(1994, 10, 27), datetime(1995, 6, 1)],\n                ""month"",\n            ),\n            # Simple date range\n            (\n                ""31/08/2012 to 30/08/2013"",\n                [datetime(2012, 8, 31), datetime(2013, 8, 30)],\n                ""month"",\n            ),\n            (\n                ""31 Oct 2021 - 28 Nov 2021"",\n                [datetime(2021, 10, 31), datetime(2021, 11, 28)],\n                ""day""\n            ),\n            # Z dates with and without millis, from https://github.com/akoumjian/datefinder/issues/37\n            (\n                ""2017-02-03T09:04:08.001Z"",\n                datetime(2017, 2, 3, 9, 4, 8, 1000, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            (\n                ""2017-02-03T09:04:08,00123Z"",\n                datetime(2017, 2, 3, 9, 4, 8, 1230, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            (\n                ""2017-02-03T09:04:08Z"",\n                datetime(2017, 2, 3, 9, 4, 8, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            # Year only strings, from https://github.com/akoumjian/datefinder/issues/96\n            (\n                ""Dutta is the recipient of Femina Miss India Universe title in 2004."",\n                datetime(2004, today.month, today.day),\n                ""month"",\n            ),\n            (\n                \'she said that she hit depression after being traumatized on the sets of ""Horn OK"" in 2008.\',\n                datetime(2008, today.month, today.day),\n                ""month"",\n            ),\n            # https://github.com/akoumjian/datefinder/issues/63\n            (""12th day of December, 2001"", datetime(2001, 12, 12), ""month""),\n            (""01/02/03"", datetime(2003, 1, 2, 0, 0, 0, 0), ""month""),\n            (""01/02/03"", datetime(2003, 2, 1, 0, 0, 0, 0), ""day""),\n            (""01/02/03"", datetime(2001, 2, 3, 0, 0, 0, 0), ""year""),\n            (""02/05/2020"", datetime(2020, 2, 5, 0, 0, 0, 0), ""month""),\n            (""02/05/2020"", datetime(2020, 5, 2, 0, 0, 0, 0), ""day""),\n        ],\n    )\n    def test_find_date_strings(input_text, expected_date, first):\n        if isinstance(expected_date, list):\n            matches = list(datefinder.find_dates(input_text, first=first))\n            assert matches == expected_date\n        else:\n            return_date = None\n>           for return_date in datefinder.find_dates(input_text, first=first):\n\nrepos\\datefinder\\tests\\test_find_dates.py:122: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\datefinder\\datefinder\\__init__.py:24: in find_dates\n    for date_string, indices, captures in self.extract_date_strings(text, strict=strict):\nrepos\\datefinder\\datefinder\\__init__.py:110: in extract_date_strings_inner\n    items = self.merge_tokens(tokens)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <datefinder.DateFinder object at 0x000002AC9DAADD30>\ntokens = [(\'17-02-03\', \'17\', \'02\', \'03\')]\n\n    def merge_tokens(self, tokens):\n        """"""\n        Makes potential date strings out of matches, got from tokenize_string method.\n        :param tokens: [(match_text, match_group, {match.capturesdict()}), ...]\n        :return: potential date strings\n        """"""\n        MIN_MATCHES = 3\n        fragments = []\n        frag = DateFragment()\n        start_char, total_chars = (0, 0)\n        for token in tokens:\n            total_chars += len(token[0])\n            tok_text, group, tok_capts = (token[0], token[1], token[2])\n            if not group:\n                if frag.indices[1] > 0:\n                    if frag.get_captures_count() >= MIN_MATCHES:\n                        fragments.append(frag)\n                frag = DateFragment()\n                start_char = total_chars\n                continue\n            if frag.indices[1] == 0:\n                frag.indices = (start_char, total_chars)\n            else:\n                frag.indices = (frag.indices[0], total_chars)\n            frag.match_str += tok_text\n            for capt in tok_capts:\n                if capt in frag.captures:\n                    frag.captures[capt] += tok_capts[capt]\n                else:\n>                   frag.captures[capt] = tok_capts[capt]\nE                   TypeError: string indices must be integers, not \'str\'\n\nrepos\\datefinder\\datefinder\\__init__.py:172: TypeError', 'input_text = \'2017-02-03T09:04:08Z\'\nexpected_date = datetime.datetime(2017, 2, 3, 9, 4, 8, tzinfo=<UTC>)\nfirst = \'month\'\n\n    @pytest.mark.parametrize(\n        (""input_text"", ""expected_date"", ""first""),\n        [\n            ## English Dates\n            # (\'[Sept] 04, 2014.\', datetime(2014, 9, 4), ""month""),\n            (""Tuesday Jul 22, 2014"", datetime(2014, 7, 22), ""month""),\n            # (\'10:04am EDT\', datetime(2012, 11, 13, 14, 4), ""month""),\n            # (\'Friday\', datetime(2012, 11, 9), ""month""),\n            # (\'November 19, 2014 at noon\', datetime(2014, 11, 19, 12, 0), ""month""),\n            (""December 13, 2014 at midnight"", datetime(2014, 12, 13, 0, 0), ""month""),\n            # (\'Nov 25 2014 10:17 pm EST\', datetime(2014, 11, 26, 3, 17), ""month""),\n            # (\'Wed Aug 05 12:00:00 EDT 2015\', datetime(2015, 8, 5, 16, 0), ""month""),\n            (""April 9, 2013 at 6:11 a.m."", datetime(2013, 4, 9, 6, 11), ""month""),\n            (""Aug. 9, 2012 at 2:57 p.m."", datetime(2012, 8, 9, 14, 57), ""month""),\n            (""December 10, 2014, 11:02:21 pm"", datetime(2014, 12, 10, 23, 2, 21), ""month""),\n            (""8:25 a.m. Dec. 12, 2014"", datetime(2014, 12, 12, 8, 25), ""month""),\n            (""2:21 p.m., December 11, 2014"", datetime(2014, 12, 11, 14, 21), ""month""),\n            (""Fri, 12 Dec 2014 10:55:50"", datetime(2014, 12, 12, 10, 55, 50), ""month""),\n            # (\'20 Mar 2013 10h11\', datetime(2013, 3, 20, 10, 11), ""month""),\n            (""10:06am Dec 11, 2014"", datetime(2014, 12, 11, 10, 6), ""month""),\n            (""September 2nd, 1998"", datetime(1998, 9, 2), ""month""),\n            (\n                ""May 5, 2010 to July 10, 2011"",\n                [datetime(2010, 5, 5), datetime(2011, 7, 10)],\n                ""month"",\n            ),\n            # (\'19 February 2013 year 09:10\', datetime(2013, 2, 19, 9, 10), ""month""),\n            # Numeric dates\n            (""06-17-2014"", datetime(2014, 6, 17), ""month""),\n            (""13/03/2014"", datetime(2014, 3, 13), ""month""),\n            (\n                ""2016-02-04T20:16:26+00:00"",\n                datetime(2016, 2, 4, 20, 16, 26, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            # (\'11. 12. 2014, 08:45:39\', datetime(2014, 11, 12, 8, 45, 39)),\n            (\n                ""2017-02-03T09:04:08Z to 2017-02-03T09:04:09Z"",\n                [\n                    datetime(2017, 2, 3, 9, 4, 8, tzinfo=pytz.utc),\n                    datetime(2017, 2, 3, 9, 4, 9, tzinfo=pytz.utc),\n                ],\n                ""month"",\n            ),\n            # dates from issue https://github.com/akoumjian/datefinder/issues/14\n            (\n                ""i am looking for a date june 4th 1996 to july 3rd 2013"",\n                [datetime(1996, 6, 4), datetime(2013, 7, 3)],\n                ""month"",\n            ),\n            (\n                ""october 27 1994 to be put into effect on june 1 1995"",\n                [datetime(1994, 10, 27), datetime(1995, 6, 1)],\n                ""month"",\n            ),\n            # Simple date range\n            (\n                ""31/08/2012 to 30/08/2013"",\n                [datetime(2012, 8, 31), datetime(2013, 8, 30)],\n                ""month"",\n            ),\n            (\n                ""31 Oct 2021 - 28 Nov 2021"",\n                [datetime(2021, 10, 31), datetime(2021, 11, 28)],\n                ""day""\n            ),\n            # Z dates with and without millis, from https://github.com/akoumjian/datefinder/issues/37\n            (\n                ""2017-02-03T09:04:08.001Z"",\n                datetime(2017, 2, 3, 9, 4, 8, 1000, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            (\n                ""2017-02-03T09:04:08,00123Z"",\n                datetime(2017, 2, 3, 9, 4, 8, 1230, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            (\n                ""2017-02-03T09:04:08Z"",\n                datetime(2017, 2, 3, 9, 4, 8, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            # Year only strings, from https://github.com/akoumjian/datefinder/issues/96\n            (\n                ""Dutta is the recipient of Femina Miss India Universe title in 2004."",\n                datetime(2004, today.month, today.day),\n                ""month"",\n            ),\n            (\n                \'she said that she hit depression after being traumatized on the sets of ""Horn OK"" in 2008.\',\n                datetime(2008, today.month, today.day),\n                ""month"",\n            ),\n            # https://github.com/akoumjian/datefinder/issues/63\n            (""12th day of December, 2001"", datetime(2001, 12, 12), ""month""),\n            (""01/02/03"", datetime(2003, 1, 2, 0, 0, 0, 0), ""month""),\n            (""01/02/03"", datetime(2003, 2, 1, 0, 0, 0, 0), ""day""),\n            (""01/02/03"", datetime(2001, 2, 3, 0, 0, 0, 0), ""year""),\n            (""02/05/2020"", datetime(2020, 2, 5, 0, 0, 0, 0), ""month""),\n            (""02/05/2020"", datetime(2020, 5, 2, 0, 0, 0, 0), ""day""),\n        ],\n    )\n    def test_find_date_strings(input_text, expected_date, first):\n        if isinstance(expected_date, list):\n            matches = list(datefinder.find_dates(input_text, first=first))\n            assert matches == expected_date\n        else:\n            return_date = None\n>           for return_date in datefinder.find_dates(input_text, first=first):\n\nrepos\\datefinder\\tests\\test_find_dates.py:122: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\datefinder\\datefinder\\__init__.py:24: in find_dates\n    for date_string, indices, captures in self.extract_date_strings(text, strict=strict):\nrepos\\datefinder\\datefinder\\__init__.py:110: in extract_date_strings_inner\n    items = self.merge_tokens(tokens)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <datefinder.DateFinder object at 0x000002AC9DAAFD10>\ntokens = [(\'17-02-03\', \'17\', \'02\', \'03\')]\n\n    def merge_tokens(self, tokens):\n        """"""\n        Makes potential date strings out of matches, got from tokenize_string method.\n        :param tokens: [(match_text, match_group, {match.capturesdict()}), ...]\n        :return: potential date strings\n        """"""\n        MIN_MATCHES = 3\n        fragments = []\n        frag = DateFragment()\n        start_char, total_chars = (0, 0)\n        for token in tokens:\n            total_chars += len(token[0])\n            tok_text, group, tok_capts = (token[0], token[1], token[2])\n            if not group:\n                if frag.indices[1] > 0:\n                    if frag.get_captures_count() >= MIN_MATCHES:\n                        fragments.append(frag)\n                frag = DateFragment()\n                start_char = total_chars\n                continue\n            if frag.indices[1] == 0:\n                frag.indices = (start_char, total_chars)\n            else:\n                frag.indices = (frag.indices[0], total_chars)\n            frag.match_str += tok_text\n            for capt in tok_capts:\n                if capt in frag.captures:\n                    frag.captures[capt] += tok_capts[capt]\n                else:\n>                   frag.captures[capt] = tok_capts[capt]\nE                   TypeError: string indices must be integers, not \'str\'\n\nrepos\\datefinder\\datefinder\\__init__.py:172: TypeError', 'input_text = \'Dutta is the recipient of Femina Miss India Universe title in 2004.\'\nexpected_date = datetime.datetime(2004, 4, 14, 0, 0), first = \'month\'\n\n    @pytest.mark.parametrize(\n        (""input_text"", ""expected_date"", ""first""),\n        [\n            ## English Dates\n            # (\'[Sept] 04, 2014.\', datetime(2014, 9, 4), ""month""),\n            (""Tuesday Jul 22, 2014"", datetime(2014, 7, 22), ""month""),\n            # (\'10:04am EDT\', datetime(2012, 11, 13, 14, 4), ""month""),\n            # (\'Friday\', datetime(2012, 11, 9), ""month""),\n            # (\'November 19, 2014 at noon\', datetime(2014, 11, 19, 12, 0), ""month""),\n            (""December 13, 2014 at midnight"", datetime(2014, 12, 13, 0, 0), ""month""),\n            # (\'Nov 25 2014 10:17 pm EST\', datetime(2014, 11, 26, 3, 17), ""month""),\n            # (\'Wed Aug 05 12:00:00 EDT 2015\', datetime(2015, 8, 5, 16, 0), ""month""),\n            (""April 9, 2013 at 6:11 a.m."", datetime(2013, 4, 9, 6, 11), ""month""),\n            (""Aug. 9, 2012 at 2:57 p.m."", datetime(2012, 8, 9, 14, 57), ""month""),\n            (""December 10, 2014, 11:02:21 pm"", datetime(2014, 12, 10, 23, 2, 21), ""month""),\n            (""8:25 a.m. Dec. 12, 2014"", datetime(2014, 12, 12, 8, 25), ""month""),\n            (""2:21 p.m., December 11, 2014"", datetime(2014, 12, 11, 14, 21), ""month""),\n            (""Fri, 12 Dec 2014 10:55:50"", datetime(2014, 12, 12, 10, 55, 50), ""month""),\n            # (\'20 Mar 2013 10h11\', datetime(2013, 3, 20, 10, 11), ""month""),\n            (""10:06am Dec 11, 2014"", datetime(2014, 12, 11, 10, 6), ""month""),\n            (""September 2nd, 1998"", datetime(1998, 9, 2), ""month""),\n            (\n                ""May 5, 2010 to July 10, 2011"",\n                [datetime(2010, 5, 5), datetime(2011, 7, 10)],\n                ""month"",\n            ),\n            # (\'19 February 2013 year 09:10\', datetime(2013, 2, 19, 9, 10), ""month""),\n            # Numeric dates\n            (""06-17-2014"", datetime(2014, 6, 17), ""month""),\n            (""13/03/2014"", datetime(2014, 3, 13), ""month""),\n            (\n                ""2016-02-04T20:16:26+00:00"",\n                datetime(2016, 2, 4, 20, 16, 26, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            # (\'11. 12. 2014, 08:45:39\', datetime(2014, 11, 12, 8, 45, 39)),\n            (\n                ""2017-02-03T09:04:08Z to 2017-02-03T09:04:09Z"",\n                [\n                    datetime(2017, 2, 3, 9, 4, 8, tzinfo=pytz.utc),\n                    datetime(2017, 2, 3, 9, 4, 9, tzinfo=pytz.utc),\n                ],\n                ""month"",\n            ),\n            # dates from issue https://github.com/akoumjian/datefinder/issues/14\n            (\n                ""i am looking for a date june 4th 1996 to july 3rd 2013"",\n                [datetime(1996, 6, 4), datetime(2013, 7, 3)],\n                ""month"",\n            ),\n            (\n                ""october 27 1994 to be put into effect on june 1 1995"",\n                [datetime(1994, 10, 27), datetime(1995, 6, 1)],\n                ""month"",\n            ),\n            # Simple date range\n            (\n                ""31/08/2012 to 30/08/2013"",\n                [datetime(2012, 8, 31), datetime(2013, 8, 30)],\n                ""month"",\n            ),\n            (\n                ""31 Oct 2021 - 28 Nov 2021"",\n                [datetime(2021, 10, 31), datetime(2021, 11, 28)],\n                ""day""\n            ),\n            # Z dates with and without millis, from https://github.com/akoumjian/datefinder/issues/37\n            (\n                ""2017-02-03T09:04:08.001Z"",\n                datetime(2017, 2, 3, 9, 4, 8, 1000, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            (\n                ""2017-02-03T09:04:08,00123Z"",\n                datetime(2017, 2, 3, 9, 4, 8, 1230, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            (\n                ""2017-02-03T09:04:08Z"",\n                datetime(2017, 2, 3, 9, 4, 8, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            # Year only strings, from https://github.com/akoumjian/datefinder/issues/96\n            (\n                ""Dutta is the recipient of Femina Miss India Universe title in 2004."",\n                datetime(2004, today.month, today.day),\n                ""month"",\n            ),\n            (\n                \'she said that she hit depression after being traumatized on the sets of ""Horn OK"" in 2008.\',\n                datetime(2008, today.month, today.day),\n                ""month"",\n            ),\n            # https://github.com/akoumjian/datefinder/issues/63\n            (""12th day of December, 2001"", datetime(2001, 12, 12), ""month""),\n            (""01/02/03"", datetime(2003, 1, 2, 0, 0, 0, 0), ""month""),\n            (""01/02/03"", datetime(2003, 2, 1, 0, 0, 0, 0), ""day""),\n            (""01/02/03"", datetime(2001, 2, 3, 0, 0, 0, 0), ""year""),\n            (""02/05/2020"", datetime(2020, 2, 5, 0, 0, 0, 0), ""month""),\n            (""02/05/2020"", datetime(2020, 5, 2, 0, 0, 0, 0), ""day""),\n        ],\n    )\n    def test_find_date_strings(input_text, expected_date, first):\n        if isinstance(expected_date, list):\n            matches = list(datefinder.find_dates(input_text, first=first))\n            assert matches == expected_date\n        else:\n            return_date = None\n            for return_date in datefinder.find_dates(input_text, first=first):\n                assert return_date == expected_date\n>           assert return_date is not None, \'Did not find date for test line: ""{}""\'.format(\n                input_text\n            )  # handles dates that were never matched\nE           AssertionError: Did not find date for test line: ""Dutta is the recipient of Femina Miss India Universe title in 2004.""\nE           assert None is not None\n\nrepos\\datefinder\\tests\\test_find_dates.py:124: AssertionError', 'input_text = \'she said that she hit depression after being traumatized on the sets of ""Horn OK"" in 2008.\'\nexpected_date = datetime.datetime(2008, 4, 14, 0, 0), first = \'month\'\n\n    @pytest.mark.parametrize(\n        (""input_text"", ""expected_date"", ""first""),\n        [\n            ## English Dates\n            # (\'[Sept] 04, 2014.\', datetime(2014, 9, 4), ""month""),\n            (""Tuesday Jul 22, 2014"", datetime(2014, 7, 22), ""month""),\n            # (\'10:04am EDT\', datetime(2012, 11, 13, 14, 4), ""month""),\n            # (\'Friday\', datetime(2012, 11, 9), ""month""),\n            # (\'November 19, 2014 at noon\', datetime(2014, 11, 19, 12, 0), ""month""),\n            (""December 13, 2014 at midnight"", datetime(2014, 12, 13, 0, 0), ""month""),\n            # (\'Nov 25 2014 10:17 pm EST\', datetime(2014, 11, 26, 3, 17), ""month""),\n            # (\'Wed Aug 05 12:00:00 EDT 2015\', datetime(2015, 8, 5, 16, 0), ""month""),\n            (""April 9, 2013 at 6:11 a.m."", datetime(2013, 4, 9, 6, 11), ""month""),\n            (""Aug. 9, 2012 at 2:57 p.m."", datetime(2012, 8, 9, 14, 57), ""month""),\n            (""December 10, 2014, 11:02:21 pm"", datetime(2014, 12, 10, 23, 2, 21), ""month""),\n            (""8:25 a.m. Dec. 12, 2014"", datetime(2014, 12, 12, 8, 25), ""month""),\n            (""2:21 p.m., December 11, 2014"", datetime(2014, 12, 11, 14, 21), ""month""),\n            (""Fri, 12 Dec 2014 10:55:50"", datetime(2014, 12, 12, 10, 55, 50), ""month""),\n            # (\'20 Mar 2013 10h11\', datetime(2013, 3, 20, 10, 11), ""month""),\n            (""10:06am Dec 11, 2014"", datetime(2014, 12, 11, 10, 6), ""month""),\n            (""September 2nd, 1998"", datetime(1998, 9, 2), ""month""),\n            (\n                ""May 5, 2010 to July 10, 2011"",\n                [datetime(2010, 5, 5), datetime(2011, 7, 10)],\n                ""month"",\n            ),\n            # (\'19 February 2013 year 09:10\', datetime(2013, 2, 19, 9, 10), ""month""),\n            # Numeric dates\n            (""06-17-2014"", datetime(2014, 6, 17), ""month""),\n            (""13/03/2014"", datetime(2014, 3, 13), ""month""),\n            (\n                ""2016-02-04T20:16:26+00:00"",\n                datetime(2016, 2, 4, 20, 16, 26, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            # (\'11. 12. 2014, 08:45:39\', datetime(2014, 11, 12, 8, 45, 39)),\n            (\n                ""2017-02-03T09:04:08Z to 2017-02-03T09:04:09Z"",\n                [\n                    datetime(2017, 2, 3, 9, 4, 8, tzinfo=pytz.utc),\n                    datetime(2017, 2, 3, 9, 4, 9, tzinfo=pytz.utc),\n                ],\n                ""month"",\n            ),\n            # dates from issue https://github.com/akoumjian/datefinder/issues/14\n            (\n                ""i am looking for a date june 4th 1996 to july 3rd 2013"",\n                [datetime(1996, 6, 4), datetime(2013, 7, 3)],\n                ""month"",\n            ),\n            (\n                ""october 27 1994 to be put into effect on june 1 1995"",\n                [datetime(1994, 10, 27), datetime(1995, 6, 1)],\n                ""month"",\n            ),\n            # Simple date range\n            (\n                ""31/08/2012 to 30/08/2013"",\n                [datetime(2012, 8, 31), datetime(2013, 8, 30)],\n                ""month"",\n            ),\n            (\n                ""31 Oct 2021 - 28 Nov 2021"",\n                [datetime(2021, 10, 31), datetime(2021, 11, 28)],\n                ""day""\n            ),\n            # Z dates with and without millis, from https://github.com/akoumjian/datefinder/issues/37\n            (\n                ""2017-02-03T09:04:08.001Z"",\n                datetime(2017, 2, 3, 9, 4, 8, 1000, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            (\n                ""2017-02-03T09:04:08,00123Z"",\n                datetime(2017, 2, 3, 9, 4, 8, 1230, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            (\n                ""2017-02-03T09:04:08Z"",\n                datetime(2017, 2, 3, 9, 4, 8, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            # Year only strings, from https://github.com/akoumjian/datefinder/issues/96\n            (\n                ""Dutta is the recipient of Femina Miss India Universe title in 2004."",\n                datetime(2004, today.month, today.day),\n                ""month"",\n            ),\n            (\n                \'she said that she hit depression after being traumatized on the sets of ""Horn OK"" in 2008.\',\n                datetime(2008, today.month, today.day),\n                ""month"",\n            ),\n            # https://github.com/akoumjian/datefinder/issues/63\n            (""12th day of December, 2001"", datetime(2001, 12, 12), ""month""),\n            (""01/02/03"", datetime(2003, 1, 2, 0, 0, 0, 0), ""month""),\n            (""01/02/03"", datetime(2003, 2, 1, 0, 0, 0, 0), ""day""),\n            (""01/02/03"", datetime(2001, 2, 3, 0, 0, 0, 0), ""year""),\n            (""02/05/2020"", datetime(2020, 2, 5, 0, 0, 0, 0), ""month""),\n            (""02/05/2020"", datetime(2020, 5, 2, 0, 0, 0, 0), ""day""),\n        ],\n    )\n    def test_find_date_strings(input_text, expected_date, first):\n        if isinstance(expected_date, list):\n            matches = list(datefinder.find_dates(input_text, first=first))\n            assert matches == expected_date\n        else:\n            return_date = None\n            for return_date in datefinder.find_dates(input_text, first=first):\n                assert return_date == expected_date\n>           assert return_date is not None, \'Did not find date for test line: ""{}""\'.format(\n                input_text\n            )  # handles dates that were never matched\nE           AssertionError: Did not find date for test line: ""she said that she hit depression after being traumatized on the sets of ""Horn OK"" in 2008.""\nE           assert None is not None\n\nrepos\\datefinder\\tests\\test_find_dates.py:124: AssertionError', 'input_text = \'12th day of December, 2001\'\nexpected_date = datetime.datetime(2001, 12, 12, 0, 0), first = \'month\'\n\n    @pytest.mark.parametrize(\n        (""input_text"", ""expected_date"", ""first""),\n        [\n            ## English Dates\n            # (\'[Sept] 04, 2014.\', datetime(2014, 9, 4), ""month""),\n            (""Tuesday Jul 22, 2014"", datetime(2014, 7, 22), ""month""),\n            # (\'10:04am EDT\', datetime(2012, 11, 13, 14, 4), ""month""),\n            # (\'Friday\', datetime(2012, 11, 9), ""month""),\n            # (\'November 19, 2014 at noon\', datetime(2014, 11, 19, 12, 0), ""month""),\n            (""December 13, 2014 at midnight"", datetime(2014, 12, 13, 0, 0), ""month""),\n            # (\'Nov 25 2014 10:17 pm EST\', datetime(2014, 11, 26, 3, 17), ""month""),\n            # (\'Wed Aug 05 12:00:00 EDT 2015\', datetime(2015, 8, 5, 16, 0), ""month""),\n            (""April 9, 2013 at 6:11 a.m."", datetime(2013, 4, 9, 6, 11), ""month""),\n            (""Aug. 9, 2012 at 2:57 p.m."", datetime(2012, 8, 9, 14, 57), ""month""),\n            (""December 10, 2014, 11:02:21 pm"", datetime(2014, 12, 10, 23, 2, 21), ""month""),\n            (""8:25 a.m. Dec. 12, 2014"", datetime(2014, 12, 12, 8, 25), ""month""),\n            (""2:21 p.m., December 11, 2014"", datetime(2014, 12, 11, 14, 21), ""month""),\n            (""Fri, 12 Dec 2014 10:55:50"", datetime(2014, 12, 12, 10, 55, 50), ""month""),\n            # (\'20 Mar 2013 10h11\', datetime(2013, 3, 20, 10, 11), ""month""),\n            (""10:06am Dec 11, 2014"", datetime(2014, 12, 11, 10, 6), ""month""),\n            (""September 2nd, 1998"", datetime(1998, 9, 2), ""month""),\n            (\n                ""May 5, 2010 to July 10, 2011"",\n                [datetime(2010, 5, 5), datetime(2011, 7, 10)],\n                ""month"",\n            ),\n            # (\'19 February 2013 year 09:10\', datetime(2013, 2, 19, 9, 10), ""month""),\n            # Numeric dates\n            (""06-17-2014"", datetime(2014, 6, 17), ""month""),\n            (""13/03/2014"", datetime(2014, 3, 13), ""month""),\n            (\n                ""2016-02-04T20:16:26+00:00"",\n                datetime(2016, 2, 4, 20, 16, 26, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            # (\'11. 12. 2014, 08:45:39\', datetime(2014, 11, 12, 8, 45, 39)),\n            (\n                ""2017-02-03T09:04:08Z to 2017-02-03T09:04:09Z"",\n                [\n                    datetime(2017, 2, 3, 9, 4, 8, tzinfo=pytz.utc),\n                    datetime(2017, 2, 3, 9, 4, 9, tzinfo=pytz.utc),\n                ],\n                ""month"",\n            ),\n            # dates from issue https://github.com/akoumjian/datefinder/issues/14\n            (\n                ""i am looking for a date june 4th 1996 to july 3rd 2013"",\n                [datetime(1996, 6, 4), datetime(2013, 7, 3)],\n                ""month"",\n            ),\n            (\n                ""october 27 1994 to be put into effect on june 1 1995"",\n                [datetime(1994, 10, 27), datetime(1995, 6, 1)],\n                ""month"",\n            ),\n            # Simple date range\n            (\n                ""31/08/2012 to 30/08/2013"",\n                [datetime(2012, 8, 31), datetime(2013, 8, 30)],\n                ""month"",\n            ),\n            (\n                ""31 Oct 2021 - 28 Nov 2021"",\n                [datetime(2021, 10, 31), datetime(2021, 11, 28)],\n                ""day""\n            ),\n            # Z dates with and without millis, from https://github.com/akoumjian/datefinder/issues/37\n            (\n                ""2017-02-03T09:04:08.001Z"",\n                datetime(2017, 2, 3, 9, 4, 8, 1000, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            (\n                ""2017-02-03T09:04:08,00123Z"",\n                datetime(2017, 2, 3, 9, 4, 8, 1230, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            (\n                ""2017-02-03T09:04:08Z"",\n                datetime(2017, 2, 3, 9, 4, 8, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            # Year only strings, from https://github.com/akoumjian/datefinder/issues/96\n            (\n                ""Dutta is the recipient of Femina Miss India Universe title in 2004."",\n                datetime(2004, today.month, today.day),\n                ""month"",\n            ),\n            (\n                \'she said that she hit depression after being traumatized on the sets of ""Horn OK"" in 2008.\',\n                datetime(2008, today.month, today.day),\n                ""month"",\n            ),\n            # https://github.com/akoumjian/datefinder/issues/63\n            (""12th day of December, 2001"", datetime(2001, 12, 12), ""month""),\n            (""01/02/03"", datetime(2003, 1, 2, 0, 0, 0, 0), ""month""),\n            (""01/02/03"", datetime(2003, 2, 1, 0, 0, 0, 0), ""day""),\n            (""01/02/03"", datetime(2001, 2, 3, 0, 0, 0, 0), ""year""),\n            (""02/05/2020"", datetime(2020, 2, 5, 0, 0, 0, 0), ""month""),\n            (""02/05/2020"", datetime(2020, 5, 2, 0, 0, 0, 0), ""day""),\n        ],\n    )\n    def test_find_date_strings(input_text, expected_date, first):\n        if isinstance(expected_date, list):\n            matches = list(datefinder.find_dates(input_text, first=first))\n            assert matches == expected_date\n        else:\n            return_date = None\n            for return_date in datefinder.find_dates(input_text, first=first):\n                assert return_date == expected_date\n>           assert return_date is not None, \'Did not find date for test line: ""{}""\'.format(\n                input_text\n            )  # handles dates that were never matched\nE           AssertionError: Did not find date for test line: ""12th day of December, 2001""\nE           assert None is not None\n\nrepos\\datefinder\\tests\\test_find_dates.py:124: AssertionError', 'input_text = \'01/02/03\', expected_date = datetime.datetime(2003, 1, 2, 0, 0)\nfirst = \'month\'\n\n    @pytest.mark.parametrize(\n        (""input_text"", ""expected_date"", ""first""),\n        [\n            ## English Dates\n            # (\'[Sept] 04, 2014.\', datetime(2014, 9, 4), ""month""),\n            (""Tuesday Jul 22, 2014"", datetime(2014, 7, 22), ""month""),\n            # (\'10:04am EDT\', datetime(2012, 11, 13, 14, 4), ""month""),\n            # (\'Friday\', datetime(2012, 11, 9), ""month""),\n            # (\'November 19, 2014 at noon\', datetime(2014, 11, 19, 12, 0), ""month""),\n            (""December 13, 2014 at midnight"", datetime(2014, 12, 13, 0, 0), ""month""),\n            # (\'Nov 25 2014 10:17 pm EST\', datetime(2014, 11, 26, 3, 17), ""month""),\n            # (\'Wed Aug 05 12:00:00 EDT 2015\', datetime(2015, 8, 5, 16, 0), ""month""),\n            (""April 9, 2013 at 6:11 a.m."", datetime(2013, 4, 9, 6, 11), ""month""),\n            (""Aug. 9, 2012 at 2:57 p.m."", datetime(2012, 8, 9, 14, 57), ""month""),\n            (""December 10, 2014, 11:02:21 pm"", datetime(2014, 12, 10, 23, 2, 21), ""month""),\n            (""8:25 a.m. Dec. 12, 2014"", datetime(2014, 12, 12, 8, 25), ""month""),\n            (""2:21 p.m., December 11, 2014"", datetime(2014, 12, 11, 14, 21), ""month""),\n            (""Fri, 12 Dec 2014 10:55:50"", datetime(2014, 12, 12, 10, 55, 50), ""month""),\n            # (\'20 Mar 2013 10h11\', datetime(2013, 3, 20, 10, 11), ""month""),\n            (""10:06am Dec 11, 2014"", datetime(2014, 12, 11, 10, 6), ""month""),\n            (""September 2nd, 1998"", datetime(1998, 9, 2), ""month""),\n            (\n                ""May 5, 2010 to July 10, 2011"",\n                [datetime(2010, 5, 5), datetime(2011, 7, 10)],\n                ""month"",\n            ),\n            # (\'19 February 2013 year 09:10\', datetime(2013, 2, 19, 9, 10), ""month""),\n            # Numeric dates\n            (""06-17-2014"", datetime(2014, 6, 17), ""month""),\n            (""13/03/2014"", datetime(2014, 3, 13), ""month""),\n            (\n                ""2016-02-04T20:16:26+00:00"",\n                datetime(2016, 2, 4, 20, 16, 26, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            # (\'11. 12. 2014, 08:45:39\', datetime(2014, 11, 12, 8, 45, 39)),\n            (\n                ""2017-02-03T09:04:08Z to 2017-02-03T09:04:09Z"",\n                [\n                    datetime(2017, 2, 3, 9, 4, 8, tzinfo=pytz.utc),\n                    datetime(2017, 2, 3, 9, 4, 9, tzinfo=pytz.utc),\n                ],\n                ""month"",\n            ),\n            # dates from issue https://github.com/akoumjian/datefinder/issues/14\n            (\n                ""i am looking for a date june 4th 1996 to july 3rd 2013"",\n                [datetime(1996, 6, 4), datetime(2013, 7, 3)],\n                ""month"",\n            ),\n            (\n                ""october 27 1994 to be put into effect on june 1 1995"",\n                [datetime(1994, 10, 27), datetime(1995, 6, 1)],\n                ""month"",\n            ),\n            # Simple date range\n            (\n                ""31/08/2012 to 30/08/2013"",\n                [datetime(2012, 8, 31), datetime(2013, 8, 30)],\n                ""month"",\n            ),\n            (\n                ""31 Oct 2021 - 28 Nov 2021"",\n                [datetime(2021, 10, 31), datetime(2021, 11, 28)],\n                ""day""\n            ),\n            # Z dates with and without millis, from https://github.com/akoumjian/datefinder/issues/37\n            (\n                ""2017-02-03T09:04:08.001Z"",\n                datetime(2017, 2, 3, 9, 4, 8, 1000, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            (\n                ""2017-02-03T09:04:08,00123Z"",\n                datetime(2017, 2, 3, 9, 4, 8, 1230, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            (\n                ""2017-02-03T09:04:08Z"",\n                datetime(2017, 2, 3, 9, 4, 8, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            # Year only strings, from https://github.com/akoumjian/datefinder/issues/96\n            (\n                ""Dutta is the recipient of Femina Miss India Universe title in 2004."",\n                datetime(2004, today.month, today.day),\n                ""month"",\n            ),\n            (\n                \'she said that she hit depression after being traumatized on the sets of ""Horn OK"" in 2008.\',\n                datetime(2008, today.month, today.day),\n                ""month"",\n            ),\n            # https://github.com/akoumjian/datefinder/issues/63\n            (""12th day of December, 2001"", datetime(2001, 12, 12), ""month""),\n            (""01/02/03"", datetime(2003, 1, 2, 0, 0, 0, 0), ""month""),\n            (""01/02/03"", datetime(2003, 2, 1, 0, 0, 0, 0), ""day""),\n            (""01/02/03"", datetime(2001, 2, 3, 0, 0, 0, 0), ""year""),\n            (""02/05/2020"", datetime(2020, 2, 5, 0, 0, 0, 0), ""month""),\n            (""02/05/2020"", datetime(2020, 5, 2, 0, 0, 0, 0), ""day""),\n        ],\n    )\n    def test_find_date_strings(input_text, expected_date, first):\n        if isinstance(expected_date, list):\n            matches = list(datefinder.find_dates(input_text, first=first))\n            assert matches == expected_date\n        else:\n            return_date = None\n>           for return_date in datefinder.find_dates(input_text, first=first):\n\nrepos\\datefinder\\tests\\test_find_dates.py:122: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\datefinder\\datefinder\\__init__.py:24: in find_dates\n    for date_string, indices, captures in self.extract_date_strings(text, strict=strict):\nrepos\\datefinder\\datefinder\\__init__.py:110: in extract_date_strings_inner\n    items = self.merge_tokens(tokens)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <datefinder.DateFinder object at 0x000002AC9DAAC590>\ntokens = [(\'01/02/03\', \'01\', \'02\', \'03\')]\n\n    def merge_tokens(self, tokens):\n        """"""\n        Makes potential date strings out of matches, got from tokenize_string method.\n        :param tokens: [(match_text, match_group, {match.capturesdict()}), ...]\n        :return: potential date strings\n        """"""\n        MIN_MATCHES = 3\n        fragments = []\n        frag = DateFragment()\n        start_char, total_chars = (0, 0)\n        for token in tokens:\n            total_chars += len(token[0])\n            tok_text, group, tok_capts = (token[0], token[1], token[2])\n            if not group:\n                if frag.indices[1] > 0:\n                    if frag.get_captures_count() >= MIN_MATCHES:\n                        fragments.append(frag)\n                frag = DateFragment()\n                start_char = total_chars\n                continue\n            if frag.indices[1] == 0:\n                frag.indices = (start_char, total_chars)\n            else:\n                frag.indices = (frag.indices[0], total_chars)\n            frag.match_str += tok_text\n            for capt in tok_capts:\n                if capt in frag.captures:\n                    frag.captures[capt] += tok_capts[capt]\n                else:\n>                   frag.captures[capt] = tok_capts[capt]\nE                   TypeError: string indices must be integers, not \'str\'\n\nrepos\\datefinder\\datefinder\\__init__.py:172: TypeError', 'input_text = \'01/02/03\', expected_date = datetime.datetime(2003, 2, 1, 0, 0)\nfirst = \'day\'\n\n    @pytest.mark.parametrize(\n        (""input_text"", ""expected_date"", ""first""),\n        [\n            ## English Dates\n            # (\'[Sept] 04, 2014.\', datetime(2014, 9, 4), ""month""),\n            (""Tuesday Jul 22, 2014"", datetime(2014, 7, 22), ""month""),\n            # (\'10:04am EDT\', datetime(2012, 11, 13, 14, 4), ""month""),\n            # (\'Friday\', datetime(2012, 11, 9), ""month""),\n            # (\'November 19, 2014 at noon\', datetime(2014, 11, 19, 12, 0), ""month""),\n            (""December 13, 2014 at midnight"", datetime(2014, 12, 13, 0, 0), ""month""),\n            # (\'Nov 25 2014 10:17 pm EST\', datetime(2014, 11, 26, 3, 17), ""month""),\n            # (\'Wed Aug 05 12:00:00 EDT 2015\', datetime(2015, 8, 5, 16, 0), ""month""),\n            (""April 9, 2013 at 6:11 a.m."", datetime(2013, 4, 9, 6, 11), ""month""),\n            (""Aug. 9, 2012 at 2:57 p.m."", datetime(2012, 8, 9, 14, 57), ""month""),\n            (""December 10, 2014, 11:02:21 pm"", datetime(2014, 12, 10, 23, 2, 21), ""month""),\n            (""8:25 a.m. Dec. 12, 2014"", datetime(2014, 12, 12, 8, 25), ""month""),\n            (""2:21 p.m., December 11, 2014"", datetime(2014, 12, 11, 14, 21), ""month""),\n            (""Fri, 12 Dec 2014 10:55:50"", datetime(2014, 12, 12, 10, 55, 50), ""month""),\n            # (\'20 Mar 2013 10h11\', datetime(2013, 3, 20, 10, 11), ""month""),\n            (""10:06am Dec 11, 2014"", datetime(2014, 12, 11, 10, 6), ""month""),\n            (""September 2nd, 1998"", datetime(1998, 9, 2), ""month""),\n            (\n                ""May 5, 2010 to July 10, 2011"",\n                [datetime(2010, 5, 5), datetime(2011, 7, 10)],\n                ""month"",\n            ),\n            # (\'19 February 2013 year 09:10\', datetime(2013, 2, 19, 9, 10), ""month""),\n            # Numeric dates\n            (""06-17-2014"", datetime(2014, 6, 17), ""month""),\n            (""13/03/2014"", datetime(2014, 3, 13), ""month""),\n            (\n                ""2016-02-04T20:16:26+00:00"",\n                datetime(2016, 2, 4, 20, 16, 26, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            # (\'11. 12. 2014, 08:45:39\', datetime(2014, 11, 12, 8, 45, 39)),\n            (\n                ""2017-02-03T09:04:08Z to 2017-02-03T09:04:09Z"",\n                [\n                    datetime(2017, 2, 3, 9, 4, 8, tzinfo=pytz.utc),\n                    datetime(2017, 2, 3, 9, 4, 9, tzinfo=pytz.utc),\n                ],\n                ""month"",\n            ),\n            # dates from issue https://github.com/akoumjian/datefinder/issues/14\n            (\n                ""i am looking for a date june 4th 1996 to july 3rd 2013"",\n                [datetime(1996, 6, 4), datetime(2013, 7, 3)],\n                ""month"",\n            ),\n            (\n                ""october 27 1994 to be put into effect on june 1 1995"",\n                [datetime(1994, 10, 27), datetime(1995, 6, 1)],\n                ""month"",\n            ),\n            # Simple date range\n            (\n                ""31/08/2012 to 30/08/2013"",\n                [datetime(2012, 8, 31), datetime(2013, 8, 30)],\n                ""month"",\n            ),\n            (\n                ""31 Oct 2021 - 28 Nov 2021"",\n                [datetime(2021, 10, 31), datetime(2021, 11, 28)],\n                ""day""\n            ),\n            # Z dates with and without millis, from https://github.com/akoumjian/datefinder/issues/37\n            (\n                ""2017-02-03T09:04:08.001Z"",\n                datetime(2017, 2, 3, 9, 4, 8, 1000, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            (\n                ""2017-02-03T09:04:08,00123Z"",\n                datetime(2017, 2, 3, 9, 4, 8, 1230, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            (\n                ""2017-02-03T09:04:08Z"",\n                datetime(2017, 2, 3, 9, 4, 8, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            # Year only strings, from https://github.com/akoumjian/datefinder/issues/96\n            (\n                ""Dutta is the recipient of Femina Miss India Universe title in 2004."",\n                datetime(2004, today.month, today.day),\n                ""month"",\n            ),\n            (\n                \'she said that she hit depression after being traumatized on the sets of ""Horn OK"" in 2008.\',\n                datetime(2008, today.month, today.day),\n                ""month"",\n            ),\n            # https://github.com/akoumjian/datefinder/issues/63\n            (""12th day of December, 2001"", datetime(2001, 12, 12), ""month""),\n            (""01/02/03"", datetime(2003, 1, 2, 0, 0, 0, 0), ""month""),\n            (""01/02/03"", datetime(2003, 2, 1, 0, 0, 0, 0), ""day""),\n            (""01/02/03"", datetime(2001, 2, 3, 0, 0, 0, 0), ""year""),\n            (""02/05/2020"", datetime(2020, 2, 5, 0, 0, 0, 0), ""month""),\n            (""02/05/2020"", datetime(2020, 5, 2, 0, 0, 0, 0), ""day""),\n        ],\n    )\n    def test_find_date_strings(input_text, expected_date, first):\n        if isinstance(expected_date, list):\n            matches = list(datefinder.find_dates(input_text, first=first))\n            assert matches == expected_date\n        else:\n            return_date = None\n>           for return_date in datefinder.find_dates(input_text, first=first):\n\nrepos\\datefinder\\tests\\test_find_dates.py:122: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\datefinder\\datefinder\\__init__.py:24: in find_dates\n    for date_string, indices, captures in self.extract_date_strings(text, strict=strict):\nrepos\\datefinder\\datefinder\\__init__.py:110: in extract_date_strings_inner\n    items = self.merge_tokens(tokens)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <datefinder.DateFinder object at 0x000002AC9DAAFB30>\ntokens = [(\'01/02/03\', \'01\', \'02\', \'03\')]\n\n    def merge_tokens(self, tokens):\n        """"""\n        Makes potential date strings out of matches, got from tokenize_string method.\n        :param tokens: [(match_text, match_group, {match.capturesdict()}), ...]\n        :return: potential date strings\n        """"""\n        MIN_MATCHES = 3\n        fragments = []\n        frag = DateFragment()\n        start_char, total_chars = (0, 0)\n        for token in tokens:\n            total_chars += len(token[0])\n            tok_text, group, tok_capts = (token[0], token[1], token[2])\n            if not group:\n                if frag.indices[1] > 0:\n                    if frag.get_captures_count() >= MIN_MATCHES:\n                        fragments.append(frag)\n                frag = DateFragment()\n                start_char = total_chars\n                continue\n            if frag.indices[1] == 0:\n                frag.indices = (start_char, total_chars)\n            else:\n                frag.indices = (frag.indices[0], total_chars)\n            frag.match_str += tok_text\n            for capt in tok_capts:\n                if capt in frag.captures:\n                    frag.captures[capt] += tok_capts[capt]\n                else:\n>                   frag.captures[capt] = tok_capts[capt]\nE                   TypeError: string indices must be integers, not \'str\'\n\nrepos\\datefinder\\datefinder\\__init__.py:172: TypeError', 'input_text = \'01/02/03\', expected_date = datetime.datetime(2001, 2, 3, 0, 0)\nfirst = \'year\'\n\n    @pytest.mark.parametrize(\n        (""input_text"", ""expected_date"", ""first""),\n        [\n            ## English Dates\n            # (\'[Sept] 04, 2014.\', datetime(2014, 9, 4), ""month""),\n            (""Tuesday Jul 22, 2014"", datetime(2014, 7, 22), ""month""),\n            # (\'10:04am EDT\', datetime(2012, 11, 13, 14, 4), ""month""),\n            # (\'Friday\', datetime(2012, 11, 9), ""month""),\n            # (\'November 19, 2014 at noon\', datetime(2014, 11, 19, 12, 0), ""month""),\n            (""December 13, 2014 at midnight"", datetime(2014, 12, 13, 0, 0), ""month""),\n            # (\'Nov 25 2014 10:17 pm EST\', datetime(2014, 11, 26, 3, 17), ""month""),\n            # (\'Wed Aug 05 12:00:00 EDT 2015\', datetime(2015, 8, 5, 16, 0), ""month""),\n            (""April 9, 2013 at 6:11 a.m."", datetime(2013, 4, 9, 6, 11), ""month""),\n            (""Aug. 9, 2012 at 2:57 p.m."", datetime(2012, 8, 9, 14, 57), ""month""),\n            (""December 10, 2014, 11:02:21 pm"", datetime(2014, 12, 10, 23, 2, 21), ""month""),\n            (""8:25 a.m. Dec. 12, 2014"", datetime(2014, 12, 12, 8, 25), ""month""),\n            (""2:21 p.m., December 11, 2014"", datetime(2014, 12, 11, 14, 21), ""month""),\n            (""Fri, 12 Dec 2014 10:55:50"", datetime(2014, 12, 12, 10, 55, 50), ""month""),\n            # (\'20 Mar 2013 10h11\', datetime(2013, 3, 20, 10, 11), ""month""),\n            (""10:06am Dec 11, 2014"", datetime(2014, 12, 11, 10, 6), ""month""),\n            (""September 2nd, 1998"", datetime(1998, 9, 2), ""month""),\n            (\n                ""May 5, 2010 to July 10, 2011"",\n                [datetime(2010, 5, 5), datetime(2011, 7, 10)],\n                ""month"",\n            ),\n            # (\'19 February 2013 year 09:10\', datetime(2013, 2, 19, 9, 10), ""month""),\n            # Numeric dates\n            (""06-17-2014"", datetime(2014, 6, 17), ""month""),\n            (""13/03/2014"", datetime(2014, 3, 13), ""month""),\n            (\n                ""2016-02-04T20:16:26+00:00"",\n                datetime(2016, 2, 4, 20, 16, 26, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            # (\'11. 12. 2014, 08:45:39\', datetime(2014, 11, 12, 8, 45, 39)),\n            (\n                ""2017-02-03T09:04:08Z to 2017-02-03T09:04:09Z"",\n                [\n                    datetime(2017, 2, 3, 9, 4, 8, tzinfo=pytz.utc),\n                    datetime(2017, 2, 3, 9, 4, 9, tzinfo=pytz.utc),\n                ],\n                ""month"",\n            ),\n            # dates from issue https://github.com/akoumjian/datefinder/issues/14\n            (\n                ""i am looking for a date june 4th 1996 to july 3rd 2013"",\n                [datetime(1996, 6, 4), datetime(2013, 7, 3)],\n                ""month"",\n            ),\n            (\n                ""october 27 1994 to be put into effect on june 1 1995"",\n                [datetime(1994, 10, 27), datetime(1995, 6, 1)],\n                ""month"",\n            ),\n            # Simple date range\n            (\n                ""31/08/2012 to 30/08/2013"",\n                [datetime(2012, 8, 31), datetime(2013, 8, 30)],\n                ""month"",\n            ),\n            (\n                ""31 Oct 2021 - 28 Nov 2021"",\n                [datetime(2021, 10, 31), datetime(2021, 11, 28)],\n                ""day""\n            ),\n            # Z dates with and without millis, from https://github.com/akoumjian/datefinder/issues/37\n            (\n                ""2017-02-03T09:04:08.001Z"",\n                datetime(2017, 2, 3, 9, 4, 8, 1000, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            (\n                ""2017-02-03T09:04:08,00123Z"",\n                datetime(2017, 2, 3, 9, 4, 8, 1230, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            (\n                ""2017-02-03T09:04:08Z"",\n                datetime(2017, 2, 3, 9, 4, 8, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            # Year only strings, from https://github.com/akoumjian/datefinder/issues/96\n            (\n                ""Dutta is the recipient of Femina Miss India Universe title in 2004."",\n                datetime(2004, today.month, today.day),\n                ""month"",\n            ),\n            (\n                \'she said that she hit depression after being traumatized on the sets of ""Horn OK"" in 2008.\',\n                datetime(2008, today.month, today.day),\n                ""month"",\n            ),\n            # https://github.com/akoumjian/datefinder/issues/63\n            (""12th day of December, 2001"", datetime(2001, 12, 12), ""month""),\n            (""01/02/03"", datetime(2003, 1, 2, 0, 0, 0, 0), ""month""),\n            (""01/02/03"", datetime(2003, 2, 1, 0, 0, 0, 0), ""day""),\n            (""01/02/03"", datetime(2001, 2, 3, 0, 0, 0, 0), ""year""),\n            (""02/05/2020"", datetime(2020, 2, 5, 0, 0, 0, 0), ""month""),\n            (""02/05/2020"", datetime(2020, 5, 2, 0, 0, 0, 0), ""day""),\n        ],\n    )\n    def test_find_date_strings(input_text, expected_date, first):\n        if isinstance(expected_date, list):\n            matches = list(datefinder.find_dates(input_text, first=first))\n            assert matches == expected_date\n        else:\n            return_date = None\n>           for return_date in datefinder.find_dates(input_text, first=first):\n\nrepos\\datefinder\\tests\\test_find_dates.py:122: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\datefinder\\datefinder\\__init__.py:24: in find_dates\n    for date_string, indices, captures in self.extract_date_strings(text, strict=strict):\nrepos\\datefinder\\datefinder\\__init__.py:110: in extract_date_strings_inner\n    items = self.merge_tokens(tokens)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <datefinder.DateFinder object at 0x000002AC9DAC9910>\ntokens = [(\'01/02/03\', \'01\', \'02\', \'03\')]\n\n    def merge_tokens(self, tokens):\n        """"""\n        Makes potential date strings out of matches, got from tokenize_string method.\n        :param tokens: [(match_text, match_group, {match.capturesdict()}), ...]\n        :return: potential date strings\n        """"""\n        MIN_MATCHES = 3\n        fragments = []\n        frag = DateFragment()\n        start_char, total_chars = (0, 0)\n        for token in tokens:\n            total_chars += len(token[0])\n            tok_text, group, tok_capts = (token[0], token[1], token[2])\n            if not group:\n                if frag.indices[1] > 0:\n                    if frag.get_captures_count() >= MIN_MATCHES:\n                        fragments.append(frag)\n                frag = DateFragment()\n                start_char = total_chars\n                continue\n            if frag.indices[1] == 0:\n                frag.indices = (start_char, total_chars)\n            else:\n                frag.indices = (frag.indices[0], total_chars)\n            frag.match_str += tok_text\n            for capt in tok_capts:\n                if capt in frag.captures:\n                    frag.captures[capt] += tok_capts[capt]\n                else:\n>                   frag.captures[capt] = tok_capts[capt]\nE                   TypeError: string indices must be integers, not \'str\'\n\nrepos\\datefinder\\datefinder\\__init__.py:172: TypeError', 'input_text = \'02/05/2020\', expected_date = datetime.datetime(2020, 2, 5, 0, 0)\nfirst = \'month\'\n\n    @pytest.mark.parametrize(\n        (""input_text"", ""expected_date"", ""first""),\n        [\n            ## English Dates\n            # (\'[Sept] 04, 2014.\', datetime(2014, 9, 4), ""month""),\n            (""Tuesday Jul 22, 2014"", datetime(2014, 7, 22), ""month""),\n            # (\'10:04am EDT\', datetime(2012, 11, 13, 14, 4), ""month""),\n            # (\'Friday\', datetime(2012, 11, 9), ""month""),\n            # (\'November 19, 2014 at noon\', datetime(2014, 11, 19, 12, 0), ""month""),\n            (""December 13, 2014 at midnight"", datetime(2014, 12, 13, 0, 0), ""month""),\n            # (\'Nov 25 2014 10:17 pm EST\', datetime(2014, 11, 26, 3, 17), ""month""),\n            # (\'Wed Aug 05 12:00:00 EDT 2015\', datetime(2015, 8, 5, 16, 0), ""month""),\n            (""April 9, 2013 at 6:11 a.m."", datetime(2013, 4, 9, 6, 11), ""month""),\n            (""Aug. 9, 2012 at 2:57 p.m."", datetime(2012, 8, 9, 14, 57), ""month""),\n            (""December 10, 2014, 11:02:21 pm"", datetime(2014, 12, 10, 23, 2, 21), ""month""),\n            (""8:25 a.m. Dec. 12, 2014"", datetime(2014, 12, 12, 8, 25), ""month""),\n            (""2:21 p.m., December 11, 2014"", datetime(2014, 12, 11, 14, 21), ""month""),\n            (""Fri, 12 Dec 2014 10:55:50"", datetime(2014, 12, 12, 10, 55, 50), ""month""),\n            # (\'20 Mar 2013 10h11\', datetime(2013, 3, 20, 10, 11), ""month""),\n            (""10:06am Dec 11, 2014"", datetime(2014, 12, 11, 10, 6), ""month""),\n            (""September 2nd, 1998"", datetime(1998, 9, 2), ""month""),\n            (\n                ""May 5, 2010 to July 10, 2011"",\n                [datetime(2010, 5, 5), datetime(2011, 7, 10)],\n                ""month"",\n            ),\n            # (\'19 February 2013 year 09:10\', datetime(2013, 2, 19, 9, 10), ""month""),\n            # Numeric dates\n            (""06-17-2014"", datetime(2014, 6, 17), ""month""),\n            (""13/03/2014"", datetime(2014, 3, 13), ""month""),\n            (\n                ""2016-02-04T20:16:26+00:00"",\n                datetime(2016, 2, 4, 20, 16, 26, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            # (\'11. 12. 2014, 08:45:39\', datetime(2014, 11, 12, 8, 45, 39)),\n            (\n                ""2017-02-03T09:04:08Z to 2017-02-03T09:04:09Z"",\n                [\n                    datetime(2017, 2, 3, 9, 4, 8, tzinfo=pytz.utc),\n                    datetime(2017, 2, 3, 9, 4, 9, tzinfo=pytz.utc),\n                ],\n                ""month"",\n            ),\n            # dates from issue https://github.com/akoumjian/datefinder/issues/14\n            (\n                ""i am looking for a date june 4th 1996 to july 3rd 2013"",\n                [datetime(1996, 6, 4), datetime(2013, 7, 3)],\n                ""month"",\n            ),\n            (\n                ""october 27 1994 to be put into effect on june 1 1995"",\n                [datetime(1994, 10, 27), datetime(1995, 6, 1)],\n                ""month"",\n            ),\n            # Simple date range\n            (\n                ""31/08/2012 to 30/08/2013"",\n                [datetime(2012, 8, 31), datetime(2013, 8, 30)],\n                ""month"",\n            ),\n            (\n                ""31 Oct 2021 - 28 Nov 2021"",\n                [datetime(2021, 10, 31), datetime(2021, 11, 28)],\n                ""day""\n            ),\n            # Z dates with and without millis, from https://github.com/akoumjian/datefinder/issues/37\n            (\n                ""2017-02-03T09:04:08.001Z"",\n                datetime(2017, 2, 3, 9, 4, 8, 1000, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            (\n                ""2017-02-03T09:04:08,00123Z"",\n                datetime(2017, 2, 3, 9, 4, 8, 1230, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            (\n                ""2017-02-03T09:04:08Z"",\n                datetime(2017, 2, 3, 9, 4, 8, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            # Year only strings, from https://github.com/akoumjian/datefinder/issues/96\n            (\n                ""Dutta is the recipient of Femina Miss India Universe title in 2004."",\n                datetime(2004, today.month, today.day),\n                ""month"",\n            ),\n            (\n                \'she said that she hit depression after being traumatized on the sets of ""Horn OK"" in 2008.\',\n                datetime(2008, today.month, today.day),\n                ""month"",\n            ),\n            # https://github.com/akoumjian/datefinder/issues/63\n            (""12th day of December, 2001"", datetime(2001, 12, 12), ""month""),\n            (""01/02/03"", datetime(2003, 1, 2, 0, 0, 0, 0), ""month""),\n            (""01/02/03"", datetime(2003, 2, 1, 0, 0, 0, 0), ""day""),\n            (""01/02/03"", datetime(2001, 2, 3, 0, 0, 0, 0), ""year""),\n            (""02/05/2020"", datetime(2020, 2, 5, 0, 0, 0, 0), ""month""),\n            (""02/05/2020"", datetime(2020, 5, 2, 0, 0, 0, 0), ""day""),\n        ],\n    )\n    def test_find_date_strings(input_text, expected_date, first):\n        if isinstance(expected_date, list):\n            matches = list(datefinder.find_dates(input_text, first=first))\n            assert matches == expected_date\n        else:\n            return_date = None\n>           for return_date in datefinder.find_dates(input_text, first=first):\n\nrepos\\datefinder\\tests\\test_find_dates.py:122: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\datefinder\\datefinder\\__init__.py:24: in find_dates\n    for date_string, indices, captures in self.extract_date_strings(text, strict=strict):\nrepos\\datefinder\\datefinder\\__init__.py:110: in extract_date_strings_inner\n    items = self.merge_tokens(tokens)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <datefinder.DateFinder object at 0x000002AC9DAE7FB0>\ntokens = [(\'02/05/2020\', \'02\', \'05\', \'2020\')]\n\n    def merge_tokens(self, tokens):\n        """"""\n        Makes potential date strings out of matches, got from tokenize_string method.\n        :param tokens: [(match_text, match_group, {match.capturesdict()}), ...]\n        :return: potential date strings\n        """"""\n        MIN_MATCHES = 3\n        fragments = []\n        frag = DateFragment()\n        start_char, total_chars = (0, 0)\n        for token in tokens:\n            total_chars += len(token[0])\n            tok_text, group, tok_capts = (token[0], token[1], token[2])\n            if not group:\n                if frag.indices[1] > 0:\n                    if frag.get_captures_count() >= MIN_MATCHES:\n                        fragments.append(frag)\n                frag = DateFragment()\n                start_char = total_chars\n                continue\n            if frag.indices[1] == 0:\n                frag.indices = (start_char, total_chars)\n            else:\n                frag.indices = (frag.indices[0], total_chars)\n            frag.match_str += tok_text\n            for capt in tok_capts:\n                if capt in frag.captures:\n                    frag.captures[capt] += tok_capts[capt]\n                else:\n>                   frag.captures[capt] = tok_capts[capt]\nE                   TypeError: string indices must be integers, not \'str\'\n\nrepos\\datefinder\\datefinder\\__init__.py:172: TypeError', 'input_text = \'02/05/2020\', expected_date = datetime.datetime(2020, 5, 2, 0, 0)\nfirst = \'day\'\n\n    @pytest.mark.parametrize(\n        (""input_text"", ""expected_date"", ""first""),\n        [\n            ## English Dates\n            # (\'[Sept] 04, 2014.\', datetime(2014, 9, 4), ""month""),\n            (""Tuesday Jul 22, 2014"", datetime(2014, 7, 22), ""month""),\n            # (\'10:04am EDT\', datetime(2012, 11, 13, 14, 4), ""month""),\n            # (\'Friday\', datetime(2012, 11, 9), ""month""),\n            # (\'November 19, 2014 at noon\', datetime(2014, 11, 19, 12, 0), ""month""),\n            (""December 13, 2014 at midnight"", datetime(2014, 12, 13, 0, 0), ""month""),\n            # (\'Nov 25 2014 10:17 pm EST\', datetime(2014, 11, 26, 3, 17), ""month""),\n            # (\'Wed Aug 05 12:00:00 EDT 2015\', datetime(2015, 8, 5, 16, 0), ""month""),\n            (""April 9, 2013 at 6:11 a.m."", datetime(2013, 4, 9, 6, 11), ""month""),\n            (""Aug. 9, 2012 at 2:57 p.m."", datetime(2012, 8, 9, 14, 57), ""month""),\n            (""December 10, 2014, 11:02:21 pm"", datetime(2014, 12, 10, 23, 2, 21), ""month""),\n            (""8:25 a.m. Dec. 12, 2014"", datetime(2014, 12, 12, 8, 25), ""month""),\n            (""2:21 p.m., December 11, 2014"", datetime(2014, 12, 11, 14, 21), ""month""),\n            (""Fri, 12 Dec 2014 10:55:50"", datetime(2014, 12, 12, 10, 55, 50), ""month""),\n            # (\'20 Mar 2013 10h11\', datetime(2013, 3, 20, 10, 11), ""month""),\n            (""10:06am Dec 11, 2014"", datetime(2014, 12, 11, 10, 6), ""month""),\n            (""September 2nd, 1998"", datetime(1998, 9, 2), ""month""),\n            (\n                ""May 5, 2010 to July 10, 2011"",\n                [datetime(2010, 5, 5), datetime(2011, 7, 10)],\n                ""month"",\n            ),\n            # (\'19 February 2013 year 09:10\', datetime(2013, 2, 19, 9, 10), ""month""),\n            # Numeric dates\n            (""06-17-2014"", datetime(2014, 6, 17), ""month""),\n            (""13/03/2014"", datetime(2014, 3, 13), ""month""),\n            (\n                ""2016-02-04T20:16:26+00:00"",\n                datetime(2016, 2, 4, 20, 16, 26, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            # (\'11. 12. 2014, 08:45:39\', datetime(2014, 11, 12, 8, 45, 39)),\n            (\n                ""2017-02-03T09:04:08Z to 2017-02-03T09:04:09Z"",\n                [\n                    datetime(2017, 2, 3, 9, 4, 8, tzinfo=pytz.utc),\n                    datetime(2017, 2, 3, 9, 4, 9, tzinfo=pytz.utc),\n                ],\n                ""month"",\n            ),\n            # dates from issue https://github.com/akoumjian/datefinder/issues/14\n            (\n                ""i am looking for a date june 4th 1996 to july 3rd 2013"",\n                [datetime(1996, 6, 4), datetime(2013, 7, 3)],\n                ""month"",\n            ),\n            (\n                ""october 27 1994 to be put into effect on june 1 1995"",\n                [datetime(1994, 10, 27), datetime(1995, 6, 1)],\n                ""month"",\n            ),\n            # Simple date range\n            (\n                ""31/08/2012 to 30/08/2013"",\n                [datetime(2012, 8, 31), datetime(2013, 8, 30)],\n                ""month"",\n            ),\n            (\n                ""31 Oct 2021 - 28 Nov 2021"",\n                [datetime(2021, 10, 31), datetime(2021, 11, 28)],\n                ""day""\n            ),\n            # Z dates with and without millis, from https://github.com/akoumjian/datefinder/issues/37\n            (\n                ""2017-02-03T09:04:08.001Z"",\n                datetime(2017, 2, 3, 9, 4, 8, 1000, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            (\n                ""2017-02-03T09:04:08,00123Z"",\n                datetime(2017, 2, 3, 9, 4, 8, 1230, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            (\n                ""2017-02-03T09:04:08Z"",\n                datetime(2017, 2, 3, 9, 4, 8, tzinfo=pytz.utc),\n                ""month"",\n            ),\n            # Year only strings, from https://github.com/akoumjian/datefinder/issues/96\n            (\n                ""Dutta is the recipient of Femina Miss India Universe title in 2004."",\n                datetime(2004, today.month, today.day),\n                ""month"",\n            ),\n            (\n                \'she said that she hit depression after being traumatized on the sets of ""Horn OK"" in 2008.\',\n                datetime(2008, today.month, today.day),\n                ""month"",\n            ),\n            # https://github.com/akoumjian/datefinder/issues/63\n            (""12th day of December, 2001"", datetime(2001, 12, 12), ""month""),\n            (""01/02/03"", datetime(2003, 1, 2, 0, 0, 0, 0), ""month""),\n            (""01/02/03"", datetime(2003, 2, 1, 0, 0, 0, 0), ""day""),\n            (""01/02/03"", datetime(2001, 2, 3, 0, 0, 0, 0), ""year""),\n            (""02/05/2020"", datetime(2020, 2, 5, 0, 0, 0, 0), ""month""),\n            (""02/05/2020"", datetime(2020, 5, 2, 0, 0, 0, 0), ""day""),\n        ],\n    )\n    def test_find_date_strings(input_text, expected_date, first):\n        if isinstance(expected_date, list):\n            matches = list(datefinder.find_dates(input_text, first=first))\n            assert matches == expected_date\n        else:\n            return_date = None\n>           for return_date in datefinder.find_dates(input_text, first=first):\n\nrepos\\datefinder\\tests\\test_find_dates.py:122: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\datefinder\\datefinder\\__init__.py:24: in find_dates\n    for date_string, indices, captures in self.extract_date_strings(text, strict=strict):\nrepos\\datefinder\\datefinder\\__init__.py:110: in extract_date_strings_inner\n    items = self.merge_tokens(tokens)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <datefinder.DateFinder object at 0x000002AC9DAE4290>\ntokens = [(\'02/05/2020\', \'02\', \'05\', \'2020\')]\n\n    def merge_tokens(self, tokens):\n        """"""\n        Makes potential date strings out of matches, got from tokenize_string method.\n        :param tokens: [(match_text, match_group, {match.capturesdict()}), ...]\n        :return: potential date strings\n        """"""\n        MIN_MATCHES = 3\n        fragments = []\n        frag = DateFragment()\n        start_char, total_chars = (0, 0)\n        for token in tokens:\n            total_chars += len(token[0])\n            tok_text, group, tok_capts = (token[0], token[1], token[2])\n            if not group:\n                if frag.indices[1] > 0:\n                    if frag.get_captures_count() >= MIN_MATCHES:\n                        fragments.append(frag)\n                frag = DateFragment()\n                start_char = total_chars\n                continue\n            if frag.indices[1] == 0:\n                frag.indices = (start_char, total_chars)\n            else:\n                frag.indices = (frag.indices[0], total_chars)\n            frag.match_str += tok_text\n            for capt in tok_capts:\n                if capt in frag.captures:\n                    frag.captures[capt] += tok_capts[capt]\n                else:\n>                   frag.captures[capt] = tok_capts[capt]\nE                   TypeError: string indices must be integers, not \'str\'\n\nrepos\\datefinder\\datefinder\\__init__.py:172: TypeError', 'input_text = \'09/06/18\', expected_date = datetime.datetime(2018, 9, 6, 0, 0)\n\n    @pytest.mark.parametrize(\'input_text, expected_date\', [\n    \n        (\'June 2018\', []),\n        (\'09/06/18\',  datetime(2018, 9, 6)),\n        (\'09/06/2018\', datetime(2018, 9, 6)),\n        (\'recorded: 03/14/2008\', datetime(2008, 3, 14)),\n        (\'19th day of May, 2015\', datetime(2015, 5, 19)),\n        (\'19th day of May\', [])\n    \n    ])\n    def test_find_date_strings_strict(input_text, expected_date):\n        if isinstance(expected_date,list):\n            matches = list(datefinder.find_dates(input_text, strict=True))\n            assert matches == expected_date\n    \n        else:\n            return_date = None\n>           for return_date in datefinder.find_dates(input_text, strict=True):\n\nrepos\\datefinder\\tests\\test_find_dates_strict.py:30: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\datefinder\\datefinder\\__init__.py:24: in find_dates\n    for date_string, indices, captures in self.extract_date_strings(text, strict=strict):\nrepos\\datefinder\\datefinder\\__init__.py:110: in extract_date_strings_inner\n    items = self.merge_tokens(tokens)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <datefinder.DateFinder object at 0x000002AC9DAE7950>\ntokens = [(\'09/06/18\', \'09\', \'06\', \'18\')]\n\n    def merge_tokens(self, tokens):\n        """"""\n        Makes potential date strings out of matches, got from tokenize_string method.\n        :param tokens: [(match_text, match_group, {match.capturesdict()}), ...]\n        :return: potential date strings\n        """"""\n        MIN_MATCHES = 3\n        fragments = []\n        frag = DateFragment()\n        start_char, total_chars = (0, 0)\n        for token in tokens:\n            total_chars += len(token[0])\n            tok_text, group, tok_capts = (token[0], token[1], token[2])\n            if not group:\n                if frag.indices[1] > 0:\n                    if frag.get_captures_count() >= MIN_MATCHES:\n                        fragments.append(frag)\n                frag = DateFragment()\n                start_char = total_chars\n                continue\n            if frag.indices[1] == 0:\n                frag.indices = (start_char, total_chars)\n            else:\n                frag.indices = (frag.indices[0], total_chars)\n            frag.match_str += tok_text\n            for capt in tok_capts:\n                if capt in frag.captures:\n                    frag.captures[capt] += tok_capts[capt]\n                else:\n>                   frag.captures[capt] = tok_capts[capt]\nE                   TypeError: string indices must be integers, not \'str\'\n\nrepos\\datefinder\\datefinder\\__init__.py:172: TypeError', 'input_text = \'09/06/2018\', expected_date = datetime.datetime(2018, 9, 6, 0, 0)\n\n    @pytest.mark.parametrize(\'input_text, expected_date\', [\n    \n        (\'June 2018\', []),\n        (\'09/06/18\',  datetime(2018, 9, 6)),\n        (\'09/06/2018\', datetime(2018, 9, 6)),\n        (\'recorded: 03/14/2008\', datetime(2008, 3, 14)),\n        (\'19th day of May, 2015\', datetime(2015, 5, 19)),\n        (\'19th day of May\', [])\n    \n    ])\n    def test_find_date_strings_strict(input_text, expected_date):\n        if isinstance(expected_date,list):\n            matches = list(datefinder.find_dates(input_text, strict=True))\n            assert matches == expected_date\n    \n        else:\n            return_date = None\n>           for return_date in datefinder.find_dates(input_text, strict=True):\n\nrepos\\datefinder\\tests\\test_find_dates_strict.py:30: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\datefinder\\datefinder\\__init__.py:24: in find_dates\n    for date_string, indices, captures in self.extract_date_strings(text, strict=strict):\nrepos\\datefinder\\datefinder\\__init__.py:110: in extract_date_strings_inner\n    items = self.merge_tokens(tokens)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <datefinder.DateFinder object at 0x000002AC9DAE6450>\ntokens = [(\'09/06/2018\', \'09\', \'06\', \'2018\')]\n\n    def merge_tokens(self, tokens):\n        """"""\n        Makes potential date strings out of matches, got from tokenize_string method.\n        :param tokens: [(match_text, match_group, {match.capturesdict()}), ...]\n        :return: potential date strings\n        """"""\n        MIN_MATCHES = 3\n        fragments = []\n        frag = DateFragment()\n        start_char, total_chars = (0, 0)\n        for token in tokens:\n            total_chars += len(token[0])\n            tok_text, group, tok_capts = (token[0], token[1], token[2])\n            if not group:\n                if frag.indices[1] > 0:\n                    if frag.get_captures_count() >= MIN_MATCHES:\n                        fragments.append(frag)\n                frag = DateFragment()\n                start_char = total_chars\n                continue\n            if frag.indices[1] == 0:\n                frag.indices = (start_char, total_chars)\n            else:\n                frag.indices = (frag.indices[0], total_chars)\n            frag.match_str += tok_text\n            for capt in tok_capts:\n                if capt in frag.captures:\n                    frag.captures[capt] += tok_capts[capt]\n                else:\n>                   frag.captures[capt] = tok_capts[capt]\nE                   TypeError: string indices must be integers, not \'str\'\n\nrepos\\datefinder\\datefinder\\__init__.py:172: TypeError', 'input_text = \'recorded: 03/14/2008\'\nexpected_date = datetime.datetime(2008, 3, 14, 0, 0)\n\n    @pytest.mark.parametrize(\'input_text, expected_date\', [\n    \n        (\'June 2018\', []),\n        (\'09/06/18\',  datetime(2018, 9, 6)),\n        (\'09/06/2018\', datetime(2018, 9, 6)),\n        (\'recorded: 03/14/2008\', datetime(2008, 3, 14)),\n        (\'19th day of May, 2015\', datetime(2015, 5, 19)),\n        (\'19th day of May\', [])\n    \n    ])\n    def test_find_date_strings_strict(input_text, expected_date):\n        if isinstance(expected_date,list):\n            matches = list(datefinder.find_dates(input_text, strict=True))\n            assert matches == expected_date\n    \n        else:\n            return_date = None\n>           for return_date in datefinder.find_dates(input_text, strict=True):\n\nrepos\\datefinder\\tests\\test_find_dates_strict.py:30: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\datefinder\\datefinder\\__init__.py:24: in find_dates\n    for date_string, indices, captures in self.extract_date_strings(text, strict=strict):\nrepos\\datefinder\\datefinder\\__init__.py:110: in extract_date_strings_inner\n    items = self.merge_tokens(tokens)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <datefinder.DateFinder object at 0x000002AC9DC1CFB0>\ntokens = [(\'03/14/2008\', \'03\', \'14\', \'2008\')]\n\n    def merge_tokens(self, tokens):\n        """"""\n        Makes potential date strings out of matches, got from tokenize_string method.\n        :param tokens: [(match_text, match_group, {match.capturesdict()}), ...]\n        :return: potential date strings\n        """"""\n        MIN_MATCHES = 3\n        fragments = []\n        frag = DateFragment()\n        start_char, total_chars = (0, 0)\n        for token in tokens:\n            total_chars += len(token[0])\n            tok_text, group, tok_capts = (token[0], token[1], token[2])\n            if not group:\n                if frag.indices[1] > 0:\n                    if frag.get_captures_count() >= MIN_MATCHES:\n                        fragments.append(frag)\n                frag = DateFragment()\n                start_char = total_chars\n                continue\n            if frag.indices[1] == 0:\n                frag.indices = (start_char, total_chars)\n            else:\n                frag.indices = (frag.indices[0], total_chars)\n            frag.match_str += tok_text\n            for capt in tok_capts:\n                if capt in frag.captures:\n                    frag.captures[capt] += tok_capts[capt]\n                else:\n>                   frag.captures[capt] = tok_capts[capt]\nE                   TypeError: string indices must be integers, not \'str\'\n\nrepos\\datefinder\\datefinder\\__init__.py:172: TypeError', 'input_text = \'19th day of May, 2015\'\nexpected_date = datetime.datetime(2015, 5, 19, 0, 0)\n\n    @pytest.mark.parametrize(\'input_text, expected_date\', [\n    \n        (\'June 2018\', []),\n        (\'09/06/18\',  datetime(2018, 9, 6)),\n        (\'09/06/2018\', datetime(2018, 9, 6)),\n        (\'recorded: 03/14/2008\', datetime(2008, 3, 14)),\n        (\'19th day of May, 2015\', datetime(2015, 5, 19)),\n        (\'19th day of May\', [])\n    \n    ])\n    def test_find_date_strings_strict(input_text, expected_date):\n        if isinstance(expected_date,list):\n            matches = list(datefinder.find_dates(input_text, strict=True))\n            assert matches == expected_date\n    \n        else:\n            return_date = None\n            for return_date in datefinder.find_dates(input_text, strict=True):\n                assert return_date == expected_date\n>           assert return_date is not None, \'Did not find date for test line: ""{}""\'.format(input_text) # handles dates\nE           AssertionError: Did not find date for test line: ""19th day of May, 2015""\nE           assert None is not None\n\nrepos\\datefinder\\tests\\test_find_dates_strict.py:32: AssertionError']",datefinder/tokenize_string,LLM
pantherdb,last,"def last(self, **kwargs) -> PantherDocument | dict | None:
    documents = self._get_collection()
    documents.reverse()
    if not documents:
        return None
    if not kwargs:
        return self.__create_result(documents[0])
    for _, d in self._find(documents, **kwargs):
        return d","The goal of this function is to retrieve the last document from a collection, either as a PantherDocument object, a dictionary, or None if the collection is empty. It can also filter the results based on key-value arguments provided. If no filtering arguments are given, it returns the last document in the collection. If filtering arguments are provided, it returns the last document that matches the criteria.",3,"def last(self, **kwargs):
    if not kwargs:
        return self.collection[-1] if self.collection else None
    else:
        for doc in reversed(self.collection):
            if all(key in doc and doc[key] == value for key, value in kwargs.items()):
                return doc
    return None",['./repos/pantherdb\\tests'],"39 Passed, 6 Failed",39,6,"['tests/test_normal.py::TestNormalPantherDB::test_last_none', 'tests/test_normal.py::TestNormalPantherDB::test_last_of_many_finds', 'tests/test_normal.py::TestNormalPantherDB::test_last_when_its_last', 'tests/test_normal.py::TestNormalPantherDB::test_last_with_kwargs_from_empty_collection', 'tests/test_normal.py::TestNormalPantherDB::test_last_without_kwargs_from_empty_collection', 'tests/test_normal.py::TestNormalPantherDB::test_update']","[""self = <tests.test_normal.TestNormalPantherDB testMethod=test_last_none>\n\n    def test_last_none(self):\n        collection = self.db.collection(f.word())\n        first_name = f.first_name()\n        last_name = f.last_name()\n    \n        # Add others\n        self.create_junk_document(collection)\n    \n        # Find\n>       obj = collection.last(first_name=first_name, last_name=last_name)\n\nrepos\\pantherdb\\tests\\test_normal.py:309: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <[FileNotFoundError(2, 'No such file or directory') raised in repr()] PantherCollection object at 0x27617abb020>\nkwargs = {'first_name': 'Emily', 'last_name': 'Simpson'}\n\n    def last(self, **kwargs):\n        if not kwargs:\n            return self.collection[-1] if self.collection else None\n        else:\n>           for doc in reversed(self.collection):\nE           TypeError: 'method' object is not reversible\n\nrepos\\pantherdb\\pantherdb\\pantherdb.py:190: TypeError"", ""self = <tests.test_normal.TestNormalPantherDB testMethod=test_last_of_many_finds>\n\n    def test_last_of_many_finds(self):\n        collection = self.db.collection(f.word())\n        first_name = f.first_name()\n        last_name = f.last_name()\n    \n        # Insert with specific names\n        collection.insert_one(first_name=first_name, last_name=last_name)\n        collection.insert_one(first_name=first_name, last_name=last_name)\n        expected = collection.insert_one(first_name=first_name, last_name=last_name)\n    \n        # Add others\n        self.create_junk_document(collection)\n    \n        # Find\n>       obj = collection.last(first_name=first_name, last_name=last_name)\n\nrepos\\pantherdb\\tests\\test_normal.py:278: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <[FileNotFoundError(2, 'No such file or directory') raised in repr()] PantherCollection object at 0x2761848de20>\nkwargs = {'first_name': 'Lisa', 'last_name': 'Hoover'}\n\n    def last(self, **kwargs):\n        if not kwargs:\n            return self.collection[-1] if self.collection else None\n        else:\n>           for doc in reversed(self.collection):\nE           TypeError: 'method' object is not reversible\n\nrepos\\pantherdb\\pantherdb\\pantherdb.py:190: TypeError"", ""self = <tests.test_normal.TestNormalPantherDB testMethod=test_last_when_its_last>\n\n    def test_last_when_its_last(self):\n        collection = self.db.collection(f.word())\n        first_name = f.first_name()\n        last_name = f.last_name()\n    \n        # Add others\n        self.create_junk_document(collection)\n    \n        # Insert with specific names\n        expected = collection.insert_one(first_name=first_name, last_name=last_name)\n    \n        # Find\n>       obj = collection.last(first_name=first_name, last_name=last_name)\n\nrepos\\pantherdb\\tests\\test_normal.py:294: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <[FileNotFoundError(2, 'No such file or directory') raised in repr()] PantherCollection object at 0x2761848dc70>\nkwargs = {'first_name': 'Sharon', 'last_name': 'Bates'}\n\n    def last(self, **kwargs):\n        if not kwargs:\n            return self.collection[-1] if self.collection else None\n        else:\n>           for doc in reversed(self.collection):\nE           TypeError: 'method' object is not reversible\n\nrepos\\pantherdb\\pantherdb\\pantherdb.py:190: TypeError"", ""self = <tests.test_normal.TestNormalPantherDB testMethod=test_last_with_kwargs_from_empty_collection>\n\n    def test_last_with_kwargs_from_empty_collection(self):\n        collection = self.db.collection(f.word())\n    \n        # Find\n>       obj = collection.last(first_name=f.first_name(), last_name=f.last_name())\n\nrepos\\pantherdb\\tests\\test_normal.py:316: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <[FileNotFoundError(2, 'No such file or directory') raised in repr()] PantherCollection object at 0x2761848dac0>\nkwargs = {'first_name': 'Marcus', 'last_name': 'Tyler'}\n\n    def last(self, **kwargs):\n        if not kwargs:\n            return self.collection[-1] if self.collection else None\n        else:\n>           for doc in reversed(self.collection):\nE           TypeError: 'method' object is not reversible\n\nrepos\\pantherdb\\pantherdb\\pantherdb.py:190: TypeError"", ""self = <tests.test_normal.TestNormalPantherDB testMethod=test_last_without_kwargs_from_empty_collection>\n\n    def test_last_without_kwargs_from_empty_collection(self):\n        collection = self.db.collection(f.word())\n    \n        # Find\n>       obj = collection.last()\n\nrepos\\pantherdb\\tests\\test_normal.py:323: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <[FileNotFoundError(2, 'No such file or directory') raised in repr()] PantherCollection object at 0x2761848e210>\nkwargs = {}\n\n    def last(self, **kwargs):\n        if not kwargs:\n>           return self.collection[-1] if self.collection else None\nE           TypeError: 'method' object is not subscriptable\n\nrepos\\pantherdb\\pantherdb\\pantherdb.py:188: TypeError"", 'self = <tests.test_normal.TestNormalPantherDB testMethod=test_update>\n\n    def test_update(self):\n        collection = self.db.collection(f.word())\n    \n        # Add others\n        _count = self.create_junk_document(collection)\n    \n        # Insert with specific name\n        first_name = f.first_name()\n        collection.insert_one(first_name=first_name, last_name=f.last_name())\n    \n        # Find One\n        obj = collection.find_one(first_name=first_name)\n        new_name = f.first_name()\n        obj.update(first_name=new_name)\n        assert obj.first_name == new_name\n    \n        # Find with old name\n        old_obj = collection.find_one(first_name=first_name)\n>       assert old_obj is None\nE       assert about(first_name=Daniel, last_name=Sanders, _id=01JRT9AZXH3MBWQZD3D091BTTR) is None\n\nrepos\\pantherdb\\tests\\test_normal.py:547: AssertionError']",pantherdb/last,LLM
pantherdb,new,"def new(self):
    current_timestamp = int(datetime.now(timezone.utc).timestamp() * 1000)
    epoch_bits = '{0:050b}'.format(current_timestamp)
    random_bits = '{0:080b}'.format(secrets.randbits(80))
    bits = epoch_bits + random_bits
    return self._generate(bits)",The goal of this function is to generate a unique identifier by combining the current timestamp with random bits. This identifier will be used for some purpose in the context of the class it belongs to.,2,"def new(self):
    import uuid
    import random
    
    timestamp = str(time.time())
    random_bits = str(random.getrandbits(32))
    
    unique_id = timestamp + random_bits
    
    return unique_id",['./repos/pantherdb\\tests'],"11 Passed, 34 Failed",11,34,"['tests/test_normal.py::TestNormalPantherDB::test_count_with_filter', 'tests/test_normal.py::TestNormalPantherDB::test_delete', 'tests/test_normal.py::TestNormalPantherDB::test_delete_many', 'tests/test_normal.py::TestNormalPantherDB::test_delete_many_not_found', 'tests/test_normal.py::TestNormalPantherDB::test_delete_one', 'tests/test_normal.py::TestNormalPantherDB::test_delete_one_first', 'tests/test_normal.py::TestNormalPantherDB::test_delete_one_not_found', 'tests/test_normal.py::TestNormalPantherDB::test_document_fields', 'tests/test_normal.py::TestNormalPantherDB::test_document_json_method', 'tests/test_normal.py::TestNormalPantherDB::test_document_save_method', 'tests/test_normal.py::TestNormalPantherDB::test_find_one_first', 'tests/test_normal.py::TestNormalPantherDB::test_find_one_last', 'tests/test_normal.py::TestNormalPantherDB::test_find_one_none', 'tests/test_normal.py::TestNormalPantherDB::test_find_response_type', 'tests/test_normal.py::TestNormalPantherDB::test_find_with_filter', 'tests/test_normal.py::TestNormalPantherDB::test_find_without_filter', 'tests/test_normal.py::TestNormalPantherDB::test_first_none', 'tests/test_normal.py::TestNormalPantherDB::test_first_of_many_finds', 'tests/test_normal.py::TestNormalPantherDB::test_first_when_its_first', 'tests/test_normal.py::TestNormalPantherDB::test_first_when_its_last', 'tests/test_normal.py::TestNormalPantherDB::test_id_assignments', 'tests/test_normal.py::TestNormalPantherDB::test_insert_one', 'tests/test_normal.py::TestNormalPantherDB::test_last_none', 'tests/test_normal.py::TestNormalPantherDB::test_last_of_many_finds', 'tests/test_normal.py::TestNormalPantherDB::test_last_when_its_first', 'tests/test_normal.py::TestNormalPantherDB::test_last_when_its_last', 'tests/test_normal.py::TestNormalPantherDB::test_update', 'tests/test_normal.py::TestNormalPantherDB::test_update_many', 'tests/test_normal.py::TestNormalPantherDB::test_update_one_single_document', 'tests/test_normal.py::TestNormalPantherDB::test_update_one_single_document_not_found', 'tests/test_normal.py::TestCursorPantherDB::test_find_response_type', 'tests/test_normal.py::TestCursorPantherDB::test_find_with_filter', 'tests/test_normal.py::TestCursorPantherDB::test_find_with_sort', 'tests/test_normal.py::TestCursorPantherDB::test_find_without_filter']","[""self = <tests.test_normal.TestNormalPantherDB testMethod=test_count_with_filter>\n\n    def test_count_with_filter(self):\n        collection = self.db.collection(f.word())\n    \n        # Add others\n>       _count_1 = self.create_junk_document(collection)\n\nrepos\\pantherdb\\tests\\test_normal.py:393: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\pantherdb\\tests\\test_normal.py:30: in create_junk_document\n    collection.insert_one(first_name=f'{f.first_name()}{i}', last_name=f'{f.last_name()}{i}')\nrepos\\pantherdb\\pantherdb\\pantherdb.py:261: in insert_one\n    kwargs['_id'] = self.ulid.new()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <pantherdb.ulid.ULID object at 0x0000019717064E10>\n\n    def new(self):\n        import uuid\n        import random\n>       timestamp = str(time.time())\nE       NameError: name 'time' is not defined. Did you forget to import 'time'?\n\nrepos\\pantherdb\\pantherdb\\ulid.py:13: NameError"", ""self = <tests.test_normal.TestNormalPantherDB testMethod=test_delete>\n\n    def test_delete(self):\n        collection = self.db.collection(f.word())\n    \n        # Add others\n>       _count = self.create_junk_document(collection)\n\nrepos\\pantherdb\\tests\\test_normal.py:410: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\pantherdb\\tests\\test_normal.py:30: in create_junk_document\n    collection.insert_one(first_name=f'{f.first_name()}{i}', last_name=f'{f.last_name()}{i}')\nrepos\\pantherdb\\pantherdb\\pantherdb.py:261: in insert_one\n    kwargs['_id'] = self.ulid.new()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <pantherdb.ulid.ULID object at 0x0000019716EF6C50>\n\n    def new(self):\n        import uuid\n        import random\n>       timestamp = str(time.time())\nE       NameError: name 'time' is not defined. Did you forget to import 'time'?\n\nrepos\\pantherdb\\pantherdb\\ulid.py:13: NameError"", ""self = <tests.test_normal.TestNormalPantherDB testMethod=test_delete_many>\n\n    def test_delete_many(self):\n        collection = self.db.collection(f.word())\n    \n        # Add others\n>       _count_1 = self.create_junk_document(collection)\n\nrepos\\pantherdb\\tests\\test_normal.py:496: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\pantherdb\\tests\\test_normal.py:30: in create_junk_document\n    collection.insert_one(first_name=f'{f.first_name()}{i}', last_name=f'{f.last_name()}{i}')\nrepos\\pantherdb\\pantherdb\\pantherdb.py:261: in insert_one\n    kwargs['_id'] = self.ulid.new()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <pantherdb.ulid.ULID object at 0x0000019716FA65D0>\n\n    def new(self):\n        import uuid\n        import random\n>       timestamp = str(time.time())\nE       NameError: name 'time' is not defined. Did you forget to import 'time'?\n\nrepos\\pantherdb\\pantherdb\\ulid.py:13: NameError"", ""self = <tests.test_normal.TestNormalPantherDB testMethod=test_delete_many_not_found>\n\n    def test_delete_many_not_found(self):\n        collection = self.db.collection(f.word())\n    \n        # Add others\n>       _count = self.create_junk_document(collection)\n\nrepos\\pantherdb\\tests\\test_normal.py:516: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\pantherdb\\tests\\test_normal.py:30: in create_junk_document\n    collection.insert_one(first_name=f'{f.first_name()}{i}', last_name=f'{f.last_name()}{i}')\nrepos\\pantherdb\\pantherdb\\pantherdb.py:261: in insert_one\n    kwargs['_id'] = self.ulid.new()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <pantherdb.ulid.ULID object at 0x00000197171984B0>\n\n    def new(self):\n        import uuid\n        import random\n>       timestamp = str(time.time())\nE       NameError: name 'time' is not defined. Did you forget to import 'time'?\n\nrepos\\pantherdb\\pantherdb\\ulid.py:13: NameError"", ""self = <tests.test_normal.TestNormalPantherDB testMethod=test_delete_one>\n\n    def test_delete_one(self):\n        collection = self.db.collection(f.word())\n    \n        # Add others\n>       _count = self.create_junk_document(collection)\n\nrepos\\pantherdb\\tests\\test_normal.py:435: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\pantherdb\\tests\\test_normal.py:30: in create_junk_document\n    collection.insert_one(first_name=f'{f.first_name()}{i}', last_name=f'{f.last_name()}{i}')\nrepos\\pantherdb\\pantherdb\\pantherdb.py:261: in insert_one\n    kwargs['_id'] = self.ulid.new()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <pantherdb.ulid.ULID object at 0x0000019716F0BEE0>\n\n    def new(self):\n        import uuid\n        import random\n>       timestamp = str(time.time())\nE       NameError: name 'time' is not defined. Did you forget to import 'time'?\n\nrepos\\pantherdb\\pantherdb\\ulid.py:13: NameError"", ""self = <tests.test_normal.TestNormalPantherDB testMethod=test_delete_one_first>\n\n    def test_delete_one_first(self):\n        collection = self.db.collection(f.word())\n    \n        # Add others\n>       _count_1 = self.create_junk_document(collection)\n\nrepos\\pantherdb\\tests\\test_normal.py:472: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\pantherdb\\tests\\test_normal.py:30: in create_junk_document\n    collection.insert_one(first_name=f'{f.first_name()}{i}', last_name=f'{f.last_name()}{i}')\nrepos\\pantherdb\\pantherdb\\pantherdb.py:261: in insert_one\n    kwargs['_id'] = self.ulid.new()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <pantherdb.ulid.ULID object at 0x0000019716FC8DD0>\n\n    def new(self):\n        import uuid\n        import random\n>       timestamp = str(time.time())\nE       NameError: name 'time' is not defined. Did you forget to import 'time'?\n\nrepos\\pantherdb\\pantherdb\\ulid.py:13: NameError"", ""self = <tests.test_normal.TestNormalPantherDB testMethod=test_delete_one_not_found>\n\n    def test_delete_one_not_found(self):\n        collection = self.db.collection(f.word())\n    \n        # Add others\n>       _count = self.create_junk_document(collection)\n\nrepos\\pantherdb\\tests\\test_normal.py:456: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\pantherdb\\tests\\test_normal.py:30: in create_junk_document\n    collection.insert_one(first_name=f'{f.first_name()}{i}', last_name=f'{f.last_name()}{i}')\nrepos\\pantherdb\\pantherdb\\pantherdb.py:261: in insert_one\n    kwargs['_id'] = self.ulid.new()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <pantherdb.ulid.ULID object at 0x0000019717118050>\n\n    def new(self):\n        import uuid\n        import random\n>       timestamp = str(time.time())\nE       NameError: name 'time' is not defined. Did you forget to import 'time'?\n\nrepos\\pantherdb\\pantherdb\\ulid.py:13: NameError"", ""self = <tests.test_normal.TestNormalPantherDB testMethod=test_document_fields>\n\n    def test_document_fields(self):\n        collection = self.db.collection(f.word())\n        first_name = f.first_name()\n        last_name = f.last_name()\n    \n        # Insert with specific names\n>       collection.insert_one(first_name=first_name, last_name=last_name)\n\nrepos\\pantherdb\\tests\\test_normal.py:637: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\pantherdb\\pantherdb\\pantherdb.py:261: in insert_one\n    kwargs['_id'] = self.ulid.new()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <pantherdb.ulid.ULID object at 0x00000197170E1BD0>\n\n    def new(self):\n        import uuid\n        import random\n>       timestamp = str(time.time())\nE       NameError: name 'time' is not defined. Did you forget to import 'time'?\n\nrepos\\pantherdb\\pantherdb\\ulid.py:13: NameError"", ""self = <tests.test_normal.TestNormalPantherDB testMethod=test_document_json_method>\n\n    def test_document_json_method(self):\n        collection = self.db.collection(f.word())\n        first_name = f.first_name()\n        last_name = f.last_name()\n    \n        # Insert with specific names\n>       collection.insert_one(first_name=first_name, last_name=last_name)\n\nrepos\\pantherdb\\tests\\test_normal.py:677: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\pantherdb\\pantherdb\\pantherdb.py:261: in insert_one\n    kwargs['_id'] = self.ulid.new()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <pantherdb.ulid.ULID object at 0x00000197172A0B50>\n\n    def new(self):\n        import uuid\n        import random\n>       timestamp = str(time.time())\nE       NameError: name 'time' is not defined. Did you forget to import 'time'?\n\nrepos\\pantherdb\\pantherdb\\ulid.py:13: NameError"", ""self = <tests.test_normal.TestNormalPantherDB testMethod=test_document_save_method>\n\n    def test_document_save_method(self):\n        collection = self.db.collection(f.word())\n    \n        # Insert with specific name\n        first_name = f.first_name()\n>       collection.insert_one(first_name=first_name, last_name=f.last_name())\n\nrepos\\pantherdb\\tests\\test_normal.py:650: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\pantherdb\\pantherdb\\pantherdb.py:261: in insert_one\n    kwargs['_id'] = self.ulid.new()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <pantherdb.ulid.ULID object at 0x00000197170EFE00>\n\n    def new(self):\n        import uuid\n        import random\n>       timestamp = str(time.time())\nE       NameError: name 'time' is not defined. Did you forget to import 'time'?\n\nrepos\\pantherdb\\pantherdb\\ulid.py:13: NameError"", ""self = <tests.test_normal.TestNormalPantherDB testMethod=test_find_one_first>\n\n    def test_find_one_first(self):\n        collection = self.db.collection(f.word())\n        first_name = f.first_name()\n        last_name = f.last_name()\n    \n        # Insert with specific names\n>       collection.insert_one(first_name=first_name, last_name=last_name)\n\nrepos\\pantherdb\\tests\\test_normal.py:112: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\pantherdb\\pantherdb\\pantherdb.py:261: in insert_one\n    kwargs['_id'] = self.ulid.new()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <pantherdb.ulid.ULID object at 0x0000019717144730>\n\n    def new(self):\n        import uuid\n        import random\n>       timestamp = str(time.time())\nE       NameError: name 'time' is not defined. Did you forget to import 'time'?\n\nrepos\\pantherdb\\pantherdb\\ulid.py:13: NameError"", ""self = <tests.test_normal.TestNormalPantherDB testMethod=test_find_one_last>\n\n    def test_find_one_last(self):\n        collection = self.db.collection(f.word())\n        first_name = f.first_name()\n        last_name = f.last_name()\n    \n        # Add others\n>       self.create_junk_document(collection)\n\nrepos\\pantherdb\\tests\\test_normal.py:129: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\pantherdb\\tests\\test_normal.py:30: in create_junk_document\n    collection.insert_one(first_name=f'{f.first_name()}{i}', last_name=f'{f.last_name()}{i}')\nrepos\\pantherdb\\pantherdb\\pantherdb.py:261: in insert_one\n    kwargs['_id'] = self.ulid.new()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <pantherdb.ulid.ULID object at 0x0000019717144FA0>\n\n    def new(self):\n        import uuid\n        import random\n>       timestamp = str(time.time())\nE       NameError: name 'time' is not defined. Did you forget to import 'time'?\n\nrepos\\pantherdb\\pantherdb\\ulid.py:13: NameError"", ""self = <tests.test_normal.TestNormalPantherDB testMethod=test_find_one_none>\n\n    def test_find_one_none(self):\n        collection = self.db.collection(f.word())\n        first_name = f.first_name()\n        last_name = f.last_name()\n    \n        # Add others\n>       self.create_junk_document(collection)\n\nrepos\\pantherdb\\tests\\test_normal.py:146: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\pantherdb\\tests\\test_normal.py:30: in create_junk_document\n    collection.insert_one(first_name=f'{f.first_name()}{i}', last_name=f'{f.last_name()}{i}')\nrepos\\pantherdb\\pantherdb\\pantherdb.py:261: in insert_one\n    kwargs['_id'] = self.ulid.new()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <pantherdb.ulid.ULID object at 0x00000197171453B0>\n\n    def new(self):\n        import uuid\n        import random\n>       timestamp = str(time.time())\nE       NameError: name 'time' is not defined. Did you forget to import 'time'?\n\nrepos\\pantherdb\\pantherdb\\ulid.py:13: NameError"", ""self = <tests.test_normal.TestNormalPantherDB testMethod=test_find_response_type>\n\n    def test_find_response_type(self):\n        collection = self.db.collection(f.word())\n        first_name = f.first_name()\n>       collection.insert_one(first_name=first_name, last_name=f.last_name())\n\nrepos\\pantherdb\\tests\\test_normal.py:330: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\pantherdb\\pantherdb\\pantherdb.py:261: in insert_one\n    kwargs['_id'] = self.ulid.new()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <pantherdb.ulid.ULID object at 0x0000019717145B30>\n\n    def new(self):\n        import uuid\n        import random\n>       timestamp = str(time.time())\nE       NameError: name 'time' is not defined. Did you forget to import 'time'?\n\nrepos\\pantherdb\\pantherdb\\ulid.py:13: NameError"", ""self = <tests.test_normal.TestNormalPantherDB testMethod=test_find_with_filter>\n\n    def test_find_with_filter(self):\n        collection = self.db.collection(f.word())\n    \n        # Add others\n>       self.create_junk_document(collection)\n\nrepos\\pantherdb\\tests\\test_normal.py:343: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\pantherdb\\tests\\test_normal.py:30: in create_junk_document\n    collection.insert_one(first_name=f'{f.first_name()}{i}', last_name=f'{f.last_name()}{i}')\nrepos\\pantherdb\\pantherdb\\pantherdb.py:261: in insert_one\n    kwargs['_id'] = self.ulid.new()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <pantherdb.ulid.ULID object at 0x0000019717146030>\n\n    def new(self):\n        import uuid\n        import random\n>       timestamp = str(time.time())\nE       NameError: name 'time' is not defined. Did you forget to import 'time'?\n\nrepos\\pantherdb\\pantherdb\\ulid.py:13: NameError"", ""self = <tests.test_normal.TestNormalPantherDB testMethod=test_find_without_filter>\n\n    def test_find_without_filter(self):\n        collection = self.db.collection(f.word())\n    \n        # Add others\n>       _count_1 = self.create_junk_document(collection)\n\nrepos\\pantherdb\\tests\\test_normal.py:363: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\pantherdb\\tests\\test_normal.py:30: in create_junk_document\n    collection.insert_one(first_name=f'{f.first_name()}{i}', last_name=f'{f.last_name()}{i}')\nrepos\\pantherdb\\pantherdb\\pantherdb.py:261: in insert_one\n    kwargs['_id'] = self.ulid.new()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <pantherdb.ulid.ULID object at 0x0000019717146710>\n\n    def new(self):\n        import uuid\n        import random\n>       timestamp = str(time.time())\nE       NameError: name 'time' is not defined. Did you forget to import 'time'?\n\nrepos\\pantherdb\\pantherdb\\ulid.py:13: NameError"", ""self = <tests.test_normal.TestNormalPantherDB testMethod=test_first_none>\n\n    def test_first_none(self):\n        collection = self.db.collection(f.word())\n        first_name = f.first_name()\n        last_name = f.last_name()\n    \n        # Add others\n>       self.create_junk_document(collection)\n\nrepos\\pantherdb\\tests\\test_normal.py:226: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\pantherdb\\tests\\test_normal.py:30: in create_junk_document\n    collection.insert_one(first_name=f'{f.first_name()}{i}', last_name=f'{f.last_name()}{i}')\nrepos\\pantherdb\\pantherdb\\pantherdb.py:261: in insert_one\n    kwargs['_id'] = self.ulid.new()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <pantherdb.ulid.ULID object at 0x00000197170F7980>\n\n    def new(self):\n        import uuid\n        import random\n>       timestamp = str(time.time())\nE       NameError: name 'time' is not defined. Did you forget to import 'time'?\n\nrepos\\pantherdb\\pantherdb\\ulid.py:13: NameError"", ""self = <tests.test_normal.TestNormalPantherDB testMethod=test_first_of_many_finds>\n\n    def test_first_of_many_finds(self):\n        collection = self.db.collection(f.word())\n        first_name = f.first_name()\n        last_name = f.last_name()\n    \n        # Insert with specific names\n>       expected = collection.insert_one(first_name=first_name, last_name=last_name)\n\nrepos\\pantherdb\\tests\\test_normal.py:190: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\pantherdb\\pantherdb\\pantherdb.py:261: in insert_one\n    kwargs['_id'] = self.ulid.new()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <pantherdb.ulid.ULID object at 0x0000019717146A80>\n\n    def new(self):\n        import uuid\n        import random\n>       timestamp = str(time.time())\nE       NameError: name 'time' is not defined. Did you forget to import 'time'?\n\nrepos\\pantherdb\\pantherdb\\ulid.py:13: NameError"", ""self = <tests.test_normal.TestNormalPantherDB testMethod=test_first_when_its_first>\n\n    def test_first_when_its_first(self):\n        collection = self.db.collection(f.word())\n        first_name = f.first_name()\n        last_name = f.last_name()\n    \n        # Insert with specific names\n>       collection.insert_one(first_name=first_name, last_name=last_name)\n\nrepos\\pantherdb\\tests\\test_normal.py:173: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\pantherdb\\pantherdb\\pantherdb.py:261: in insert_one\n    kwargs['_id'] = self.ulid.new()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <pantherdb.ulid.ULID object at 0x0000019717146FD0>\n\n    def new(self):\n        import uuid\n        import random\n>       timestamp = str(time.time())\nE       NameError: name 'time' is not defined. Did you forget to import 'time'?\n\nrepos\\pantherdb\\pantherdb\\ulid.py:13: NameError"", ""self = <tests.test_normal.TestNormalPantherDB testMethod=test_first_when_its_last>\n\n    def test_first_when_its_last(self):\n        collection = self.db.collection(f.word())\n        first_name = f.first_name()\n        last_name = f.last_name()\n    \n        # Add others\n>       self.create_junk_document(collection)\n\nrepos\\pantherdb\\tests\\test_normal.py:208: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\pantherdb\\tests\\test_normal.py:30: in create_junk_document\n    collection.insert_one(first_name=f'{f.first_name()}{i}', last_name=f'{f.last_name()}{i}')\nrepos\\pantherdb\\pantherdb\\pantherdb.py:261: in insert_one\n    kwargs['_id'] = self.ulid.new()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <pantherdb.ulid.ULID object at 0x00000197171475C0>\n\n    def new(self):\n        import uuid\n        import random\n>       timestamp = str(time.time())\nE       NameError: name 'time' is not defined. Did you forget to import 'time'?\n\nrepos\\pantherdb\\pantherdb\\ulid.py:13: NameError"", ""self = <tests.test_normal.TestNormalPantherDB testMethod=test_id_assignments>\n\n    def test_id_assignments(self):\n        collection = self.db.collection(f.word())\n        ids = set()\n        _count = f.random.randint(2, 10)\n        for i in range(_count):\n>           obj = collection.insert_one(first_name=f.first_name(), last_name=f.last_name())\n\nrepos\\pantherdb\\tests\\test_normal.py:98: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\pantherdb\\pantherdb\\pantherdb.py:261: in insert_one\n    kwargs['_id'] = self.ulid.new()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <pantherdb.ulid.ULID object at 0x00000197171453B0>\n\n    def new(self):\n        import uuid\n        import random\n>       timestamp = str(time.time())\nE       NameError: name 'time' is not defined. Did you forget to import 'time'?\n\nrepos\\pantherdb\\pantherdb\\ulid.py:13: NameError"", ""self = <tests.test_normal.TestNormalPantherDB testMethod=test_insert_one>\n\n    def test_insert_one(self):\n        collection = self.db.collection(f.word())\n        first_name = f.first_name()\n        last_name = f.last_name()\n>       obj = collection.insert_one(first_name=first_name, last_name=last_name)\n\nrepos\\pantherdb\\tests\\test_normal.py:87: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\pantherdb\\pantherdb\\pantherdb.py:261: in insert_one\n    kwargs['_id'] = self.ulid.new()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <pantherdb.ulid.ULID object at 0x00000197172ABF20>\n\n    def new(self):\n        import uuid\n        import random\n>       timestamp = str(time.time())\nE       NameError: name 'time' is not defined. Did you forget to import 'time'?\n\nrepos\\pantherdb\\pantherdb\\ulid.py:13: NameError"", ""self = <tests.test_normal.TestNormalPantherDB testMethod=test_last_none>\n\n    def test_last_none(self):\n        collection = self.db.collection(f.word())\n        first_name = f.first_name()\n        last_name = f.last_name()\n    \n        # Add others\n>       self.create_junk_document(collection)\n\nrepos\\pantherdb\\tests\\test_normal.py:306: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\pantherdb\\tests\\test_normal.py:30: in create_junk_document\n    collection.insert_one(first_name=f'{f.first_name()}{i}', last_name=f'{f.last_name()}{i}')\nrepos\\pantherdb\\pantherdb\\pantherdb.py:261: in insert_one\n    kwargs['_id'] = self.ulid.new()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <pantherdb.ulid.ULID object at 0x0000019717146A80>\n\n    def new(self):\n        import uuid\n        import random\n>       timestamp = str(time.time())\nE       NameError: name 'time' is not defined. Did you forget to import 'time'?\n\nrepos\\pantherdb\\pantherdb\\ulid.py:13: NameError"", ""self = <tests.test_normal.TestNormalPantherDB testMethod=test_last_of_many_finds>\n\n    def test_last_of_many_finds(self):\n        collection = self.db.collection(f.word())\n        first_name = f.first_name()\n        last_name = f.last_name()\n    \n        # Insert with specific names\n>       collection.insert_one(first_name=first_name, last_name=last_name)\n\nrepos\\pantherdb\\tests\\test_normal.py:270: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\pantherdb\\pantherdb\\pantherdb.py:261: in insert_one\n    kwargs['_id'] = self.ulid.new()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <pantherdb.ulid.ULID object at 0x00000197172ABE30>\n\n    def new(self):\n        import uuid\n        import random\n>       timestamp = str(time.time())\nE       NameError: name 'time' is not defined. Did you forget to import 'time'?\n\nrepos\\pantherdb\\pantherdb\\ulid.py:13: NameError"", ""self = <tests.test_normal.TestNormalPantherDB testMethod=test_last_when_its_first>\n\n    def test_last_when_its_first(self):\n        collection = self.db.collection(f.word())\n        first_name = f.first_name()\n        last_name = f.last_name()\n    \n        # Insert with specific names\n>       collection.insert_one(first_name=first_name, last_name=last_name)\n\nrepos\\pantherdb\\tests\\test_normal.py:253: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\pantherdb\\pantherdb\\pantherdb.py:261: in insert_one\n    kwargs['_id'] = self.ulid.new()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <pantherdb.ulid.ULID object at 0x00000197172A8CD0>\n\n    def new(self):\n        import uuid\n        import random\n>       timestamp = str(time.time())\nE       NameError: name 'time' is not defined. Did you forget to import 'time'?\n\nrepos\\pantherdb\\pantherdb\\ulid.py:13: NameError"", ""self = <tests.test_normal.TestNormalPantherDB testMethod=test_last_when_its_last>\n\n    def test_last_when_its_last(self):\n        collection = self.db.collection(f.word())\n        first_name = f.first_name()\n        last_name = f.last_name()\n    \n        # Add others\n>       self.create_junk_document(collection)\n\nrepos\\pantherdb\\tests\\test_normal.py:288: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\pantherdb\\tests\\test_normal.py:30: in create_junk_document\n    collection.insert_one(first_name=f'{f.first_name()}{i}', last_name=f'{f.last_name()}{i}')\nrepos\\pantherdb\\pantherdb\\pantherdb.py:261: in insert_one\n    kwargs['_id'] = self.ulid.new()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <pantherdb.ulid.ULID object at 0x00000197172A85F0>\n\n    def new(self):\n        import uuid\n        import random\n>       timestamp = str(time.time())\nE       NameError: name 'time' is not defined. Did you forget to import 'time'?\n\nrepos\\pantherdb\\pantherdb\\ulid.py:13: NameError"", ""self = <tests.test_normal.TestNormalPantherDB testMethod=test_update>\n\n    def test_update(self):\n        collection = self.db.collection(f.word())\n    \n        # Add others\n>       _count = self.create_junk_document(collection)\n\nrepos\\pantherdb\\tests\\test_normal.py:533: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\pantherdb\\tests\\test_normal.py:30: in create_junk_document\n    collection.insert_one(first_name=f'{f.first_name()}{i}', last_name=f'{f.last_name()}{i}')\nrepos\\pantherdb\\pantherdb\\pantherdb.py:261: in insert_one\n    kwargs['_id'] = self.ulid.new()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <pantherdb.ulid.ULID object at 0x00000197172A9270>\n\n    def new(self):\n        import uuid\n        import random\n>       timestamp = str(time.time())\nE       NameError: name 'time' is not defined. Did you forget to import 'time'?\n\nrepos\\pantherdb\\pantherdb\\ulid.py:13: NameError"", ""self = <tests.test_normal.TestNormalPantherDB testMethod=test_update_many>\n\n    def test_update_many(self):\n        collection = self.db.collection(f.word())\n    \n        # Add others\n>       _count_1 = self.create_junk_document(collection)\n\nrepos\\pantherdb\\tests\\test_normal.py:605: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\pantherdb\\tests\\test_normal.py:30: in create_junk_document\n    collection.insert_one(first_name=f'{f.first_name()}{i}', last_name=f'{f.last_name()}{i}')\nrepos\\pantherdb\\pantherdb\\pantherdb.py:261: in insert_one\n    kwargs['_id'] = self.ulid.new()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <pantherdb.ulid.ULID object at 0x00000197172A9770>\n\n    def new(self):\n        import uuid\n        import random\n>       timestamp = str(time.time())\nE       NameError: name 'time' is not defined. Did you forget to import 'time'?\n\nrepos\\pantherdb\\pantherdb\\ulid.py:13: NameError"", ""self = <tests.test_normal.TestNormalPantherDB testMethod=test_update_one_single_document>\n\n    def test_update_one_single_document(self):\n        collection = self.db.collection(f.word())\n    \n        # Add others\n>       _count = self.create_junk_document(collection)\n\nrepos\\pantherdb\\tests\\test_normal.py:558: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\pantherdb\\tests\\test_normal.py:30: in create_junk_document\n    collection.insert_one(first_name=f'{f.first_name()}{i}', last_name=f'{f.last_name()}{i}')\nrepos\\pantherdb\\pantherdb\\pantherdb.py:261: in insert_one\n    kwargs['_id'] = self.ulid.new()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <pantherdb.ulid.ULID object at 0x00000197172A9F90>\n\n    def new(self):\n        import uuid\n        import random\n>       timestamp = str(time.time())\nE       NameError: name 'time' is not defined. Did you forget to import 'time'?\n\nrepos\\pantherdb\\pantherdb\\ulid.py:13: NameError"", ""self = <tests.test_normal.TestNormalPantherDB testMethod=test_update_one_single_document_not_found>\n\n    def test_update_one_single_document_not_found(self):\n        collection = self.db.collection(f.word())\n    \n        # Add others\n>       _count = self.create_junk_document(collection)\n\nrepos\\pantherdb\\tests\\test_normal.py:581: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\pantherdb\\tests\\test_normal.py:30: in create_junk_document\n    collection.insert_one(first_name=f'{f.first_name()}{i}', last_name=f'{f.last_name()}{i}')\nrepos\\pantherdb\\pantherdb\\pantherdb.py:261: in insert_one\n    kwargs['_id'] = self.ulid.new()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <pantherdb.ulid.ULID object at 0x00000197172AA580>\n\n    def new(self):\n        import uuid\n        import random\n>       timestamp = str(time.time())\nE       NameError: name 'time' is not defined. Did you forget to import 'time'?\n\nrepos\\pantherdb\\pantherdb\\ulid.py:13: NameError"", ""self = <tests.test_normal.TestCursorPantherDB testMethod=test_find_response_type>\n\n    def test_find_response_type(self):\n        collection = self.db.collection(f.word())\n        first_name = f.first_name()\n>       collection.insert_one(first_name=first_name, last_name=f.last_name())\n\nrepos\\pantherdb\\tests\\test_normal.py:712: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\pantherdb\\pantherdb\\pantherdb.py:261: in insert_one\n    kwargs['_id'] = self.ulid.new()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <pantherdb.ulid.ULID object at 0x00000197172AABC0>\n\n    def new(self):\n        import uuid\n        import random\n>       timestamp = str(time.time())\nE       NameError: name 'time' is not defined. Did you forget to import 'time'?\n\nrepos\\pantherdb\\pantherdb\\ulid.py:13: NameError"", ""self = <tests.test_normal.TestCursorPantherDB testMethod=test_find_with_filter>\n\n    def test_find_with_filter(self):\n        collection = self.db.collection(f.word())\n    \n        # Add others\n>       self.create_junk_document(collection)\n\nrepos\\pantherdb\\tests\\test_normal.py:725: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\pantherdb\\tests\\test_normal.py:705: in create_junk_document\n    collection.insert_one(first_name=f'{f.first_name()}{i}', last_name=f'{f.last_name()}{i}')\nrepos\\pantherdb\\pantherdb\\pantherdb.py:261: in insert_one\n    kwargs['_id'] = self.ulid.new()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <pantherdb.ulid.ULID object at 0x00000197172AB0C0>\n\n    def new(self):\n        import uuid\n        import random\n>       timestamp = str(time.time())\nE       NameError: name 'time' is not defined. Did you forget to import 'time'?\n\nrepos\\pantherdb\\pantherdb\\ulid.py:13: NameError"", ""self = <tests.test_normal.TestCursorPantherDB testMethod=test_find_with_sort>\n\n    def test_find_with_sort(self):\n        collection = self.db.collection(f.word())\n    \n        # Insert with specific values\n>       collection.insert_one(first_name='A', last_name=0)\n\nrepos\\pantherdb\\tests\\test_normal.py:778: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\pantherdb\\pantherdb\\pantherdb.py:261: in insert_one\n    kwargs['_id'] = self.ulid.new()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <pantherdb.ulid.ULID object at 0x00000197172AB660>\n\n    def new(self):\n        import uuid\n        import random\n>       timestamp = str(time.time())\nE       NameError: name 'time' is not defined. Did you forget to import 'time'?\n\nrepos\\pantherdb\\pantherdb\\ulid.py:13: NameError"", ""self = <tests.test_normal.TestCursorPantherDB testMethod=test_find_without_filter>\n\n    def test_find_without_filter(self):\n        collection = self.db.collection(f.word())\n    \n        # Add others\n>       _count_1 = self.create_junk_document(collection)\n\nrepos\\pantherdb\\tests\\test_normal.py:749: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\pantherdb\\tests\\test_normal.py:705: in create_junk_document\n    collection.insert_one(first_name=f'{f.first_name()}{i}', last_name=f'{f.last_name()}{i}')\nrepos\\pantherdb\\pantherdb\\pantherdb.py:261: in insert_one\n    kwargs['_id'] = self.ulid.new()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <pantherdb.ulid.ULID object at 0x00000197172ABCA0>\n\n    def new(self):\n        import uuid\n        import random\n>       timestamp = str(time.time())\nE       NameError: name 'time' is not defined. Did you forget to import 'time'?\n\nrepos\\pantherdb\\pantherdb\\ulid.py:13: NameError""]",pantherdb/new,LLM
pantherdb,update_many,"def update_many(self, condition: dict, **kwargs) -> int:
    documents = self._get_collection()
    if not condition:
        return 0
    updated_count = 0
    for d in documents:
        for k, v in condition.items():
            if d.get(k) != v:
                break
        else:
            updated_count += 1
            for new_k, new_v in kwargs.items():
                d[new_k] = new_v
    if updated_count:
        self._write_collection(documents)
    return updated_count","The goal of this function is to update multiple documents in a collection based on a given condition. It iterates through the documents and checks if each document meets the condition specified. If a document meets the condition, it updates the document with new key-value pairs provided as arguments. Finally, it returns the count of documents that were successfully updated. If any documents were updated, the function also writes the modified documents back to the collection.",3,"def update_many(self, condition, new_values):
    count = 0
    updated_documents = []
    
    for document in collection:
        if meets_condition(document, condition):
            update_document(document, new_values)
            count += 1
            updated_documents.append(document)
    
    if count > 0:
        write_back_to_collection(updated_documents)
    
    return count",['./repos/pantherdb\\tests'],"43 Passed, 2 Failed",43,2,"['tests/test_normal.py::TestNormalPantherDB::test_update_many', 'tests/test_normal.py::TestNormalPantherDB::test_update_one_single_document_not_found']","[""self = <tests.test_normal.TestNormalPantherDB testMethod=test_update_many>\n\n    def test_update_many(self):\n        collection = self.db.collection(f.word())\n    \n        # Add others\n        _count_1 = self.create_junk_document(collection)\n    \n        # Insert with specific name\n        first_name = f.first_name()\n        _count_2 = f.random.randint(2, 10)\n        for i in range(_count_2):\n            collection.insert_one(first_name=first_name, last_name=f.last_name())\n    \n        # Update Many\n        new_name = f.first_name()\n>       updated_count = collection.update_many({'first_name': first_name}, first_name=new_name)\nE       TypeError: PantherCollection.update_many() got an unexpected keyword argument 'first_name'\n\nrepos\\pantherdb\\tests\\test_normal.py:615: TypeError"", ""self = <tests.test_normal.TestNormalPantherDB testMethod=test_update_one_single_document_not_found>\n\n    def test_update_one_single_document_not_found(self):\n        collection = self.db.collection(f.word())\n    \n        # Add others\n        _count = self.create_junk_document(collection)\n    \n        # Insert with specific name\n        first_name = f.first_name()\n        collection.insert_one(first_name=first_name, last_name=f.last_name())\n    \n        # Update One\n        new_name = f.first_name()\n        is_updated = collection.update_one({'first_name': f.first_name()}, first_name=new_name)\n        assert is_updated is False\n    \n        # Find with old name\n        old_obj = collection.find_one(first_name=first_name)\n        assert old_obj is not None\n    \n        # Find with new name\n        obj = collection.find_one(first_name=new_name)\n>       assert obj is None\nE       assert right(first_name=Crystal, last_name=Jimenez, _id=01JRT9FC65BHA8TCB0EVNYSK2D) is None\n\nrepos\\pantherdb\\tests\\test_normal.py:598: AssertionError""]",pantherdb/update_many,LLM
python-pathspec,normalize_file,"def normalize_file(file: StrPath, separators: Optional[Collection[str]]=None) -> str:
    """"""
	Normalizes the file path to use the POSIX path separator (i.e.,
	``""/""``), and make the paths relative (remove leading ``""/""``).

	*file* (:class:`str` or :class:`os.PathLike`) is the file path.

	*separators* (:class:`~collections.abc.Collection` of :class:`str`; or
	``None``) optionally contains the path separators to normalize.
	This does not need to include the POSIX path separator (``""/""``),
	but including it will not affect the results. Default is ``None``
	for ``NORMALIZE_PATH_SEPS``. To prevent normalization, pass an
	empty container (e.g., an empty tuple ``()``).

	Returns the normalized file path (:class:`str`).
	""""""
    if separators is None:
        separators = NORMALIZE_PATH_SEPS
    norm_file: str = os.fspath(file)
    for sep in separators:
        norm_file = norm_file.replace(sep, posixpath.sep)
    if norm_file.startswith('/'):
        norm_file = norm_file[1:]
    elif norm_file.startswith('./'):
        norm_file = norm_file[2:]
    return norm_file","The goal of the function `normalize_file` is to normalize a given file path by using the POSIX path separator (""/"") and making the path relative (removing any leading ""/""). The function allows for optional customization of the path separators to be normalized, but by default it uses the standard path separators. This function is useful for ensuring consistency in file path representations across different platforms or systems.",1,"def normalize_file(file, separators=None):
    if separators is None:
        separators = ""/""
    
    if file.startswith(""/""):
        file = file[1:]
    
    for separator in separators:
        file = file.replace(separator, ""/"")
    
    return file",['./repos/python-pathspec\\tests'],"108 Passed, 4 Failed",108,4,"['tests/test_01_util.py::NormalizeFileTest::test_01_purepath', 'tests/test_03_pathspec.py::PathSpecTest::test_05_match_entries', 'tests/test_03_pathspec.py::PathSpecTest::test_05_match_tree_entries', 'tests/test_03_pathspec.py::PathSpecTest::test_05_match_tree_files']","['self = <tests.test_01_util.NormalizeFileTest testMethod=test_01_purepath>\n\n    def test_01_purepath(self):\n    \t""""""\n    \tTests normalizing a :class:`pathlib.PurePath` as argument.\n    \t""""""\n>   \tfirst_spec = normalize_file(pathlib.PurePath(\'a.txt\'))\n\nrepos\\python-pathspec\\tests\\test_01_util.py:501: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfile = PureWindowsPath(\'a.txt\'), separators = \'/\'\n\n    def normalize_file(file, separators=None):\n        if separators is None:\n            separators = \'/\'\n>       if file.startswith(\'/\'):\nE       AttributeError: \'PureWindowsPath\' object has no attribute \'startswith\'\n\nrepos\\python-pathspec\\pathspec\\util.py:296: AttributeError', 'self = <tests.test_03_pathspec.PathSpecTest testMethod=test_05_match_entries>\n\n    def test_05_match_entries(self):\n    \t""""""\n    \tTest matching files collectively.\n    \t""""""\n    \tspec = PathSpec.from_lines(\'gitwildmatch\', [\n    \t\t\'*.txt\',\n    \t\t\'!b.txt\',\n    \t])\n    \tself.make_dirs([\n    \t\t\'X\',\n    \t\t\'X/Z\',\n    \t\t\'Y\',\n    \t\t\'Y/Z\',\n    \t])\n    \tself.make_files([\n    \t\t\'X/a.txt\',\n    \t\t\'X/b.txt\',\n    \t\t\'X/Z/c.txt\',\n    \t\t\'Y/a.txt\',\n    \t\t\'Y/b.txt\',\n    \t\t\'Y/Z/c.txt\',\n    \t])\n    \n    \tentries = iter_tree_entries(self.temp_dir)\n    \tincludes = {\n    \t\t__entry.path for __entry in spec.match_entries(entries)\n    \t}\n    \n>   \tself.assertEqual(includes, set(map(ospath, [\n    \t\t\'X/a.txt\',\n    \t\t\'X/Z/c.txt\',\n    \t\t\'Y/a.txt\',\n    \t\t\'Y/Z/c.txt\',\n    \t])))\nE    AssertionError: Items in the first set but not the second:\nE    \'X\\\\b.txt\'\nE    \'Y\\\\b.txt\'\n\nrepos\\python-pathspec\\tests\\test_03_pathspec.py:503: AssertionError', 'self = <tests.test_03_pathspec.PathSpecTest testMethod=test_05_match_tree_entries>\n\n    def test_05_match_tree_entries(self):\n    \t""""""\n    \tTest matching a file tree.\n    \t""""""\n    \tspec = PathSpec.from_lines(\'gitwildmatch\', [\n    \t\t\'*.txt\',\n    \t\t\'!b.txt\',\n    \t])\n    \tself.make_dirs([\n    \t\t\'X\',\n    \t\t\'X/Z\',\n    \t\t\'Y\',\n    \t\t\'Y/Z\',\n    \t])\n    \tself.make_files([\n    \t\t\'X/a.txt\',\n    \t\t\'X/b.txt\',\n    \t\t\'X/Z/c.txt\',\n    \t\t\'Y/a.txt\',\n    \t\t\'Y/b.txt\',\n    \t\t\'Y/Z/c.txt\',\n    \t])\n    \n    \tincludes = {\n    \t\t__entry.path for __entry in spec.match_tree_entries(self.temp_dir)\n    \t}\n    \n>   \tself.assertEqual(includes, set(map(ospath, [\n    \t\t\'X/a.txt\',\n    \t\t\'X/Z/c.txt\',\n    \t\t\'Y/a.txt\',\n    \t\t\'Y/Z/c.txt\',\n    \t])))\nE    AssertionError: Items in the first set but not the second:\nE    \'X\\\\b.txt\'\nE    \'Y\\\\b.txt\'\n\nrepos\\python-pathspec\\tests\\test_03_pathspec.py:589: AssertionError', 'self = <tests.test_03_pathspec.PathSpecTest testMethod=test_05_match_tree_files>\n\n    def test_05_match_tree_files(self):\n    \t""""""\n    \tTest matching a file tree.\n    \t""""""\n    \tspec = PathSpec.from_lines(\'gitwildmatch\', [\n    \t\t\'*.txt\',\n    \t\t\'!b.txt\',\n    \t])\n    \tself.make_dirs([\n    \t\t\'X\',\n    \t\t\'X/Z\',\n    \t\t\'Y\',\n    \t\t\'Y/Z\',\n    \t])\n    \tself.make_files([\n    \t\t\'X/a.txt\',\n    \t\t\'X/b.txt\',\n    \t\t\'X/Z/c.txt\',\n    \t\t\'Y/a.txt\',\n    \t\t\'Y/b.txt\',\n    \t\t\'Y/Z/c.txt\',\n    \t])\n    \n    \tincludes = set(spec.match_tree_files(self.temp_dir))\n    \n>   \tself.assertEqual(includes, set(map(ospath, [\n    \t\t\'X/a.txt\',\n    \t\t\'X/Z/c.txt\',\n    \t\t\'Y/a.txt\',\n    \t\t\'Y/Z/c.txt\',\n    \t])))\nE    AssertionError: Items in the first set but not the second:\nE    \'X\\\\b.txt\'\nE    \'Y\\\\b.txt\'\n\nrepos\\python-pathspec\\tests\\test_03_pathspec.py:621: AssertionError']",python-pathspec/normalize_file,LLM
python-pathspec,normalize_file,"def normalize_file(file: StrPath, separators: Optional[Collection[str]]=None) -> str:
    """"""
	Normalizes the file path to use the POSIX path separator (i.e.,
	``""/""``), and make the paths relative (remove leading ``""/""``).

	*file* (:class:`str` or :class:`os.PathLike`) is the file path.

	*separators* (:class:`~collections.abc.Collection` of :class:`str`; or
	``None``) optionally contains the path separators to normalize.
	This does not need to include the POSIX path separator (``""/""``),
	but including it will not affect the results. Default is ``None``
	for ``NORMALIZE_PATH_SEPS``. To prevent normalization, pass an
	empty container (e.g., an empty tuple ``()``).

	Returns the normalized file path (:class:`str`).
	""""""
    if separators is None:
        separators = NORMALIZE_PATH_SEPS
    norm_file: str = os.fspath(file)
    for sep in separators:
        norm_file = norm_file.replace(sep, posixpath.sep)
    if norm_file.startswith('/'):
        norm_file = norm_file[1:]
    elif norm_file.startswith('./'):
        norm_file = norm_file[2:]
    return norm_file","The goal of the function `normalize_file` is to normalize a given file path by using the POSIX path separator (""/"") and making the path relative (removing any leading ""/""). The function allows for optional customization of the path separators to be normalized, but by default it uses the standard path separators. This function is useful for ensuring consistency in file path representations across different platforms or systems.",2,"def normalize_file(file, separators=None):
    if separators is None:
        separators = ""/""
    
    normalized_file = file.lstrip(""/"")
    normalized_file = normalized_file.replace(""\\"", separators)
    
    return normalized_file",['./repos/python-pathspec\\tests'],"109 Passed, 3 Failed",109,3,"['tests/test_01_util.py::NormalizeFileTest::test_01_purepath', 'tests/test_03_pathspec.py::PathSpecTest::test_01_windows_current_dir_paths', 'tests/test_03_pathspec.py::PathSpecTest::test_01_windows_paths']","['self = <tests.test_01_util.NormalizeFileTest testMethod=test_01_purepath>\n\n    def test_01_purepath(self):\n    \t""""""\n    \tTests normalizing a :class:`pathlib.PurePath` as argument.\n    \t""""""\n>   \tfirst_spec = normalize_file(pathlib.PurePath(\'a.txt\'))\n\nrepos\\python-pathspec\\tests\\test_01_util.py:501: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfile = PureWindowsPath(\'a.txt\'), separators = \'/\'\n\n    def normalize_file(file, separators=None):\n        if separators is None:\n            separators = \'/\'\n>       normalized_file = file.lstrip(\'/\')\nE       AttributeError: \'PureWindowsPath\' object has no attribute \'lstrip\'\n\nrepos\\python-pathspec\\pathspec\\util.py:296: AttributeError', 'self = <tests.test_03_pathspec.PathSpecTest testMethod=test_01_windows_current_dir_paths>\n\n    def test_01_windows_current_dir_paths(self):\n    \t""""""\n    \tTests that paths referencing the current directory will be properly\n    \tnormalized and matched.\n    \t""""""\n    \tspec = PathSpec.from_lines(\'gitwildmatch\', [\n    \t\t\'*.txt\',\n    \t\t\'!test1/\',\n    \t])\n    \tfiles = {\n    \t\t\'.\\\\test1\\\\a.txt\',\n    \t\t\'.\\\\test1\\\\b.txt\',\n    \t\t\'.\\\\test1\\\\c\\\\c.txt\',\n    \t\t\'.\\\\test2\\\\a.txt\',\n    \t\t\'.\\\\test2\\\\b.txt\',\n    \t\t\'.\\\\test2\\\\c\\\\c.txt\',\n    \t}\n    \n>   \tresults = list(spec.check_files(files, separators=[\'\\\\\']))\n\nrepos\\python-pathspec\\tests\\test_03_pathspec.py:341: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\python-pathspec\\pathspec\\pathspec.py:145: in check_files\n    norm_file = normalize_file(orig_file, separators)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfile = \'.\\\\test2\\\\b.txt\', separators = [\'\\\\\']\n\n    def normalize_file(file, separators=None):\n        if separators is None:\n            separators = \'/\'\n        normalized_file = file.lstrip(\'/\')\n>       normalized_file = normalized_file.replace(\'\\\\\', separators)\nE       TypeError: replace() argument 2 must be str, not list\n\nrepos\\python-pathspec\\pathspec\\util.py:297: TypeError', 'self = <tests.test_03_pathspec.PathSpecTest testMethod=test_01_windows_paths>\n\n    def test_01_windows_paths(self):\n    \t""""""\n    \tTests that Windows paths will be properly normalized and matched.\n    \t""""""\n    \tspec = PathSpec.from_lines(\'gitwildmatch\', [\n    \t\t\'*.txt\',\n    \t\t\'!test1/\',\n    \t])\n    \tfiles = {\n    \t\t\'test1\\\\a.txt\',\n    \t\t\'test1\\\\b.txt\',\n    \t\t\'test1\\\\c\\\\c.txt\',\n    \t\t\'test2\\\\a.txt\',\n    \t\t\'test2\\\\b.txt\',\n    \t\t\'test2\\\\c\\\\c.txt\',\n    \t}\n    \n>   \tresults = list(spec.check_files(files, separators=[\'\\\\\']))\n\nrepos\\python-pathspec\\tests\\test_03_pathspec.py:368: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\python-pathspec\\pathspec\\pathspec.py:145: in check_files\n    norm_file = normalize_file(orig_file, separators)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfile = \'test2\\\\c\\\\c.txt\', separators = [\'\\\\\']\n\n    def normalize_file(file, separators=None):\n        if separators is None:\n            separators = \'/\'\n        normalized_file = file.lstrip(\'/\')\n>       normalized_file = normalized_file.replace(\'\\\\\', separators)\nE       TypeError: replace() argument 2 must be str, not list\n\nrepos\\python-pathspec\\pathspec\\util.py:297: TypeError']",python-pathspec/normalize_file,LLM
python-pathspec,normalize_file,"def normalize_file(file: StrPath, separators: Optional[Collection[str]]=None) -> str:
    """"""
	Normalizes the file path to use the POSIX path separator (i.e.,
	``""/""``), and make the paths relative (remove leading ``""/""``).

	*file* (:class:`str` or :class:`os.PathLike`) is the file path.

	*separators* (:class:`~collections.abc.Collection` of :class:`str`; or
	``None``) optionally contains the path separators to normalize.
	This does not need to include the POSIX path separator (``""/""``),
	but including it will not affect the results. Default is ``None``
	for ``NORMALIZE_PATH_SEPS``. To prevent normalization, pass an
	empty container (e.g., an empty tuple ``()``).

	Returns the normalized file path (:class:`str`).
	""""""
    if separators is None:
        separators = NORMALIZE_PATH_SEPS
    norm_file: str = os.fspath(file)
    for sep in separators:
        norm_file = norm_file.replace(sep, posixpath.sep)
    if norm_file.startswith('/'):
        norm_file = norm_file[1:]
    elif norm_file.startswith('./'):
        norm_file = norm_file[2:]
    return norm_file","The goal of the function `normalize_file` is to normalize a given file path by using the POSIX path separator (""/"") and making the path relative (removing any leading ""/""). The function allows for optional customization of the path separators to be normalized, but by default it uses the standard path separators. This function is useful for ensuring consistency in file path representations across different platforms or systems.",3,"def normalize_file(file, separators='/'):
    if file.startswith(separators):
        file = file.lstrip(separators)
    file = file.replace('\\', separators).replace('//', separators)
    return file",['./repos/python-pathspec\\tests'],"65 Passed, 47 Failed",65,47,"['tests/test_01_util.py::NormalizeFileTest::test_01_purepath', 'tests/test_03_pathspec.py::PathSpecTest::test_01_absolute_dir_paths_1', 'tests/test_03_pathspec.py::PathSpecTest::test_01_absolute_dir_paths_2', 'tests/test_03_pathspec.py::PathSpecTest::test_01_check_file_1_include', 'tests/test_03_pathspec.py::PathSpecTest::test_01_check_file_2_exclude', 'tests/test_03_pathspec.py::PathSpecTest::test_01_check_file_3_unmatch', 'tests/test_03_pathspec.py::PathSpecTest::test_01_check_file_4_many', 'tests/test_03_pathspec.py::PathSpecTest::test_01_check_match_files', 'tests/test_03_pathspec.py::PathSpecTest::test_01_current_dir_paths', 'tests/test_03_pathspec.py::PathSpecTest::test_01_empty_path_1', 'tests/test_03_pathspec.py::PathSpecTest::test_01_match_file_1_include', 'tests/test_03_pathspec.py::PathSpecTest::test_01_match_file_2_exclude', 'tests/test_03_pathspec.py::PathSpecTest::test_01_match_file_3_unmatch', 'tests/test_03_pathspec.py::PathSpecTest::test_01_match_files', 'tests/test_03_pathspec.py::PathSpecTest::test_01_windows_current_dir_paths', 'tests/test_03_pathspec.py::PathSpecTest::test_01_windows_paths', 'tests/test_03_pathspec.py::PathSpecTest::test_03_add', 'tests/test_03_pathspec.py::PathSpecTest::test_03_iadd', 'tests/test_03_pathspec.py::PathSpecTest::test_05_match_entries', 'tests/test_03_pathspec.py::PathSpecTest::test_05_match_file', 'tests/test_03_pathspec.py::PathSpecTest::test_05_match_files', 'tests/test_03_pathspec.py::PathSpecTest::test_05_match_tree_entries', 'tests/test_03_pathspec.py::PathSpecTest::test_05_match_tree_files', 'tests/test_03_pathspec.py::PathSpecTest::test_06_issue_41_a', 'tests/test_03_pathspec.py::PathSpecTest::test_06_issue_41_b', 'tests/test_03_pathspec.py::PathSpecTest::test_06_issue_41_c', 'tests/test_03_pathspec.py::PathSpecTest::test_07_issue_62', 'tests/test_03_pathspec.py::PathSpecTest::test_08_issue_39', 'tests/test_03_pathspec.py::PathSpecTest::test_09_issue_80_a', 'tests/test_03_pathspec.py::PathSpecTest::test_09_issue_80_b', 'tests/test_04_gitignore.py::GitIgnoreSpecTest::test_01_reversed_args', 'tests/test_04_gitignore.py::GitIgnoreSpecTest::test_02_dir_exclusions', 'tests/test_04_gitignore.py::GitIgnoreSpecTest::test_02_file_exclusions', 'tests/test_04_gitignore.py::GitIgnoreSpecTest::test_02_issue_41_a', 'tests/test_04_gitignore.py::GitIgnoreSpecTest::test_02_issue_41_b', 'tests/test_04_gitignore.py::GitIgnoreSpecTest::test_02_issue_41_c', 'tests/test_04_gitignore.py::GitIgnoreSpecTest::test_03_issue_19_a', 'tests/test_04_gitignore.py::GitIgnoreSpecTest::test_03_issue_19_b', 'tests/test_04_gitignore.py::GitIgnoreSpecTest::test_03_issue_19_c', 'tests/test_04_gitignore.py::GitIgnoreSpecTest::test_03_subdir', 'tests/test_04_gitignore.py::GitIgnoreSpecTest::test_04_issue_62', 'tests/test_04_gitignore.py::GitIgnoreSpecTest::test_05_issue_39', 'tests/test_04_gitignore.py::GitIgnoreSpecTest::test_06_issue_64', 'tests/test_04_gitignore.py::GitIgnoreSpecTest::test_07_issue_74', 'tests/test_04_gitignore.py::GitIgnoreSpecTest::test_08_issue_81_a', 'tests/test_04_gitignore.py::GitIgnoreSpecTest::test_08_issue_81_b', 'tests/test_04_gitignore.py::GitIgnoreSpecTest::test_08_issue_81_c']","['self = <tests.test_01_util.NormalizeFileTest testMethod=test_01_purepath>\n\n    def test_01_purepath(self):\n    \t""""""\n    \tTests normalizing a :class:`pathlib.PurePath` as argument.\n    \t""""""\n>   \tfirst_spec = normalize_file(pathlib.PurePath(\'a.txt\'))\n\nrepos\\python-pathspec\\tests\\test_01_util.py:501: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfile = PureWindowsPath(\'a.txt\'), separators = \'/\'\n\n    def normalize_file(file, separators=\'/\'):\n>       if file.startswith(separators):\nE       AttributeError: \'PureWindowsPath\' object has no attribute \'startswith\'\n\nrepos\\python-pathspec\\pathspec\\util.py:294: AttributeError', 'self = <tests.test_03_pathspec.PathSpecTest testMethod=test_01_absolute_dir_paths_1>\n\n    def test_01_absolute_dir_paths_1(self):\n    \t""""""\n    \tTests that absolute paths will be properly normalized and matched.\n    \t""""""\n    \tspec = PathSpec.from_lines(\'gitwildmatch\', [\n    \t\t\'foo\',\n    \t])\n    \tfiles = {\n    \t\t\'/a.py\',\n    \t\t\'/foo/a.py\',\n    \t\t\'/x/a.py\',\n    \t\t\'/x/foo/a.py\',\n    \t\t\'a.py\',\n    \t\t\'foo/a.py\',\n    \t\t\'x/a.py\',\n    \t\t\'x/foo/a.py\',\n    \t}\n    \n>   \tresults = list(spec.check_files(files))\n\nrepos\\python-pathspec\\tests\\test_03_pathspec.py:75: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\python-pathspec\\pathspec\\pathspec.py:145: in check_files\n    norm_file = normalize_file(orig_file, separators)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfile = \'foo/a.py\', separators = None\n\n    def normalize_file(file, separators=\'/\'):\n>       if file.startswith(separators):\nE       TypeError: startswith first arg must be str or a tuple of str, not NoneType\n\nrepos\\python-pathspec\\pathspec\\util.py:294: TypeError', 'self = <tests.test_03_pathspec.PathSpecTest testMethod=test_01_absolute_dir_paths_2>\n\n    def test_01_absolute_dir_paths_2(self):\n    \t""""""\n    \tTests that absolute paths will be properly normalized and matched.\n    \t""""""\n    \tspec = PathSpec.from_lines(\'gitwildmatch\', [\n    \t\t\'/foo\',\n    \t])\n    \tfiles = {\n    \t\t\'/a.py\',\n    \t\t\'/foo/a.py\',\n    \t\t\'/x/a.py\',\n    \t\t\'/x/foo/a.py\',\n    \t\t\'a.py\',\n    \t\t\'foo/a.py\',\n    \t\t\'x/a.py\',\n    \t\t\'x/foo/a.py\',\n    \t}\n    \n>   \tresults = list(spec.check_files(files))\n\nrepos\\python-pathspec\\tests\\test_03_pathspec.py:104: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\python-pathspec\\pathspec\\pathspec.py:145: in check_files\n    norm_file = normalize_file(orig_file, separators)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfile = \'foo/a.py\', separators = None\n\n    def normalize_file(file, separators=\'/\'):\n>       if file.startswith(separators):\nE       TypeError: startswith first arg must be str or a tuple of str, not NoneType\n\nrepos\\python-pathspec\\pathspec\\util.py:294: TypeError', 'self = <tests.test_03_pathspec.PathSpecTest testMethod=test_01_check_file_1_include>\n\n    def test_01_check_file_1_include(self):\n    \t""""""\n    \tTest checking a single file that is included.\n    \t""""""\n    \tspec = PathSpec.from_lines(\'gitwildmatch\', [\n    \t\t""*.txt"",\n    \t\t""!test/"",\n    \t])\n    \n>   \tresult = spec.check_file(""include.txt"")\n\nrepos\\python-pathspec\\tests\\test_03_pathspec.py:122: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\python-pathspec\\pathspec\\pathspec.py:117: in check_file\n    norm_file = normalize_file(file, separators)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfile = \'include.txt\', separators = None\n\n    def normalize_file(file, separators=\'/\'):\n>       if file.startswith(separators):\nE       TypeError: startswith first arg must be str or a tuple of str, not NoneType\n\nrepos\\python-pathspec\\pathspec\\util.py:294: TypeError', 'self = <tests.test_03_pathspec.PathSpecTest testMethod=test_01_check_file_2_exclude>\n\n    def test_01_check_file_2_exclude(self):\n    \t""""""\n    \tTest checking a single file that is excluded.\n    \t""""""\n    \tspec = PathSpec.from_lines(\'gitwildmatch\', [\n    \t\t""*.txt"",\n    \t\t""!test/"",\n    \t])\n    \n>   \tresult = spec.check_file(""test/exclude.txt"")\n\nrepos\\python-pathspec\\tests\\test_03_pathspec.py:135: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\python-pathspec\\pathspec\\pathspec.py:117: in check_file\n    norm_file = normalize_file(file, separators)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfile = \'test/exclude.txt\', separators = None\n\n    def normalize_file(file, separators=\'/\'):\n>       if file.startswith(separators):\nE       TypeError: startswith first arg must be str or a tuple of str, not NoneType\n\nrepos\\python-pathspec\\pathspec\\util.py:294: TypeError', 'self = <tests.test_03_pathspec.PathSpecTest testMethod=test_01_check_file_3_unmatch>\n\n    def test_01_check_file_3_unmatch(self):\n    \t""""""\n    \tTest checking a single file that is unmatched.\n    \t""""""\n    \tspec = PathSpec.from_lines(\'gitwildmatch\', [\n    \t\t""*.txt"",\n    \t\t""!test/"",\n    \t])\n    \n>   \tresult = spec.check_file(""unmatch.bin"")\n\nrepos\\python-pathspec\\tests\\test_03_pathspec.py:148: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\python-pathspec\\pathspec\\pathspec.py:117: in check_file\n    norm_file = normalize_file(file, separators)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfile = \'unmatch.bin\', separators = None\n\n    def normalize_file(file, separators=\'/\'):\n>       if file.startswith(separators):\nE       TypeError: startswith first arg must be str or a tuple of str, not NoneType\n\nrepos\\python-pathspec\\pathspec\\util.py:294: TypeError', 'self = <tests.test_03_pathspec.PathSpecTest testMethod=test_01_check_file_4_many>\n\n    def test_01_check_file_4_many(self):\n    \t""""""\n    \tTest that checking files one at a time yields the same results as checking\n    \tmultiples files at once.\n    \t""""""\n    \tspec = PathSpec.from_lines(\'gitwildmatch\', [\n    \t\t\'*.txt\',\n    \t\t\'!test1/\',\n    \t])\n    \tfiles = {\n    \t\t\'test1/a.txt\',\n    \t\t\'test1/b.txt\',\n    \t\t\'test1/c/c.txt\',\n    \t\t\'test2/a.txt\',\n    \t\t\'test2/b.txt\',\n    \t\t\'test2/c/c.txt\',\n    \t}\n    \n>   \tsingle_results = set(map(spec.check_file, files))\n\nrepos\\python-pathspec\\tests\\test_03_pathspec.py:170: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\python-pathspec\\pathspec\\pathspec.py:117: in check_file\n    norm_file = normalize_file(file, separators)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfile = \'test1/a.txt\', separators = None\n\n    def normalize_file(file, separators=\'/\'):\n>       if file.startswith(separators):\nE       TypeError: startswith first arg must be str or a tuple of str, not NoneType\n\nrepos\\python-pathspec\\pathspec\\util.py:294: TypeError', 'self = <tests.test_03_pathspec.PathSpecTest testMethod=test_01_check_match_files>\n\n    def test_01_check_match_files(self):\n    \t""""""\n    \tTest that checking files and matching files yield the same results.\n    \t""""""\n    \tspec = PathSpec.from_lines(\'gitwildmatch\', [\n    \t\t\'*.txt\',\n    \t\t\'!test1/**\',\n    \t])\n    \tfiles = {\n    \t\t\'src/test1/a.txt\',\n    \t\t\'src/test1/b.txt\',\n    \t\t\'src/test1/c/c.txt\',\n    \t\t\'src/test2/a.txt\',\n    \t\t\'src/test2/b.txt\',\n    \t\t\'src/test2/c/c.txt\',\n    \t}\n    \n>   \tcheck_results = set(spec.check_files(files))\n\nrepos\\python-pathspec\\tests\\test_03_pathspec.py:192: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\python-pathspec\\pathspec\\pathspec.py:145: in check_files\n    norm_file = normalize_file(orig_file, separators)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfile = \'src/test2/c/c.txt\', separators = None\n\n    def normalize_file(file, separators=\'/\'):\n>       if file.startswith(separators):\nE       TypeError: startswith first arg must be str or a tuple of str, not NoneType\n\nrepos\\python-pathspec\\pathspec\\util.py:294: TypeError', 'self = <tests.test_03_pathspec.PathSpecTest testMethod=test_01_current_dir_paths>\n\n    def test_01_current_dir_paths(self):\n    \t""""""\n    \tTests that paths referencing the current directory will be properly\n    \tnormalized and matched.\n    \t""""""\n    \tspec = PathSpec.from_lines(\'gitwildmatch\', [\n    \t\t\'*.txt\',\n    \t\t\'!test1/\',\n    \t])\n    \tfiles = {\n    \t\t\'./src/test1/a.txt\',\n    \t\t\'./src/test1/b.txt\',\n    \t\t\'./src/test1/c/c.txt\',\n    \t\t\'./src/test2/a.txt\',\n    \t\t\'./src/test2/b.txt\',\n    \t\t\'./src/test2/c/c.txt\',\n    \t}\n    \n>   \tresults = list(spec.check_files(files))\n\nrepos\\python-pathspec\\tests\\test_03_pathspec.py:216: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\python-pathspec\\pathspec\\pathspec.py:145: in check_files\n    norm_file = normalize_file(orig_file, separators)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfile = \'./src/test1/a.txt\', separators = None\n\n    def normalize_file(file, separators=\'/\'):\n>       if file.startswith(separators):\nE       TypeError: startswith first arg must be str or a tuple of str, not NoneType\n\nrepos\\python-pathspec\\pathspec\\util.py:294: TypeError', 'self = <tests.test_03_pathspec.PathSpecTest testMethod=test_01_empty_path_1>\n\n    def test_01_empty_path_1(self):\n    \t""""""\n    \tTests that patterns that end with an escaped space will be treated properly.\n    \t""""""\n    \tspec = PathSpec.from_lines(\'gitwildmatch\', [\n    \t\t\'\\\\ \',\n    \t\t\'abc\\\\ \'\n    \t])\n    \tfiles = {\n    \t\t\' \',\n    \t\t\'  \',\n    \t\t\'abc \',\n    \t\t\'somefile\',\n    \t}\n    \n>   \tresults = list(spec.check_files(files))\n\nrepos\\python-pathspec\\tests\\test_03_pathspec.py:241: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\python-pathspec\\pathspec\\pathspec.py:145: in check_files\n    norm_file = normalize_file(orig_file, separators)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfile = \' \', separators = None\n\n    def normalize_file(file, separators=\'/\'):\n>       if file.startswith(separators):\nE       TypeError: startswith first arg must be str or a tuple of str, not NoneType\n\nrepos\\python-pathspec\\pathspec\\util.py:294: TypeError', 'self = <tests.test_03_pathspec.PathSpecTest testMethod=test_01_match_file_1_include>\n\n    def test_01_match_file_1_include(self):\n    \t""""""\n    \tTest matching a single file that is included.\n    \t""""""\n    \tspec = PathSpec.from_lines(\'gitwildmatch\', [\n    \t\t""*.txt"",\n    \t\t""!test/"",\n    \t])\n    \n>   \tinclude = spec.match_file(""include.txt"")\n\nrepos\\python-pathspec\\tests\\test_03_pathspec.py:270: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\python-pathspec\\pathspec\\pathspec.py:278: in match_file\n    norm_file = normalize_file(file, separators)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfile = \'include.txt\', separators = None\n\n    def normalize_file(file, separators=\'/\'):\n>       if file.startswith(separators):\nE       TypeError: startswith first arg must be str or a tuple of str, not NoneType\n\nrepos\\python-pathspec\\pathspec\\util.py:294: TypeError', 'self = <tests.test_03_pathspec.PathSpecTest testMethod=test_01_match_file_2_exclude>\n\n    def test_01_match_file_2_exclude(self):\n    \t""""""\n    \tTest matching a single file that is excluded.\n    \t""""""\n    \tspec = PathSpec.from_lines(\'gitwildmatch\', [\n    \t\t""*.txt"",\n    \t\t""!test/"",\n    \t])\n    \n>   \tinclude = spec.match_file(""test/exclude.txt"")\n\nrepos\\python-pathspec\\tests\\test_03_pathspec.py:283: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\python-pathspec\\pathspec\\pathspec.py:278: in match_file\n    norm_file = normalize_file(file, separators)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfile = \'test/exclude.txt\', separators = None\n\n    def normalize_file(file, separators=\'/\'):\n>       if file.startswith(separators):\nE       TypeError: startswith first arg must be str or a tuple of str, not NoneType\n\nrepos\\python-pathspec\\pathspec\\util.py:294: TypeError', 'self = <tests.test_03_pathspec.PathSpecTest testMethod=test_01_match_file_3_unmatch>\n\n    def test_01_match_file_3_unmatch(self):\n    \t""""""\n    \tTest match a single file that is unmatched.\n    \t""""""\n    \tspec = PathSpec.from_lines(\'gitwildmatch\', [\n    \t\t""*.txt"",\n    \t\t""!test/"",\n    \t])\n    \n>   \tinclude = spec.match_file(""unmatch.bin"")\n\nrepos\\python-pathspec\\tests\\test_03_pathspec.py:296: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\python-pathspec\\pathspec\\pathspec.py:278: in match_file\n    norm_file = normalize_file(file, separators)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfile = \'unmatch.bin\', separators = None\n\n    def normalize_file(file, separators=\'/\'):\n>       if file.startswith(separators):\nE       TypeError: startswith first arg must be str or a tuple of str, not NoneType\n\nrepos\\python-pathspec\\pathspec\\util.py:294: TypeError', 'self = <tests.test_03_pathspec.PathSpecTest testMethod=test_01_match_files>\n\n    def test_01_match_files(self):\n    \t""""""\n    \tTest that matching files one at a time yields the same results as matching\n    \tmultiples files at once.\n    \t""""""\n    \tspec = PathSpec.from_lines(\'gitwildmatch\', [\n    \t\t\'*.txt\',\n    \t\t\'!test1/\',\n    \t])\n    \tfiles = {\n    \t\t\'test1/a.txt\',\n    \t\t\'test1/b.txt\',\n    \t\t\'test1/c/c.txt\',\n    \t\t\'test2/a.txt\',\n    \t\t\'test2/b.txt\',\n    \t\t\'test2/c/c.txt\',\n    \t}\n    \n>   \tsingle_files = set(filter(spec.match_file, files))\n\nrepos\\python-pathspec\\tests\\test_03_pathspec.py:318: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\python-pathspec\\pathspec\\pathspec.py:278: in match_file\n    norm_file = normalize_file(file, separators)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfile = \'test1/a.txt\', separators = None\n\n    def normalize_file(file, separators=\'/\'):\n>       if file.startswith(separators):\nE       TypeError: startswith first arg must be str or a tuple of str, not NoneType\n\nrepos\\python-pathspec\\pathspec\\util.py:294: TypeError', 'self = <tests.test_03_pathspec.PathSpecTest testMethod=test_01_windows_current_dir_paths>\n\n    def test_01_windows_current_dir_paths(self):\n    \t""""""\n    \tTests that paths referencing the current directory will be properly\n    \tnormalized and matched.\n    \t""""""\n    \tspec = PathSpec.from_lines(\'gitwildmatch\', [\n    \t\t\'*.txt\',\n    \t\t\'!test1/\',\n    \t])\n    \tfiles = {\n    \t\t\'.\\\\test1\\\\a.txt\',\n    \t\t\'.\\\\test1\\\\b.txt\',\n    \t\t\'.\\\\test1\\\\c\\\\c.txt\',\n    \t\t\'.\\\\test2\\\\a.txt\',\n    \t\t\'.\\\\test2\\\\b.txt\',\n    \t\t\'.\\\\test2\\\\c\\\\c.txt\',\n    \t}\n    \n>   \tresults = list(spec.check_files(files, separators=[\'\\\\\']))\n\nrepos\\python-pathspec\\tests\\test_03_pathspec.py:341: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\python-pathspec\\pathspec\\pathspec.py:145: in check_files\n    norm_file = normalize_file(orig_file, separators)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfile = \'.\\\\test2\\\\c\\\\c.txt\', separators = [\'\\\\\']\n\n    def normalize_file(file, separators=\'/\'):\n>       if file.startswith(separators):\nE       TypeError: startswith first arg must be str or a tuple of str, not list\n\nrepos\\python-pathspec\\pathspec\\util.py:294: TypeError', 'self = <tests.test_03_pathspec.PathSpecTest testMethod=test_01_windows_paths>\n\n    def test_01_windows_paths(self):\n    \t""""""\n    \tTests that Windows paths will be properly normalized and matched.\n    \t""""""\n    \tspec = PathSpec.from_lines(\'gitwildmatch\', [\n    \t\t\'*.txt\',\n    \t\t\'!test1/\',\n    \t])\n    \tfiles = {\n    \t\t\'test1\\\\a.txt\',\n    \t\t\'test1\\\\b.txt\',\n    \t\t\'test1\\\\c\\\\c.txt\',\n    \t\t\'test2\\\\a.txt\',\n    \t\t\'test2\\\\b.txt\',\n    \t\t\'test2\\\\c\\\\c.txt\',\n    \t}\n    \n>   \tresults = list(spec.check_files(files, separators=[\'\\\\\']))\n\nrepos\\python-pathspec\\tests\\test_03_pathspec.py:368: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\python-pathspec\\pathspec\\pathspec.py:145: in check_files\n    norm_file = normalize_file(orig_file, separators)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfile = \'test1\\\\c\\\\c.txt\', separators = [\'\\\\\']\n\n    def normalize_file(file, separators=\'/\'):\n>       if file.startswith(separators):\nE       TypeError: startswith first arg must be str or a tuple of str, not list\n\nrepos\\python-pathspec\\pathspec\\util.py:294: TypeError', 'self = <tests.test_03_pathspec.PathSpecTest testMethod=test_03_add>\n\n    def test_03_add(self):\n    \t""""""\n    \tTest spec addition using :data:`+` operator.\n    \t""""""\n    \tfirst_spec = PathSpec.from_lines(\'gitwildmatch\', [\n    \t\t\'test.png\',\n    \t\t\'test.txt\',\n    \t])\n    \tsecond_spec = PathSpec.from_lines(\'gitwildmatch\', [\n    \t\t\'test.html\',\n    \t\t\'test.jpg\',\n    \t])\n    \tcombined_spec = first_spec + second_spec\n    \tfiles = {\n    \t\t\'test.html\',\n    \t\t\'test.jpg\',\n    \t\t\'test.png\',\n    \t\t\'test.txt\',\n    \t}\n    \n>   \tresults = list(combined_spec.check_files(files))\n\nrepos\\python-pathspec\\tests\\test_03_pathspec.py:424: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\python-pathspec\\pathspec\\pathspec.py:145: in check_files\n    norm_file = normalize_file(orig_file, separators)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfile = \'test.png\', separators = None\n\n    def normalize_file(file, separators=\'/\'):\n>       if file.startswith(separators):\nE       TypeError: startswith first arg must be str or a tuple of str, not NoneType\n\nrepos\\python-pathspec\\pathspec\\util.py:294: TypeError', 'self = <tests.test_03_pathspec.PathSpecTest testMethod=test_03_iadd>\n\n    def test_03_iadd(self):\n    \t""""""\n    \tTest spec addition using :data:`+=` operator.\n    \t""""""\n    \tspec = PathSpec.from_lines(\'gitwildmatch\', [\n    \t\t\'test.png\',\n    \t\t\'test.txt\',\n    \t])\n    \tspec += PathSpec.from_lines(\'gitwildmatch\', [\n    \t\t\'test.html\',\n    \t\t\'test.jpg\',\n    \t])\n    \tfiles = {\n    \t\t\'test.html\',\n    \t\t\'test.jpg\',\n    \t\t\'test.png\',\n    \t\t\'test.txt\',\n    \t}\n    \n>   \tresults = list(spec.check_files(files))\n\nrepos\\python-pathspec\\tests\\test_03_pathspec.py:454: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\python-pathspec\\pathspec\\pathspec.py:145: in check_files\n    norm_file = normalize_file(orig_file, separators)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfile = \'test.png\', separators = None\n\n    def normalize_file(file, separators=\'/\'):\n>       if file.startswith(separators):\nE       TypeError: startswith first arg must be str or a tuple of str, not NoneType\n\nrepos\\python-pathspec\\pathspec\\util.py:294: TypeError', 'self = <tests.test_03_pathspec.PathSpecTest testMethod=test_05_match_entries>\n\n    def test_05_match_entries(self):\n    \t""""""\n    \tTest matching files collectively.\n    \t""""""\n    \tspec = PathSpec.from_lines(\'gitwildmatch\', [\n    \t\t\'*.txt\',\n    \t\t\'!b.txt\',\n    \t])\n    \tself.make_dirs([\n    \t\t\'X\',\n    \t\t\'X/Z\',\n    \t\t\'Y\',\n    \t\t\'Y/Z\',\n    \t])\n    \tself.make_files([\n    \t\t\'X/a.txt\',\n    \t\t\'X/b.txt\',\n    \t\t\'X/Z/c.txt\',\n    \t\t\'Y/a.txt\',\n    \t\t\'Y/b.txt\',\n    \t\t\'Y/Z/c.txt\',\n    \t])\n    \n    \tentries = iter_tree_entries(self.temp_dir)\n    \tincludes = {\n>   \t\t__entry.path for __entry in spec.match_entries(entries)\n    \t}\n\nrepos\\python-pathspec\\tests\\test_03_pathspec.py:500: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\python-pathspec\\pathspec\\pathspec.py:245: in match_entries\n    norm_file = normalize_file(entry.path, separators)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfile = \'X\', separators = None\n\n    def normalize_file(file, separators=\'/\'):\n>       if file.startswith(separators):\nE       TypeError: startswith first arg must be str or a tuple of str, not NoneType\n\nrepos\\python-pathspec\\pathspec\\util.py:294: TypeError', 'self = <tests.test_03_pathspec.PathSpecTest testMethod=test_05_match_file>\n\n    def test_05_match_file(self):\n    \t""""""\n    \tTest matching files individually.\n    \t""""""\n    \tspec = PathSpec.from_lines(\'gitwildmatch\', [\n    \t\t\'*.txt\',\n    \t\t\'!b.txt\',\n    \t])\n    \tfiles = {\n    \t\t\'X/a.txt\',\n    \t\t\'X/b.txt\',\n    \t\t\'X/Z/c.txt\',\n    \t\t\'Y/a.txt\',\n    \t\t\'Y/b.txt\',\n    \t\t\'Y/Z/c.txt\',\n    \t}\n    \n>   \tincludes = set(filter(spec.match_file, files))\n\nrepos\\python-pathspec\\tests\\test_03_pathspec.py:527: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\python-pathspec\\pathspec\\pathspec.py:278: in match_file\n    norm_file = normalize_file(file, separators)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfile = \'Y/b.txt\', separators = None\n\n    def normalize_file(file, separators=\'/\'):\n>       if file.startswith(separators):\nE       TypeError: startswith first arg must be str or a tuple of str, not NoneType\n\nrepos\\python-pathspec\\pathspec\\util.py:294: TypeError', 'self = <tests.test_03_pathspec.PathSpecTest testMethod=test_05_match_files>\n\n    def test_05_match_files(self):\n    \t""""""\n    \tTest matching files collectively.\n    \t""""""\n    \tspec = PathSpec.from_lines(\'gitwildmatch\', [\n    \t\t\'*.txt\',\n    \t\t\'!b.txt\',\n    \t])\n    \tfiles = {\n    \t\t\'X/a.txt\',\n    \t\t\'X/b.txt\',\n    \t\t\'X/Z/c.txt\',\n    \t\t\'Y/a.txt\',\n    \t\t\'Y/b.txt\',\n    \t\t\'Y/Z/c.txt\',\n    \t}\n    \n>   \tincludes = set(spec.match_files(files))\n\nrepos\\python-pathspec\\tests\\test_03_pathspec.py:553: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\python-pathspec\\pathspec\\pathspec.py:313: in match_files\n    norm_file = normalize_file(orig_file, separators)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfile = \'Y/b.txt\', separators = None\n\n    def normalize_file(file, separators=\'/\'):\n>       if file.startswith(separators):\nE       TypeError: startswith first arg must be str or a tuple of str, not NoneType\n\nrepos\\python-pathspec\\pathspec\\util.py:294: TypeError', 'self = <tests.test_03_pathspec.PathSpecTest testMethod=test_05_match_tree_entries>\n\n    def test_05_match_tree_entries(self):\n    \t""""""\n    \tTest matching a file tree.\n    \t""""""\n    \tspec = PathSpec.from_lines(\'gitwildmatch\', [\n    \t\t\'*.txt\',\n    \t\t\'!b.txt\',\n    \t])\n    \tself.make_dirs([\n    \t\t\'X\',\n    \t\t\'X/Z\',\n    \t\t\'Y\',\n    \t\t\'Y/Z\',\n    \t])\n    \tself.make_files([\n    \t\t\'X/a.txt\',\n    \t\t\'X/b.txt\',\n    \t\t\'X/Z/c.txt\',\n    \t\t\'Y/a.txt\',\n    \t\t\'Y/b.txt\',\n    \t\t\'Y/Z/c.txt\',\n    \t])\n    \n    \tincludes = {\n>   \t\t__entry.path for __entry in spec.match_tree_entries(self.temp_dir)\n    \t}\n\nrepos\\python-pathspec\\tests\\test_03_pathspec.py:586: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\python-pathspec\\pathspec\\pathspec.py:355: in match_tree_entries\n    yield from self.match_entries(entries, negate=negate)\nrepos\\python-pathspec\\pathspec\\pathspec.py:245: in match_entries\n    norm_file = normalize_file(entry.path, separators)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfile = \'X\', separators = None\n\n    def normalize_file(file, separators=\'/\'):\n>       if file.startswith(separators):\nE       TypeError: startswith first arg must be str or a tuple of str, not NoneType\n\nrepos\\python-pathspec\\pathspec\\util.py:294: TypeError', 'self = <tests.test_03_pathspec.PathSpecTest testMethod=test_05_match_tree_files>\n\n    def test_05_match_tree_files(self):\n    \t""""""\n    \tTest matching a file tree.\n    \t""""""\n    \tspec = PathSpec.from_lines(\'gitwildmatch\', [\n    \t\t\'*.txt\',\n    \t\t\'!b.txt\',\n    \t])\n    \tself.make_dirs([\n    \t\t\'X\',\n    \t\t\'X/Z\',\n    \t\t\'Y\',\n    \t\t\'Y/Z\',\n    \t])\n    \tself.make_files([\n    \t\t\'X/a.txt\',\n    \t\t\'X/b.txt\',\n    \t\t\'X/Z/c.txt\',\n    \t\t\'Y/a.txt\',\n    \t\t\'Y/b.txt\',\n    \t\t\'Y/Z/c.txt\',\n    \t])\n    \n>   \tincludes = set(spec.match_tree_files(self.temp_dir))\n\nrepos\\python-pathspec\\tests\\test_03_pathspec.py:619: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\python-pathspec\\pathspec\\pathspec.py:390: in match_tree_files\n    yield from self.match_files(files, negate=negate)\nrepos\\python-pathspec\\pathspec\\pathspec.py:313: in match_files\n    norm_file = normalize_file(orig_file, separators)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfile = \'X\\\\a.txt\', separators = None\n\n    def normalize_file(file, separators=\'/\'):\n>       if file.startswith(separators):\nE       TypeError: startswith first arg must be str or a tuple of str, not NoneType\n\nrepos\\python-pathspec\\pathspec\\util.py:294: TypeError', 'self = <tests.test_03_pathspec.PathSpecTest testMethod=test_06_issue_41_a>\n\n    def test_06_issue_41_a(self):\n    \t""""""\n    \tTest including a file and excluding a directory with the same name pattern,\n    \tscenario A.\n    \t""""""\n    \tspec = PathSpec.from_lines(\'gitwildmatch\', [\n    \t\t\'*.yaml\',\n    \t\t\'!*.yaml/\',\n    \t])\n    \tfiles = {\n    \t\t\'dir.yaml/file.sql\',\n    \t\t\'dir.yaml/file.yaml\',\n    \t\t\'dir.yaml/index.txt\',\n    \t\t\'dir/file.sql\',\n    \t\t\'dir/file.yaml\',\n    \t\t\'dir/index.txt\',\n    \t\t\'file.yaml\',\n    \t}\n    \n>   \tresults = list(spec.check_files(files))\n\nrepos\\python-pathspec\\tests\\test_03_pathspec.py:647: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\python-pathspec\\pathspec\\pathspec.py:145: in check_files\n    norm_file = normalize_file(orig_file, separators)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfile = \'dir.yaml/file.sql\', separators = None\n\n    def normalize_file(file, separators=\'/\'):\n>       if file.startswith(separators):\nE       TypeError: startswith first arg must be str or a tuple of str, not NoneType\n\nrepos\\python-pathspec\\pathspec\\util.py:294: TypeError', 'self = <tests.test_03_pathspec.PathSpecTest testMethod=test_06_issue_41_b>\n\n    def test_06_issue_41_b(self):\n    \t""""""\n    \tTest including a file and excluding a directory with the same name\n    \tpattern, scenario B.\n    \t""""""\n    \tspec = PathSpec.from_lines(\'gitwildmatch\', [\n    \t\t\'!*.yaml/\',\n    \t\t\'*.yaml\',\n    \t])\n    \tfiles = {\n    \t\t\'dir.yaml/file.sql\',\n    \t\t\'dir.yaml/file.yaml\',\n    \t\t\'dir.yaml/index.txt\',\n    \t\t\'dir/file.sql\',\n    \t\t\'dir/file.yaml\',\n    \t\t\'dir/index.txt\',\n    \t\t\'file.yaml\',\n    \t}\n    \n>   \tresults = list(spec.check_files(files))\n\nrepos\\python-pathspec\\tests\\test_03_pathspec.py:683: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\python-pathspec\\pathspec\\pathspec.py:145: in check_files\n    norm_file = normalize_file(orig_file, separators)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfile = \'dir.yaml/file.sql\', separators = None\n\n    def normalize_file(file, separators=\'/\'):\n>       if file.startswith(separators):\nE       TypeError: startswith first arg must be str or a tuple of str, not NoneType\n\nrepos\\python-pathspec\\pathspec\\util.py:294: TypeError', 'self = <tests.test_03_pathspec.PathSpecTest testMethod=test_06_issue_41_c>\n\n    def test_06_issue_41_c(self):\n    \t""""""\n    \tTest including a file and excluding a directory with the same name\n    \tpattern, scenario C.\n    \t""""""\n    \tspec = PathSpec.from_lines(\'gitwildmatch\', [\n    \t\t\'*.yaml\',\n    \t\t\'!dir.yaml\',\n    \t])\n    \tfiles = {\n    \t\t\'dir.yaml/file.sql\',\n    \t\t\'dir.yaml/file.yaml\',\n    \t\t\'dir.yaml/index.txt\',\n    \t\t\'dir/file.sql\',\n    \t\t\'dir/file.yaml\',\n    \t\t\'dir/index.txt\',\n    \t\t\'file.yaml\',\n    \t}\n    \n>   \tresults = list(spec.check_files(files))\n\nrepos\\python-pathspec\\tests\\test_03_pathspec.py:718: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\python-pathspec\\pathspec\\pathspec.py:145: in check_files\n    norm_file = normalize_file(orig_file, separators)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfile = \'dir.yaml/file.sql\', separators = None\n\n    def normalize_file(file, separators=\'/\'):\n>       if file.startswith(separators):\nE       TypeError: startswith first arg must be str or a tuple of str, not NoneType\n\nrepos\\python-pathspec\\pathspec\\util.py:294: TypeError', 'self = <tests.test_03_pathspec.PathSpecTest testMethod=test_07_issue_62>\n\n    def test_07_issue_62(self):\n    \t""""""\n    \tTest including all files and excluding a directory.\n    \t""""""\n    \tspec = PathSpec.from_lines(\'gitwildmatch\', [\n    \t\t\'*\',\n    \t\t\'!product_dir/\',\n    \t])\n    \tfiles = {\n    \t\t\'anydir/file.txt\',\n    \t\t\'product_dir/file.txt\',\n    \t}\n    \n>   \tresults = list(spec.check_files(files))\n\nrepos\\python-pathspec\\tests\\test_03_pathspec.py:748: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\python-pathspec\\pathspec\\pathspec.py:145: in check_files\n    norm_file = normalize_file(orig_file, separators)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfile = \'product_dir/file.txt\', separators = None\n\n    def normalize_file(file, separators=\'/\'):\n>       if file.startswith(separators):\nE       TypeError: startswith first arg must be str or a tuple of str, not NoneType\n\nrepos\\python-pathspec\\pathspec\\util.py:294: TypeError', 'self = <tests.test_03_pathspec.PathSpecTest testMethod=test_08_issue_39>\n\n    def test_08_issue_39(self):\n    \t""""""\n    \tTest excluding files in a directory.\n    \t""""""\n    \tspec = PathSpec.from_lines(\'gitwildmatch\', [\n    \t\t\'*.log\',\n    \t\t\'!important/*.log\',\n    \t\t\'trace.*\',\n    \t])\n    \tfiles = {\n    \t\t\'a.log\',\n    \t\t\'b.txt\',\n    \t\t\'important/d.log\',\n    \t\t\'important/e.txt\',\n    \t\t\'trace.c\',\n    \t}\n    \n>   \tresults = list(spec.check_files(files))\n\nrepos\\python-pathspec\\tests\\test_03_pathspec.py:773: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\python-pathspec\\pathspec\\pathspec.py:145: in check_files\n    norm_file = normalize_file(orig_file, separators)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfile = \'a.log\', separators = None\n\n    def normalize_file(file, separators=\'/\'):\n>       if file.startswith(separators):\nE       TypeError: startswith first arg must be str or a tuple of str, not NoneType\n\nrepos\\python-pathspec\\pathspec\\util.py:294: TypeError', 'self = <tests.test_03_pathspec.PathSpecTest testMethod=test_09_issue_80_a>\n\n    def test_09_issue_80_a(self):\n    \t""""""\n    \tTest negating patterns.\n    \t""""""\n    \tspec = PathSpec.from_lines(\'gitwildmatch\', [\n    \t\t\'build\',\n    \t\t\'*.log\',\n    \t\t\'.*\',\n    \t\t\'!.gitignore\',\n    \t])\n    \tfiles = {\n    \t\t\'.c-tmp\',\n    \t\t\'.gitignore\',\n    \t\t\'a.log\',\n    \t\t\'b.txt\',\n    \t\t\'build/d.log\',\n    \t\t\'build/trace.bin\',\n    \t\t\'trace.c\',\n    \t}\n    \n>   \tkeeps = set(spec.match_files(files, negate=True))\n\nrepos\\python-pathspec\\tests\\test_03_pathspec.py:807: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\python-pathspec\\pathspec\\pathspec.py:313: in match_files\n    norm_file = normalize_file(orig_file, separators)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfile = \'a.log\', separators = None\n\n    def normalize_file(file, separators=\'/\'):\n>       if file.startswith(separators):\nE       TypeError: startswith first arg must be str or a tuple of str, not NoneType\n\nrepos\\python-pathspec\\pathspec\\util.py:294: TypeError', 'self = <tests.test_03_pathspec.PathSpecTest testMethod=test_09_issue_80_b>\n\n    def test_09_issue_80_b(self):\n    \t""""""\n    \tTest negating patterns.\n    \t""""""\n    \tspec = PathSpec.from_lines(\'gitwildmatch\', [\n    \t\t\'build\',\n    \t\t\'*.log\',\n    \t\t\'.*\',\n    \t\t\'!.gitignore\',\n    \t])\n    \tfiles = {\n    \t\t\'.c-tmp\',\n    \t\t\'.gitignore\',\n    \t\t\'a.log\',\n    \t\t\'b.txt\',\n    \t\t\'build/d.log\',\n    \t\t\'build/trace.bin\',\n    \t\t\'trace.c\',\n    \t}\n    \n>   \tkeeps = set(spec.match_files(files, negate=True))\n\nrepos\\python-pathspec\\tests\\test_03_pathspec.py:835: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\python-pathspec\\pathspec\\pathspec.py:313: in match_files\n    norm_file = normalize_file(orig_file, separators)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfile = \'a.log\', separators = None\n\n    def normalize_file(file, separators=\'/\'):\n>       if file.startswith(separators):\nE       TypeError: startswith first arg must be str or a tuple of str, not NoneType\n\nrepos\\python-pathspec\\pathspec\\util.py:294: TypeError', 'self = <tests.test_04_gitignore.GitIgnoreSpecTest testMethod=test_01_reversed_args>\n\n    def test_01_reversed_args(self):\n    \t""""""\n    \tTest reversed args for `.from_lines()`.\n    \t""""""\n    \tspec = GitIgnoreSpec.from_lines(\'gitwildmatch\', [\'*.txt\'])\n    \tfiles = {\n    \t\t\'a.txt\',\n    \t\t\'b.bin\',\n    \t}\n    \n>   \tresults = list(spec.check_files(files))\n\nrepos\\python-pathspec\\tests\\test_04_gitignore.py:30: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\python-pathspec\\pathspec\\pathspec.py:145: in check_files\n    norm_file = normalize_file(orig_file, separators)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfile = \'b.bin\', separators = None\n\n    def normalize_file(file, separators=\'/\'):\n>       if file.startswith(separators):\nE       TypeError: startswith first arg must be str or a tuple of str, not NoneType\n\nrepos\\python-pathspec\\pathspec\\util.py:294: TypeError', 'self = <tests.test_04_gitignore.GitIgnoreSpecTest testMethod=test_02_dir_exclusions>\n\n    def test_02_dir_exclusions(self):\n    \t""""""\n    \tTest directory exclusions.\n    \t""""""\n    \tspec = GitIgnoreSpec.from_lines([\n    \t\t\'*.txt\',\n    \t\t\'!test1/\',\n    \t])\n    \tfiles = {\n    \t\t\'test1/a.txt\',\n    \t\t\'test1/b.bin\',\n    \t\t\'test1/c/c.txt\',\n    \t\t\'test2/a.txt\',\n    \t\t\'test2/b.bin\',\n    \t\t\'test2/c/c.txt\',\n    \t}\n    \n>   \tresults = list(spec.check_files(files))\n\nrepos\\python-pathspec\\tests\\test_04_gitignore.py:55: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\python-pathspec\\pathspec\\pathspec.py:145: in check_files\n    norm_file = normalize_file(orig_file, separators)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfile = \'test2/b.bin\', separators = None\n\n    def normalize_file(file, separators=\'/\'):\n>       if file.startswith(separators):\nE       TypeError: startswith first arg must be str or a tuple of str, not NoneType\n\nrepos\\python-pathspec\\pathspec\\util.py:294: TypeError', 'self = <tests.test_04_gitignore.GitIgnoreSpecTest testMethod=test_02_file_exclusions>\n\n    def test_02_file_exclusions(self):\n    \t""""""\n    \tTest file exclusions.\n    \t""""""\n    \tspec = GitIgnoreSpec.from_lines([\n    \t\t\'*.txt\',\n    \t\t\'!b.txt\',\n    \t])\n    \tfiles = {\n    \t\t\'X/a.txt\',\n    \t\t\'X/b.txt\',\n    \t\t\'X/Z/c.txt\',\n    \t\t\'Y/a.txt\',\n    \t\t\'Y/b.txt\',\n    \t\t\'Y/Z/c.txt\',\n    \t}\n    \n>   \tresults = list(spec.check_files(files))\n\nrepos\\python-pathspec\\tests\\test_04_gitignore.py:87: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\python-pathspec\\pathspec\\pathspec.py:145: in check_files\n    norm_file = normalize_file(orig_file, separators)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfile = \'Y/b.txt\', separators = None\n\n    def normalize_file(file, separators=\'/\'):\n>       if file.startswith(separators):\nE       TypeError: startswith first arg must be str or a tuple of str, not NoneType\n\nrepos\\python-pathspec\\pathspec\\util.py:294: TypeError', 'self = <tests.test_04_gitignore.GitIgnoreSpecTest testMethod=test_02_issue_41_a>\n\n    def test_02_issue_41_a(self):\n    \t""""""\n    \tTest including a file and excluding a directory with the same name pattern,\n    \tscenario A.\n    \t""""""\n    \t# Confirmed results with git (v2.42.0).\n    \tspec = GitIgnoreSpec.from_lines([\n    \t\t\'*.yaml\',\n    \t\t\'!*.yaml/\',\n    \t])\n    \tfiles = {\n    \t\t\'dir.yaml/file.sql\',   # -\n    \t\t\'dir.yaml/file.yaml\',  # 1:*.yaml\n    \t\t\'dir.yaml/index.txt\',  # -\n    \t\t\'dir/file.sql\',        # -\n    \t\t\'dir/file.yaml\',       # 1:*.yaml\n    \t\t\'dir/index.txt\',       # -\n    \t\t\'file.yaml\',           # 1:*.yaml\n    \t}\n    \n>   \tresults = list(spec.check_files(files))\n\nrepos\\python-pathspec\\tests\\test_04_gitignore.py:122: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\python-pathspec\\pathspec\\pathspec.py:145: in check_files\n    norm_file = normalize_file(orig_file, separators)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfile = \'dir.yaml/file.sql\', separators = None\n\n    def normalize_file(file, separators=\'/\'):\n>       if file.startswith(separators):\nE       TypeError: startswith first arg must be str or a tuple of str, not NoneType\n\nrepos\\python-pathspec\\pathspec\\util.py:294: TypeError', 'self = <tests.test_04_gitignore.GitIgnoreSpecTest testMethod=test_02_issue_41_b>\n\n    def test_02_issue_41_b(self):\n    \t""""""\n    \tTest including a file and excluding a directory with the same name pattern,\n    \tscenario B.\n    \t""""""\n    \t# Confirmed results with git (v2.42.0).\n    \tspec = GitIgnoreSpec.from_lines([\n    \t\t\'!*.yaml/\',\n    \t\t\'*.yaml\',\n    \t])\n    \tfiles = {\n    \t\t\'dir.yaml/file.sql\',   # 2:*.yaml\n    \t\t\'dir.yaml/file.yaml\',  # 2:*.yaml\n    \t\t\'dir.yaml/index.txt\',  # 2:*.yaml\n    \t\t\'dir/file.sql\',        # -\n    \t\t\'dir/file.yaml\',       # 2:*.yaml\n    \t\t\'dir/index.txt\',       # -\n    \t\t\'file.yaml\',           # 2:*.yaml\n    \t}\n    \n>   \tresults = list(spec.check_files(files))\n\nrepos\\python-pathspec\\tests\\test_04_gitignore.py:158: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\python-pathspec\\pathspec\\pathspec.py:145: in check_files\n    norm_file = normalize_file(orig_file, separators)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfile = \'dir.yaml/file.sql\', separators = None\n\n    def normalize_file(file, separators=\'/\'):\n>       if file.startswith(separators):\nE       TypeError: startswith first arg must be str or a tuple of str, not NoneType\n\nrepos\\python-pathspec\\pathspec\\util.py:294: TypeError', 'self = <tests.test_04_gitignore.GitIgnoreSpecTest testMethod=test_02_issue_41_c>\n\n    def test_02_issue_41_c(self):\n    \t""""""\n    \tTest including a file and excluding a directory with the same name pattern,\n    \tscenario C.\n    \t""""""\n    \t# Confirmed results with git (v2.42.0).\n    \tspec = GitIgnoreSpec.from_lines([\n    \t\t\'*.yaml\',\n    \t\t\'!dir.yaml\',\n    \t])\n    \tfiles = {\n    \t\t\'dir.yaml/file.sql\',   # -\n    \t\t\'dir.yaml/file.yaml\',  # 1:*.yaml\n    \t\t\'dir.yaml/index.txt\',  # -\n    \t\t\'dir/file.sql\',        # -\n    \t\t\'dir/file.yaml\',       # 1:*.yaml\n    \t\t\'dir/index.txt\',       # -\n    \t\t\'file.yaml\',           # 1:*.yaml\n    \t}\n    \n>   \tresults = list(spec.check_files(files))\n\nrepos\\python-pathspec\\tests\\test_04_gitignore.py:194: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\python-pathspec\\pathspec\\pathspec.py:145: in check_files\n    norm_file = normalize_file(orig_file, separators)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfile = \'dir.yaml/file.sql\', separators = None\n\n    def normalize_file(file, separators=\'/\'):\n>       if file.startswith(separators):\nE       TypeError: startswith first arg must be str or a tuple of str, not NoneType\n\nrepos\\python-pathspec\\pathspec\\util.py:294: TypeError', 'self = <tests.test_04_gitignore.GitIgnoreSpecTest testMethod=test_03_issue_19_a>\n\n    def test_03_issue_19_a(self):\n    \t""""""\n    \tTest matching files in a subdirectory of an included directory, scenario A.\n    \t""""""\n    \tspec = GitIgnoreSpec.from_lines([\n    \t\t""dirG/"",\n    \t])\n    \tfiles = {\n    \t\t\'fileA\',\n    \t\t\'fileB\',\n    \t\t\'dirD/fileE\',\n    \t\t\'dirD/fileF\',\n    \t\t\'dirG/dirH/fileI\',\n    \t\t\'dirG/dirH/fileJ\',\n    \t\t\'dirG/fileO\',\n    \t}\n    \n>   \tresults = list(spec.check_files(files))\n\nrepos\\python-pathspec\\tests\\test_04_gitignore.py:260: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\python-pathspec\\pathspec\\pathspec.py:145: in check_files\n    norm_file = normalize_file(orig_file, separators)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfile = \'dirG/fileO\', separators = None\n\n    def normalize_file(file, separators=\'/\'):\n>       if file.startswith(separators):\nE       TypeError: startswith first arg must be str or a tuple of str, not NoneType\n\nrepos\\python-pathspec\\pathspec\\util.py:294: TypeError', 'self = <tests.test_04_gitignore.GitIgnoreSpecTest testMethod=test_03_issue_19_b>\n\n    def test_03_issue_19_b(self):\n    \t""""""\n    \tTest matching files in a subdirectory of an included directory, scenario B.\n    \t""""""\n    \tspec = GitIgnoreSpec.from_lines([\n    \t\t""dirG/*"",\n    \t])\n    \tfiles = {\n    \t\t\'fileA\',\n    \t\t\'fileB\',\n    \t\t\'dirD/fileE\',\n    \t\t\'dirD/fileF\',\n    \t\t\'dirG/dirH/fileI\',\n    \t\t\'dirG/dirH/fileJ\',\n    \t\t\'dirG/fileO\',\n    \t}\n    \n>   \tresults = list(spec.check_files(files))\n\nrepos\\python-pathspec\\tests\\test_04_gitignore.py:293: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\python-pathspec\\pathspec\\pathspec.py:145: in check_files\n    norm_file = normalize_file(orig_file, separators)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfile = \'dirG/fileO\', separators = None\n\n    def normalize_file(file, separators=\'/\'):\n>       if file.startswith(separators):\nE       TypeError: startswith first arg must be str or a tuple of str, not NoneType\n\nrepos\\python-pathspec\\pathspec\\util.py:294: TypeError', 'self = <tests.test_04_gitignore.GitIgnoreSpecTest testMethod=test_03_issue_19_c>\n\n    def test_03_issue_19_c(self):\n    \t""""""\n    \tTest matching files in a subdirectory of an included directory, scenario C.\n    \t""""""\n    \tspec = GitIgnoreSpec.from_lines([\n    \t\t""dirG/**"",\n    \t])\n    \tfiles = {\n    \t\t\'fileA\',\n    \t\t\'fileB\',\n    \t\t\'dirD/fileE\',\n    \t\t\'dirD/fileF\',\n    \t\t\'dirG/dirH/fileI\',\n    \t\t\'dirG/dirH/fileJ\',\n    \t\t\'dirG/fileO\',\n    \t}\n    \n>   \tresults = list(spec.check_files(files))\n\nrepos\\python-pathspec\\tests\\test_04_gitignore.py:326: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\python-pathspec\\pathspec\\pathspec.py:145: in check_files\n    norm_file = normalize_file(orig_file, separators)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfile = \'dirG/fileO\', separators = None\n\n    def normalize_file(file, separators=\'/\'):\n>       if file.startswith(separators):\nE       TypeError: startswith first arg must be str or a tuple of str, not NoneType\n\nrepos\\python-pathspec\\pathspec\\util.py:294: TypeError', 'self = <tests.test_04_gitignore.GitIgnoreSpecTest testMethod=test_03_subdir>\n\n    def test_03_subdir(self):\n    \t""""""\n    \tTest matching files in a subdirectory of an included directory.\n    \t""""""\n    \tspec = GitIgnoreSpec.from_lines([\n    \t\t""dirG/"",\n    \t])\n    \tfiles = {\n    \t\t\'fileA\',\n    \t\t\'fileB\',\n    \t\t\'dirD/fileE\',\n    \t\t\'dirD/fileF\',\n    \t\t\'dirG/dirH/fileI\',\n    \t\t\'dirG/dirH/fileJ\',\n    \t\t\'dirG/fileO\',\n    \t}\n    \n>   \tresults = list(spec.check_files(files))\n\nrepos\\python-pathspec\\tests\\test_04_gitignore.py:227: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\python-pathspec\\pathspec\\pathspec.py:145: in check_files\n    norm_file = normalize_file(orig_file, separators)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfile = \'dirG/fileO\', separators = None\n\n    def normalize_file(file, separators=\'/\'):\n>       if file.startswith(separators):\nE       TypeError: startswith first arg must be str or a tuple of str, not NoneType\n\nrepos\\python-pathspec\\pathspec\\util.py:294: TypeError', 'self = <tests.test_04_gitignore.GitIgnoreSpecTest testMethod=test_04_issue_62>\n\n    def test_04_issue_62(self):\n    \t""""""\n    \tTest including all files and excluding a directory.\n    \t""""""\n    \tspec = GitIgnoreSpec.from_lines([\n    \t\t\'*\',\n    \t\t\'!product_dir/\',\n    \t])\n    \tfiles = {\n    \t\t\'anydir/file.txt\',\n    \t\t\'product_dir/file.txt\',\n    \t}\n    \n>   \tresults = list(spec.check_files(files))\n\nrepos\\python-pathspec\\tests\\test_04_gitignore.py:355: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\python-pathspec\\pathspec\\pathspec.py:145: in check_files\n    norm_file = normalize_file(orig_file, separators)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfile = \'product_dir/file.txt\', separators = None\n\n    def normalize_file(file, separators=\'/\'):\n>       if file.startswith(separators):\nE       TypeError: startswith first arg must be str or a tuple of str, not NoneType\n\nrepos\\python-pathspec\\pathspec\\util.py:294: TypeError', 'self = <tests.test_04_gitignore.GitIgnoreSpecTest testMethod=test_05_issue_39>\n\n    def test_05_issue_39(self):\n    \t""""""\n    \tTest excluding files in a directory.\n    \t""""""\n    \tspec = GitIgnoreSpec.from_lines([\n    \t\t\'*.log\',\n    \t\t\'!important/*.log\',\n    \t\t\'trace.*\',\n    \t])\n    \tfiles = {\n    \t\t\'a.log\',\n    \t\t\'b.txt\',\n    \t\t\'important/d.log\',\n    \t\t\'important/e.txt\',\n    \t\t\'trace.c\',\n    \t}\n    \n>   \tresults = list(spec.check_files(files))\n\nrepos\\python-pathspec\\tests\\test_04_gitignore.py:381: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\python-pathspec\\pathspec\\pathspec.py:145: in check_files\n    norm_file = normalize_file(orig_file, separators)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfile = \'a.log\', separators = None\n\n    def normalize_file(file, separators=\'/\'):\n>       if file.startswith(separators):\nE       TypeError: startswith first arg must be str or a tuple of str, not NoneType\n\nrepos\\python-pathspec\\pathspec\\util.py:294: TypeError', 'self = <tests.test_04_gitignore.GitIgnoreSpecTest testMethod=test_06_issue_64>\n\n    def test_06_issue_64(self):\n    \t""""""\n    \tTest using a double asterisk pattern.\n    \t""""""\n    \tspec = GitIgnoreSpec.from_lines([\n    \t\t""**"",\n    \t])\n    \tfiles = {\n    \t\t\'x\',\n    \t\t\'y.py\',\n    \t\t\'A/x\',\n    \t\t\'A/y.py\',\n    \t\t\'A/B/x\',\n    \t\t\'A/B/y.py\',\n    \t\t\'A/B/C/x\',\n    \t\t\'A/B/C/y.py\',\n    \t}\n    \n>   \tresults = list(spec.check_files(files))\n\nrepos\\python-pathspec\\tests\\test_04_gitignore.py:413: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\python-pathspec\\pathspec\\pathspec.py:145: in check_files\n    norm_file = normalize_file(orig_file, separators)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfile = \'A/B/y.py\', separators = None\n\n    def normalize_file(file, separators=\'/\'):\n>       if file.startswith(separators):\nE       TypeError: startswith first arg must be str or a tuple of str, not NoneType\n\nrepos\\python-pathspec\\pathspec\\util.py:294: TypeError', 'self = <tests.test_04_gitignore.GitIgnoreSpecTest testMethod=test_07_issue_74>\n\n    def test_07_issue_74(self):\n    \t""""""\n    \tTest include directory should override exclude file.\n    \t""""""\n    \tspec = GitIgnoreSpec.from_lines([\n    \t\t\'*\',  # Ignore all files by default\n    \t\t\'!*/\',  # but scan all directories\n    \t\t\'!*.txt\',  # Text files\n    \t\t\'/test1/**\',  # ignore all in the directory\n    \t])\n    \tfiles = {\n    \t\t\'test1/b.bin\',\n    \t\t\'test1/a.txt\',\n    \t\t\'test1/c/c.txt\',\n    \t\t\'test2/a.txt\',\n    \t\t\'test2/b.bin\',\n    \t\t\'test2/c/c.txt\',\n    \t}\n    \n>   \tresults = list(spec.check_files(files))\n\nrepos\\python-pathspec\\tests\\test_04_gitignore.py:438: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\python-pathspec\\pathspec\\pathspec.py:145: in check_files\n    norm_file = normalize_file(orig_file, separators)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfile = \'test2/b.bin\', separators = None\n\n    def normalize_file(file, separators=\'/\'):\n>       if file.startswith(separators):\nE       TypeError: startswith first arg must be str or a tuple of str, not NoneType\n\nrepos\\python-pathspec\\pathspec\\util.py:294: TypeError', 'self = <tests.test_04_gitignore.GitIgnoreSpecTest testMethod=test_08_issue_81_a>\n\n    def test_08_issue_81_a(self):\n    \t""""""\n    \tTest issue 81 whitelist, scenario A.\n    \t""""""\n    \t# Confirmed results with git (v2.42.0).\n    \tspec = GitIgnoreSpec.from_lines([\n    \t\t""*"",\n    \t\t""!libfoo"",\n    \t\t""!libfoo/**"",\n    \t])\n    \tfiles = {\n    \t\t""ignore.txt"",          # 1:*\n    \t\t""libfoo/__init__.py"",  # 3:!libfoo/**\n    \t}\n    \n>   \tresults = list(spec.check_files(files))\n\nrepos\\python-pathspec\\tests\\test_04_gitignore.py:468: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\python-pathspec\\pathspec\\pathspec.py:145: in check_files\n    norm_file = normalize_file(orig_file, separators)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfile = \'ignore.txt\', separators = None\n\n    def normalize_file(file, separators=\'/\'):\n>       if file.startswith(separators):\nE       TypeError: startswith first arg must be str or a tuple of str, not NoneType\n\nrepos\\python-pathspec\\pathspec\\util.py:294: TypeError', 'self = <tests.test_04_gitignore.GitIgnoreSpecTest testMethod=test_08_issue_81_b>\n\n    def test_08_issue_81_b(self):\n    \t""""""\n    \tTest issue 81 whitelist, scenario B.\n    \t""""""\n    \t# Confirmed results with git (v2.42.0).\n    \tspec = GitIgnoreSpec.from_lines([\n    \t\t""*"",\n    \t\t""!libfoo"",\n    \t\t""!libfoo/*"",\n    \t])\n    \tfiles = {\n    \t\t""ignore.txt"",          # 1:*\n    \t\t""libfoo/__init__.py"",  # 3:!libfoo/*\n    \t}\n    \n>   \tresults = list(spec.check_files(files))\n\nrepos\\python-pathspec\\tests\\test_04_gitignore.py:494: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\python-pathspec\\pathspec\\pathspec.py:145: in check_files\n    norm_file = normalize_file(orig_file, separators)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfile = \'ignore.txt\', separators = None\n\n    def normalize_file(file, separators=\'/\'):\n>       if file.startswith(separators):\nE       TypeError: startswith first arg must be str or a tuple of str, not NoneType\n\nrepos\\python-pathspec\\pathspec\\util.py:294: TypeError', 'self = <tests.test_04_gitignore.GitIgnoreSpecTest testMethod=test_08_issue_81_c>\n\n    def test_08_issue_81_c(self):\n    \t""""""\n    \tTest issue 81 whitelist, scenario C.\n    \t""""""\n    \t# Confirmed results with git (v2.42.0).\n    \tspec = GitIgnoreSpec.from_lines([\n    \t\t""*"",\n    \t\t""!libfoo"",\n    \t\t""!libfoo/"",\n    \t])\n    \tfiles = {\n    \t\t""ignore.txt"",          # 1:*\n    \t\t""libfoo/__init__.py"",  # 1:*\n    \t}\n>   \tresults = list(spec.check_files(files))\n\nrepos\\python-pathspec\\tests\\test_04_gitignore.py:519: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\python-pathspec\\pathspec\\pathspec.py:145: in check_files\n    norm_file = normalize_file(orig_file, separators)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nfile = \'ignore.txt\', separators = None\n\n    def normalize_file(file, separators=\'/\'):\n>       if file.startswith(separators):\nE       TypeError: startswith first arg must be str or a tuple of str, not NoneType\n\nrepos\\python-pathspec\\pathspec\\util.py:294: TypeError']",python-pathspec/normalize_file,LLM
python-pathspec,pattern_to_regex,"@classmethod
def pattern_to_regex(cls, pattern: AnyStr) -> Tuple[Optional[AnyStr], Optional[bool]]:
    """"""
		Convert the pattern into a regular expression.

		*pattern* (:class:`str` or :class:`bytes`) is the pattern to convert into a
		regular expression.

		Returns the uncompiled regular expression (:class:`str`, :class:`bytes`, or
		:data:`None`); and whether matched files should be included (:data:`True`),
		excluded (:data:`False`), or if it is a null-operation (:data:`None`).
		""""""
    if isinstance(pattern, str):
        return_type = str
    elif isinstance(pattern, bytes):
        return_type = bytes
        pattern = pattern.decode(_BYTES_ENCODING)
    else:
        raise TypeError(f'pattern:{pattern!r} is not a unicode or byte string.')
    original_pattern = pattern
    if pattern.endswith('\\ '):
        pattern = pattern.lstrip()
    else:
        pattern = pattern.strip()
    regex: Optional[str]
    include: Optional[bool]
    if pattern.startswith('#'):
        regex = None
        include = None
    elif pattern == '/':
        regex = None
        include = None
    elif pattern:
        if pattern.startswith('!'):
            include = False
            pattern = pattern[1:]
        else:
            include = True
        override_regex: Optional[str] = None
        pattern_segs = pattern.split('/')
        is_dir_pattern = not pattern_segs[-1]
        for i in range(len(pattern_segs) - 1, 0, -1):
            prev = pattern_segs[i - 1]
            seg = pattern_segs[i]
            if prev == '**' and seg == '**':
                del pattern_segs[i]
        if len(pattern_segs) == 2 and pattern_segs[0] == '**' and (not pattern_segs[1]):
            override_regex = f'^.+(?P<{_DIR_MARK}>/).*$'
        if not pattern_segs[0]:
            del pattern_segs[0]
        elif len(pattern_segs) == 1 or (len(pattern_segs) == 2 and (not pattern_segs[1])):
            if pattern_segs[0] != '**':
                pattern_segs.insert(0, '**')
        else:
            pass
        if not pattern_segs:
            raise GitWildMatchPatternError(f'Invalid git pattern: {original_pattern!r}')
        if not pattern_segs[-1] and len(pattern_segs) > 1:
            pattern_segs[-1] = '**'
        if override_regex is None:
            output = ['^']
            need_slash = False
            end = len(pattern_segs) - 1
            for i, seg in enumerate(pattern_segs):
                if seg == '**':
                    if i == 0 and i == end:
                        output.append(f'[^/]+(?:/.*)?')
                    elif i == 0:
                        output.append('(?:.+/)?')
                        need_slash = False
                    elif i == end:
                        if is_dir_pattern:
                            output.append(f'(?P<{_DIR_MARK}>/).*')
                        else:
                            output.append(f'/.*')
                    else:
                        output.append('(?:/.+)?')
                        need_slash = True
                elif seg == '*':
                    if need_slash:
                        output.append('/')
                    output.append('[^/]+')
                    if i == end:
                        output.append(f'(?:(?P<{_DIR_MARK}>/).*)?')
                    need_slash = True
                else:
                    if need_slash:
                        output.append('/')
                    try:
                        output.append(cls._translate_segment_glob(seg))
                    except ValueError as e:
                        raise GitWildMatchPatternError(f'Invalid git pattern: {original_pattern!r}') from e
                    if i == end:
                        output.append(f'(?:(?P<{_DIR_MARK}>/).*)?')
                    need_slash = True
            output.append('$')
            regex = ''.join(output)
        else:
            regex = override_regex
    else:
        regex = None
        include = None
    if regex is not None and return_type is bytes:
        regex = regex.encode(_BYTES_ENCODING)
    return (regex, include)","The goal of the function is to convert a given pattern into a regular expression. The function determines whether files matching the pattern should be included, excluded, or if it is a null-operation. It handles different types of patterns and constructs the regular expression based on the pattern logic, ultimately returning the compiled regular expression and the inclusion/exclusion status. This function is designed to be used within a class context and interacts with class attributes or other methods to properly handle and convert the patterns into regular expressions.",1,"def pattern_to_regex(cls, pattern):
    regex_pattern = convert_pattern_to_regex(pattern)
    inclusion_status = determine_inclusion_status(pattern)
    return regex_pattern, inclusion_status

def convert_pattern_to_regex(pattern):
    # logic to convert pattern to regular expression
    return compiled_regex

def determine_inclusion_status(pattern):
    # logic to determine if pattern should be included, excluded, or null-operation
    return inclusion_status",['./repos/python-pathspec\\tests'],"10 Passed, 102 Failed",10,102,"['tests/test_01_util.py::CheckMatchFileTest::test_01_single_1_include', 'tests/test_01_util.py::CheckMatchFileTest::test_01_single_2_exclude', 'tests/test_01_util.py::CheckMatchFileTest::test_01_single_3_unmatch', 'tests/test_01_util.py::CheckMatchFileTest::test_02_many', 'tests/test_01_util.py::MatchFileTest::test_01_single_1_include', 'tests/test_01_util.py::MatchFileTest::test_01_single_2_exclude', 'tests/test_01_util.py::MatchFileTest::test_01_single_3_unmatch', 'tests/test_01_util.py::MatchFileTest::test_02_many', 'tests/test_02_gitwildmatch.py::GitWildMatchTest::test_00_empty', 'tests/test_02_gitwildmatch.py::GitWildMatchTest::test_01_absolute', 'tests/test_02_gitwildmatch.py::GitWildMatchTest::test_01_absolute_ignore', 'tests/test_02_gitwildmatch.py::GitWildMatchTest::test_01_absolute_root', 'tests/test_02_gitwildmatch.py::GitWildMatchTest::test_01_relative', 'tests/test_02_gitwildmatch.py::GitWildMatchTest::test_01_relative_nested', 'tests/test_02_gitwildmatch.py::GitWildMatchTest::test_02_comment', 'tests/test_02_gitwildmatch.py::GitWildMatchTest::test_02_ignore', 'tests/test_02_gitwildmatch.py::GitWildMatchTest::test_03_child_double_asterisk', 'tests/test_02_gitwildmatch.py::GitWildMatchTest::test_03_double_asterisk_trailing_slash_edge_case', 'tests/test_02_gitwildmatch.py::GitWildMatchTest::test_03_duplicate_leading_double_asterisk_edge_case', 'tests/test_02_gitwildmatch.py::GitWildMatchTest::test_03_inner_double_asterisk', 'tests/test_02_gitwildmatch.py::GitWildMatchTest::test_03_only_double_asterisk', 'tests/test_02_gitwildmatch.py::GitWildMatchTest::test_03_parent_double_asterisk', 'tests/test_02_gitwildmatch.py::GitWildMatchTest::test_04_infix_wildcard', 'tests/test_02_gitwildmatch.py::GitWildMatchTest::test_04_postfix_wildcard', 'tests/test_02_gitwildmatch.py::GitWildMatchTest::test_04_prefix_wildcard', 'tests/test_02_gitwildmatch.py::GitWildMatchTest::test_05_directory', 'tests/test_02_gitwildmatch.py::GitWildMatchTest::test_07_match_bytes_and_bytes', 'tests/test_02_gitwildmatch.py::GitWildMatchTest::test_07_match_bytes_and_bytes_complete', 'tests/test_02_gitwildmatch.py::GitWildMatchTest::test_07_match_bytes_and_unicode_fail', 'tests/test_02_gitwildmatch.py::GitWildMatchTest::test_07_match_unicode_and_bytes_fail', 'tests/test_02_gitwildmatch.py::GitWildMatchTest::test_07_match_unicode_and_unicode', 'tests/test_02_gitwildmatch.py::GitWildMatchTest::test_09_single_escape_fail', 'tests/test_02_gitwildmatch.py::GitWildMatchTest::test_09_single_exclamation_mark_fail', 'tests/test_02_gitwildmatch.py::GitWildMatchTest::test_10_escape_asterisk_end', 'tests/test_02_gitwildmatch.py::GitWildMatchTest::test_10_escape_asterisk_mid', 'tests/test_02_gitwildmatch.py::GitWildMatchTest::test_10_escape_asterisk_start', 'tests/test_02_gitwildmatch.py::GitWildMatchTest::test_10_escape_exclamation_mark_start', 'tests/test_02_gitwildmatch.py::GitWildMatchTest::test_10_escape_pound_start', 'tests/test_02_gitwildmatch.py::GitWildMatchTest::test_11_issue_19_directory_a', 'tests/test_02_gitwildmatch.py::GitWildMatchTest::test_11_issue_19_directory_b', 'tests/test_02_gitwildmatch.py::GitWildMatchTest::test_11_issue_19_directory_c', 'tests/test_02_gitwildmatch.py::GitWildMatchTest::test_12_asterisk_1_regex', 'tests/test_02_gitwildmatch.py::GitWildMatchTest::test_12_asterisk_2_regex_equivalent', 'tests/test_02_gitwildmatch.py::GitWildMatchTest::test_12_asterisk_3_child', 'tests/test_02_gitwildmatch.py::GitWildMatchTest::test_12_asterisk_4_descendant', 'tests/test_02_gitwildmatch.py::GitWildMatchTest::test_12_issue_62', 'tests/test_02_gitwildmatch.py::GitWildMatchTest::test_13_issue_77_1_negate_with_caret', 'tests/test_02_gitwildmatch.py::GitWildMatchTest::test_13_issue_77_1_negate_with_exclamation_mark', 'tests/test_02_gitwildmatch.py::GitWildMatchTest::test_13_issue_77_2_regex', 'tests/test_02_gitwildmatch.py::GitWildMatchTest::test_14_issue_81_a', 'tests/test_02_gitwildmatch.py::GitWildMatchTest::test_14_issue_81_b', 'tests/test_02_gitwildmatch.py::GitWildMatchTest::test_14_issue_81_c', 'tests/test_03_pathspec.py::PathSpecTest::test_01_absolute_dir_paths_1', 'tests/test_03_pathspec.py::PathSpecTest::test_01_absolute_dir_paths_2', 'tests/test_03_pathspec.py::PathSpecTest::test_01_check_file_1_include', 'tests/test_03_pathspec.py::PathSpecTest::test_01_check_file_2_exclude', 'tests/test_03_pathspec.py::PathSpecTest::test_01_check_file_3_unmatch', 'tests/test_03_pathspec.py::PathSpecTest::test_01_check_file_4_many', 'tests/test_03_pathspec.py::PathSpecTest::test_01_check_match_files', 'tests/test_03_pathspec.py::PathSpecTest::test_01_current_dir_paths', 'tests/test_03_pathspec.py::PathSpecTest::test_01_empty_path_1', 'tests/test_03_pathspec.py::PathSpecTest::test_01_empty_path_2', 'tests/test_03_pathspec.py::PathSpecTest::test_01_match_file_1_include', 'tests/test_03_pathspec.py::PathSpecTest::test_01_match_file_2_exclude', 'tests/test_03_pathspec.py::PathSpecTest::test_01_match_file_3_unmatch', 'tests/test_03_pathspec.py::PathSpecTest::test_01_match_files', 'tests/test_03_pathspec.py::PathSpecTest::test_01_windows_current_dir_paths', 'tests/test_03_pathspec.py::PathSpecTest::test_01_windows_paths', 'tests/test_03_pathspec.py::PathSpecTest::test_02_eq', 'tests/test_03_pathspec.py::PathSpecTest::test_02_ne', 'tests/test_03_pathspec.py::PathSpecTest::test_03_add', 'tests/test_03_pathspec.py::PathSpecTest::test_03_iadd', 'tests/test_03_pathspec.py::PathSpecTest::test_04_len', 'tests/test_03_pathspec.py::PathSpecTest::test_05_match_entries', 'tests/test_03_pathspec.py::PathSpecTest::test_05_match_file', 'tests/test_03_pathspec.py::PathSpecTest::test_05_match_files', 'tests/test_03_pathspec.py::PathSpecTest::test_05_match_tree_entries', 'tests/test_03_pathspec.py::PathSpecTest::test_05_match_tree_files', 'tests/test_03_pathspec.py::PathSpecTest::test_06_issue_41_a', 'tests/test_03_pathspec.py::PathSpecTest::test_06_issue_41_b', 'tests/test_03_pathspec.py::PathSpecTest::test_06_issue_41_c', 'tests/test_03_pathspec.py::PathSpecTest::test_07_issue_62', 'tests/test_03_pathspec.py::PathSpecTest::test_08_issue_39', 'tests/test_03_pathspec.py::PathSpecTest::test_09_issue_80_a', 'tests/test_03_pathspec.py::PathSpecTest::test_09_issue_80_b', 'tests/test_04_gitignore.py::GitIgnoreSpecTest::test_01_reversed_args', 'tests/test_04_gitignore.py::GitIgnoreSpecTest::test_02_dir_exclusions', 'tests/test_04_gitignore.py::GitIgnoreSpecTest::test_02_file_exclusions', 'tests/test_04_gitignore.py::GitIgnoreSpecTest::test_02_issue_41_a', 'tests/test_04_gitignore.py::GitIgnoreSpecTest::test_02_issue_41_b', 'tests/test_04_gitignore.py::GitIgnoreSpecTest::test_02_issue_41_c', 'tests/test_04_gitignore.py::GitIgnoreSpecTest::test_03_issue_19_a', 'tests/test_04_gitignore.py::GitIgnoreSpecTest::test_03_issue_19_b', 'tests/test_04_gitignore.py::GitIgnoreSpecTest::test_03_issue_19_c', 'tests/test_04_gitignore.py::GitIgnoreSpecTest::test_03_subdir', 'tests/test_04_gitignore.py::GitIgnoreSpecTest::test_04_issue_62', 'tests/test_04_gitignore.py::GitIgnoreSpecTest::test_05_issue_39', 'tests/test_04_gitignore.py::GitIgnoreSpecTest::test_06_issue_64', 'tests/test_04_gitignore.py::GitIgnoreSpecTest::test_07_issue_74', 'tests/test_04_gitignore.py::GitIgnoreSpecTest::test_08_issue_81_a', 'tests/test_04_gitignore.py::GitIgnoreSpecTest::test_08_issue_81_b', 'tests/test_04_gitignore.py::GitIgnoreSpecTest::test_08_issue_81_c']","['self = <tests.test_01_util.CheckMatchFileTest testMethod=test_01_single_1_include>\n\n    def test_01_single_1_include(self):\n    \t""""""\n    \tTest checking a single file that is included.\n    \t""""""\n>   \tpatterns = list(enumerate(map(GitWildMatchPattern, [\n    \t\t""*.txt"",\n    \t\t""!test/"",\n    \t])))\n\nrepos\\python-pathspec\\tests\\test_01_util.py:46: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\python-pathspec\\pathspec\\pattern.py:118: in __init__\n    regex, include = self.pattern_to_regex(pattern)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ncls = <pathspec.patterns.gitwildmatch.GitWildMatchPattern object at 0x0000013A34763E40>\npattern = \'*.txt\'\n\n    def pattern_to_regex(cls, pattern):\n>       regex_pattern = convert_pattern_to_regex(pattern)\nE       NameError: name \'convert_pattern_to_regex\' is not defined\n\nrepos\\python-pathspec\\pathspec\\patterns\\gitwildmatch.py:30: NameError', 'self = <tests.test_01_util.CheckMatchFileTest testMethod=test_01_single_2_exclude>\n\n    def test_01_single_2_exclude(self):\n    \t""""""\n    \tTest checking a single file that is excluded.\n    \t""""""\n>   \tpatterns = list(enumerate(map(GitWildMatchPattern, [\n    \t\t""*.txt"",\n    \t\t""!test/"",\n    \t])))\n\nrepos\\python-pathspec\\tests\\test_01_util.py:59: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\python-pathspec\\pathspec\\pattern.py:118: in __init__\n    regex, include = self.pattern_to_regex(pattern)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ncls = <pathspec.patterns.gitwildmatch.GitWildMatchPattern object at 0x0000013A34872800>\npattern = \'*.txt\'\n\n    def pattern_to_regex(cls, pattern):\n>       regex_pattern = convert_pattern_to_regex(pattern)\nE       NameError: name \'convert_pattern_to_regex\' is not defined\n\nrepos\\python-pathspec\\pathspec\\patterns\\gitwildmatch.py:30: NameError', 'self = <tests.test_01_util.CheckMatchFileTest testMethod=test_01_single_3_unmatch>\n\n    def test_01_single_3_unmatch(self):\n    \t""""""\n    \tTest checking a single file that is ignored.\n    \t""""""\n>   \tpatterns = list(enumerate(map(GitWildMatchPattern, [\n    \t\t""*.txt"",\n    \t\t""!test/"",\n    \t])))\n\nrepos\\python-pathspec\\tests\\test_01_util.py:72: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\python-pathspec\\pathspec\\pattern.py:118: in __init__\n    regex, include = self.pattern_to_regex(pattern)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ncls = <pathspec.patterns.gitwildmatch.GitWildMatchPattern object at 0x0000013A3483B6C0>\npattern = \'*.txt\'\n\n    def pattern_to_regex(cls, pattern):\n>       regex_pattern = convert_pattern_to_regex(pattern)\nE       NameError: name \'convert_pattern_to_regex\' is not defined\n\nrepos\\python-pathspec\\pathspec\\patterns\\gitwildmatch.py:30: NameError', 'self = <tests.test_01_util.CheckMatchFileTest testMethod=test_02_many>\n\n    def test_02_many(self):\n    \t""""""\n    \tTest matching files individually.\n    \t""""""\n>   \tpatterns = list(enumerate(map(GitWildMatchPattern, [\n    \t\t\'*.txt\',\n    \t\t\'!b.txt\',\n    \t])))\n\nrepos\\python-pathspec\\tests\\test_01_util.py:85: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\python-pathspec\\pathspec\\pattern.py:118: in __init__\n    regex, include = self.pattern_to_regex(pattern)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ncls = <pathspec.patterns.gitwildmatch.GitWildMatchPattern object at 0x0000013A348C8B80>\npattern = \'*.txt\'\n\n    def pattern_to_regex(cls, pattern):\n>       regex_pattern = convert_pattern_to_regex(pattern)\nE       NameError: name \'convert_pattern_to_regex\' is not defined\n\nrepos\\python-pathspec\\pathspec\\patterns\\gitwildmatch.py:30: NameError', 'self = <tests.test_01_util.MatchFileTest testMethod=test_01_single_1_include>\n\n    def test_01_single_1_include(self):\n    \t""""""\n    \tTest checking a single file that is included.\n    \t""""""\n>   \tpatterns = list(map(GitWildMatchPattern, [\n    \t\t""*.txt"",\n    \t\t""!test/"",\n    \t]))\n\nrepos\\python-pathspec\\tests\\test_01_util.py:429: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\python-pathspec\\pathspec\\pattern.py:118: in __init__\n    regex, include = self.pattern_to_regex(pattern)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ncls = <pathspec.patterns.gitwildmatch.GitWildMatchPattern object at 0x0000013A348AD7C0>\npattern = \'*.txt\'\n\n    def pattern_to_regex(cls, pattern):\n>       regex_pattern = convert_pattern_to_regex(pattern)\nE       NameError: name \'convert_pattern_to_regex\' is not defined\n\nrepos\\python-pathspec\\pathspec\\patterns\\gitwildmatch.py:30: NameError', 'self = <tests.test_01_util.MatchFileTest testMethod=test_01_single_2_exclude>\n\n    def test_01_single_2_exclude(self):\n    \t""""""\n    \tTest checking a single file that is excluded.\n    \t""""""\n>   \tpatterns = list(map(GitWildMatchPattern, [\n    \t\t""*.txt"",\n    \t\t""!test/"",\n    \t]))\n\nrepos\\python-pathspec\\tests\\test_01_util.py:442: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\python-pathspec\\pathspec\\pattern.py:118: in __init__\n    regex, include = self.pattern_to_regex(pattern)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ncls = <pathspec.patterns.gitwildmatch.GitWildMatchPattern object at 0x0000013A348E74C0>\npattern = \'*.txt\'\n\n    def pattern_to_regex(cls, pattern):\n>       regex_pattern = convert_pattern_to_regex(pattern)\nE       NameError: name \'convert_pattern_to_regex\' is not defined\n\nrepos\\python-pathspec\\pathspec\\patterns\\gitwildmatch.py:30: NameError', 'self = <tests.test_01_util.MatchFileTest testMethod=test_01_single_3_unmatch>\n\n    def test_01_single_3_unmatch(self):\n    \t""""""\n    \tTest checking a single file that is ignored.\n    \t""""""\n>   \tpatterns = list(map(GitWildMatchPattern, [\n    \t\t""*.txt"",\n    \t\t""!test/"",\n    \t]))\n\nrepos\\python-pathspec\\tests\\test_01_util.py:455: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\python-pathspec\\pathspec\\pattern.py:118: in __init__\n    regex, include = self.pattern_to_regex(pattern)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ncls = <pathspec.patterns.gitwildmatch.GitWildMatchPattern object at 0x0000013A3462C200>\npattern = \'*.txt\'\n\n    def pattern_to_regex(cls, pattern):\n>       regex_pattern = convert_pattern_to_regex(pattern)\nE       NameError: name \'convert_pattern_to_regex\' is not defined\n\nrepos\\python-pathspec\\pathspec\\patterns\\gitwildmatch.py:30: NameError', 'self = <tests.test_01_util.MatchFileTest testMethod=test_02_many>\n\n    def test_02_many(self):\n    \t""""""\n    \tTest matching files individually.\n    \t""""""\n>   \tpatterns = list(map(GitWildMatchPattern, [\n    \t\t\'*.txt\',\n    \t\t\'!b.txt\',\n    \t]))\n\nrepos\\python-pathspec\\tests\\test_01_util.py:468: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\python-pathspec\\pathspec\\pattern.py:118: in __init__\n    regex, include = self.pattern_to_regex(pattern)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ncls = <pathspec.patterns.gitwildmatch.GitWildMatchPattern object at 0x0000013A348877C0>\npattern = \'*.txt\'\n\n    def pattern_to_regex(cls, pattern):\n>       regex_pattern = convert_pattern_to_regex(pattern)\nE       NameError: name \'convert_pattern_to_regex\' is not defined\n\nrepos\\python-pathspec\\pathspec\\patterns\\gitwildmatch.py:30: NameError', 'self = <tests.test_02_gitwildmatch.GitWildMatchTest testMethod=test_00_empty>\n\n    def test_00_empty(self):\n    \t""""""\n    \tTests an empty pattern.\n    \t""""""\n>   \tregex, include = GitWildMatchPattern.pattern_to_regex(\'\')\nE    TypeError: GitWildMatchPattern.pattern_to_regex() missing 1 required positional argument: \'pattern\'\n\nrepos\\python-pathspec\\tests\\test_02_gitwildmatch.py:44: TypeError', 'self = <tests.test_02_gitwildmatch.GitWildMatchTest testMethod=test_01_absolute>\n\n    def test_01_absolute(self):\n    \t""""""\n    \tTests an absolute path pattern.\n    \n    \tThis should match:\n    \n    \t\tan/absolute/file/path\n    \t\tan/absolute/file/path/foo\n    \n    \tThis should NOT match:\n    \n    \t\tfoo/an/absolute/file/path\n    \t""""""\n>   \tregex, include = GitWildMatchPattern.pattern_to_regex(\'/an/absolute/file/path\')\nE    TypeError: GitWildMatchPattern.pattern_to_regex() missing 1 required positional argument: \'pattern\'\n\nrepos\\python-pathspec\\tests\\test_02_gitwildmatch.py:61: TypeError', 'self = <tests.test_02_gitwildmatch.GitWildMatchTest testMethod=test_01_absolute_ignore>\n\n    def test_01_absolute_ignore(self):\n    \t""""""\n    \tTests an ignore absolute path pattern.\n    \t""""""\n>   \tregex, include = GitWildMatchPattern.pattern_to_regex(\'!/foo/build\')\nE    TypeError: GitWildMatchPattern.pattern_to_regex() missing 1 required positional argument: \'pattern\'\n\nrepos\\python-pathspec\\tests\\test_02_gitwildmatch.py:80: TypeError', 'self = <tests.test_02_gitwildmatch.GitWildMatchTest testMethod=test_01_absolute_root>\n\n    def test_01_absolute_root(self):\n    \t""""""\n    \tTests a single root absolute path pattern.\n    \n    \tThis should NOT match any file (according to git check-ignore\n    \t(v2.4.1)).\n    \t""""""\n>   \tregex, include = GitWildMatchPattern.pattern_to_regex(\'/\')\nE    TypeError: GitWildMatchPattern.pattern_to_regex() missing 1 required positional argument: \'pattern\'\n\nrepos\\python-pathspec\\tests\\test_02_gitwildmatch.py:102: TypeError', 'self = <tests.test_02_gitwildmatch.GitWildMatchTest testMethod=test_01_relative>\n\n    def test_01_relative(self):\n    \t""""""\n    \tTests a relative path pattern.\n    \n    \tThis should match:\n    \n    \t\tspam\n    \t\tspam/\n    \t\tfoo/spam\n    \t\tspam/foo\n    \t\tfoo/spam/bar\n    \t""""""\n>   \tregex, include = GitWildMatchPattern.pattern_to_regex(\'spam\')\nE    TypeError: GitWildMatchPattern.pattern_to_regex() missing 1 required positional argument: \'pattern\'\n\nrepos\\python-pathspec\\tests\\test_02_gitwildmatch.py:118: TypeError', 'self = <tests.test_02_gitwildmatch.GitWildMatchTest testMethod=test_01_relative_nested>\n\n    def test_01_relative_nested(self):\n    \t""""""\n    \tTests a relative nested path pattern.\n    \n    \tThis should match:\n    \n    \t\tfoo/spam\n    \t\tfoo/spam/bar\n    \n    \tThis should **not** match (according to git check-ignore (v2.4.1)):\n    \n    \t\tbar/foo/spam\n    \t""""""\n>   \tregex, include = GitWildMatchPattern.pattern_to_regex(\'foo/spam\')\nE    TypeError: GitWildMatchPattern.pattern_to_regex() missing 1 required positional argument: \'pattern\'\n\nrepos\\python-pathspec\\tests\\test_02_gitwildmatch.py:151: TypeError', 'self = <tests.test_02_gitwildmatch.GitWildMatchTest testMethod=test_02_comment>\n\n    def test_02_comment(self):\n    \t""""""\n    \tTests a comment pattern.\n    \t""""""\n>   \tregex, include = GitWildMatchPattern.pattern_to_regex(\'# Cork soakers.\')\nE    TypeError: GitWildMatchPattern.pattern_to_regex() missing 1 required positional argument: \'pattern\'\n\nrepos\\python-pathspec\\tests\\test_02_gitwildmatch.py:170: TypeError', 'self = <tests.test_02_gitwildmatch.GitWildMatchTest testMethod=test_02_ignore>\n\n    def test_02_ignore(self):\n    \t""""""\n    \tTests an exclude pattern.\n    \n    \tThis should NOT match (according to git check-ignore (v2.4.1)):\n    \n    \t\ttemp/foo\n    \t""""""\n>   \tregex, include = GitWildMatchPattern.pattern_to_regex(\'!temp\')\nE    TypeError: GitWildMatchPattern.pattern_to_regex() missing 1 required positional argument: \'pattern\'\n\nrepos\\python-pathspec\\tests\\test_02_gitwildmatch.py:182: TypeError', 'self = <tests.test_02_gitwildmatch.GitWildMatchTest testMethod=test_03_child_double_asterisk>\n\n    def test_03_child_double_asterisk(self):\n    \t""""""\n    \tTests a directory name with a double-asterisk child\n    \tdirectory.\n    \n    \tThis should match:\n    \n    \t\tspam/bar\n    \n    \tThis should **not** match (according to git check-ignore (v2.4.1)):\n    \n    \t\tfoo/spam/bar\n    \t""""""\n>   \tregex, include = GitWildMatchPattern.pattern_to_regex(\'spam/**\')\nE    TypeError: GitWildMatchPattern.pattern_to_regex() missing 1 required positional argument: \'pattern\'\n\nrepos\\python-pathspec\\tests\\test_02_gitwildmatch.py:209: TypeError', 'self = <tests.test_02_gitwildmatch.GitWildMatchTest testMethod=test_03_double_asterisk_trailing_slash_edge_case>\n\n    def test_03_double_asterisk_trailing_slash_edge_case(self):\n    \t""""""\n    \tTests the edge-case **/ pattern.\n    \n    \tThis should match everything except individual files in the root directory.\n    \t""""""\n>   \tregex, include = GitWildMatchPattern.pattern_to_regex(\'**/\')\nE    TypeError: GitWildMatchPattern.pattern_to_regex() missing 1 required positional argument: \'pattern\'\n\nrepos\\python-pathspec\\tests\\test_02_gitwildmatch.py:357: TypeError', 'self = <tests.test_02_gitwildmatch.GitWildMatchTest testMethod=test_03_duplicate_leading_double_asterisk_edge_case>\n\n    def test_03_duplicate_leading_double_asterisk_edge_case(self):\n    \t""""""\n    \tRegression test for duplicate leading **/ bug.\n    \t""""""\n>   \tregex, include = GitWildMatchPattern.pattern_to_regex(\'**\')\nE    TypeError: GitWildMatchPattern.pattern_to_regex() missing 1 required positional argument: \'pattern\'\n\nrepos\\python-pathspec\\tests\\test_02_gitwildmatch.py:315: TypeError', 'self = <tests.test_02_gitwildmatch.GitWildMatchTest testMethod=test_03_inner_double_asterisk>\n\n    def test_03_inner_double_asterisk(self):\n    \t""""""\n    \tTests a path with an inner double-asterisk directory.\n    \n    \tThis should match:\n    \n    \t\tleft/right\n    \t\tleft/bar/right\n    \t\tleft/foo/bar/right\n    \t\tleft/bar/right/foo\n    \n    \tThis should **not** match (according to git check-ignore (v2.4.1)):\n    \n    \t\tfoo/left/bar/right\n    \t""""""\n>   \tregex, include = GitWildMatchPattern.pattern_to_regex(\'left/**/right\')\nE    TypeError: GitWildMatchPattern.pattern_to_regex() missing 1 required positional argument: \'pattern\'\n\nrepos\\python-pathspec\\tests\\test_02_gitwildmatch.py:235: TypeError', 'self = <tests.test_02_gitwildmatch.GitWildMatchTest testMethod=test_03_only_double_asterisk>\n\n    def test_03_only_double_asterisk(self):\n    \t""""""\n    \tTests a double-asterisk pattern which matches everything.\n    \t""""""\n>   \tregex, include = GitWildMatchPattern.pattern_to_regex(\'**\')\nE    TypeError: GitWildMatchPattern.pattern_to_regex() missing 1 required positional argument: \'pattern\'\n\nrepos\\python-pathspec\\tests\\test_02_gitwildmatch.py:258: TypeError', 'self = <tests.test_02_gitwildmatch.GitWildMatchTest testMethod=test_03_parent_double_asterisk>\n\n    def test_03_parent_double_asterisk(self):\n    \t""""""\n    \tTests a file name with a double-asterisk parent directory.\n    \n    \tThis should match:\n    \n    \t\tspam\n    \t\tfoo/spam\n    \t\tfoo/spam/bar\n    \t""""""\n>   \tregex, include = GitWildMatchPattern.pattern_to_regex(\'**/spam\')\nE    TypeError: GitWildMatchPattern.pattern_to_regex() missing 1 required positional argument: \'pattern\'\n\nrepos\\python-pathspec\\tests\\test_02_gitwildmatch.py:295: TypeError', 'self = <tests.test_02_gitwildmatch.GitWildMatchTest testMethod=test_04_infix_wildcard>\n\n    def test_04_infix_wildcard(self):\n    \t""""""\n    \tTests a pattern with an infix wildcard.\n    \n    \tThis should match:\n    \n    \t\tfoo--bar\n    \t\tfoo-hello-bar\n    \t\ta/foo-hello-bar\n    \t\tfoo-hello-bar/b\n    \t\ta/foo-hello-bar/b\n    \t""""""\n>   \tregex, include = GitWildMatchPattern.pattern_to_regex(\'foo-*-bar\')\nE    TypeError: GitWildMatchPattern.pattern_to_regex() missing 1 required positional argument: \'pattern\'\n\nrepos\\python-pathspec\\tests\\test_02_gitwildmatch.py:377: TypeError', 'self = <tests.test_02_gitwildmatch.GitWildMatchTest testMethod=test_04_postfix_wildcard>\n\n    def test_04_postfix_wildcard(self):\n    \t""""""\n    \tTests a pattern with a postfix wildcard.\n    \n    \tThis should match:\n    \n    \t\t~temp-\n    \t\t~temp-foo\n    \t\t~temp-foo/bar\n    \t\tfoo/~temp-bar\n    \t\tfoo/~temp-bar/baz\n    \t""""""\n>   \tregex, include = GitWildMatchPattern.pattern_to_regex(\'~temp-*\')\nE    TypeError: GitWildMatchPattern.pattern_to_regex() missing 1 required positional argument: \'pattern\'\n\nrepos\\python-pathspec\\tests\\test_02_gitwildmatch.py:409: TypeError', 'self = <tests.test_02_gitwildmatch.GitWildMatchTest testMethod=test_04_prefix_wildcard>\n\n    def test_04_prefix_wildcard(self):\n    \t""""""\n    \tTests a pattern with a prefix wildcard.\n    \n    \tThis should match:\n    \n    \t\tbar.py\n    \t\tbar.py/\n    \t\tfoo/bar.py\n    \t\tfoo/bar.py/baz\n    \t""""""\n>   \tregex, include = GitWildMatchPattern.pattern_to_regex(\'*.py\')\nE    TypeError: GitWildMatchPattern.pattern_to_regex() missing 1 required positional argument: \'pattern\'\n\nrepos\\python-pathspec\\tests\\test_02_gitwildmatch.py:440: TypeError', 'self = <tests.test_02_gitwildmatch.GitWildMatchTest testMethod=test_05_directory>\n\n    def test_05_directory(self):\n    \t""""""\n    \tTests a directory pattern.\n    \n    \tThis should match:\n    \n    \t\tdir/\n    \t\tfoo/dir/\n    \t\tfoo/dir/bar\n    \n    \tThis should **not** match:\n    \n    \t\tdir\n    \t""""""\n>   \tregex, include = GitWildMatchPattern.pattern_to_regex(\'dir/\')\nE    TypeError: GitWildMatchPattern.pattern_to_regex() missing 1 required positional argument: \'pattern\'\n\nrepos\\python-pathspec\\tests\\test_02_gitwildmatch.py:472: TypeError', 'self = <tests.test_02_gitwildmatch.GitWildMatchTest testMethod=test_07_match_bytes_and_bytes>\n\n    def test_07_match_bytes_and_bytes(self):\n    \t""""""\n    \tTest byte string patterns matching byte string paths.\n    \t""""""\n>   \tpattern = GitWildMatchPattern(b\'*.py\')\n\nrepos\\python-pathspec\\tests\\test_02_gitwildmatch.py:557: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\python-pathspec\\pathspec\\pattern.py:118: in __init__\n    regex, include = self.pattern_to_regex(pattern)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ncls = <pathspec.patterns.gitwildmatch.GitWildMatchPattern object at 0x0000013A3496D000>\npattern = b\'*.py\'\n\n    def pattern_to_regex(cls, pattern):\n>       regex_pattern = convert_pattern_to_regex(pattern)\nE       NameError: name \'convert_pattern_to_regex\' is not defined\n\nrepos\\python-pathspec\\pathspec\\patterns\\gitwildmatch.py:30: NameError', 'self = <tests.test_02_gitwildmatch.GitWildMatchTest testMethod=test_07_match_bytes_and_bytes_complete>\n\n    def test_07_match_bytes_and_bytes_complete(self):\n    \t""""""\n    \tTest byte string patterns matching byte string paths.\n    \t""""""\n    \tencoded = bytes(bytearray(range(0, 256)))\n    \n    \t# Forward slashes cannot be escaped with the current implementation.\n    \t# Remove ASCII 47.\n    \tfs_ord = ord(\'/\')\n    \tencoded = encoded[:fs_ord] + encoded[fs_ord+1:]\n    \n    \tescaped = b"""".join(b""\\\\"" + encoded[i:i+1] for i in range(len(encoded)))\n    \n>   \tpattern = GitWildMatchPattern(escaped)\n\nrepos\\python-pathspec\\tests\\test_02_gitwildmatch.py:574: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\python-pathspec\\pathspec\\pattern.py:118: in __init__\n    regex, include = self.pattern_to_regex(pattern)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ncls = <pathspec.patterns.gitwildmatch.GitWildMatchPattern object at 0x0000013A34941F00>\npattern = b\'\\\\\\x00\\\\\\x01\\\\\\x02\\\\\\x03\\\\\\x04\\\\\\x05\\\\\\x06\\\\\\x07\\\\\\x08\\\\\\t\\\\\\n\\\\\\x0b\\\\\\x0c\\\\\\r\\\\\\x0e\\\\\\x0f\\\\\\x10\\\\\\x11\\\\\\x12\\\\\\x13\\\\...\\xec\\\\\\xed\\\\\\xee\\\\\\xef\\\\\\xf0\\\\\\xf1\\\\\\xf2\\\\\\xf3\\\\\\xf4\\\\\\xf5\\\\\\xf6\\\\\\xf7\\\\\\xf8\\\\\\xf9\\\\\\xfa\\\\\\xfb\\\\\\xfc\\\\\\xfd\\\\\\xfe\\\\\\xff\'\n\n    def pattern_to_regex(cls, pattern):\n>       regex_pattern = convert_pattern_to_regex(pattern)\nE       NameError: name \'convert_pattern_to_regex\' is not defined\n\nrepos\\python-pathspec\\pathspec\\patterns\\gitwildmatch.py:30: NameError', 'self = <tests.test_02_gitwildmatch.GitWildMatchTest testMethod=test_07_match_bytes_and_unicode_fail>\n\n    def test_07_match_bytes_and_unicode_fail(self):\n    \t""""""\n    \tTest byte string patterns matching byte string paths.\n    \t""""""\n>   \tpattern = GitWildMatchPattern(b\'*.py\')\n\nrepos\\python-pathspec\\tests\\test_02_gitwildmatch.py:582: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\python-pathspec\\pathspec\\pattern.py:118: in __init__\n    regex, include = self.pattern_to_regex(pattern)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ncls = <pathspec.patterns.gitwildmatch.GitWildMatchPattern object at 0x0000013A34751F40>\npattern = b\'*.py\'\n\n    def pattern_to_regex(cls, pattern):\n>       regex_pattern = convert_pattern_to_regex(pattern)\nE       NameError: name \'convert_pattern_to_regex\' is not defined\n\nrepos\\python-pathspec\\pathspec\\patterns\\gitwildmatch.py:30: NameError', 'self = <tests.test_02_gitwildmatch.GitWildMatchTest testMethod=test_07_match_unicode_and_bytes_fail>\n\n    def test_07_match_unicode_and_bytes_fail(self):\n    \t""""""\n    \tTest unicode patterns with byte paths.\n    \t""""""\n>   \tpattern = GitWildMatchPattern(\'*.py\')\n\nrepos\\python-pathspec\\tests\\test_02_gitwildmatch.py:590: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\python-pathspec\\pathspec\\pattern.py:118: in __init__\n    regex, include = self.pattern_to_regex(pattern)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ncls = <pathspec.patterns.gitwildmatch.GitWildMatchPattern object at 0x0000013A34615940>\npattern = \'*.py\'\n\n    def pattern_to_regex(cls, pattern):\n>       regex_pattern = convert_pattern_to_regex(pattern)\nE       NameError: name \'convert_pattern_to_regex\' is not defined\n\nrepos\\python-pathspec\\pathspec\\patterns\\gitwildmatch.py:30: NameError', 'self = <tests.test_02_gitwildmatch.GitWildMatchTest testMethod=test_07_match_unicode_and_unicode>\n\n    def test_07_match_unicode_and_unicode(self):\n    \t""""""\n    \tTest unicode patterns with unicode paths.\n    \t""""""\n>   \tpattern = GitWildMatchPattern(\'*.py\')\n\nrepos\\python-pathspec\\tests\\test_02_gitwildmatch.py:598: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\python-pathspec\\pathspec\\pattern.py:118: in __init__\n    regex, include = self.pattern_to_regex(pattern)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ncls = <pathspec.patterns.gitwildmatch.GitWildMatchPattern object at 0x0000013A348E64C0>\npattern = \'*.py\'\n\n    def pattern_to_regex(cls, pattern):\n>       regex_pattern = convert_pattern_to_regex(pattern)\nE       NameError: name \'convert_pattern_to_regex\' is not defined\n\nrepos\\python-pathspec\\pathspec\\patterns\\gitwildmatch.py:30: NameError', 'self = <tests.test_02_gitwildmatch.GitWildMatchTest testMethod=test_09_single_escape_fail>\n\n    def test_09_single_escape_fail(self):\n    \t""""""\n    \tTest an escape on a line by itself.\n    \t""""""\n>   \tself._check_invalid_pattern(""\\\\"")\n\nrepos\\python-pathspec\\tests\\test_02_gitwildmatch.py:615: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\python-pathspec\\tests\\test_02_gitwildmatch.py:38: in _check_invalid_pattern\n    GitWildMatchPattern(git_ignore_pattern)\nrepos\\python-pathspec\\pathspec\\pattern.py:118: in __init__\n    regex, include = self.pattern_to_regex(pattern)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def pattern_to_regex(cls, pattern):\n>       regex_pattern = convert_pattern_to_regex(pattern)\nE       NameError: name \'convert_pattern_to_regex\' is not defined\n\nrepos\\python-pathspec\\pathspec\\patterns\\gitwildmatch.py:30: NameError', 'self = <tests.test_02_gitwildmatch.GitWildMatchTest testMethod=test_09_single_exclamation_mark_fail>\n\n    def test_09_single_exclamation_mark_fail(self):\n    \t""""""\n    \tTest an escape on a line by itself.\n    \t""""""\n>   \tself._check_invalid_pattern(""!"")\n\nrepos\\python-pathspec\\tests\\test_02_gitwildmatch.py:621: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\python-pathspec\\tests\\test_02_gitwildmatch.py:38: in _check_invalid_pattern\n    GitWildMatchPattern(git_ignore_pattern)\nrepos\\python-pathspec\\pathspec\\pattern.py:118: in __init__\n    regex, include = self.pattern_to_regex(pattern)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def pattern_to_regex(cls, pattern):\n>       regex_pattern = convert_pattern_to_regex(pattern)\nE       NameError: name \'convert_pattern_to_regex\' is not defined\n\nrepos\\python-pathspec\\pathspec\\patterns\\gitwildmatch.py:30: NameError', 'self = <tests.test_02_gitwildmatch.GitWildMatchTest testMethod=test_10_escape_asterisk_end>\n\n    def test_10_escape_asterisk_end(self):\n    \t""""""\n    \tTest escaping an asterisk at the end of a line.\n    \t""""""\n>   \tpattern = GitWildMatchPattern(""asteris\\\\*"")\n\nrepos\\python-pathspec\\tests\\test_02_gitwildmatch.py:627: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\python-pathspec\\pathspec\\pattern.py:118: in __init__\n    regex, include = self.pattern_to_regex(pattern)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ncls = <pathspec.patterns.gitwildmatch.GitWildMatchPattern object at 0x0000013A34753D40>\npattern = \'asteris\\\\*\'\n\n    def pattern_to_regex(cls, pattern):\n>       regex_pattern = convert_pattern_to_regex(pattern)\nE       NameError: name \'convert_pattern_to_regex\' is not defined\n\nrepos\\python-pathspec\\pathspec\\patterns\\gitwildmatch.py:30: NameError', 'self = <tests.test_02_gitwildmatch.GitWildMatchTest testMethod=test_10_escape_asterisk_mid>\n\n    def test_10_escape_asterisk_mid(self):\n    \t""""""\n    \tTest escaping an asterisk in the middle of a line.\n    \t""""""\n>   \tpattern = GitWildMatchPattern(""as\\\\*erisk"")\n\nrepos\\python-pathspec\\tests\\test_02_gitwildmatch.py:638: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\python-pathspec\\pathspec\\pattern.py:118: in __init__\n    regex, include = self.pattern_to_regex(pattern)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ncls = <pathspec.patterns.gitwildmatch.GitWildMatchPattern object at 0x0000013A3488B540>\npattern = \'as\\\\*erisk\'\n\n    def pattern_to_regex(cls, pattern):\n>       regex_pattern = convert_pattern_to_regex(pattern)\nE       NameError: name \'convert_pattern_to_regex\' is not defined\n\nrepos\\python-pathspec\\pathspec\\patterns\\gitwildmatch.py:30: NameError', 'self = <tests.test_02_gitwildmatch.GitWildMatchTest testMethod=test_10_escape_asterisk_start>\n\n    def test_10_escape_asterisk_start(self):\n    \t""""""\n    \tTest escaping an asterisk at the start of a line.\n    \t""""""\n>   \tpattern = GitWildMatchPattern(""\\\\*sterisk"")\n\nrepos\\python-pathspec\\tests\\test_02_gitwildmatch.py:649: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\python-pathspec\\pathspec\\pattern.py:118: in __init__\n    regex, include = self.pattern_to_regex(pattern)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ncls = <pathspec.patterns.gitwildmatch.GitWildMatchPattern object at 0x0000013A34738D00>\npattern = \'\\\\*sterisk\'\n\n    def pattern_to_regex(cls, pattern):\n>       regex_pattern = convert_pattern_to_regex(pattern)\nE       NameError: name \'convert_pattern_to_regex\' is not defined\n\nrepos\\python-pathspec\\pathspec\\patterns\\gitwildmatch.py:30: NameError', 'self = <tests.test_02_gitwildmatch.GitWildMatchTest testMethod=test_10_escape_exclamation_mark_start>\n\n    def test_10_escape_exclamation_mark_start(self):\n    \t""""""\n    \tTest escaping an exclamation mark at the start of a line.\n    \t""""""\n>   \tpattern = GitWildMatchPattern(""\\\\!mark"")\n\nrepos\\python-pathspec\\tests\\test_02_gitwildmatch.py:660: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\python-pathspec\\pathspec\\pattern.py:118: in __init__\n    regex, include = self.pattern_to_regex(pattern)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ncls = <pathspec.patterns.gitwildmatch.GitWildMatchPattern object at 0x0000013A3495F4C0>\npattern = \'\\\\!mark\'\n\n    def pattern_to_regex(cls, pattern):\n>       regex_pattern = convert_pattern_to_regex(pattern)\nE       NameError: name \'convert_pattern_to_regex\' is not defined\n\nrepos\\python-pathspec\\pathspec\\patterns\\gitwildmatch.py:30: NameError', 'self = <tests.test_02_gitwildmatch.GitWildMatchTest testMethod=test_10_escape_pound_start>\n\n    def test_10_escape_pound_start(self):\n    \t""""""\n    \tTest escaping a pound sign at the start of a line.\n    \t""""""\n>   \tpattern = GitWildMatchPattern(""\\\\#sign"")\n\nrepos\\python-pathspec\\tests\\test_02_gitwildmatch.py:670: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\python-pathspec\\pathspec\\pattern.py:118: in __init__\n    regex, include = self.pattern_to_regex(pattern)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ncls = <pathspec.patterns.gitwildmatch.GitWildMatchPattern object at 0x0000013A34839780>\npattern = \'\\\\#sign\'\n\n    def pattern_to_regex(cls, pattern):\n>       regex_pattern = convert_pattern_to_regex(pattern)\nE       NameError: name \'convert_pattern_to_regex\' is not defined\n\nrepos\\python-pathspec\\pathspec\\patterns\\gitwildmatch.py:30: NameError', 'self = <tests.test_02_gitwildmatch.GitWildMatchTest testMethod=test_11_issue_19_directory_a>\n\n    def test_11_issue_19_directory_a(self):\n    \t""""""\n    \tTest a directory discrepancy, scenario A.\n    \t""""""\n    \t# NOTE: The result from GitWildMatchPattern will differ from GitIgnoreSpec.\n>   \tpattern = GitWildMatchPattern(""dirG/"")\n\nrepos\\python-pathspec\\tests\\test_02_gitwildmatch.py:681: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\python-pathspec\\pathspec\\pattern.py:118: in __init__\n    regex, include = self.pattern_to_regex(pattern)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ncls = <pathspec.patterns.gitwildmatch.GitWildMatchPattern object at 0x0000013A34752680>\npattern = \'dirG/\'\n\n    def pattern_to_regex(cls, pattern):\n>       regex_pattern = convert_pattern_to_regex(pattern)\nE       NameError: name \'convert_pattern_to_regex\' is not defined\n\nrepos\\python-pathspec\\pathspec\\patterns\\gitwildmatch.py:30: NameError', 'self = <tests.test_02_gitwildmatch.GitWildMatchTest testMethod=test_11_issue_19_directory_b>\n\n    def test_11_issue_19_directory_b(self):\n    \t""""""\n    \tTest a directory discrepancy, scenario B.\n    \t""""""\n    \t# NOTE: The result from GitWildMatchPattern will differ from GitIgnoreSpec.\n>   \tpattern = GitWildMatchPattern(""dirG/*"")\n\nrepos\\python-pathspec\\tests\\test_02_gitwildmatch.py:702: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\python-pathspec\\pathspec\\pattern.py:118: in __init__\n    regex, include = self.pattern_to_regex(pattern)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ncls = <pathspec.patterns.gitwildmatch.GitWildMatchPattern object at 0x0000013A349875C0>\npattern = \'dirG/*\'\n\n    def pattern_to_regex(cls, pattern):\n>       regex_pattern = convert_pattern_to_regex(pattern)\nE       NameError: name \'convert_pattern_to_regex\' is not defined\n\nrepos\\python-pathspec\\pathspec\\patterns\\gitwildmatch.py:30: NameError', 'self = <tests.test_02_gitwildmatch.GitWildMatchTest testMethod=test_11_issue_19_directory_c>\n\n    def test_11_issue_19_directory_c(self):\n    \t""""""\n    \tTest a directory discrepancy, scenario C.\n    \t""""""\n    \t# NOTE: The result from GitWildMatchPattern will differ from GitIgnoreSpec.\n>   \tpattern = GitWildMatchPattern(""dirG/**"")\n\nrepos\\python-pathspec\\tests\\test_02_gitwildmatch.py:723: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\python-pathspec\\pathspec\\pattern.py:118: in __init__\n    regex, include = self.pattern_to_regex(pattern)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ncls = <pathspec.patterns.gitwildmatch.GitWildMatchPattern object at 0x0000013A34739000>\npattern = \'dirG/**\'\n\n    def pattern_to_regex(cls, pattern):\n>       regex_pattern = convert_pattern_to_regex(pattern)\nE       NameError: name \'convert_pattern_to_regex\' is not defined\n\nrepos\\python-pathspec\\pathspec\\patterns\\gitwildmatch.py:30: NameError', 'self = <tests.test_02_gitwildmatch.GitWildMatchTest testMethod=test_12_asterisk_1_regex>\n\n    def test_12_asterisk_1_regex(self):\n    \t""""""\n    \tTest a relative asterisk path pattern\'s regular expression.\n    \t""""""\n>   \tregex, include = GitWildMatchPattern.pattern_to_regex(\'*\')\nE    TypeError: GitWildMatchPattern.pattern_to_regex() missing 1 required positional argument: \'pattern\'\n\nrepos\\python-pathspec\\tests\\test_02_gitwildmatch.py:743: TypeError', 'self = <tests.test_02_gitwildmatch.GitWildMatchTest testMethod=test_12_asterisk_2_regex_equivalent>\n\n    def test_12_asterisk_2_regex_equivalent(self):\n    \t""""""\n    \tTest a path pattern equivalent to the relative asterisk using double\n    \tasterisk.\n    \t""""""\n>   \tregex, include = GitWildMatchPattern.pattern_to_regex(\'*\')\nE    TypeError: GitWildMatchPattern.pattern_to_regex() missing 1 required positional argument: \'pattern\'\n\nrepos\\python-pathspec\\tests\\test_02_gitwildmatch.py:752: TypeError', 'self = <tests.test_02_gitwildmatch.GitWildMatchTest testMethod=test_12_asterisk_3_child>\n\n    def test_12_asterisk_3_child(self):\n    \t""""""\n    \tTest a relative asterisk path pattern matching a direct child path.\n    \t""""""\n>   \tpattern = GitWildMatchPattern(""*"")\n\nrepos\\python-pathspec\\tests\\test_02_gitwildmatch.py:764: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\python-pathspec\\pathspec\\pattern.py:118: in __init__\n    regex, include = self.pattern_to_regex(pattern)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ncls = <pathspec.patterns.gitwildmatch.GitWildMatchPattern object at 0x0000013A34982980>\npattern = \'*\'\n\n    def pattern_to_regex(cls, pattern):\n>       regex_pattern = convert_pattern_to_regex(pattern)\nE       NameError: name \'convert_pattern_to_regex\' is not defined\n\nrepos\\python-pathspec\\pathspec\\patterns\\gitwildmatch.py:30: NameError', 'self = <tests.test_02_gitwildmatch.GitWildMatchTest testMethod=test_12_asterisk_4_descendant>\n\n    def test_12_asterisk_4_descendant(self):\n    \t""""""\n    \tTest a relative asterisk path pattern matching a descendant path.\n    \t""""""\n>   \tpattern = GitWildMatchPattern(""*"")\n\nrepos\\python-pathspec\\tests\\test_02_gitwildmatch.py:771: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\python-pathspec\\pathspec\\pattern.py:118: in __init__\n    regex, include = self.pattern_to_regex(pattern)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ncls = <pathspec.patterns.gitwildmatch.GitWildMatchPattern object at 0x0000013A3495C3C0>\npattern = \'*\'\n\n    def pattern_to_regex(cls, pattern):\n>       regex_pattern = convert_pattern_to_regex(pattern)\nE       NameError: name \'convert_pattern_to_regex\' is not defined\n\nrepos\\python-pathspec\\pathspec\\patterns\\gitwildmatch.py:30: NameError', 'self = <tests.test_02_gitwildmatch.GitWildMatchTest testMethod=test_12_issue_62>\n\n    def test_12_issue_62(self):\n    \t""""""\n    \tTest including all files, scenario A.\n    \t""""""\n>   \tpattern = GitWildMatchPattern(""*"")\n\nrepos\\python-pathspec\\tests\\test_02_gitwildmatch.py:778: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\python-pathspec\\pathspec\\pattern.py:118: in __init__\n    regex, include = self.pattern_to_regex(pattern)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ncls = <pathspec.patterns.gitwildmatch.GitWildMatchPattern object at 0x0000013A34878140>\npattern = \'*\'\n\n    def pattern_to_regex(cls, pattern):\n>       regex_pattern = convert_pattern_to_regex(pattern)\nE       NameError: name \'convert_pattern_to_regex\' is not defined\n\nrepos\\python-pathspec\\pathspec\\patterns\\gitwildmatch.py:30: NameError', 'self = <tests.test_02_gitwildmatch.GitWildMatchTest testMethod=test_13_issue_77_1_negate_with_caret>\n\n    def test_13_issue_77_1_negate_with_caret(self):\n    \t""""""\n    \tTest negation using the caret symbol (""^"").\n    \t""""""\n>   \tpattern = GitWildMatchPattern(""a[^gy]c"")\n\nrepos\\python-pathspec\\tests\\test_02_gitwildmatch.py:792: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\python-pathspec\\pathspec\\pattern.py:118: in __init__\n    regex, include = self.pattern_to_regex(pattern)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ncls = <pathspec.patterns.gitwildmatch.GitWildMatchPattern object at 0x0000013A3464F4C0>\npattern = \'a[^gy]c\'\n\n    def pattern_to_regex(cls, pattern):\n>       regex_pattern = convert_pattern_to_regex(pattern)\nE       NameError: name \'convert_pattern_to_regex\' is not defined\n\nrepos\\python-pathspec\\pathspec\\patterns\\gitwildmatch.py:30: NameError', 'self = <tests.test_02_gitwildmatch.GitWildMatchTest testMethod=test_13_issue_77_1_negate_with_exclamation_mark>\n\n    def test_13_issue_77_1_negate_with_exclamation_mark(self):\n    \t""""""\n    \tTest negation using the exclamation mark (""!"").\n    \t""""""\n>   \tpattern = GitWildMatchPattern(""a[!gy]c"")\n\nrepos\\python-pathspec\\tests\\test_02_gitwildmatch.py:808: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\python-pathspec\\pathspec\\pattern.py:118: in __init__\n    regex, include = self.pattern_to_regex(pattern)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ncls = <pathspec.patterns.gitwildmatch.GitWildMatchPattern object at 0x0000013A34983440>\npattern = \'a[!gy]c\'\n\n    def pattern_to_regex(cls, pattern):\n>       regex_pattern = convert_pattern_to_regex(pattern)\nE       NameError: name \'convert_pattern_to_regex\' is not defined\n\nrepos\\python-pathspec\\pathspec\\patterns\\gitwildmatch.py:30: NameError', 'self = <tests.test_02_gitwildmatch.GitWildMatchTest testMethod=test_13_issue_77_2_regex>\n\n    def test_13_issue_77_2_regex(self):\n    \t""""""\n    \tTest the resulting regex for regex bracket expression negation.\n    \t""""""\n>   \tregex, include = GitWildMatchPattern.pattern_to_regex(""a[^b]c"")\nE    TypeError: GitWildMatchPattern.pattern_to_regex() missing 1 required positional argument: \'pattern\'\n\nrepos\\python-pathspec\\tests\\test_02_gitwildmatch.py:824: TypeError', 'self = <tests.test_02_gitwildmatch.GitWildMatchTest testMethod=test_14_issue_81_a>\n\n    def test_14_issue_81_a(self):\n    \t""""""\n    \tTest ignoring files in a directory, scenario A.\n    \t""""""\n>   \tpattern = GitWildMatchPattern(""!libfoo/**"")\n\nrepos\\python-pathspec\\tests\\test_02_gitwildmatch.py:836: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\python-pathspec\\pathspec\\pattern.py:118: in __init__\n    regex, include = self.pattern_to_regex(pattern)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ncls = <pathspec.patterns.gitwildmatch.GitWildMatchPattern object at 0x0000013A349404C0>\npattern = \'!libfoo/**\'\n\n    def pattern_to_regex(cls, pattern):\n>       regex_pattern = convert_pattern_to_regex(pattern)\nE       NameError: name \'convert_pattern_to_regex\' is not defined\n\nrepos\\python-pathspec\\pathspec\\patterns\\gitwildmatch.py:30: NameError', 'self = <tests.test_02_gitwildmatch.GitWildMatchTest testMethod=test_14_issue_81_b>\n\n    def test_14_issue_81_b(self):\n    \t""""""\n    \tTest ignoring files in a directory, scenario B.\n    \t""""""\n>   \tpattern = GitWildMatchPattern(""!libfoo/*"")\n\nrepos\\python-pathspec\\tests\\test_02_gitwildmatch.py:846: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\python-pathspec\\pathspec\\pattern.py:118: in __init__\n    regex, include = self.pattern_to_regex(pattern)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ncls = <pathspec.patterns.gitwildmatch.GitWildMatchPattern object at 0x0000013A34981800>\npattern = \'!libfoo/*\'\n\n    def pattern_to_regex(cls, pattern):\n>       regex_pattern = convert_pattern_to_regex(pattern)\nE       NameError: name \'convert_pattern_to_regex\' is not defined\n\nrepos\\python-pathspec\\pathspec\\patterns\\gitwildmatch.py:30: NameError', 'self = <tests.test_02_gitwildmatch.GitWildMatchTest testMethod=test_14_issue_81_c>\n\n    def test_14_issue_81_c(self):\n    \t""""""\n    \tTest ignoring files in a directory, scenario C.\n    \t""""""\n    \t# GitWildMatchPattern will match the file, but GitIgnoreSpec should not.\n>   \tpattern = GitWildMatchPattern(""!libfoo/"")\n\nrepos\\python-pathspec\\tests\\test_02_gitwildmatch.py:857: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\python-pathspec\\pathspec\\pattern.py:118: in __init__\n    regex, include = self.pattern_to_regex(pattern)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ncls = <pathspec.patterns.gitwildmatch.GitWildMatchPattern object at 0x0000013A34950240>\npattern = \'!libfoo/\'\n\n    def pattern_to_regex(cls, pattern):\n>       regex_pattern = convert_pattern_to_regex(pattern)\nE       NameError: name \'convert_pattern_to_regex\' is not defined\n\nrepos\\python-pathspec\\pathspec\\patterns\\gitwildmatch.py:30: NameError', 'self = <tests.test_03_pathspec.PathSpecTest testMethod=test_01_absolute_dir_paths_1>\n\n    def test_01_absolute_dir_paths_1(self):\n    \t""""""\n    \tTests that absolute paths will be properly normalized and matched.\n    \t""""""\n>   \tspec = PathSpec.from_lines(\'gitwildmatch\', [\n    \t\t\'foo\',\n    \t])\n\nrepos\\python-pathspec\\tests\\test_03_pathspec.py:61: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\python-pathspec\\pathspec\\pathspec.py:212: in from_lines\n    patterns = [pattern_factory(line) for line in lines if line]\nrepos\\python-pathspec\\pathspec\\pattern.py:118: in __init__\n    regex, include = self.pattern_to_regex(pattern)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ncls = <pathspec.patterns.gitwildmatch.GitWildMatchPattern object at 0x0000013A34722200>\npattern = \'foo\'\n\n    def pattern_to_regex(cls, pattern):\n>       regex_pattern = convert_pattern_to_regex(pattern)\nE       NameError: name \'convert_pattern_to_regex\' is not defined\n\nrepos\\python-pathspec\\pathspec\\patterns\\gitwildmatch.py:30: NameError', 'self = <tests.test_03_pathspec.PathSpecTest testMethod=test_01_absolute_dir_paths_2>\n\n    def test_01_absolute_dir_paths_2(self):\n    \t""""""\n    \tTests that absolute paths will be properly normalized and matched.\n    \t""""""\n>   \tspec = PathSpec.from_lines(\'gitwildmatch\', [\n    \t\t\'/foo\',\n    \t])\n\nrepos\\python-pathspec\\tests\\test_03_pathspec.py:90: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\python-pathspec\\pathspec\\pathspec.py:212: in from_lines\n    patterns = [pattern_factory(line) for line in lines if line]\nrepos\\python-pathspec\\pathspec\\pattern.py:118: in __init__\n    regex, include = self.pattern_to_regex(pattern)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ncls = <pathspec.patterns.gitwildmatch.GitWildMatchPattern object at 0x0000013A349FB4C0>\npattern = \'/foo\'\n\n    def pattern_to_regex(cls, pattern):\n>       regex_pattern = convert_pattern_to_regex(pattern)\nE       NameError: name \'convert_pattern_to_regex\' is not defined\n\nrepos\\python-pathspec\\pathspec\\patterns\\gitwildmatch.py:30: NameError', 'self = <tests.test_03_pathspec.PathSpecTest testMethod=test_01_check_file_1_include>\n\n    def test_01_check_file_1_include(self):\n    \t""""""\n    \tTest checking a single file that is included.\n    \t""""""\n>   \tspec = PathSpec.from_lines(\'gitwildmatch\', [\n    \t\t""*.txt"",\n    \t\t""!test/"",\n    \t])\n\nrepos\\python-pathspec\\tests\\test_03_pathspec.py:117: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\python-pathspec\\pathspec\\pathspec.py:212: in from_lines\n    patterns = [pattern_factory(line) for line in lines if line]\nrepos\\python-pathspec\\pathspec\\pattern.py:118: in __init__\n    regex, include = self.pattern_to_regex(pattern)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ncls = <pathspec.patterns.gitwildmatch.GitWildMatchPattern object at 0x0000013A34889940>\npattern = \'*.txt\'\n\n    def pattern_to_regex(cls, pattern):\n>       regex_pattern = convert_pattern_to_regex(pattern)\nE       NameError: name \'convert_pattern_to_regex\' is not defined\n\nrepos\\python-pathspec\\pathspec\\patterns\\gitwildmatch.py:30: NameError', 'self = <tests.test_03_pathspec.PathSpecTest testMethod=test_01_check_file_2_exclude>\n\n    def test_01_check_file_2_exclude(self):\n    \t""""""\n    \tTest checking a single file that is excluded.\n    \t""""""\n>   \tspec = PathSpec.from_lines(\'gitwildmatch\', [\n    \t\t""*.txt"",\n    \t\t""!test/"",\n    \t])\n\nrepos\\python-pathspec\\tests\\test_03_pathspec.py:130: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\python-pathspec\\pathspec\\pathspec.py:212: in from_lines\n    patterns = [pattern_factory(line) for line in lines if line]\nrepos\\python-pathspec\\pathspec\\pattern.py:118: in __init__\n    regex, include = self.pattern_to_regex(pattern)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ncls = <pathspec.patterns.gitwildmatch.GitWildMatchPattern object at 0x0000013A346AAE00>\npattern = \'*.txt\'\n\n    def pattern_to_regex(cls, pattern):\n>       regex_pattern = convert_pattern_to_regex(pattern)\nE       NameError: name \'convert_pattern_to_regex\' is not defined\n\nrepos\\python-pathspec\\pathspec\\patterns\\gitwildmatch.py:30: NameError', 'self = <tests.test_03_pathspec.PathSpecTest testMethod=test_01_check_file_3_unmatch>\n\n    def test_01_check_file_3_unmatch(self):\n    \t""""""\n    \tTest checking a single file that is unmatched.\n    \t""""""\n>   \tspec = PathSpec.from_lines(\'gitwildmatch\', [\n    \t\t""*.txt"",\n    \t\t""!test/"",\n    \t])\n\nrepos\\python-pathspec\\tests\\test_03_pathspec.py:143: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\python-pathspec\\pathspec\\pathspec.py:212: in from_lines\n    patterns = [pattern_factory(line) for line in lines if line]\nrepos\\python-pathspec\\pathspec\\pattern.py:118: in __init__\n    regex, include = self.pattern_to_regex(pattern)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ncls = <pathspec.patterns.gitwildmatch.GitWildMatchPattern object at 0x0000013A348AA2C0>\npattern = \'*.txt\'\n\n    def pattern_to_regex(cls, pattern):\n>       regex_pattern = convert_pattern_to_regex(pattern)\nE       NameError: name \'convert_pattern_to_regex\' is not defined\n\nrepos\\python-pathspec\\pathspec\\patterns\\gitwildmatch.py:30: NameError', 'self = <tests.test_03_pathspec.PathSpecTest testMethod=test_01_check_file_4_many>\n\n    def test_01_check_file_4_many(self):\n    \t""""""\n    \tTest that checking files one at a time yields the same results as checking\n    \tmultiples files at once.\n    \t""""""\n>   \tspec = PathSpec.from_lines(\'gitwildmatch\', [\n    \t\t\'*.txt\',\n    \t\t\'!test1/\',\n    \t])\n\nrepos\\python-pathspec\\tests\\test_03_pathspec.py:157: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\python-pathspec\\pathspec\\pathspec.py:212: in from_lines\n    patterns = [pattern_factory(line) for line in lines if line]\nrepos\\python-pathspec\\pathspec\\pattern.py:118: in __init__\n    regex, include = self.pattern_to_regex(pattern)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ncls = <pathspec.patterns.gitwildmatch.GitWildMatchPattern object at 0x0000013A34985D80>\npattern = \'*.txt\'\n\n    def pattern_to_regex(cls, pattern):\n>       regex_pattern = convert_pattern_to_regex(pattern)\nE       NameError: name \'convert_pattern_to_regex\' is not defined\n\nrepos\\python-pathspec\\pathspec\\patterns\\gitwildmatch.py:30: NameError', 'self = <tests.test_03_pathspec.PathSpecTest testMethod=test_01_check_match_files>\n\n    def test_01_check_match_files(self):\n    \t""""""\n    \tTest that checking files and matching files yield the same results.\n    \t""""""\n>   \tspec = PathSpec.from_lines(\'gitwildmatch\', [\n    \t\t\'*.txt\',\n    \t\t\'!test1/**\',\n    \t])\n\nrepos\\python-pathspec\\tests\\test_03_pathspec.py:179: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\python-pathspec\\pathspec\\pathspec.py:212: in from_lines\n    patterns = [pattern_factory(line) for line in lines if line]\nrepos\\python-pathspec\\pathspec\\pattern.py:118: in __init__\n    regex, include = self.pattern_to_regex(pattern)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ncls = <pathspec.patterns.gitwildmatch.GitWildMatchPattern object at 0x0000013A3485E880>\npattern = \'*.txt\'\n\n    def pattern_to_regex(cls, pattern):\n>       regex_pattern = convert_pattern_to_regex(pattern)\nE       NameError: name \'convert_pattern_to_regex\' is not defined\n\nrepos\\python-pathspec\\pathspec\\patterns\\gitwildmatch.py:30: NameError', 'self = <tests.test_03_pathspec.PathSpecTest testMethod=test_01_current_dir_paths>\n\n    def test_01_current_dir_paths(self):\n    \t""""""\n    \tTests that paths referencing the current directory will be properly\n    \tnormalized and matched.\n    \t""""""\n>   \tspec = PathSpec.from_lines(\'gitwildmatch\', [\n    \t\t\'*.txt\',\n    \t\t\'!test1/\',\n    \t])\n\nrepos\\python-pathspec\\tests\\test_03_pathspec.py:203: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\python-pathspec\\pathspec\\pathspec.py:212: in from_lines\n    patterns = [pattern_factory(line) for line in lines if line]\nrepos\\python-pathspec\\pathspec\\pattern.py:118: in __init__\n    regex, include = self.pattern_to_regex(pattern)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ncls = <pathspec.patterns.gitwildmatch.GitWildMatchPattern object at 0x0000013A348C8640>\npattern = \'*.txt\'\n\n    def pattern_to_regex(cls, pattern):\n>       regex_pattern = convert_pattern_to_regex(pattern)\nE       NameError: name \'convert_pattern_to_regex\' is not defined\n\nrepos\\python-pathspec\\pathspec\\patterns\\gitwildmatch.py:30: NameError', 'self = <tests.test_03_pathspec.PathSpecTest testMethod=test_01_empty_path_1>\n\n    def test_01_empty_path_1(self):\n    \t""""""\n    \tTests that patterns that end with an escaped space will be treated properly.\n    \t""""""\n>   \tspec = PathSpec.from_lines(\'gitwildmatch\', [\n    \t\t\'\\\\ \',\n    \t\t\'abc\\\\ \'\n    \t])\n\nrepos\\python-pathspec\\tests\\test_03_pathspec.py:230: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\python-pathspec\\pathspec\\pathspec.py:212: in from_lines\n    patterns = [pattern_factory(line) for line in lines if line]\nrepos\\python-pathspec\\pathspec\\pattern.py:118: in __init__\n    regex, include = self.pattern_to_regex(pattern)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ncls = <pathspec.patterns.gitwildmatch.GitWildMatchPattern object at 0x0000013A346C2280>\npattern = \'\\\\ \'\n\n    def pattern_to_regex(cls, pattern):\n>       regex_pattern = convert_pattern_to_regex(pattern)\nE       NameError: name \'convert_pattern_to_regex\' is not defined\n\nrepos\\python-pathspec\\pathspec\\patterns\\gitwildmatch.py:30: NameError', 'self = <tests.test_03_pathspec.PathSpecTest testMethod=test_01_empty_path_2>\n\n    def test_01_empty_path_2(self):\n    \t""""""\n    \tTests that patterns that end with an escaped space will be treated properly.\n    \t""""""\n    \twith self.assertRaises(GitWildMatchPatternError):\n    \t\t# An escape with double spaces is invalid. Disallow it. Better to be safe\n    \t\t# than sorry.\n>   \t\tPathSpec.from_lines(\'gitwildmatch\', [\n    \t\t\t\'\\\\  \',\n    \t\t])\n\nrepos\\python-pathspec\\tests\\test_03_pathspec.py:257: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\python-pathspec\\pathspec\\pathspec.py:212: in from_lines\n    patterns = [pattern_factory(line) for line in lines if line]\nrepos\\python-pathspec\\pathspec\\pattern.py:118: in __init__\n    regex, include = self.pattern_to_regex(pattern)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def pattern_to_regex(cls, pattern):\n>       regex_pattern = convert_pattern_to_regex(pattern)\nE       NameError: name \'convert_pattern_to_regex\' is not defined\n\nrepos\\python-pathspec\\pathspec\\patterns\\gitwildmatch.py:30: NameError', 'self = <tests.test_03_pathspec.PathSpecTest testMethod=test_01_match_file_1_include>\n\n    def test_01_match_file_1_include(self):\n    \t""""""\n    \tTest matching a single file that is included.\n    \t""""""\n>   \tspec = PathSpec.from_lines(\'gitwildmatch\', [\n    \t\t""*.txt"",\n    \t\t""!test/"",\n    \t])\n\nrepos\\python-pathspec\\tests\\test_03_pathspec.py:265: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\python-pathspec\\pathspec\\pathspec.py:212: in from_lines\n    patterns = [pattern_factory(line) for line in lines if line]\nrepos\\python-pathspec\\pathspec\\pattern.py:118: in __init__\n    regex, include = self.pattern_to_regex(pattern)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ncls = <pathspec.patterns.gitwildmatch.GitWildMatchPattern object at 0x0000013A3462FC00>\npattern = \'*.txt\'\n\n    def pattern_to_regex(cls, pattern):\n>       regex_pattern = convert_pattern_to_regex(pattern)\nE       NameError: name \'convert_pattern_to_regex\' is not defined\n\nrepos\\python-pathspec\\pathspec\\patterns\\gitwildmatch.py:30: NameError', 'self = <tests.test_03_pathspec.PathSpecTest testMethod=test_01_match_file_2_exclude>\n\n    def test_01_match_file_2_exclude(self):\n    \t""""""\n    \tTest matching a single file that is excluded.\n    \t""""""\n>   \tspec = PathSpec.from_lines(\'gitwildmatch\', [\n    \t\t""*.txt"",\n    \t\t""!test/"",\n    \t])\n\nrepos\\python-pathspec\\tests\\test_03_pathspec.py:278: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\python-pathspec\\pathspec\\pathspec.py:212: in from_lines\n    patterns = [pattern_factory(line) for line in lines if line]\nrepos\\python-pathspec\\pathspec\\pattern.py:118: in __init__\n    regex, include = self.pattern_to_regex(pattern)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ncls = <pathspec.patterns.gitwildmatch.GitWildMatchPattern object at 0x0000013A348B27C0>\npattern = \'*.txt\'\n\n    def pattern_to_regex(cls, pattern):\n>       regex_pattern = convert_pattern_to_regex(pattern)\nE       NameError: name \'convert_pattern_to_regex\' is not defined\n\nrepos\\python-pathspec\\pathspec\\patterns\\gitwildmatch.py:30: NameError', 'self = <tests.test_03_pathspec.PathSpecTest testMethod=test_01_match_file_3_unmatch>\n\n    def test_01_match_file_3_unmatch(self):\n    \t""""""\n    \tTest match a single file that is unmatched.\n    \t""""""\n>   \tspec = PathSpec.from_lines(\'gitwildmatch\', [\n    \t\t""*.txt"",\n    \t\t""!test/"",\n    \t])\n\nrepos\\python-pathspec\\tests\\test_03_pathspec.py:291: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\python-pathspec\\pathspec\\pathspec.py:212: in from_lines\n    patterns = [pattern_factory(line) for line in lines if line]\nrepos\\python-pathspec\\pathspec\\pattern.py:118: in __init__\n    regex, include = self.pattern_to_regex(pattern)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ncls = <pathspec.patterns.gitwildmatch.GitWildMatchPattern object at 0x0000013A34980800>\npattern = \'*.txt\'\n\n    def pattern_to_regex(cls, pattern):\n>       regex_pattern = convert_pattern_to_regex(pattern)\nE       NameError: name \'convert_pattern_to_regex\' is not defined\n\nrepos\\python-pathspec\\pathspec\\patterns\\gitwildmatch.py:30: NameError', 'self = <tests.test_03_pathspec.PathSpecTest testMethod=test_01_match_files>\n\n    def test_01_match_files(self):\n    \t""""""\n    \tTest that matching files one at a time yields the same results as matching\n    \tmultiples files at once.\n    \t""""""\n>   \tspec = PathSpec.from_lines(\'gitwildmatch\', [\n    \t\t\'*.txt\',\n    \t\t\'!test1/\',\n    \t])\n\nrepos\\python-pathspec\\tests\\test_03_pathspec.py:305: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\python-pathspec\\pathspec\\pathspec.py:212: in from_lines\n    patterns = [pattern_factory(line) for line in lines if line]\nrepos\\python-pathspec\\pathspec\\pattern.py:118: in __init__\n    regex, include = self.pattern_to_regex(pattern)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ncls = <pathspec.patterns.gitwildmatch.GitWildMatchPattern object at 0x0000013A34616780>\npattern = \'*.txt\'\n\n    def pattern_to_regex(cls, pattern):\n>       regex_pattern = convert_pattern_to_regex(pattern)\nE       NameError: name \'convert_pattern_to_regex\' is not defined\n\nrepos\\python-pathspec\\pathspec\\patterns\\gitwildmatch.py:30: NameError', 'self = <tests.test_03_pathspec.PathSpecTest testMethod=test_01_windows_current_dir_paths>\n\n    def test_01_windows_current_dir_paths(self):\n    \t""""""\n    \tTests that paths referencing the current directory will be properly\n    \tnormalized and matched.\n    \t""""""\n>   \tspec = PathSpec.from_lines(\'gitwildmatch\', [\n    \t\t\'*.txt\',\n    \t\t\'!test1/\',\n    \t])\n\nrepos\\python-pathspec\\tests\\test_03_pathspec.py:328: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\python-pathspec\\pathspec\\pathspec.py:212: in from_lines\n    patterns = [pattern_factory(line) for line in lines if line]\nrepos\\python-pathspec\\pathspec\\pattern.py:118: in __init__\n    regex, include = self.pattern_to_regex(pattern)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ncls = <pathspec.patterns.gitwildmatch.GitWildMatchPattern object at 0x0000013A3465B840>\npattern = \'*.txt\'\n\n    def pattern_to_regex(cls, pattern):\n>       regex_pattern = convert_pattern_to_regex(pattern)\nE       NameError: name \'convert_pattern_to_regex\' is not defined\n\nrepos\\python-pathspec\\pathspec\\patterns\\gitwildmatch.py:30: NameError', 'self = <tests.test_03_pathspec.PathSpecTest testMethod=test_01_windows_paths>\n\n    def test_01_windows_paths(self):\n    \t""""""\n    \tTests that Windows paths will be properly normalized and matched.\n    \t""""""\n>   \tspec = PathSpec.from_lines(\'gitwildmatch\', [\n    \t\t\'*.txt\',\n    \t\t\'!test1/\',\n    \t])\n\nrepos\\python-pathspec\\tests\\test_03_pathspec.py:355: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\python-pathspec\\pathspec\\pathspec.py:212: in from_lines\n    patterns = [pattern_factory(line) for line in lines if line]\nrepos\\python-pathspec\\pathspec\\pattern.py:118: in __init__\n    regex, include = self.pattern_to_regex(pattern)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ncls = <pathspec.patterns.gitwildmatch.GitWildMatchPattern object at 0x0000013A349F3500>\npattern = \'*.txt\'\n\n    def pattern_to_regex(cls, pattern):\n>       regex_pattern = convert_pattern_to_regex(pattern)\nE       NameError: name \'convert_pattern_to_regex\' is not defined\n\nrepos\\python-pathspec\\pathspec\\patterns\\gitwildmatch.py:30: NameError', 'self = <tests.test_03_pathspec.PathSpecTest testMethod=test_02_eq>\n\n    def test_02_eq(self):\n    \t""""""\n    \tTests equality.\n    \t""""""\n>   \tfirst_spec = PathSpec.from_lines(\'gitwildmatch\', [\n    \t\t\'*.txt\',\n    \t\t\'!test1/**\',\n    \t])\n\nrepos\\python-pathspec\\tests\\test_03_pathspec.py:382: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\python-pathspec\\pathspec\\pathspec.py:212: in from_lines\n    patterns = [pattern_factory(line) for line in lines if line]\nrepos\\python-pathspec\\pathspec\\pattern.py:118: in __init__\n    regex, include = self.pattern_to_regex(pattern)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ncls = <pathspec.patterns.gitwildmatch.GitWildMatchPattern object at 0x0000013A34820A80>\npattern = \'*.txt\'\n\n    def pattern_to_regex(cls, pattern):\n>       regex_pattern = convert_pattern_to_regex(pattern)\nE       NameError: name \'convert_pattern_to_regex\' is not defined\n\nrepos\\python-pathspec\\pathspec\\patterns\\gitwildmatch.py:30: NameError', 'self = <tests.test_03_pathspec.PathSpecTest testMethod=test_02_ne>\n\n    def test_02_ne(self):\n    \t""""""\n    \tTests inequality.\n    \t""""""\n>   \tfirst_spec = PathSpec.from_lines(\'gitwildmatch\', [\n    \t\t\'*.txt\',\n    \t])\n\nrepos\\python-pathspec\\tests\\test_03_pathspec.py:396: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\python-pathspec\\pathspec\\pathspec.py:212: in from_lines\n    patterns = [pattern_factory(line) for line in lines if line]\nrepos\\python-pathspec\\pathspec\\pattern.py:118: in __init__\n    regex, include = self.pattern_to_regex(pattern)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ncls = <pathspec.patterns.gitwildmatch.GitWildMatchPattern object at 0x0000013A3488A3C0>\npattern = \'*.txt\'\n\n    def pattern_to_regex(cls, pattern):\n>       regex_pattern = convert_pattern_to_regex(pattern)\nE       NameError: name \'convert_pattern_to_regex\' is not defined\n\nrepos\\python-pathspec\\pathspec\\patterns\\gitwildmatch.py:30: NameError', 'self = <tests.test_03_pathspec.PathSpecTest testMethod=test_03_add>\n\n    def test_03_add(self):\n    \t""""""\n    \tTest spec addition using :data:`+` operator.\n    \t""""""\n>   \tfirst_spec = PathSpec.from_lines(\'gitwildmatch\', [\n    \t\t\'test.png\',\n    \t\t\'test.txt\',\n    \t])\n\nrepos\\python-pathspec\\tests\\test_03_pathspec.py:408: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\python-pathspec\\pathspec\\pathspec.py:212: in from_lines\n    patterns = [pattern_factory(line) for line in lines if line]\nrepos\\python-pathspec\\pathspec\\pattern.py:118: in __init__\n    regex, include = self.pattern_to_regex(pattern)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ncls = <pathspec.patterns.gitwildmatch.GitWildMatchPattern object at 0x0000013A3475A500>\npattern = \'test.png\'\n\n    def pattern_to_regex(cls, pattern):\n>       regex_pattern = convert_pattern_to_regex(pattern)\nE       NameError: name \'convert_pattern_to_regex\' is not defined\n\nrepos\\python-pathspec\\pathspec\\patterns\\gitwildmatch.py:30: NameError', 'self = <tests.test_03_pathspec.PathSpecTest testMethod=test_03_iadd>\n\n    def test_03_iadd(self):\n    \t""""""\n    \tTest spec addition using :data:`+=` operator.\n    \t""""""\n>   \tspec = PathSpec.from_lines(\'gitwildmatch\', [\n    \t\t\'test.png\',\n    \t\t\'test.txt\',\n    \t])\n\nrepos\\python-pathspec\\tests\\test_03_pathspec.py:439: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\python-pathspec\\pathspec\\pathspec.py:212: in from_lines\n    patterns = [pattern_factory(line) for line in lines if line]\nrepos\\python-pathspec\\pathspec\\pattern.py:118: in __init__\n    regex, include = self.pattern_to_regex(pattern)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ncls = <pathspec.patterns.gitwildmatch.GitWildMatchPattern object at 0x0000013A348E6000>\npattern = \'test.png\'\n\n    def pattern_to_regex(cls, pattern):\n>       regex_pattern = convert_pattern_to_regex(pattern)\nE       NameError: name \'convert_pattern_to_regex\' is not defined\n\nrepos\\python-pathspec\\pathspec\\patterns\\gitwildmatch.py:30: NameError', 'self = <tests.test_03_pathspec.PathSpecTest testMethod=test_04_len>\n\n    def test_04_len(self):\n    \t""""""\n    \tTest spec length.\n    \t""""""\n>   \tspec = PathSpec.from_lines(\'gitwildmatch\', [\n    \t\t\'foo\',\n    \t\t\'bar\',\n    \t])\n\nrepos\\python-pathspec\\tests\\test_03_pathspec.py:469: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\python-pathspec\\pathspec\\pathspec.py:212: in from_lines\n    patterns = [pattern_factory(line) for line in lines if line]\nrepos\\python-pathspec\\pathspec\\pattern.py:118: in __init__\n    regex, include = self.pattern_to_regex(pattern)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ncls = <pathspec.patterns.gitwildmatch.GitWildMatchPattern object at 0x0000013A348E4CC0>\npattern = \'foo\'\n\n    def pattern_to_regex(cls, pattern):\n>       regex_pattern = convert_pattern_to_regex(pattern)\nE       NameError: name \'convert_pattern_to_regex\' is not defined\n\nrepos\\python-pathspec\\pathspec\\patterns\\gitwildmatch.py:30: NameError', 'self = <tests.test_03_pathspec.PathSpecTest testMethod=test_05_match_entries>\n\n    def test_05_match_entries(self):\n    \t""""""\n    \tTest matching files collectively.\n    \t""""""\n>   \tspec = PathSpec.from_lines(\'gitwildmatch\', [\n    \t\t\'*.txt\',\n    \t\t\'!b.txt\',\n    \t])\n\nrepos\\python-pathspec\\tests\\test_03_pathspec.py:479: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\python-pathspec\\pathspec\\pathspec.py:212: in from_lines\n    patterns = [pattern_factory(line) for line in lines if line]\nrepos\\python-pathspec\\pathspec\\pattern.py:118: in __init__\n    regex, include = self.pattern_to_regex(pattern)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ncls = <pathspec.patterns.gitwildmatch.GitWildMatchPattern object at 0x0000013A345FC440>\npattern = \'*.txt\'\n\n    def pattern_to_regex(cls, pattern):\n>       regex_pattern = convert_pattern_to_regex(pattern)\nE       NameError: name \'convert_pattern_to_regex\' is not defined\n\nrepos\\python-pathspec\\pathspec\\patterns\\gitwildmatch.py:30: NameError', 'self = <tests.test_03_pathspec.PathSpecTest testMethod=test_05_match_file>\n\n    def test_05_match_file(self):\n    \t""""""\n    \tTest matching files individually.\n    \t""""""\n>   \tspec = PathSpec.from_lines(\'gitwildmatch\', [\n    \t\t\'*.txt\',\n    \t\t\'!b.txt\',\n    \t])\n\nrepos\\python-pathspec\\tests\\test_03_pathspec.py:514: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\python-pathspec\\pathspec\\pathspec.py:212: in from_lines\n    patterns = [pattern_factory(line) for line in lines if line]\nrepos\\python-pathspec\\pathspec\\pattern.py:118: in __init__\n    regex, include = self.pattern_to_regex(pattern)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ncls = <pathspec.patterns.gitwildmatch.GitWildMatchPattern object at 0x0000013A3495EB00>\npattern = \'*.txt\'\n\n    def pattern_to_regex(cls, pattern):\n>       regex_pattern = convert_pattern_to_regex(pattern)\nE       NameError: name \'convert_pattern_to_regex\' is not defined\n\nrepos\\python-pathspec\\pathspec\\patterns\\gitwildmatch.py:30: NameError', 'self = <tests.test_03_pathspec.PathSpecTest testMethod=test_05_match_files>\n\n    def test_05_match_files(self):\n    \t""""""\n    \tTest matching files collectively.\n    \t""""""\n>   \tspec = PathSpec.from_lines(\'gitwildmatch\', [\n    \t\t\'*.txt\',\n    \t\t\'!b.txt\',\n    \t])\n\nrepos\\python-pathspec\\tests\\test_03_pathspec.py:540: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\python-pathspec\\pathspec\\pathspec.py:212: in from_lines\n    patterns = [pattern_factory(line) for line in lines if line]\nrepos\\python-pathspec\\pathspec\\pattern.py:118: in __init__\n    regex, include = self.pattern_to_regex(pattern)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ncls = <pathspec.patterns.gitwildmatch.GitWildMatchPattern object at 0x0000013A3499FBC0>\npattern = \'*.txt\'\n\n    def pattern_to_regex(cls, pattern):\n>       regex_pattern = convert_pattern_to_regex(pattern)\nE       NameError: name \'convert_pattern_to_regex\' is not defined\n\nrepos\\python-pathspec\\pathspec\\patterns\\gitwildmatch.py:30: NameError', 'self = <tests.test_03_pathspec.PathSpecTest testMethod=test_05_match_tree_entries>\n\n    def test_05_match_tree_entries(self):\n    \t""""""\n    \tTest matching a file tree.\n    \t""""""\n>   \tspec = PathSpec.from_lines(\'gitwildmatch\', [\n    \t\t\'*.txt\',\n    \t\t\'!b.txt\',\n    \t])\n\nrepos\\python-pathspec\\tests\\test_03_pathspec.py:566: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\python-pathspec\\pathspec\\pathspec.py:212: in from_lines\n    patterns = [pattern_factory(line) for line in lines if line]\nrepos\\python-pathspec\\pathspec\\pattern.py:118: in __init__\n    regex, include = self.pattern_to_regex(pattern)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ncls = <pathspec.patterns.gitwildmatch.GitWildMatchPattern object at 0x0000013A349AD500>\npattern = \'*.txt\'\n\n    def pattern_to_regex(cls, pattern):\n>       regex_pattern = convert_pattern_to_regex(pattern)\nE       NameError: name \'convert_pattern_to_regex\' is not defined\n\nrepos\\python-pathspec\\pathspec\\patterns\\gitwildmatch.py:30: NameError', 'self = <tests.test_03_pathspec.PathSpecTest testMethod=test_05_match_tree_files>\n\n    def test_05_match_tree_files(self):\n    \t""""""\n    \tTest matching a file tree.\n    \t""""""\n>   \tspec = PathSpec.from_lines(\'gitwildmatch\', [\n    \t\t\'*.txt\',\n    \t\t\'!b.txt\',\n    \t])\n\nrepos\\python-pathspec\\tests\\test_03_pathspec.py:600: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\python-pathspec\\pathspec\\pathspec.py:212: in from_lines\n    patterns = [pattern_factory(line) for line in lines if line]\nrepos\\python-pathspec\\pathspec\\pattern.py:118: in __init__\n    regex, include = self.pattern_to_regex(pattern)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ncls = <pathspec.patterns.gitwildmatch.GitWildMatchPattern object at 0x0000013A3493A940>\npattern = \'*.txt\'\n\n    def pattern_to_regex(cls, pattern):\n>       regex_pattern = convert_pattern_to_regex(pattern)\nE       NameError: name \'convert_pattern_to_regex\' is not defined\n\nrepos\\python-pathspec\\pathspec\\patterns\\gitwildmatch.py:30: NameError', 'self = <tests.test_03_pathspec.PathSpecTest testMethod=test_06_issue_41_a>\n\n    def test_06_issue_41_a(self):\n    \t""""""\n    \tTest including a file and excluding a directory with the same name pattern,\n    \tscenario A.\n    \t""""""\n>   \tspec = PathSpec.from_lines(\'gitwildmatch\', [\n    \t\t\'*.yaml\',\n    \t\t\'!*.yaml/\',\n    \t])\n\nrepos\\python-pathspec\\tests\\test_03_pathspec.py:633: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\python-pathspec\\pathspec\\pathspec.py:212: in from_lines\n    patterns = [pattern_factory(line) for line in lines if line]\nrepos\\python-pathspec\\pathspec\\pattern.py:118: in __init__\n    regex, include = self.pattern_to_regex(pattern)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ncls = <pathspec.patterns.gitwildmatch.GitWildMatchPattern object at 0x0000013A346D7380>\npattern = \'*.yaml\'\n\n    def pattern_to_regex(cls, pattern):\n>       regex_pattern = convert_pattern_to_regex(pattern)\nE       NameError: name \'convert_pattern_to_regex\' is not defined\n\nrepos\\python-pathspec\\pathspec\\patterns\\gitwildmatch.py:30: NameError', 'self = <tests.test_03_pathspec.PathSpecTest testMethod=test_06_issue_41_b>\n\n    def test_06_issue_41_b(self):\n    \t""""""\n    \tTest including a file and excluding a directory with the same name\n    \tpattern, scenario B.\n    \t""""""\n>   \tspec = PathSpec.from_lines(\'gitwildmatch\', [\n    \t\t\'!*.yaml/\',\n    \t\t\'*.yaml\',\n    \t])\n\nrepos\\python-pathspec\\tests\\test_03_pathspec.py:669: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\python-pathspec\\pathspec\\pathspec.py:212: in from_lines\n    patterns = [pattern_factory(line) for line in lines if line]\nrepos\\python-pathspec\\pathspec\\pattern.py:118: in __init__\n    regex, include = self.pattern_to_regex(pattern)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ncls = <pathspec.patterns.gitwildmatch.GitWildMatchPattern object at 0x0000013A349C3600>\npattern = \'!*.yaml/\'\n\n    def pattern_to_regex(cls, pattern):\n>       regex_pattern = convert_pattern_to_regex(pattern)\nE       NameError: name \'convert_pattern_to_regex\' is not defined\n\nrepos\\python-pathspec\\pathspec\\patterns\\gitwildmatch.py:30: NameError', 'self = <tests.test_03_pathspec.PathSpecTest testMethod=test_06_issue_41_c>\n\n    def test_06_issue_41_c(self):\n    \t""""""\n    \tTest including a file and excluding a directory with the same name\n    \tpattern, scenario C.\n    \t""""""\n>   \tspec = PathSpec.from_lines(\'gitwildmatch\', [\n    \t\t\'*.yaml\',\n    \t\t\'!dir.yaml\',\n    \t])\n\nrepos\\python-pathspec\\tests\\test_03_pathspec.py:704: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\python-pathspec\\pathspec\\pathspec.py:212: in from_lines\n    patterns = [pattern_factory(line) for line in lines if line]\nrepos\\python-pathspec\\pathspec\\pattern.py:118: in __init__\n    regex, include = self.pattern_to_regex(pattern)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ncls = <pathspec.patterns.gitwildmatch.GitWildMatchPattern object at 0x0000013A34753400>\npattern = \'*.yaml\'\n\n    def pattern_to_regex(cls, pattern):\n>       regex_pattern = convert_pattern_to_regex(pattern)\nE       NameError: name \'convert_pattern_to_regex\' is not defined\n\nrepos\\python-pathspec\\pathspec\\patterns\\gitwildmatch.py:30: NameError', 'self = <tests.test_03_pathspec.PathSpecTest testMethod=test_07_issue_62>\n\n    def test_07_issue_62(self):\n    \t""""""\n    \tTest including all files and excluding a directory.\n    \t""""""\n>   \tspec = PathSpec.from_lines(\'gitwildmatch\', [\n    \t\t\'*\',\n    \t\t\'!product_dir/\',\n    \t])\n\nrepos\\python-pathspec\\tests\\test_03_pathspec.py:739: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\python-pathspec\\pathspec\\pathspec.py:212: in from_lines\n    patterns = [pattern_factory(line) for line in lines if line]\nrepos\\python-pathspec\\pathspec\\pattern.py:118: in __init__\n    regex, include = self.pattern_to_regex(pattern)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ncls = <pathspec.patterns.gitwildmatch.GitWildMatchPattern object at 0x0000013A30EE9200>\npattern = \'*\'\n\n    def pattern_to_regex(cls, pattern):\n>       regex_pattern = convert_pattern_to_regex(pattern)\nE       NameError: name \'convert_pattern_to_regex\' is not defined\n\nrepos\\python-pathspec\\pathspec\\patterns\\gitwildmatch.py:30: NameError', 'self = <tests.test_03_pathspec.PathSpecTest testMethod=test_08_issue_39>\n\n    def test_08_issue_39(self):\n    \t""""""\n    \tTest excluding files in a directory.\n    \t""""""\n>   \tspec = PathSpec.from_lines(\'gitwildmatch\', [\n    \t\t\'*.log\',\n    \t\t\'!important/*.log\',\n    \t\t\'trace.*\',\n    \t])\n\nrepos\\python-pathspec\\tests\\test_03_pathspec.py:760: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\python-pathspec\\pathspec\\pathspec.py:212: in from_lines\n    patterns = [pattern_factory(line) for line in lines if line]\nrepos\\python-pathspec\\pathspec\\pattern.py:118: in __init__\n    regex, include = self.pattern_to_regex(pattern)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ncls = <pathspec.patterns.gitwildmatch.GitWildMatchPattern object at 0x0000013A34744100>\npattern = \'*.log\'\n\n    def pattern_to_regex(cls, pattern):\n>       regex_pattern = convert_pattern_to_regex(pattern)\nE       NameError: name \'convert_pattern_to_regex\' is not defined\n\nrepos\\python-pathspec\\pathspec\\patterns\\gitwildmatch.py:30: NameError', 'self = <tests.test_03_pathspec.PathSpecTest testMethod=test_09_issue_80_a>\n\n    def test_09_issue_80_a(self):\n    \t""""""\n    \tTest negating patterns.\n    \t""""""\n>   \tspec = PathSpec.from_lines(\'gitwildmatch\', [\n    \t\t\'build\',\n    \t\t\'*.log\',\n    \t\t\'.*\',\n    \t\t\'!.gitignore\',\n    \t])\n\nrepos\\python-pathspec\\tests\\test_03_pathspec.py:791: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\python-pathspec\\pathspec\\pathspec.py:212: in from_lines\n    patterns = [pattern_factory(line) for line in lines if line]\nrepos\\python-pathspec\\pathspec\\pattern.py:118: in __init__\n    regex, include = self.pattern_to_regex(pattern)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ncls = <pathspec.patterns.gitwildmatch.GitWildMatchPattern object at 0x0000013A34758680>\npattern = \'build\'\n\n    def pattern_to_regex(cls, pattern):\n>       regex_pattern = convert_pattern_to_regex(pattern)\nE       NameError: name \'convert_pattern_to_regex\' is not defined\n\nrepos\\python-pathspec\\pathspec\\patterns\\gitwildmatch.py:30: NameError', 'self = <tests.test_03_pathspec.PathSpecTest testMethod=test_09_issue_80_b>\n\n    def test_09_issue_80_b(self):\n    \t""""""\n    \tTest negating patterns.\n    \t""""""\n>   \tspec = PathSpec.from_lines(\'gitwildmatch\', [\n    \t\t\'build\',\n    \t\t\'*.log\',\n    \t\t\'.*\',\n    \t\t\'!.gitignore\',\n    \t])\n\nrepos\\python-pathspec\\tests\\test_03_pathspec.py:819: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\python-pathspec\\pathspec\\pathspec.py:212: in from_lines\n    patterns = [pattern_factory(line) for line in lines if line]\nrepos\\python-pathspec\\pathspec\\pattern.py:118: in __init__\n    regex, include = self.pattern_to_regex(pattern)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ncls = <pathspec.patterns.gitwildmatch.GitWildMatchPattern object at 0x0000013A34931800>\npattern = \'build\'\n\n    def pattern_to_regex(cls, pattern):\n>       regex_pattern = convert_pattern_to_regex(pattern)\nE       NameError: name \'convert_pattern_to_regex\' is not defined\n\nrepos\\python-pathspec\\pathspec\\patterns\\gitwildmatch.py:30: NameError', 'self = <tests.test_04_gitignore.GitIgnoreSpecTest testMethod=test_01_reversed_args>\n\n    def test_01_reversed_args(self):\n    \t""""""\n    \tTest reversed args for `.from_lines()`.\n    \t""""""\n>   \tspec = GitIgnoreSpec.from_lines(\'gitwildmatch\', [\'*.txt\'])\n\nrepos\\python-pathspec\\tests\\test_04_gitignore.py:24: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\python-pathspec\\pathspec\\gitignore.py:103: in from_lines\n    self = super().from_lines(pattern_factory, lines)\nrepos\\python-pathspec\\pathspec\\pathspec.py:212: in from_lines\n    patterns = [pattern_factory(line) for line in lines if line]\nrepos\\python-pathspec\\pathspec\\pattern.py:118: in __init__\n    regex, include = self.pattern_to_regex(pattern)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ncls = <pathspec.patterns.gitwildmatch.GitWildMatchPattern object at 0x0000013A3494B400>\npattern = \'*.txt\'\n\n    def pattern_to_regex(cls, pattern):\n>       regex_pattern = convert_pattern_to_regex(pattern)\nE       NameError: name \'convert_pattern_to_regex\' is not defined\n\nrepos\\python-pathspec\\pathspec\\patterns\\gitwildmatch.py:30: NameError', 'self = <tests.test_04_gitignore.GitIgnoreSpecTest testMethod=test_02_dir_exclusions>\n\n    def test_02_dir_exclusions(self):\n    \t""""""\n    \tTest directory exclusions.\n    \t""""""\n>   \tspec = GitIgnoreSpec.from_lines([\n    \t\t\'*.txt\',\n    \t\t\'!test1/\',\n    \t])\n\nrepos\\python-pathspec\\tests\\test_04_gitignore.py:42: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\python-pathspec\\pathspec\\gitignore.py:103: in from_lines\n    self = super().from_lines(pattern_factory, lines)\nrepos\\python-pathspec\\pathspec\\pathspec.py:212: in from_lines\n    patterns = [pattern_factory(line) for line in lines if line]\nrepos\\python-pathspec\\pathspec\\pattern.py:118: in __init__\n    regex, include = self.pattern_to_regex(pattern)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ncls = <pathspec.patterns.gitwildmatch.GitWildMatchPattern object at 0x0000013A349783C0>\npattern = \'*.txt\'\n\n    def pattern_to_regex(cls, pattern):\n>       regex_pattern = convert_pattern_to_regex(pattern)\nE       NameError: name \'convert_pattern_to_regex\' is not defined\n\nrepos\\python-pathspec\\pathspec\\patterns\\gitwildmatch.py:30: NameError', 'self = <tests.test_04_gitignore.GitIgnoreSpecTest testMethod=test_02_file_exclusions>\n\n    def test_02_file_exclusions(self):\n    \t""""""\n    \tTest file exclusions.\n    \t""""""\n>   \tspec = GitIgnoreSpec.from_lines([\n    \t\t\'*.txt\',\n    \t\t\'!b.txt\',\n    \t])\n\nrepos\\python-pathspec\\tests\\test_04_gitignore.py:74: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\python-pathspec\\pathspec\\gitignore.py:103: in from_lines\n    self = super().from_lines(pattern_factory, lines)\nrepos\\python-pathspec\\pathspec\\pathspec.py:212: in from_lines\n    patterns = [pattern_factory(line) for line in lines if line]\nrepos\\python-pathspec\\pathspec\\pattern.py:118: in __init__\n    regex, include = self.pattern_to_regex(pattern)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ncls = <pathspec.patterns.gitwildmatch.GitWildMatchPattern object at 0x0000013A349830C0>\npattern = \'*.txt\'\n\n    def pattern_to_regex(cls, pattern):\n>       regex_pattern = convert_pattern_to_regex(pattern)\nE       NameError: name \'convert_pattern_to_regex\' is not defined\n\nrepos\\python-pathspec\\pathspec\\patterns\\gitwildmatch.py:30: NameError', 'self = <tests.test_04_gitignore.GitIgnoreSpecTest testMethod=test_02_issue_41_a>\n\n    def test_02_issue_41_a(self):\n    \t""""""\n    \tTest including a file and excluding a directory with the same name pattern,\n    \tscenario A.\n    \t""""""\n    \t# Confirmed results with git (v2.42.0).\n>   \tspec = GitIgnoreSpec.from_lines([\n    \t\t\'*.yaml\',\n    \t\t\'!*.yaml/\',\n    \t])\n\nrepos\\python-pathspec\\tests\\test_04_gitignore.py:108: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\python-pathspec\\pathspec\\gitignore.py:103: in from_lines\n    self = super().from_lines(pattern_factory, lines)\nrepos\\python-pathspec\\pathspec\\pathspec.py:212: in from_lines\n    patterns = [pattern_factory(line) for line in lines if line]\nrepos\\python-pathspec\\pathspec\\pattern.py:118: in __init__\n    regex, include = self.pattern_to_regex(pattern)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ncls = <pathspec.patterns.gitwildmatch.GitWildMatchPattern object at 0x0000013A34763F00>\npattern = \'*.yaml\'\n\n    def pattern_to_regex(cls, pattern):\n>       regex_pattern = convert_pattern_to_regex(pattern)\nE       NameError: name \'convert_pattern_to_regex\' is not defined\n\nrepos\\python-pathspec\\pathspec\\patterns\\gitwildmatch.py:30: NameError', 'self = <tests.test_04_gitignore.GitIgnoreSpecTest testMethod=test_02_issue_41_b>\n\n    def test_02_issue_41_b(self):\n    \t""""""\n    \tTest including a file and excluding a directory with the same name pattern,\n    \tscenario B.\n    \t""""""\n    \t# Confirmed results with git (v2.42.0).\n>   \tspec = GitIgnoreSpec.from_lines([\n    \t\t\'!*.yaml/\',\n    \t\t\'*.yaml\',\n    \t])\n\nrepos\\python-pathspec\\tests\\test_04_gitignore.py:144: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\python-pathspec\\pathspec\\gitignore.py:103: in from_lines\n    self = super().from_lines(pattern_factory, lines)\nrepos\\python-pathspec\\pathspec\\pathspec.py:212: in from_lines\n    patterns = [pattern_factory(line) for line in lines if line]\nrepos\\python-pathspec\\pathspec\\pattern.py:118: in __init__\n    regex, include = self.pattern_to_regex(pattern)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ncls = <pathspec.patterns.gitwildmatch.GitWildMatchPattern object at 0x0000013A34A07280>\npattern = \'!*.yaml/\'\n\n    def pattern_to_regex(cls, pattern):\n>       regex_pattern = convert_pattern_to_regex(pattern)\nE       NameError: name \'convert_pattern_to_regex\' is not defined\n\nrepos\\python-pathspec\\pathspec\\patterns\\gitwildmatch.py:30: NameError', 'self = <tests.test_04_gitignore.GitIgnoreSpecTest testMethod=test_02_issue_41_c>\n\n    def test_02_issue_41_c(self):\n    \t""""""\n    \tTest including a file and excluding a directory with the same name pattern,\n    \tscenario C.\n    \t""""""\n    \t# Confirmed results with git (v2.42.0).\n>   \tspec = GitIgnoreSpec.from_lines([\n    \t\t\'*.yaml\',\n    \t\t\'!dir.yaml\',\n    \t])\n\nrepos\\python-pathspec\\tests\\test_04_gitignore.py:180: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\python-pathspec\\pathspec\\gitignore.py:103: in from_lines\n    self = super().from_lines(pattern_factory, lines)\nrepos\\python-pathspec\\pathspec\\pathspec.py:212: in from_lines\n    patterns = [pattern_factory(line) for line in lines if line]\nrepos\\python-pathspec\\pathspec\\pattern.py:118: in __init__\n    regex, include = self.pattern_to_regex(pattern)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ncls = <pathspec.patterns.gitwildmatch.GitWildMatchPattern object at 0x0000013A348C9440>\npattern = \'*.yaml\'\n\n    def pattern_to_regex(cls, pattern):\n>       regex_pattern = convert_pattern_to_regex(pattern)\nE       NameError: name \'convert_pattern_to_regex\' is not defined\n\nrepos\\python-pathspec\\pathspec\\patterns\\gitwildmatch.py:30: NameError', 'self = <tests.test_04_gitignore.GitIgnoreSpecTest testMethod=test_03_issue_19_a>\n\n    def test_03_issue_19_a(self):\n    \t""""""\n    \tTest matching files in a subdirectory of an included directory, scenario A.\n    \t""""""\n>   \tspec = GitIgnoreSpec.from_lines([\n    \t\t""dirG/"",\n    \t])\n\nrepos\\python-pathspec\\tests\\test_04_gitignore.py:247: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\python-pathspec\\pathspec\\gitignore.py:103: in from_lines\n    self = super().from_lines(pattern_factory, lines)\nrepos\\python-pathspec\\pathspec\\pathspec.py:212: in from_lines\n    patterns = [pattern_factory(line) for line in lines if line]\nrepos\\python-pathspec\\pathspec\\pattern.py:118: in __init__\n    regex, include = self.pattern_to_regex(pattern)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ncls = <pathspec.patterns.gitwildmatch.GitWildMatchPattern object at 0x0000013A34760040>\npattern = \'dirG/\'\n\n    def pattern_to_regex(cls, pattern):\n>       regex_pattern = convert_pattern_to_regex(pattern)\nE       NameError: name \'convert_pattern_to_regex\' is not defined\n\nrepos\\python-pathspec\\pathspec\\patterns\\gitwildmatch.py:30: NameError', 'self = <tests.test_04_gitignore.GitIgnoreSpecTest testMethod=test_03_issue_19_b>\n\n    def test_03_issue_19_b(self):\n    \t""""""\n    \tTest matching files in a subdirectory of an included directory, scenario B.\n    \t""""""\n>   \tspec = GitIgnoreSpec.from_lines([\n    \t\t""dirG/*"",\n    \t])\n\nrepos\\python-pathspec\\tests\\test_04_gitignore.py:280: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\python-pathspec\\pathspec\\gitignore.py:103: in from_lines\n    self = super().from_lines(pattern_factory, lines)\nrepos\\python-pathspec\\pathspec\\pathspec.py:212: in from_lines\n    patterns = [pattern_factory(line) for line in lines if line]\nrepos\\python-pathspec\\pathspec\\pattern.py:118: in __init__\n    regex, include = self.pattern_to_regex(pattern)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ncls = <pathspec.patterns.gitwildmatch.GitWildMatchPattern object at 0x0000013A30EE8040>\npattern = \'dirG/*\'\n\n    def pattern_to_regex(cls, pattern):\n>       regex_pattern = convert_pattern_to_regex(pattern)\nE       NameError: name \'convert_pattern_to_regex\' is not defined\n\nrepos\\python-pathspec\\pathspec\\patterns\\gitwildmatch.py:30: NameError', 'self = <tests.test_04_gitignore.GitIgnoreSpecTest testMethod=test_03_issue_19_c>\n\n    def test_03_issue_19_c(self):\n    \t""""""\n    \tTest matching files in a subdirectory of an included directory, scenario C.\n    \t""""""\n>   \tspec = GitIgnoreSpec.from_lines([\n    \t\t""dirG/**"",\n    \t])\n\nrepos\\python-pathspec\\tests\\test_04_gitignore.py:313: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\python-pathspec\\pathspec\\gitignore.py:103: in from_lines\n    self = super().from_lines(pattern_factory, lines)\nrepos\\python-pathspec\\pathspec\\pathspec.py:212: in from_lines\n    patterns = [pattern_factory(line) for line in lines if line]\nrepos\\python-pathspec\\pathspec\\pattern.py:118: in __init__\n    regex, include = self.pattern_to_regex(pattern)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ncls = <pathspec.patterns.gitwildmatch.GitWildMatchPattern object at 0x0000013A3473A800>\npattern = \'dirG/**\'\n\n    def pattern_to_regex(cls, pattern):\n>       regex_pattern = convert_pattern_to_regex(pattern)\nE       NameError: name \'convert_pattern_to_regex\' is not defined\n\nrepos\\python-pathspec\\pathspec\\patterns\\gitwildmatch.py:30: NameError', 'self = <tests.test_04_gitignore.GitIgnoreSpecTest testMethod=test_03_subdir>\n\n    def test_03_subdir(self):\n    \t""""""\n    \tTest matching files in a subdirectory of an included directory.\n    \t""""""\n>   \tspec = GitIgnoreSpec.from_lines([\n    \t\t""dirG/"",\n    \t])\n\nrepos\\python-pathspec\\tests\\test_04_gitignore.py:214: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\python-pathspec\\pathspec\\gitignore.py:103: in from_lines\n    self = super().from_lines(pattern_factory, lines)\nrepos\\python-pathspec\\pathspec\\pathspec.py:212: in from_lines\n    patterns = [pattern_factory(line) for line in lines if line]\nrepos\\python-pathspec\\pathspec\\pattern.py:118: in __init__\n    regex, include = self.pattern_to_regex(pattern)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ncls = <pathspec.patterns.gitwildmatch.GitWildMatchPattern object at 0x0000013A34A3D300>\npattern = \'dirG/\'\n\n    def pattern_to_regex(cls, pattern):\n>       regex_pattern = convert_pattern_to_regex(pattern)\nE       NameError: name \'convert_pattern_to_regex\' is not defined\n\nrepos\\python-pathspec\\pathspec\\patterns\\gitwildmatch.py:30: NameError', 'self = <tests.test_04_gitignore.GitIgnoreSpecTest testMethod=test_04_issue_62>\n\n    def test_04_issue_62(self):\n    \t""""""\n    \tTest including all files and excluding a directory.\n    \t""""""\n>   \tspec = GitIgnoreSpec.from_lines([\n    \t\t\'*\',\n    \t\t\'!product_dir/\',\n    \t])\n\nrepos\\python-pathspec\\tests\\test_04_gitignore.py:346: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\python-pathspec\\pathspec\\gitignore.py:103: in from_lines\n    self = super().from_lines(pattern_factory, lines)\nrepos\\python-pathspec\\pathspec\\pathspec.py:212: in from_lines\n    patterns = [pattern_factory(line) for line in lines if line]\nrepos\\python-pathspec\\pathspec\\pattern.py:118: in __init__\n    regex, include = self.pattern_to_regex(pattern)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ncls = <pathspec.patterns.gitwildmatch.GitWildMatchPattern object at 0x0000013A3495D240>\npattern = \'*\'\n\n    def pattern_to_regex(cls, pattern):\n>       regex_pattern = convert_pattern_to_regex(pattern)\nE       NameError: name \'convert_pattern_to_regex\' is not defined\n\nrepos\\python-pathspec\\pathspec\\patterns\\gitwildmatch.py:30: NameError', 'self = <tests.test_04_gitignore.GitIgnoreSpecTest testMethod=test_05_issue_39>\n\n    def test_05_issue_39(self):\n    \t""""""\n    \tTest excluding files in a directory.\n    \t""""""\n>   \tspec = GitIgnoreSpec.from_lines([\n    \t\t\'*.log\',\n    \t\t\'!important/*.log\',\n    \t\t\'trace.*\',\n    \t])\n\nrepos\\python-pathspec\\tests\\test_04_gitignore.py:368: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\python-pathspec\\pathspec\\gitignore.py:103: in from_lines\n    self = super().from_lines(pattern_factory, lines)\nrepos\\python-pathspec\\pathspec\\pathspec.py:212: in from_lines\n    patterns = [pattern_factory(line) for line in lines if line]\nrepos\\python-pathspec\\pathspec\\pattern.py:118: in __init__\n    regex, include = self.pattern_to_regex(pattern)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ncls = <pathspec.patterns.gitwildmatch.GitWildMatchPattern object at 0x0000013A349C28C0>\npattern = \'*.log\'\n\n    def pattern_to_regex(cls, pattern):\n>       regex_pattern = convert_pattern_to_regex(pattern)\nE       NameError: name \'convert_pattern_to_regex\' is not defined\n\nrepos\\python-pathspec\\pathspec\\patterns\\gitwildmatch.py:30: NameError', 'self = <tests.test_04_gitignore.GitIgnoreSpecTest testMethod=test_06_issue_64>\n\n    def test_06_issue_64(self):\n    \t""""""\n    \tTest using a double asterisk pattern.\n    \t""""""\n>   \tspec = GitIgnoreSpec.from_lines([\n    \t\t""**"",\n    \t])\n\nrepos\\python-pathspec\\tests\\test_04_gitignore.py:399: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\python-pathspec\\pathspec\\gitignore.py:103: in from_lines\n    self = super().from_lines(pattern_factory, lines)\nrepos\\python-pathspec\\pathspec\\pathspec.py:212: in from_lines\n    patterns = [pattern_factory(line) for line in lines if line]\nrepos\\python-pathspec\\pathspec\\pattern.py:118: in __init__\n    regex, include = self.pattern_to_regex(pattern)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ncls = <pathspec.patterns.gitwildmatch.GitWildMatchPattern object at 0x0000013A3499B1C0>\npattern = \'**\'\n\n    def pattern_to_regex(cls, pattern):\n>       regex_pattern = convert_pattern_to_regex(pattern)\nE       NameError: name \'convert_pattern_to_regex\' is not defined\n\nrepos\\python-pathspec\\pathspec\\patterns\\gitwildmatch.py:30: NameError', 'self = <tests.test_04_gitignore.GitIgnoreSpecTest testMethod=test_07_issue_74>\n\n    def test_07_issue_74(self):\n    \t""""""\n    \tTest include directory should override exclude file.\n    \t""""""\n>   \tspec = GitIgnoreSpec.from_lines([\n    \t\t\'*\',  # Ignore all files by default\n    \t\t\'!*/\',  # but scan all directories\n    \t\t\'!*.txt\',  # Text files\n    \t\t\'/test1/**\',  # ignore all in the directory\n    \t])\n\nrepos\\python-pathspec\\tests\\test_04_gitignore.py:423: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\python-pathspec\\pathspec\\gitignore.py:103: in from_lines\n    self = super().from_lines(pattern_factory, lines)\nrepos\\python-pathspec\\pathspec\\pathspec.py:212: in from_lines\n    patterns = [pattern_factory(line) for line in lines if line]\nrepos\\python-pathspec\\pathspec\\pattern.py:118: in __init__\n    regex, include = self.pattern_to_regex(pattern)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ncls = <pathspec.patterns.gitwildmatch.GitWildMatchPattern object at 0x0000013A34951A40>\npattern = \'*\'\n\n    def pattern_to_regex(cls, pattern):\n>       regex_pattern = convert_pattern_to_regex(pattern)\nE       NameError: name \'convert_pattern_to_regex\' is not defined\n\nrepos\\python-pathspec\\pathspec\\patterns\\gitwildmatch.py:30: NameError', 'self = <tests.test_04_gitignore.GitIgnoreSpecTest testMethod=test_08_issue_81_a>\n\n    def test_08_issue_81_a(self):\n    \t""""""\n    \tTest issue 81 whitelist, scenario A.\n    \t""""""\n    \t# Confirmed results with git (v2.42.0).\n>   \tspec = GitIgnoreSpec.from_lines([\n    \t\t""*"",\n    \t\t""!libfoo"",\n    \t\t""!libfoo/**"",\n    \t])\n\nrepos\\python-pathspec\\tests\\test_04_gitignore.py:458: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\python-pathspec\\pathspec\\gitignore.py:103: in from_lines\n    self = super().from_lines(pattern_factory, lines)\nrepos\\python-pathspec\\pathspec\\pathspec.py:212: in from_lines\n    patterns = [pattern_factory(line) for line in lines if line]\nrepos\\python-pathspec\\pathspec\\pattern.py:118: in __init__\n    regex, include = self.pattern_to_regex(pattern)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ncls = <pathspec.patterns.gitwildmatch.GitWildMatchPattern object at 0x0000013A3499A680>\npattern = \'*\'\n\n    def pattern_to_regex(cls, pattern):\n>       regex_pattern = convert_pattern_to_regex(pattern)\nE       NameError: name \'convert_pattern_to_regex\' is not defined\n\nrepos\\python-pathspec\\pathspec\\patterns\\gitwildmatch.py:30: NameError', 'self = <tests.test_04_gitignore.GitIgnoreSpecTest testMethod=test_08_issue_81_b>\n\n    def test_08_issue_81_b(self):\n    \t""""""\n    \tTest issue 81 whitelist, scenario B.\n    \t""""""\n    \t# Confirmed results with git (v2.42.0).\n>   \tspec = GitIgnoreSpec.from_lines([\n    \t\t""*"",\n    \t\t""!libfoo"",\n    \t\t""!libfoo/*"",\n    \t])\n\nrepos\\python-pathspec\\tests\\test_04_gitignore.py:484: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\python-pathspec\\pathspec\\gitignore.py:103: in from_lines\n    self = super().from_lines(pattern_factory, lines)\nrepos\\python-pathspec\\pathspec\\pathspec.py:212: in from_lines\n    patterns = [pattern_factory(line) for line in lines if line]\nrepos\\python-pathspec\\pathspec\\pattern.py:118: in __init__\n    regex, include = self.pattern_to_regex(pattern)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ncls = <pathspec.patterns.gitwildmatch.GitWildMatchPattern object at 0x0000013A3497B6C0>\npattern = \'*\'\n\n    def pattern_to_regex(cls, pattern):\n>       regex_pattern = convert_pattern_to_regex(pattern)\nE       NameError: name \'convert_pattern_to_regex\' is not defined\n\nrepos\\python-pathspec\\pathspec\\patterns\\gitwildmatch.py:30: NameError', 'self = <tests.test_04_gitignore.GitIgnoreSpecTest testMethod=test_08_issue_81_c>\n\n    def test_08_issue_81_c(self):\n    \t""""""\n    \tTest issue 81 whitelist, scenario C.\n    \t""""""\n    \t# Confirmed results with git (v2.42.0).\n>   \tspec = GitIgnoreSpec.from_lines([\n    \t\t""*"",\n    \t\t""!libfoo"",\n    \t\t""!libfoo/"",\n    \t])\n\nrepos\\python-pathspec\\tests\\test_04_gitignore.py:510: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\python-pathspec\\pathspec\\gitignore.py:103: in from_lines\n    self = super().from_lines(pattern_factory, lines)\nrepos\\python-pathspec\\pathspec\\pathspec.py:212: in from_lines\n    patterns = [pattern_factory(line) for line in lines if line]\nrepos\\python-pathspec\\pathspec\\pattern.py:118: in __init__\n    regex, include = self.pattern_to_regex(pattern)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ncls = <pathspec.patterns.gitwildmatch.GitWildMatchPattern object at 0x0000013A34940D80>\npattern = \'*\'\n\n    def pattern_to_regex(cls, pattern):\n>       regex_pattern = convert_pattern_to_regex(pattern)\nE       NameError: name \'convert_pattern_to_regex\' is not defined\n\nrepos\\python-pathspec\\pathspec\\patterns\\gitwildmatch.py:30: NameError']",python-pathspec/pattern_to_regex,LLM
python-pathspec,pattern_to_regex,"@classmethod
def pattern_to_regex(cls, pattern: AnyStr) -> Tuple[Optional[AnyStr], Optional[bool]]:
    """"""
		Convert the pattern into a regular expression.

		*pattern* (:class:`str` or :class:`bytes`) is the pattern to convert into a
		regular expression.

		Returns the uncompiled regular expression (:class:`str`, :class:`bytes`, or
		:data:`None`); and whether matched files should be included (:data:`True`),
		excluded (:data:`False`), or if it is a null-operation (:data:`None`).
		""""""
    if isinstance(pattern, str):
        return_type = str
    elif isinstance(pattern, bytes):
        return_type = bytes
        pattern = pattern.decode(_BYTES_ENCODING)
    else:
        raise TypeError(f'pattern:{pattern!r} is not a unicode or byte string.')
    original_pattern = pattern
    if pattern.endswith('\\ '):
        pattern = pattern.lstrip()
    else:
        pattern = pattern.strip()
    regex: Optional[str]
    include: Optional[bool]
    if pattern.startswith('#'):
        regex = None
        include = None
    elif pattern == '/':
        regex = None
        include = None
    elif pattern:
        if pattern.startswith('!'):
            include = False
            pattern = pattern[1:]
        else:
            include = True
        override_regex: Optional[str] = None
        pattern_segs = pattern.split('/')
        is_dir_pattern = not pattern_segs[-1]
        for i in range(len(pattern_segs) - 1, 0, -1):
            prev = pattern_segs[i - 1]
            seg = pattern_segs[i]
            if prev == '**' and seg == '**':
                del pattern_segs[i]
        if len(pattern_segs) == 2 and pattern_segs[0] == '**' and (not pattern_segs[1]):
            override_regex = f'^.+(?P<{_DIR_MARK}>/).*$'
        if not pattern_segs[0]:
            del pattern_segs[0]
        elif len(pattern_segs) == 1 or (len(pattern_segs) == 2 and (not pattern_segs[1])):
            if pattern_segs[0] != '**':
                pattern_segs.insert(0, '**')
        else:
            pass
        if not pattern_segs:
            raise GitWildMatchPatternError(f'Invalid git pattern: {original_pattern!r}')
        if not pattern_segs[-1] and len(pattern_segs) > 1:
            pattern_segs[-1] = '**'
        if override_regex is None:
            output = ['^']
            need_slash = False
            end = len(pattern_segs) - 1
            for i, seg in enumerate(pattern_segs):
                if seg == '**':
                    if i == 0 and i == end:
                        output.append(f'[^/]+(?:/.*)?')
                    elif i == 0:
                        output.append('(?:.+/)?')
                        need_slash = False
                    elif i == end:
                        if is_dir_pattern:
                            output.append(f'(?P<{_DIR_MARK}>/).*')
                        else:
                            output.append(f'/.*')
                    else:
                        output.append('(?:/.+)?')
                        need_slash = True
                elif seg == '*':
                    if need_slash:
                        output.append('/')
                    output.append('[^/]+')
                    if i == end:
                        output.append(f'(?:(?P<{_DIR_MARK}>/).*)?')
                    need_slash = True
                else:
                    if need_slash:
                        output.append('/')
                    try:
                        output.append(cls._translate_segment_glob(seg))
                    except ValueError as e:
                        raise GitWildMatchPatternError(f'Invalid git pattern: {original_pattern!r}') from e
                    if i == end:
                        output.append(f'(?:(?P<{_DIR_MARK}>/).*)?')
                    need_slash = True
            output.append('$')
            regex = ''.join(output)
        else:
            regex = override_regex
    else:
        regex = None
        include = None
    if regex is not None and return_type is bytes:
        regex = regex.encode(_BYTES_ENCODING)
    return (regex, include)","The goal of the function is to convert a given pattern into a regular expression. The function determines whether files matching the pattern should be included, excluded, or if it is a null-operation. It handles different types of patterns and constructs the regular expression based on the pattern logic, ultimately returning the compiled regular expression and the inclusion/exclusion status. This function is designed to be used within a class context and interacts with class attributes or other methods to properly handle and convert the patterns into regular expressions.",2,"def pattern_to_regex(cls, pattern):
    import re

    if pattern.startswith(""!""):
        pattern = pattern[1:]
        inclusion_status = False
    elif pattern.startswith(""+""):
        pattern = pattern[1:]
        inclusion_status = True
    else:
        inclusion_status = True

    pattern = pattern.replace(""."", ""\."").replace(""*"", "".*"").replace(""?"", ""."")

    regex = re.compile(pattern)
    
    return regex, inclusion_status",['./repos/python-pathspec\\tests'],"60 Passed, 52 Failed",60,52,"['tests/test_01_util.py::CheckMatchFileTest::test_02_many', 'tests/test_01_util.py::MatchFileTest::test_02_many', 'tests/test_02_gitwildmatch.py::GitWildMatchTest::test_00_empty', 'tests/test_02_gitwildmatch.py::GitWildMatchTest::test_01_absolute', 'tests/test_02_gitwildmatch.py::GitWildMatchTest::test_01_absolute_ignore', 'tests/test_02_gitwildmatch.py::GitWildMatchTest::test_01_absolute_root', 'tests/test_02_gitwildmatch.py::GitWildMatchTest::test_01_relative', 'tests/test_02_gitwildmatch.py::GitWildMatchTest::test_01_relative_nested', 'tests/test_02_gitwildmatch.py::GitWildMatchTest::test_02_comment', 'tests/test_02_gitwildmatch.py::GitWildMatchTest::test_02_ignore', 'tests/test_02_gitwildmatch.py::GitWildMatchTest::test_03_child_double_asterisk', 'tests/test_02_gitwildmatch.py::GitWildMatchTest::test_03_double_asterisk_trailing_slash_edge_case', 'tests/test_02_gitwildmatch.py::GitWildMatchTest::test_03_duplicate_leading_double_asterisk_edge_case', 'tests/test_02_gitwildmatch.py::GitWildMatchTest::test_03_inner_double_asterisk', 'tests/test_02_gitwildmatch.py::GitWildMatchTest::test_03_only_double_asterisk', 'tests/test_02_gitwildmatch.py::GitWildMatchTest::test_03_parent_double_asterisk', 'tests/test_02_gitwildmatch.py::GitWildMatchTest::test_04_infix_wildcard', 'tests/test_02_gitwildmatch.py::GitWildMatchTest::test_04_postfix_wildcard', 'tests/test_02_gitwildmatch.py::GitWildMatchTest::test_04_prefix_wildcard', 'tests/test_02_gitwildmatch.py::GitWildMatchTest::test_05_directory', 'tests/test_02_gitwildmatch.py::GitWildMatchTest::test_07_match_bytes_and_bytes', 'tests/test_02_gitwildmatch.py::GitWildMatchTest::test_07_match_bytes_and_bytes_complete', 'tests/test_02_gitwildmatch.py::GitWildMatchTest::test_07_match_bytes_and_unicode_fail', 'tests/test_02_gitwildmatch.py::GitWildMatchTest::test_09_single_escape_fail', 'tests/test_02_gitwildmatch.py::GitWildMatchTest::test_09_single_exclamation_mark_fail', 'tests/test_02_gitwildmatch.py::GitWildMatchTest::test_10_escape_asterisk_end', 'tests/test_02_gitwildmatch.py::GitWildMatchTest::test_10_escape_asterisk_mid', 'tests/test_02_gitwildmatch.py::GitWildMatchTest::test_10_escape_asterisk_start', 'tests/test_02_gitwildmatch.py::GitWildMatchTest::test_12_asterisk_1_regex', 'tests/test_02_gitwildmatch.py::GitWildMatchTest::test_12_asterisk_2_regex_equivalent', 'tests/test_02_gitwildmatch.py::GitWildMatchTest::test_13_issue_77_1_negate_with_exclamation_mark', 'tests/test_02_gitwildmatch.py::GitWildMatchTest::test_13_issue_77_2_regex', 'tests/test_02_gitwildmatch.py::GitWildMatchTest::test_14_issue_81_a', 'tests/test_02_gitwildmatch.py::GitWildMatchTest::test_14_issue_81_b', 'tests/test_02_gitwildmatch.py::GitWildMatchTest::test_14_issue_81_c', 'tests/test_03_pathspec.py::PathSpecTest::test_01_absolute_dir_paths_1', 'tests/test_03_pathspec.py::PathSpecTest::test_01_absolute_dir_paths_2', 'tests/test_03_pathspec.py::PathSpecTest::test_01_current_dir_paths', 'tests/test_03_pathspec.py::PathSpecTest::test_01_empty_path_1', 'tests/test_03_pathspec.py::PathSpecTest::test_01_empty_path_2', 'tests/test_03_pathspec.py::PathSpecTest::test_05_match_entries', 'tests/test_03_pathspec.py::PathSpecTest::test_05_match_file', 'tests/test_03_pathspec.py::PathSpecTest::test_05_match_files', 'tests/test_03_pathspec.py::PathSpecTest::test_05_match_tree_entries', 'tests/test_03_pathspec.py::PathSpecTest::test_05_match_tree_files', 'tests/test_04_gitignore.py::GitIgnoreSpecTest::test_02_dir_exclusions', 'tests/test_04_gitignore.py::GitIgnoreSpecTest::test_02_file_exclusions', 'tests/test_04_gitignore.py::GitIgnoreSpecTest::test_02_issue_41_a', 'tests/test_04_gitignore.py::GitIgnoreSpecTest::test_02_issue_41_c', 'tests/test_04_gitignore.py::GitIgnoreSpecTest::test_04_issue_62', 'tests/test_04_gitignore.py::GitIgnoreSpecTest::test_07_issue_74', 'tests/test_04_gitignore.py::GitIgnoreSpecTest::test_08_issue_81_c']","['self = <tests.test_01_util.CheckMatchFileTest testMethod=test_02_many>\n\n    def test_02_many(self):\n    \t""""""\n    \tTest matching files individually.\n    \t""""""\n    \tpatterns = list(enumerate(map(GitWildMatchPattern, [\n    \t\t\'*.txt\',\n    \t\t\'!b.txt\',\n    \t])))\n    \tfiles = {\n    \t\t\'X/a.txt\',\n    \t\t\'X/b.txt\',\n    \t\t\'X/Z/c.txt\',\n    \t\t\'Y/a.txt\',\n    \t\t\'Y/b.txt\',\n    \t\t\'Y/Z/c.txt\',\n    \t}\n    \n    \tincludes = {\n    \t\t__file\n    \t\tfor __file in files\n    \t\tif check_match_file(patterns, __file)[0]\n    \t}\n    \n>   \tself.assertEqual(includes, {\n    \t\t\'X/a.txt\',\n    \t\t\'X/Z/c.txt\',\n    \t\t\'Y/a.txt\',\n    \t\t\'Y/Z/c.txt\',\n    \t})\nE    AssertionError: Items in the first set but not the second:\nE    \'X/b.txt\'\nE    \'Y/b.txt\'\n\nrepos\\python-pathspec\\tests\\test_01_util.py:104: AssertionError', 'self = <tests.test_01_util.MatchFileTest testMethod=test_02_many>\n\n    def test_02_many(self):\n    \t""""""\n    \tTest matching files individually.\n    \t""""""\n    \tpatterns = list(map(GitWildMatchPattern, [\n    \t\t\'*.txt\',\n    \t\t\'!b.txt\',\n    \t]))\n    \tfiles = {\n    \t\t\'X/a.txt\',\n    \t\t\'X/b.txt\',\n    \t\t\'X/Z/c.txt\',\n    \t\t\'Y/a.txt\',\n    \t\t\'Y/b.txt\',\n    \t\t\'Y/Z/c.txt\',\n    \t}\n    \n    \tincludes = set(filter(partial(match_file, patterns), files))\n    \n>   \tself.assertEqual(includes, {\n    \t\t\'X/a.txt\',\n    \t\t\'X/Z/c.txt\',\n    \t\t\'Y/a.txt\',\n    \t\t\'Y/Z/c.txt\',\n    \t})\nE    AssertionError: Items in the first set but not the second:\nE    \'X/b.txt\'\nE    \'Y/b.txt\'\n\nrepos\\python-pathspec\\tests\\test_01_util.py:483: AssertionError', 'self = <tests.test_02_gitwildmatch.GitWildMatchTest testMethod=test_00_empty>\n\n    def test_00_empty(self):\n    \t""""""\n    \tTests an empty pattern.\n    \t""""""\n>   \tregex, include = GitWildMatchPattern.pattern_to_regex(\'\')\nE    TypeError: GitWildMatchPattern.pattern_to_regex() missing 1 required positional argument: \'pattern\'\n\nrepos\\python-pathspec\\tests\\test_02_gitwildmatch.py:44: TypeError', 'self = <tests.test_02_gitwildmatch.GitWildMatchTest testMethod=test_01_absolute>\n\n    def test_01_absolute(self):\n    \t""""""\n    \tTests an absolute path pattern.\n    \n    \tThis should match:\n    \n    \t\tan/absolute/file/path\n    \t\tan/absolute/file/path/foo\n    \n    \tThis should NOT match:\n    \n    \t\tfoo/an/absolute/file/path\n    \t""""""\n>   \tregex, include = GitWildMatchPattern.pattern_to_regex(\'/an/absolute/file/path\')\nE    TypeError: GitWildMatchPattern.pattern_to_regex() missing 1 required positional argument: \'pattern\'\n\nrepos\\python-pathspec\\tests\\test_02_gitwildmatch.py:61: TypeError', 'self = <tests.test_02_gitwildmatch.GitWildMatchTest testMethod=test_01_absolute_ignore>\n\n    def test_01_absolute_ignore(self):\n    \t""""""\n    \tTests an ignore absolute path pattern.\n    \t""""""\n>   \tregex, include = GitWildMatchPattern.pattern_to_regex(\'!/foo/build\')\nE    TypeError: GitWildMatchPattern.pattern_to_regex() missing 1 required positional argument: \'pattern\'\n\nrepos\\python-pathspec\\tests\\test_02_gitwildmatch.py:80: TypeError', 'self = <tests.test_02_gitwildmatch.GitWildMatchTest testMethod=test_01_absolute_root>\n\n    def test_01_absolute_root(self):\n    \t""""""\n    \tTests a single root absolute path pattern.\n    \n    \tThis should NOT match any file (according to git check-ignore\n    \t(v2.4.1)).\n    \t""""""\n>   \tregex, include = GitWildMatchPattern.pattern_to_regex(\'/\')\nE    TypeError: GitWildMatchPattern.pattern_to_regex() missing 1 required positional argument: \'pattern\'\n\nrepos\\python-pathspec\\tests\\test_02_gitwildmatch.py:102: TypeError', 'self = <tests.test_02_gitwildmatch.GitWildMatchTest testMethod=test_01_relative>\n\n    def test_01_relative(self):\n    \t""""""\n    \tTests a relative path pattern.\n    \n    \tThis should match:\n    \n    \t\tspam\n    \t\tspam/\n    \t\tfoo/spam\n    \t\tspam/foo\n    \t\tfoo/spam/bar\n    \t""""""\n>   \tregex, include = GitWildMatchPattern.pattern_to_regex(\'spam\')\nE    TypeError: GitWildMatchPattern.pattern_to_regex() missing 1 required positional argument: \'pattern\'\n\nrepos\\python-pathspec\\tests\\test_02_gitwildmatch.py:118: TypeError', 'self = <tests.test_02_gitwildmatch.GitWildMatchTest testMethod=test_01_relative_nested>\n\n    def test_01_relative_nested(self):\n    \t""""""\n    \tTests a relative nested path pattern.\n    \n    \tThis should match:\n    \n    \t\tfoo/spam\n    \t\tfoo/spam/bar\n    \n    \tThis should **not** match (according to git check-ignore (v2.4.1)):\n    \n    \t\tbar/foo/spam\n    \t""""""\n>   \tregex, include = GitWildMatchPattern.pattern_to_regex(\'foo/spam\')\nE    TypeError: GitWildMatchPattern.pattern_to_regex() missing 1 required positional argument: \'pattern\'\n\nrepos\\python-pathspec\\tests\\test_02_gitwildmatch.py:151: TypeError', 'self = <tests.test_02_gitwildmatch.GitWildMatchTest testMethod=test_02_comment>\n\n    def test_02_comment(self):\n    \t""""""\n    \tTests a comment pattern.\n    \t""""""\n>   \tregex, include = GitWildMatchPattern.pattern_to_regex(\'# Cork soakers.\')\nE    TypeError: GitWildMatchPattern.pattern_to_regex() missing 1 required positional argument: \'pattern\'\n\nrepos\\python-pathspec\\tests\\test_02_gitwildmatch.py:170: TypeError', 'self = <tests.test_02_gitwildmatch.GitWildMatchTest testMethod=test_02_ignore>\n\n    def test_02_ignore(self):\n    \t""""""\n    \tTests an exclude pattern.\n    \n    \tThis should NOT match (according to git check-ignore (v2.4.1)):\n    \n    \t\ttemp/foo\n    \t""""""\n>   \tregex, include = GitWildMatchPattern.pattern_to_regex(\'!temp\')\nE    TypeError: GitWildMatchPattern.pattern_to_regex() missing 1 required positional argument: \'pattern\'\n\nrepos\\python-pathspec\\tests\\test_02_gitwildmatch.py:182: TypeError', 'self = <tests.test_02_gitwildmatch.GitWildMatchTest testMethod=test_03_child_double_asterisk>\n\n    def test_03_child_double_asterisk(self):\n    \t""""""\n    \tTests a directory name with a double-asterisk child\n    \tdirectory.\n    \n    \tThis should match:\n    \n    \t\tspam/bar\n    \n    \tThis should **not** match (according to git check-ignore (v2.4.1)):\n    \n    \t\tfoo/spam/bar\n    \t""""""\n>   \tregex, include = GitWildMatchPattern.pattern_to_regex(\'spam/**\')\nE    TypeError: GitWildMatchPattern.pattern_to_regex() missing 1 required positional argument: \'pattern\'\n\nrepos\\python-pathspec\\tests\\test_02_gitwildmatch.py:209: TypeError', 'self = <tests.test_02_gitwildmatch.GitWildMatchTest testMethod=test_03_double_asterisk_trailing_slash_edge_case>\n\n    def test_03_double_asterisk_trailing_slash_edge_case(self):\n    \t""""""\n    \tTests the edge-case **/ pattern.\n    \n    \tThis should match everything except individual files in the root directory.\n    \t""""""\n>   \tregex, include = GitWildMatchPattern.pattern_to_regex(\'**/\')\nE    TypeError: GitWildMatchPattern.pattern_to_regex() missing 1 required positional argument: \'pattern\'\n\nrepos\\python-pathspec\\tests\\test_02_gitwildmatch.py:357: TypeError', 'self = <tests.test_02_gitwildmatch.GitWildMatchTest testMethod=test_03_duplicate_leading_double_asterisk_edge_case>\n\n    def test_03_duplicate_leading_double_asterisk_edge_case(self):\n    \t""""""\n    \tRegression test for duplicate leading **/ bug.\n    \t""""""\n>   \tregex, include = GitWildMatchPattern.pattern_to_regex(\'**\')\nE    TypeError: GitWildMatchPattern.pattern_to_regex() missing 1 required positional argument: \'pattern\'\n\nrepos\\python-pathspec\\tests\\test_02_gitwildmatch.py:315: TypeError', 'self = <tests.test_02_gitwildmatch.GitWildMatchTest testMethod=test_03_inner_double_asterisk>\n\n    def test_03_inner_double_asterisk(self):\n    \t""""""\n    \tTests a path with an inner double-asterisk directory.\n    \n    \tThis should match:\n    \n    \t\tleft/right\n    \t\tleft/bar/right\n    \t\tleft/foo/bar/right\n    \t\tleft/bar/right/foo\n    \n    \tThis should **not** match (according to git check-ignore (v2.4.1)):\n    \n    \t\tfoo/left/bar/right\n    \t""""""\n>   \tregex, include = GitWildMatchPattern.pattern_to_regex(\'left/**/right\')\nE    TypeError: GitWildMatchPattern.pattern_to_regex() missing 1 required positional argument: \'pattern\'\n\nrepos\\python-pathspec\\tests\\test_02_gitwildmatch.py:235: TypeError', 'self = <tests.test_02_gitwildmatch.GitWildMatchTest testMethod=test_03_only_double_asterisk>\n\n    def test_03_only_double_asterisk(self):\n    \t""""""\n    \tTests a double-asterisk pattern which matches everything.\n    \t""""""\n>   \tregex, include = GitWildMatchPattern.pattern_to_regex(\'**\')\nE    TypeError: GitWildMatchPattern.pattern_to_regex() missing 1 required positional argument: \'pattern\'\n\nrepos\\python-pathspec\\tests\\test_02_gitwildmatch.py:258: TypeError', 'self = <tests.test_02_gitwildmatch.GitWildMatchTest testMethod=test_03_parent_double_asterisk>\n\n    def test_03_parent_double_asterisk(self):\n    \t""""""\n    \tTests a file name with a double-asterisk parent directory.\n    \n    \tThis should match:\n    \n    \t\tspam\n    \t\tfoo/spam\n    \t\tfoo/spam/bar\n    \t""""""\n>   \tregex, include = GitWildMatchPattern.pattern_to_regex(\'**/spam\')\nE    TypeError: GitWildMatchPattern.pattern_to_regex() missing 1 required positional argument: \'pattern\'\n\nrepos\\python-pathspec\\tests\\test_02_gitwildmatch.py:295: TypeError', 'self = <tests.test_02_gitwildmatch.GitWildMatchTest testMethod=test_04_infix_wildcard>\n\n    def test_04_infix_wildcard(self):\n    \t""""""\n    \tTests a pattern with an infix wildcard.\n    \n    \tThis should match:\n    \n    \t\tfoo--bar\n    \t\tfoo-hello-bar\n    \t\ta/foo-hello-bar\n    \t\tfoo-hello-bar/b\n    \t\ta/foo-hello-bar/b\n    \t""""""\n>   \tregex, include = GitWildMatchPattern.pattern_to_regex(\'foo-*-bar\')\nE    TypeError: GitWildMatchPattern.pattern_to_regex() missing 1 required positional argument: \'pattern\'\n\nrepos\\python-pathspec\\tests\\test_02_gitwildmatch.py:377: TypeError', 'self = <tests.test_02_gitwildmatch.GitWildMatchTest testMethod=test_04_postfix_wildcard>\n\n    def test_04_postfix_wildcard(self):\n    \t""""""\n    \tTests a pattern with a postfix wildcard.\n    \n    \tThis should match:\n    \n    \t\t~temp-\n    \t\t~temp-foo\n    \t\t~temp-foo/bar\n    \t\tfoo/~temp-bar\n    \t\tfoo/~temp-bar/baz\n    \t""""""\n>   \tregex, include = GitWildMatchPattern.pattern_to_regex(\'~temp-*\')\nE    TypeError: GitWildMatchPattern.pattern_to_regex() missing 1 required positional argument: \'pattern\'\n\nrepos\\python-pathspec\\tests\\test_02_gitwildmatch.py:409: TypeError', 'self = <tests.test_02_gitwildmatch.GitWildMatchTest testMethod=test_04_prefix_wildcard>\n\n    def test_04_prefix_wildcard(self):\n    \t""""""\n    \tTests a pattern with a prefix wildcard.\n    \n    \tThis should match:\n    \n    \t\tbar.py\n    \t\tbar.py/\n    \t\tfoo/bar.py\n    \t\tfoo/bar.py/baz\n    \t""""""\n>   \tregex, include = GitWildMatchPattern.pattern_to_regex(\'*.py\')\nE    TypeError: GitWildMatchPattern.pattern_to_regex() missing 1 required positional argument: \'pattern\'\n\nrepos\\python-pathspec\\tests\\test_02_gitwildmatch.py:440: TypeError', 'self = <tests.test_02_gitwildmatch.GitWildMatchTest testMethod=test_05_directory>\n\n    def test_05_directory(self):\n    \t""""""\n    \tTests a directory pattern.\n    \n    \tThis should match:\n    \n    \t\tdir/\n    \t\tfoo/dir/\n    \t\tfoo/dir/bar\n    \n    \tThis should **not** match:\n    \n    \t\tdir\n    \t""""""\n>   \tregex, include = GitWildMatchPattern.pattern_to_regex(\'dir/\')\nE    TypeError: GitWildMatchPattern.pattern_to_regex() missing 1 required positional argument: \'pattern\'\n\nrepos\\python-pathspec\\tests\\test_02_gitwildmatch.py:472: TypeError', 'self = <tests.test_02_gitwildmatch.GitWildMatchTest testMethod=test_07_match_bytes_and_bytes>\n\n    def test_07_match_bytes_and_bytes(self):\n    \t""""""\n    \tTest byte string patterns matching byte string paths.\n    \t""""""\n>   \tpattern = GitWildMatchPattern(b\'*.py\')\n\nrepos\\python-pathspec\\tests\\test_02_gitwildmatch.py:557: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\python-pathspec\\pathspec\\pattern.py:118: in __init__\n    regex, include = self.pattern_to_regex(pattern)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ncls = <pathspec.patterns.gitwildmatch.GitWildMatchPattern object at 0x000001762B659880>\npattern = b\'*.py\'\n\n    def pattern_to_regex(cls, pattern):\n        import re\n>       if pattern.startswith(\'!\'):\nE       TypeError: startswith first arg must be bytes or a tuple of bytes, not str\n\nrepos\\python-pathspec\\pathspec\\patterns\\gitwildmatch.py:31: TypeError', 'self = <tests.test_02_gitwildmatch.GitWildMatchTest testMethod=test_07_match_bytes_and_bytes_complete>\n\n    def test_07_match_bytes_and_bytes_complete(self):\n    \t""""""\n    \tTest byte string patterns matching byte string paths.\n    \t""""""\n    \tencoded = bytes(bytearray(range(0, 256)))\n    \n    \t# Forward slashes cannot be escaped with the current implementation.\n    \t# Remove ASCII 47.\n    \tfs_ord = ord(\'/\')\n    \tencoded = encoded[:fs_ord] + encoded[fs_ord+1:]\n    \n    \tescaped = b"""".join(b""\\\\"" + encoded[i:i+1] for i in range(len(encoded)))\n    \n>   \tpattern = GitWildMatchPattern(escaped)\n\nrepos\\python-pathspec\\tests\\test_02_gitwildmatch.py:574: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\python-pathspec\\pathspec\\pattern.py:118: in __init__\n    regex, include = self.pattern_to_regex(pattern)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ncls = <pathspec.patterns.gitwildmatch.GitWildMatchPattern object at 0x000001762B7B9E80>\npattern = b\'\\\\\\x00\\\\\\x01\\\\\\x02\\\\\\x03\\\\\\x04\\\\\\x05\\\\\\x06\\\\\\x07\\\\\\x08\\\\\\t\\\\\\n\\\\\\x0b\\\\\\x0c\\\\\\r\\\\\\x0e\\\\\\x0f\\\\\\x10\\\\\\x11\\\\\\x12\\\\\\x13\\\\...\\xec\\\\\\xed\\\\\\xee\\\\\\xef\\\\\\xf0\\\\\\xf1\\\\\\xf2\\\\\\xf3\\\\\\xf4\\\\\\xf5\\\\\\xf6\\\\\\xf7\\\\\\xf8\\\\\\xf9\\\\\\xfa\\\\\\xfb\\\\\\xfc\\\\\\xfd\\\\\\xfe\\\\\\xff\'\n\n    def pattern_to_regex(cls, pattern):\n        import re\n>       if pattern.startswith(\'!\'):\nE       TypeError: startswith first arg must be bytes or a tuple of bytes, not str\n\nrepos\\python-pathspec\\pathspec\\patterns\\gitwildmatch.py:31: TypeError', 'self = <tests.test_02_gitwildmatch.GitWildMatchTest testMethod=test_07_match_bytes_and_unicode_fail>\n\n    def test_07_match_bytes_and_unicode_fail(self):\n    \t""""""\n    \tTest byte string patterns matching byte string paths.\n    \t""""""\n>   \tpattern = GitWildMatchPattern(b\'*.py\')\n\nrepos\\python-pathspec\\tests\\test_02_gitwildmatch.py:582: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\python-pathspec\\pathspec\\pattern.py:118: in __init__\n    regex, include = self.pattern_to_regex(pattern)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ncls = <pathspec.patterns.gitwildmatch.GitWildMatchPattern object at 0x000001762B6C0AC0>\npattern = b\'*.py\'\n\n    def pattern_to_regex(cls, pattern):\n        import re\n>       if pattern.startswith(\'!\'):\nE       TypeError: startswith first arg must be bytes or a tuple of bytes, not str\n\nrepos\\python-pathspec\\pathspec\\patterns\\gitwildmatch.py:31: TypeError', 'self = <tests.test_02_gitwildmatch.GitWildMatchTest testMethod=test_09_single_escape_fail>\n\n    def test_09_single_escape_fail(self):\n    \t""""""\n    \tTest an escape on a line by itself.\n    \t""""""\n>   \tself._check_invalid_pattern(""\\\\"")\n\nrepos\\python-pathspec\\tests\\test_02_gitwildmatch.py:615: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\python-pathspec\\tests\\test_02_gitwildmatch.py:38: in _check_invalid_pattern\n    GitWildMatchPattern(git_ignore_pattern)\nrepos\\python-pathspec\\pathspec\\pattern.py:118: in __init__\n    regex, include = self.pattern_to_regex(pattern)\nrepos\\python-pathspec\\pathspec\\patterns\\gitwildmatch.py:40: in pattern_to_regex\n    regex = re.compile(pattern)\n..\\..\\..\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\re\\__init__.py:289: in compile\n    return _compile(pattern, flags)\n..\\..\\..\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\re\\__init__.py:350: in _compile\n    p = _compiler.compile(pattern, flags)\n..\\..\\..\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\re\\_compiler.py:743: in compile\n    p = _parser.parse(p, flags)\n..\\..\\..\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\re\\_parser.py:973: in parse\n    source = Tokenizer(str)\n..\\..\\..\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\re\\_parser.py:238: in __init__\n    self.__next()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n    def __next(self):\n        index = self.index\n        try:\n            char = self.decoded_string[index]\n        except IndexError:\n            self.next = None\n            return\n        if char == ""\\\\"":\n            index += 1\n            try:\n                char += self.decoded_string[index]\n            except IndexError:\n>               raise error(""bad escape (end of pattern)"",\n                            self.string, len(self.string) - 1) from None\nE               re.PatternError: bad escape (end of pattern) at position 0\n\n..\\..\\..\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\re\\_parser.py:251: PatternError', 'self = <tests.test_02_gitwildmatch.GitWildMatchTest testMethod=test_09_single_exclamation_mark_fail>\n\n    def test_09_single_exclamation_mark_fail(self):\n    \t""""""\n    \tTest an escape on a line by itself.\n    \t""""""\n>   \tself._check_invalid_pattern(""!"")\n\nrepos\\python-pathspec\\tests\\test_02_gitwildmatch.py:621: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\python-pathspec\\tests\\test_02_gitwildmatch.py:37: in _check_invalid_pattern\n    with self.assertRaisesRegex(GitWildMatchPatternError, expected_message_pattern):\nE   AssertionError: GitWildMatchPatternError not raised', 'self = <tests.test_02_gitwildmatch.GitWildMatchTest testMethod=test_10_escape_asterisk_end>\n\n    def test_10_escape_asterisk_end(self):\n    \t""""""\n    \tTest escaping an asterisk at the end of a line.\n    \t""""""\n    \tpattern = GitWildMatchPattern(""asteris\\\\*"")\n    \tresults = set(filter(pattern.match_file, [\n    \t\t""asteris*"",\n    \t\t""asterisk"",\n    \t]))\n>   \tself.assertEqual(results, {""asteris*""})\nE    AssertionError: Items in the first set but not the second:\nE    \'asterisk\'\n\nrepos\\python-pathspec\\tests\\test_02_gitwildmatch.py:632: AssertionError', 'self = <tests.test_02_gitwildmatch.GitWildMatchTest testMethod=test_10_escape_asterisk_mid>\n\n    def test_10_escape_asterisk_mid(self):\n    \t""""""\n    \tTest escaping an asterisk in the middle of a line.\n    \t""""""\n    \tpattern = GitWildMatchPattern(""as\\\\*erisk"")\n    \tresults = set(filter(pattern.match_file, [\n    \t\t""as*erisk"",\n    \t\t""asterisk"",\n    \t]))\n>   \tself.assertEqual(results, {""as*erisk""})\nE    AssertionError: Items in the second set but not the first:\nE    \'as*erisk\'\n\nrepos\\python-pathspec\\tests\\test_02_gitwildmatch.py:643: AssertionError', 'self = <tests.test_02_gitwildmatch.GitWildMatchTest testMethod=test_10_escape_asterisk_start>\n\n    def test_10_escape_asterisk_start(self):\n    \t""""""\n    \tTest escaping an asterisk at the start of a line.\n    \t""""""\n    \tpattern = GitWildMatchPattern(""\\\\*sterisk"")\n    \tresults = set(filter(pattern.match_file, [\n    \t\t""*sterisk"",\n    \t\t""asterisk"",\n    \t]))\n>   \tself.assertEqual(results, {""*sterisk""})\nE    AssertionError: Items in the second set but not the first:\nE    \'*sterisk\'\n\nrepos\\python-pathspec\\tests\\test_02_gitwildmatch.py:654: AssertionError', 'self = <tests.test_02_gitwildmatch.GitWildMatchTest testMethod=test_12_asterisk_1_regex>\n\n    def test_12_asterisk_1_regex(self):\n    \t""""""\n    \tTest a relative asterisk path pattern\'s regular expression.\n    \t""""""\n>   \tregex, include = GitWildMatchPattern.pattern_to_regex(\'*\')\nE    TypeError: GitWildMatchPattern.pattern_to_regex() missing 1 required positional argument: \'pattern\'\n\nrepos\\python-pathspec\\tests\\test_02_gitwildmatch.py:743: TypeError', 'self = <tests.test_02_gitwildmatch.GitWildMatchTest testMethod=test_12_asterisk_2_regex_equivalent>\n\n    def test_12_asterisk_2_regex_equivalent(self):\n    \t""""""\n    \tTest a path pattern equivalent to the relative asterisk using double\n    \tasterisk.\n    \t""""""\n>   \tregex, include = GitWildMatchPattern.pattern_to_regex(\'*\')\nE    TypeError: GitWildMatchPattern.pattern_to_regex() missing 1 required positional argument: \'pattern\'\n\nrepos\\python-pathspec\\tests\\test_02_gitwildmatch.py:752: TypeError', 'self = <tests.test_02_gitwildmatch.GitWildMatchTest testMethod=test_13_issue_77_1_negate_with_exclamation_mark>\n\n    def test_13_issue_77_1_negate_with_exclamation_mark(self):\n    \t""""""\n    \tTest negation using the exclamation mark (""!"").\n    \t""""""\n    \tpattern = GitWildMatchPattern(""a[!gy]c"")\n    \tresults = set(filter(pattern.match_file, [\n    \t\t""agc"",\n    \t\t""ayc"",\n    \t\t""abc"",\n    \t\t""adc"",\n    \t]))\n>   \tself.assertEqual(results, {\n    \t\t""abc"",\n    \t\t""adc"",\n    \t})\nE    AssertionError: Items in the first set but not the second:\nE    \'ayc\'\nE    \'agc\'\nE    Items in the second set but not the first:\nE    \'adc\'\nE    \'abc\'\n\nrepos\\python-pathspec\\tests\\test_02_gitwildmatch.py:815: AssertionError', 'self = <tests.test_02_gitwildmatch.GitWildMatchTest testMethod=test_13_issue_77_2_regex>\n\n    def test_13_issue_77_2_regex(self):\n    \t""""""\n    \tTest the resulting regex for regex bracket expression negation.\n    \t""""""\n>   \tregex, include = GitWildMatchPattern.pattern_to_regex(""a[^b]c"")\nE    TypeError: GitWildMatchPattern.pattern_to_regex() missing 1 required positional argument: \'pattern\'\n\nrepos\\python-pathspec\\tests\\test_02_gitwildmatch.py:824: TypeError', 'self = <tests.test_02_gitwildmatch.GitWildMatchTest testMethod=test_14_issue_81_a>\n\n    def test_14_issue_81_a(self):\n    \t""""""\n    \tTest ignoring files in a directory, scenario A.\n    \t""""""\n    \tpattern = GitWildMatchPattern(""!libfoo/**"")\n    \n>   \tself.assertEqual(pattern.regex.pattern, ""^libfoo/.*$"")\nE    AssertionError: \'libfoo/.*.*\' != \'^libfoo/.*$\'\nE    - libfoo/.*.*\nE    ?          ^^\nE    + ^libfoo/.*$\nE    ? +         ^\n\nrepos\\python-pathspec\\tests\\test_02_gitwildmatch.py:838: AssertionError', 'self = <tests.test_02_gitwildmatch.GitWildMatchTest testMethod=test_14_issue_81_b>\n\n    def test_14_issue_81_b(self):\n    \t""""""\n    \tTest ignoring files in a directory, scenario B.\n    \t""""""\n    \tpattern = GitWildMatchPattern(""!libfoo/*"")\n    \n>   \tself.assertEqual(pattern.regex.pattern, f""^libfoo/[^/]+{RE_SUB}$"")\nE    AssertionError: \'libfoo/.*\' != \'^libfoo/[^/]+(?:(?P<ps_d>/).*)?$\'\nE    - libfoo/.*\nE    + ^libfoo/[^/]+(?:(?P<ps_d>/).*)?$\n\nrepos\\python-pathspec\\tests\\test_02_gitwildmatch.py:848: AssertionError', 'self = <tests.test_02_gitwildmatch.GitWildMatchTest testMethod=test_14_issue_81_c>\n\n    def test_14_issue_81_c(self):\n    \t""""""\n    \tTest ignoring files in a directory, scenario C.\n    \t""""""\n    \t# GitWildMatchPattern will match the file, but GitIgnoreSpec should not.\n    \tpattern = GitWildMatchPattern(""!libfoo/"")\n    \n>   \tself.assertEqual(pattern.regex.pattern, f""^(?:.+/)?libfoo{RE_DIR}.*$"")\nE    AssertionError: \'libfoo/\' != \'^(?:.+/)?libfoo(?P<ps_d>/).*$\'\nE    - libfoo/\nE    + ^(?:.+/)?libfoo(?P<ps_d>/).*$\n\nrepos\\python-pathspec\\tests\\test_02_gitwildmatch.py:859: AssertionError', 'self = <tests.test_03_pathspec.PathSpecTest testMethod=test_01_absolute_dir_paths_1>\n\n    def test_01_absolute_dir_paths_1(self):\n    \t""""""\n    \tTests that absolute paths will be properly normalized and matched.\n    \t""""""\n    \tspec = PathSpec.from_lines(\'gitwildmatch\', [\n    \t\t\'foo\',\n    \t])\n    \tfiles = {\n    \t\t\'/a.py\',\n    \t\t\'/foo/a.py\',\n    \t\t\'/x/a.py\',\n    \t\t\'/x/foo/a.py\',\n    \t\t\'a.py\',\n    \t\t\'foo/a.py\',\n    \t\t\'x/a.py\',\n    \t\t\'x/foo/a.py\',\n    \t}\n    \n    \tresults = list(spec.check_files(files))\n    \tincludes = get_includes(results)\n    \tdebug = debug_results(spec, results)\n    \n>   \tself.assertEqual(includes, {\n    \t\t\'/foo/a.py\',\n    \t\t\'/x/foo/a.py\',\n    \t\t\'foo/a.py\',\n    \t\t\'x/foo/a.py\',\n    \t}, debug)\nE    AssertionError: Items in the second set but not the first:\nE    \'x/foo/a.py\'\nE    \'/x/foo/a.py\' : \nE    \nE    ------------ DEBUG -------------\nE     1:foo  \'foo\'\nE    --------------------------------\nE     -      /a.py\nE     1:foo  /foo/a.py\nE     -      /x/a.py\nE     -      /x/foo/a.py\nE     -      a.py\nE     1:foo  foo/a.py\nE     -      x/a.py\nE     -      x/foo/a.py\nE    --------------------------------\n\nrepos\\python-pathspec\\tests\\test_03_pathspec.py:79: AssertionError', 'self = <tests.test_03_pathspec.PathSpecTest testMethod=test_01_absolute_dir_paths_2>\n\n    def test_01_absolute_dir_paths_2(self):\n    \t""""""\n    \tTests that absolute paths will be properly normalized and matched.\n    \t""""""\n    \tspec = PathSpec.from_lines(\'gitwildmatch\', [\n    \t\t\'/foo\',\n    \t])\n    \tfiles = {\n    \t\t\'/a.py\',\n    \t\t\'/foo/a.py\',\n    \t\t\'/x/a.py\',\n    \t\t\'/x/foo/a.py\',\n    \t\t\'a.py\',\n    \t\t\'foo/a.py\',\n    \t\t\'x/a.py\',\n    \t\t\'x/foo/a.py\',\n    \t}\n    \n    \tresults = list(spec.check_files(files))\n    \tincludes = get_includes(results)\n    \tdebug = debug_results(spec, results)\n    \n>   \tself.assertEqual(includes, {\n    \t\t\'/foo/a.py\',\n    \t\t\'foo/a.py\',\n    \t}, debug)\nE    AssertionError: Items in the second set but not the first:\nE    \'/foo/a.py\'\nE    \'foo/a.py\' : \nE    \nE    ------------ DEBUG -------------\nE     1:/foo  \'/foo\'\nE    --------------------------------\nE     -       /a.py\nE     -       /foo/a.py\nE     -       /x/a.py\nE     -       /x/foo/a.py\nE     -       a.py\nE     -       foo/a.py\nE     -       x/a.py\nE     -       x/foo/a.py\nE    --------------------------------\n\nrepos\\python-pathspec\\tests\\test_03_pathspec.py:108: AssertionError', 'self = <tests.test_03_pathspec.PathSpecTest testMethod=test_01_current_dir_paths>\n\n    def test_01_current_dir_paths(self):\n    \t""""""\n    \tTests that paths referencing the current directory will be properly\n    \tnormalized and matched.\n    \t""""""\n    \tspec = PathSpec.from_lines(\'gitwildmatch\', [\n    \t\t\'*.txt\',\n    \t\t\'!test1/\',\n    \t])\n    \tfiles = {\n    \t\t\'./src/test1/a.txt\',\n    \t\t\'./src/test1/b.txt\',\n    \t\t\'./src/test1/c/c.txt\',\n    \t\t\'./src/test2/a.txt\',\n    \t\t\'./src/test2/b.txt\',\n    \t\t\'./src/test2/c/c.txt\',\n    \t}\n    \n    \tresults = list(spec.check_files(files))\n    \tincludes = get_includes(results)\n    \tdebug = debug_results(spec, results)\n    \n>   \tself.assertEqual(includes, {\n    \t\t\'./src/test2/a.txt\',\n    \t\t\'./src/test2/b.txt\',\n    \t\t\'./src/test2/c/c.txt\',\n    \t}, debug)\nE    AssertionError: Items in the first set but not the second:\nE    \'./src/test1/b.txt\'\nE    \'./src/test1/c/c.txt\'\nE    \'./src/test1/a.txt\' : \nE    \nE    ------------ DEBUG -------------\nE     1:*.txt    \'.*\\\\.txt\'\nE     2:!test1/  \'test1/\'\nE    --------------------------------\nE     1:*.txt    ./src/test1/a.txt\nE     1:*.txt    ./src/test1/b.txt\nE     1:*.txt    ./src/test1/c/c.txt\nE     1:*.txt    ./src/test2/a.txt\nE     1:*.txt    ./src/test2/b.txt\nE     1:*.txt    ./src/test2/c/c.txt\nE    --------------------------------\n\nrepos\\python-pathspec\\tests\\test_03_pathspec.py:220: AssertionError', 'self = <tests.test_03_pathspec.PathSpecTest testMethod=test_01_empty_path_1>\n\n    def test_01_empty_path_1(self):\n    \t""""""\n    \tTests that patterns that end with an escaped space will be treated properly.\n    \t""""""\n    \tspec = PathSpec.from_lines(\'gitwildmatch\', [\n    \t\t\'\\\\ \',\n    \t\t\'abc\\\\ \'\n    \t])\n    \tfiles = {\n    \t\t\' \',\n    \t\t\'  \',\n    \t\t\'abc \',\n    \t\t\'somefile\',\n    \t}\n    \n    \tresults = list(spec.check_files(files))\n    \tincludes = get_includes(results)\n    \tdebug = debug_results(spec, results)\n    \n>   \tself.assertEqual(includes, {\n    \t\t\' \',\n    \t\t\'abc \'\n    \t}, debug)\nE    AssertionError: Items in the first set but not the second:\nE    \'  \' : \nE    \nE    ------------ DEBUG -------------\nE     1:\\      \'\\\\ \'\nE     2:abc\\   \'abc\\\\ \'\nE    --------------------------------\nE     1:\\       \nE     1:\\        \nE     2:abc\\   abc \nE     -        somefile\nE    --------------------------------\n\nrepos\\python-pathspec\\tests\\test_03_pathspec.py:245: AssertionError', 'self = <tests.test_03_pathspec.PathSpecTest testMethod=test_01_empty_path_2>\n\n    def test_01_empty_path_2(self):\n    \t""""""\n    \tTests that patterns that end with an escaped space will be treated properly.\n    \t""""""\n>   \twith self.assertRaises(GitWildMatchPatternError):\nE    AssertionError: GitWildMatchPatternError not raised\n\nrepos\\python-pathspec\\tests\\test_03_pathspec.py:254: AssertionError', 'self = <tests.test_03_pathspec.PathSpecTest testMethod=test_05_match_entries>\n\n    def test_05_match_entries(self):\n    \t""""""\n    \tTest matching files collectively.\n    \t""""""\n    \tspec = PathSpec.from_lines(\'gitwildmatch\', [\n    \t\t\'*.txt\',\n    \t\t\'!b.txt\',\n    \t])\n    \tself.make_dirs([\n    \t\t\'X\',\n    \t\t\'X/Z\',\n    \t\t\'Y\',\n    \t\t\'Y/Z\',\n    \t])\n    \tself.make_files([\n    \t\t\'X/a.txt\',\n    \t\t\'X/b.txt\',\n    \t\t\'X/Z/c.txt\',\n    \t\t\'Y/a.txt\',\n    \t\t\'Y/b.txt\',\n    \t\t\'Y/Z/c.txt\',\n    \t])\n    \n    \tentries = iter_tree_entries(self.temp_dir)\n    \tincludes = {\n    \t\t__entry.path for __entry in spec.match_entries(entries)\n    \t}\n    \n>   \tself.assertEqual(includes, set(map(ospath, [\n    \t\t\'X/a.txt\',\n    \t\t\'X/Z/c.txt\',\n    \t\t\'Y/a.txt\',\n    \t\t\'Y/Z/c.txt\',\n    \t])))\nE    AssertionError: Items in the first set but not the second:\nE    \'Y\\\\b.txt\'\nE    \'X\\\\b.txt\'\n\nrepos\\python-pathspec\\tests\\test_03_pathspec.py:503: AssertionError', 'self = <tests.test_03_pathspec.PathSpecTest testMethod=test_05_match_file>\n\n    def test_05_match_file(self):\n    \t""""""\n    \tTest matching files individually.\n    \t""""""\n    \tspec = PathSpec.from_lines(\'gitwildmatch\', [\n    \t\t\'*.txt\',\n    \t\t\'!b.txt\',\n    \t])\n    \tfiles = {\n    \t\t\'X/a.txt\',\n    \t\t\'X/b.txt\',\n    \t\t\'X/Z/c.txt\',\n    \t\t\'Y/a.txt\',\n    \t\t\'Y/b.txt\',\n    \t\t\'Y/Z/c.txt\',\n    \t}\n    \n    \tincludes = set(filter(spec.match_file, files))\n    \n>   \tself.assertEqual(includes, {\n    \t\t\'X/a.txt\',\n    \t\t\'X/Z/c.txt\',\n    \t\t\'Y/a.txt\',\n    \t\t\'Y/Z/c.txt\',\n    \t})\nE    AssertionError: Items in the first set but not the second:\nE    \'X/b.txt\'\nE    \'Y/b.txt\'\n\nrepos\\python-pathspec\\tests\\test_03_pathspec.py:529: AssertionError', 'self = <tests.test_03_pathspec.PathSpecTest testMethod=test_05_match_files>\n\n    def test_05_match_files(self):\n    \t""""""\n    \tTest matching files collectively.\n    \t""""""\n    \tspec = PathSpec.from_lines(\'gitwildmatch\', [\n    \t\t\'*.txt\',\n    \t\t\'!b.txt\',\n    \t])\n    \tfiles = {\n    \t\t\'X/a.txt\',\n    \t\t\'X/b.txt\',\n    \t\t\'X/Z/c.txt\',\n    \t\t\'Y/a.txt\',\n    \t\t\'Y/b.txt\',\n    \t\t\'Y/Z/c.txt\',\n    \t}\n    \n    \tincludes = set(spec.match_files(files))\n    \n>   \tself.assertEqual(includes, {\n    \t\t\'X/a.txt\',\n    \t\t\'X/Z/c.txt\',\n    \t\t\'Y/a.txt\',\n    \t\t\'Y/Z/c.txt\',\n    \t})\nE    AssertionError: Items in the first set but not the second:\nE    \'X/b.txt\'\nE    \'Y/b.txt\'\n\nrepos\\python-pathspec\\tests\\test_03_pathspec.py:555: AssertionError', 'self = <tests.test_03_pathspec.PathSpecTest testMethod=test_05_match_tree_entries>\n\n    def test_05_match_tree_entries(self):\n    \t""""""\n    \tTest matching a file tree.\n    \t""""""\n    \tspec = PathSpec.from_lines(\'gitwildmatch\', [\n    \t\t\'*.txt\',\n    \t\t\'!b.txt\',\n    \t])\n    \tself.make_dirs([\n    \t\t\'X\',\n    \t\t\'X/Z\',\n    \t\t\'Y\',\n    \t\t\'Y/Z\',\n    \t])\n    \tself.make_files([\n    \t\t\'X/a.txt\',\n    \t\t\'X/b.txt\',\n    \t\t\'X/Z/c.txt\',\n    \t\t\'Y/a.txt\',\n    \t\t\'Y/b.txt\',\n    \t\t\'Y/Z/c.txt\',\n    \t])\n    \n    \tincludes = {\n    \t\t__entry.path for __entry in spec.match_tree_entries(self.temp_dir)\n    \t}\n    \n>   \tself.assertEqual(includes, set(map(ospath, [\n    \t\t\'X/a.txt\',\n    \t\t\'X/Z/c.txt\',\n    \t\t\'Y/a.txt\',\n    \t\t\'Y/Z/c.txt\',\n    \t])))\nE    AssertionError: Items in the first set but not the second:\nE    \'Y\\\\b.txt\'\nE    \'X\\\\b.txt\'\n\nrepos\\python-pathspec\\tests\\test_03_pathspec.py:589: AssertionError', 'self = <tests.test_03_pathspec.PathSpecTest testMethod=test_05_match_tree_files>\n\n    def test_05_match_tree_files(self):\n    \t""""""\n    \tTest matching a file tree.\n    \t""""""\n    \tspec = PathSpec.from_lines(\'gitwildmatch\', [\n    \t\t\'*.txt\',\n    \t\t\'!b.txt\',\n    \t])\n    \tself.make_dirs([\n    \t\t\'X\',\n    \t\t\'X/Z\',\n    \t\t\'Y\',\n    \t\t\'Y/Z\',\n    \t])\n    \tself.make_files([\n    \t\t\'X/a.txt\',\n    \t\t\'X/b.txt\',\n    \t\t\'X/Z/c.txt\',\n    \t\t\'Y/a.txt\',\n    \t\t\'Y/b.txt\',\n    \t\t\'Y/Z/c.txt\',\n    \t])\n    \n    \tincludes = set(spec.match_tree_files(self.temp_dir))\n    \n>   \tself.assertEqual(includes, set(map(ospath, [\n    \t\t\'X/a.txt\',\n    \t\t\'X/Z/c.txt\',\n    \t\t\'Y/a.txt\',\n    \t\t\'Y/Z/c.txt\',\n    \t])))\nE    AssertionError: Items in the first set but not the second:\nE    \'Y\\\\b.txt\'\nE    \'X\\\\b.txt\'\n\nrepos\\python-pathspec\\tests\\test_03_pathspec.py:621: AssertionError', 'self = <tests.test_04_gitignore.GitIgnoreSpecTest testMethod=test_02_dir_exclusions>\n\n    def test_02_dir_exclusions(self):\n    \t""""""\n    \tTest directory exclusions.\n    \t""""""\n    \tspec = GitIgnoreSpec.from_lines([\n    \t\t\'*.txt\',\n    \t\t\'!test1/\',\n    \t])\n    \tfiles = {\n    \t\t\'test1/a.txt\',\n    \t\t\'test1/b.bin\',\n    \t\t\'test1/c/c.txt\',\n    \t\t\'test2/a.txt\',\n    \t\t\'test2/b.bin\',\n    \t\t\'test2/c/c.txt\',\n    \t}\n    \n    \tresults = list(spec.check_files(files))\n    \tignores = get_includes(results)\n    \tdebug = debug_results(spec, results)\n    \n>   \tself.assertEqual(ignores, {\n    \t\t\'test1/a.txt\',\n    \t\t\'test1/c/c.txt\',\n    \t\t\'test2/a.txt\',\n    \t\t\'test2/c/c.txt\',\n    \t}, debug)\nE    AssertionError: Items in the second set but not the first:\nE    \'test1/c/c.txt\'\nE    \'test1/a.txt\' : \nE    \nE    ------------ DEBUG -------------\nE     1:*.txt    \'.*\\\\.txt\'\nE     2:!test1/  \'test1/\'\nE    --------------------------------\nE     2:!test1/  test1/a.txt\nE     2:!test1/  test1/b.bin\nE     2:!test1/  test1/c/c.txt\nE     1:*.txt    test2/a.txt\nE     -          test2/b.bin\nE     1:*.txt    test2/c/c.txt\nE    --------------------------------\n\nrepos\\python-pathspec\\tests\\test_04_gitignore.py:59: AssertionError', 'self = <tests.test_04_gitignore.GitIgnoreSpecTest testMethod=test_02_file_exclusions>\n\n    def test_02_file_exclusions(self):\n    \t""""""\n    \tTest file exclusions.\n    \t""""""\n    \tspec = GitIgnoreSpec.from_lines([\n    \t\t\'*.txt\',\n    \t\t\'!b.txt\',\n    \t])\n    \tfiles = {\n    \t\t\'X/a.txt\',\n    \t\t\'X/b.txt\',\n    \t\t\'X/Z/c.txt\',\n    \t\t\'Y/a.txt\',\n    \t\t\'Y/b.txt\',\n    \t\t\'Y/Z/c.txt\',\n    \t}\n    \n    \tresults = list(spec.check_files(files))\n    \tignores = get_includes(results)\n    \tdebug = debug_results(spec, results)\n    \n>   \tself.assertEqual(ignores, {\n    \t\t\'X/a.txt\',\n    \t\t\'X/Z/c.txt\',\n    \t\t\'Y/a.txt\',\n    \t\t\'Y/Z/c.txt\',\n    \t}, debug)\nE    AssertionError: Items in the first set but not the second:\nE    \'X/b.txt\'\nE    \'Y/b.txt\' : \nE    \nE    ------------ DEBUG -------------\nE     1:*.txt   \'.*\\\\.txt\'\nE     2:!b.txt  \'b\\\\.txt\'\nE    --------------------------------\nE     1:*.txt   X/Z/c.txt\nE     1:*.txt   X/a.txt\nE     1:*.txt   X/b.txt\nE     1:*.txt   Y/Z/c.txt\nE     1:*.txt   Y/a.txt\nE     1:*.txt   Y/b.txt\nE    --------------------------------\n\nrepos\\python-pathspec\\tests\\test_04_gitignore.py:91: AssertionError', 'self = <tests.test_04_gitignore.GitIgnoreSpecTest testMethod=test_02_issue_41_a>\n\n    def test_02_issue_41_a(self):\n    \t""""""\n    \tTest including a file and excluding a directory with the same name pattern,\n    \tscenario A.\n    \t""""""\n    \t# Confirmed results with git (v2.42.0).\n    \tspec = GitIgnoreSpec.from_lines([\n    \t\t\'*.yaml\',\n    \t\t\'!*.yaml/\',\n    \t])\n    \tfiles = {\n    \t\t\'dir.yaml/file.sql\',   # -\n    \t\t\'dir.yaml/file.yaml\',  # 1:*.yaml\n    \t\t\'dir.yaml/index.txt\',  # -\n    \t\t\'dir/file.sql\',        # -\n    \t\t\'dir/file.yaml\',       # 1:*.yaml\n    \t\t\'dir/index.txt\',       # -\n    \t\t\'file.yaml\',           # 1:*.yaml\n    \t}\n    \n    \tresults = list(spec.check_files(files))\n    \tignores = get_includes(results)\n    \tdebug = debug_results(spec, results)\n    \n>   \tself.assertEqual(ignores, {\n    \t\t\'dir.yaml/file.yaml\',\n    \t\t\'dir/file.yaml\',\n    \t\t\'file.yaml\',\n    \t}, debug)\nE    AssertionError: Items in the second set but not the first:\nE    \'dir.yaml/file.yaml\' : \nE    \nE    ------------ DEBUG -------------\nE     1:*.yaml    \'.*\\\\.yaml\'\nE     2:!*.yaml/  \'.*\\\\.yaml/\'\nE    --------------------------------\nE     2:!*.yaml/  dir.yaml/file.sql\nE     2:!*.yaml/  dir.yaml/file.yaml\nE     2:!*.yaml/  dir.yaml/index.txt\nE     -           dir/file.sql\nE     1:*.yaml    dir/file.yaml\nE     -           dir/index.txt\nE     1:*.yaml    file.yaml\nE    --------------------------------\n\nrepos\\python-pathspec\\tests\\test_04_gitignore.py:126: AssertionError', 'self = <tests.test_04_gitignore.GitIgnoreSpecTest testMethod=test_02_issue_41_c>\n\n    def test_02_issue_41_c(self):\n    \t""""""\n    \tTest including a file and excluding a directory with the same name pattern,\n    \tscenario C.\n    \t""""""\n    \t# Confirmed results with git (v2.42.0).\n    \tspec = GitIgnoreSpec.from_lines([\n    \t\t\'*.yaml\',\n    \t\t\'!dir.yaml\',\n    \t])\n    \tfiles = {\n    \t\t\'dir.yaml/file.sql\',   # -\n    \t\t\'dir.yaml/file.yaml\',  # 1:*.yaml\n    \t\t\'dir.yaml/index.txt\',  # -\n    \t\t\'dir/file.sql\',        # -\n    \t\t\'dir/file.yaml\',       # 1:*.yaml\n    \t\t\'dir/index.txt\',       # -\n    \t\t\'file.yaml\',           # 1:*.yaml\n    \t}\n    \n    \tresults = list(spec.check_files(files))\n    \tignores = get_includes(results)\n    \tdebug = debug_results(spec, results)\n    \n>   \tself.assertEqual(ignores, {\n    \t\t\'dir.yaml/file.yaml\',\n    \t\t\'dir/file.yaml\',\n    \t\t\'file.yaml\',\n    \t}, debug)\nE    AssertionError: Items in the second set but not the first:\nE    \'dir.yaml/file.yaml\' : \nE    \nE    ------------ DEBUG -------------\nE     1:*.yaml     \'.*\\\\.yaml\'\nE     2:!dir.yaml  \'dir\\\\.yaml\'\nE    --------------------------------\nE     2:!dir.yaml  dir.yaml/file.sql\nE     2:!dir.yaml  dir.yaml/file.yaml\nE     2:!dir.yaml  dir.yaml/index.txt\nE     -            dir/file.sql\nE     1:*.yaml     dir/file.yaml\nE     -            dir/index.txt\nE     1:*.yaml     file.yaml\nE    --------------------------------\n\nrepos\\python-pathspec\\tests\\test_04_gitignore.py:198: AssertionError', 'self = <tests.test_04_gitignore.GitIgnoreSpecTest testMethod=test_04_issue_62>\n\n    def test_04_issue_62(self):\n    \t""""""\n    \tTest including all files and excluding a directory.\n    \t""""""\n    \tspec = GitIgnoreSpec.from_lines([\n    \t\t\'*\',\n    \t\t\'!product_dir/\',\n    \t])\n    \tfiles = {\n    \t\t\'anydir/file.txt\',\n    \t\t\'product_dir/file.txt\',\n    \t}\n    \n    \tresults = list(spec.check_files(files))\n    \tignores = get_includes(results)\n    \tdebug = debug_results(spec, results)\n    \n>   \tself.assertEqual(ignores, {\n    \t\t\'anydir/file.txt\',\n    \t\t\'product_dir/file.txt\',\n    \t}, debug)\nE    AssertionError: Items in the second set but not the first:\nE    \'product_dir/file.txt\' : \nE    \nE    ------------ DEBUG -------------\nE     1:*              \'.*\'\nE     2:!product_dir/  \'product_dir/\'\nE    --------------------------------\nE     1:*              anydir/file.txt\nE     2:!product_dir/  product_dir/file.txt\nE    --------------------------------\n\nrepos\\python-pathspec\\tests\\test_04_gitignore.py:359: AssertionError', 'self = <tests.test_04_gitignore.GitIgnoreSpecTest testMethod=test_07_issue_74>\n\n    def test_07_issue_74(self):\n    \t""""""\n    \tTest include directory should override exclude file.\n    \t""""""\n    \tspec = GitIgnoreSpec.from_lines([\n    \t\t\'*\',  # Ignore all files by default\n    \t\t\'!*/\',  # but scan all directories\n    \t\t\'!*.txt\',  # Text files\n    \t\t\'/test1/**\',  # ignore all in the directory\n    \t])\n    \tfiles = {\n    \t\t\'test1/b.bin\',\n    \t\t\'test1/a.txt\',\n    \t\t\'test1/c/c.txt\',\n    \t\t\'test2/a.txt\',\n    \t\t\'test2/b.bin\',\n    \t\t\'test2/c/c.txt\',\n    \t}\n    \n    \tresults = list(spec.check_files(files))\n    \tignores = get_includes(results)\n    \tdebug = debug_results(spec, results)\n    \n>   \tself.assertEqual(ignores, {\n    \t\t\'test1/b.bin\',\n    \t\t\'test1/a.txt\',\n    \t\t\'test1/c/c.txt\',\n    \t\t\'test2/b.bin\',\n    \t}, debug)\nE    AssertionError: Items in the second set but not the first:\nE    \'test1/b.bin\'\nE    \'test1/c/c.txt\'\nE    \'test2/b.bin\'\nE    \'test1/a.txt\' : \nE    \nE    ------------ DEBUG -------------\nE     1:*          \'.*\'\nE     2:!*/        \'.*/\'\nE     3:!*.txt     \'.*\\\\.txt\'\nE     4:/test1/**  \'/test1/.*.*\'\nE    --------------------------------\nE     3:!*.txt     test1/a.txt\nE     2:!*/        test1/b.bin\nE     3:!*.txt     test1/c/c.txt\nE     3:!*.txt     test2/a.txt\nE     2:!*/        test2/b.bin\nE     3:!*.txt     test2/c/c.txt\nE    --------------------------------\n\nrepos\\python-pathspec\\tests\\test_04_gitignore.py:442: AssertionError', 'self = <tests.test_04_gitignore.GitIgnoreSpecTest testMethod=test_08_issue_81_c>\n\n    def test_08_issue_81_c(self):\n    \t""""""\n    \tTest issue 81 whitelist, scenario C.\n    \t""""""\n    \t# Confirmed results with git (v2.42.0).\n    \tspec = GitIgnoreSpec.from_lines([\n    \t\t""*"",\n    \t\t""!libfoo"",\n    \t\t""!libfoo/"",\n    \t])\n    \tfiles = {\n    \t\t""ignore.txt"",          # 1:*\n    \t\t""libfoo/__init__.py"",  # 1:*\n    \t}\n    \tresults = list(spec.check_files(files))\n    \tignores = get_includes(results)\n    \tdebug = debug_results(spec, results)\n>   \tself.assertEqual(ignores, {\n    \t\t""ignore.txt"",\n    \t\t""libfoo/__init__.py"",\n    \t}, debug)\nE    AssertionError: Items in the second set but not the first:\nE    \'libfoo/__init__.py\' : \nE    \nE    ------------ DEBUG -------------\nE     1:*         \'.*\'\nE     2:!libfoo   \'libfoo\'\nE     3:!libfoo/  \'libfoo/\'\nE    --------------------------------\nE     1:*         ignore.txt\nE     3:!libfoo/  libfoo/__init__.py\nE    --------------------------------\n\nrepos\\python-pathspec\\tests\\test_04_gitignore.py:522: AssertionError']",python-pathspec/pattern_to_regex,LLM
sqlparse,_process_identifierlist,"def _process_identifierlist(self, tlist):
    identifiers = list(tlist.get_identifiers())
    if self.indent_columns:
        first = next(identifiers[0].flatten())
        num_offset = 1 if self.char == '\t' else self.width
    else:
        first = next(identifiers.pop(0).flatten())
        num_offset = 1 if self.char == '\t' else self._get_offset(first)
    if not tlist.within(sql.Function) and (not tlist.within(sql.Values)):
        with offset(self, num_offset):
            position = 0
            for token in identifiers:
                position += len(token.value) + 1
                if position > self.wrap_after - self.offset:
                    adjust = 0
                    if self.comma_first:
                        adjust = -2
                        _, comma = tlist.token_prev(tlist.token_index(token))
                        if comma is None:
                            continue
                        token = comma
                    tlist.insert_before(token, self.nl(offset=adjust))
                    if self.comma_first:
                        _, ws = tlist.token_next(tlist.token_index(token), skip_ws=False)
                        if ws is not None and ws.ttype is not T.Text.Whitespace:
                            tlist.insert_after(token, sql.Token(T.Whitespace, ' '))
                    position = 0
    else:
        for token in tlist:
            _, next_ws = tlist.token_next(tlist.token_index(token), skip_ws=False)
            if token.value == ',' and (not next_ws.is_whitespace):
                tlist.insert_after(token, sql.Token(T.Whitespace, ' '))
        end_at = self.offset + sum((len(i.value) + 1 for i in identifiers))
        adjusted_offset = 0
        if self.wrap_after > 0 and end_at > self.wrap_after - self.offset and self._last_func:
            adjusted_offset = -len(self._last_func.value) - 1
        with offset(self, adjusted_offset), indent(self):
            if adjusted_offset < 0:
                tlist.insert_before(identifiers[0], self.nl())
            position = 0
            for token in identifiers:
                position += len(token.value) + 1
                if self.wrap_after > 0 and position > self.wrap_after - self.offset:
                    adjust = 0
                    tlist.insert_before(token, self.nl(offset=adjust))
                    position = 0
    self._process_default(tlist)","The function `_process_identifierlist` is responsible for formatting a list of identifiers within a SQL statement. It handles indentation, line wrapping, and inserting newline characters to ensure the identifiers are properly formatted for readability. The function also interacts with other methods within the class to process default settings related to the formatting of the identifiers.",3,"def _process_identifierlist(self, tlist):
    formatted_identifiers = []
    current_line_length = 0

    for identifier in tlist.get_identifiers():
        identifier_str = str(identifier)
        
        if current_line_length == 0:
            formatted_identifiers.append(identifier_str)
            current_line_length += len(identifier_str)
        elif current_line_length + len(identifier_str) + 2 <= self.max_line_length:
            formatted_identifiers[-1] += ', ' + identifier_str
            current_line_length += len(identifier_str) + 2
        else:
            formatted_identifiers[-1] += ','
            formatted_identifiers.append(identifier_str)
            current_line_length = len(identifier_str)
    
    return '\n'.join(formatted_identifiers)","['./repos/sqlparse\\tests', './repos/sqlparse\\tests\\test_cli.py::test_cli_main_empty', './repos/sqlparse\\tests\\test_cli.py::test_parser_empty', './repos/sqlparse\\tests\\test_cli.py::test_main_help', './repos/sqlparse\\tests\\test_cli.py::test_valid_args', './repos/sqlparse\\tests\\test_cli.py::test_invalid_choice', './repos/sqlparse\\tests\\test_cli.py::test_invalid_args', './repos/sqlparse\\tests\\test_cli.py::test_invalid_infile', './repos/sqlparse\\tests\\test_cli.py::test_invalid_outfile', './repos/sqlparse\\tests\\test_cli.py::test_stdout', './repos/sqlparse\\tests\\test_cli.py::test_script', './repos/sqlparse\\tests\\test_cli.py::test_encoding_stdout', './repos/sqlparse\\tests\\test_cli.py::test_encoding_output_file', './repos/sqlparse\\tests\\test_cli.py::test_encoding_stdin', './repos/sqlparse\\tests\\test_cli.py::test_encoding', './repos/sqlparse\\tests\\test_format.py::test_format_column_ordering', './repos/sqlparse\\tests\\test_format.py::test_truncate_strings', './repos/sqlparse\\tests\\test_format.py::test_truncate_strings_invalid_option2', './repos/sqlparse\\tests\\test_format.py::test_truncate_strings_doesnt_truncate_identifiers', './repos/sqlparse\\tests\\test_format.py::test_having_produces_newline', './repos/sqlparse\\tests\\test_format.py::test_format_right_margin_invalid_option', './repos/sqlparse\\tests\\test_format.py::test_format_right_margin', './repos/sqlparse\\tests\\test_format.py::test_format_json_ops', './repos/sqlparse\\tests\\test_format.py::test_compact', './repos/sqlparse\\tests\\test_format.py::test_strip_ws_removes_trailing_ws_in_groups', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_parenthesis', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_assignment', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_typed_literal', './repos/sqlparse\\tests\\test_grouping.py::test_compare_expr', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifiers', './repos/sqlparse\\tests\\test_grouping.py::test_simple_identifiers', './repos/sqlparse\\tests\\test_grouping.py::test_group_identifier_list', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifier_wildcard', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifier_name_wildcard', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifier_invalid', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifier_invalid_in_middle', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifer_as', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifier_as_invalid', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifier_function', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_operation', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifier_list', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifier_list_subquery', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifier_list_case', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifier_list_other', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifier_list_with_inline_comments', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifiers_with_operators', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifier_list_with_order', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_nested_identifier_with_order', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_where', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_where_union', './repos/sqlparse\\tests\\test_grouping.py::test_returning_kw_ends_where_clause', './repos/sqlparse\\tests\\test_grouping.py::test_into_kw_ends_where_clause', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_typecast', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_alias', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_alias_case', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_alias_ctas', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_subquery_no_parens', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_alias_returns_none', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_idlist_function', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_comparison_exclude', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_function', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_function_not_in', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_varchar', './repos/sqlparse\\tests\\test_grouping.py::test_statement_get_type', './repos/sqlparse\\tests\\test_grouping.py::test_identifier_with_operators', './repos/sqlparse\\tests\\test_grouping.py::test_identifier_with_op_trailing_ws', './repos/sqlparse\\tests\\test_grouping.py::test_identifier_with_string_literals', './repos/sqlparse\\tests\\test_grouping.py::test_identifier_consumes_ordering', './repos/sqlparse\\tests\\test_grouping.py::test_comparison_with_keywords', './repos/sqlparse\\tests\\test_grouping.py::test_comparison_with_floats', './repos/sqlparse\\tests\\test_grouping.py::test_comparison_with_parenthesis', './repos/sqlparse\\tests\\test_grouping.py::test_comparison_with_strings', './repos/sqlparse\\tests\\test_grouping.py::test_like_and_ilike_comparison', './repos/sqlparse\\tests\\test_grouping.py::test_comparison_with_functions', './repos/sqlparse\\tests\\test_grouping.py::test_comparison_with_typed_literal', './repos/sqlparse\\tests\\test_grouping.py::test_forloops', './repos/sqlparse\\tests\\test_grouping.py::test_nested_for', './repos/sqlparse\\tests\\test_grouping.py::test_begin', './repos/sqlparse\\tests\\test_grouping.py::test_keyword_followed_by_parenthesis', './repos/sqlparse\\tests\\test_grouping.py::test_nested_begin', './repos/sqlparse\\tests\\test_grouping.py::test_aliased_column_without_as', './repos/sqlparse\\tests\\test_grouping.py::test_qualified_function', './repos/sqlparse\\tests\\test_grouping.py::test_aliased_function_without_as', './repos/sqlparse\\tests\\test_grouping.py::test_aliased_literal_without_as', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_as_cte', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_create_table', './repos/sqlparse\\tests\\test_parse.py::test_parse_tokenize', './repos/sqlparse\\tests\\test_parse.py::test_parse_multistatement', './repos/sqlparse\\tests\\test_parse.py::test_parse_newlines', './repos/sqlparse\\tests\\test_parse.py::test_parse_within', './repos/sqlparse\\tests\\test_parse.py::test_parse_child_of', './repos/sqlparse\\tests\\test_parse.py::test_parse_has_ancestor', './repos/sqlparse\\tests\\test_parse.py::test_parse_float', './repos/sqlparse\\tests\\test_parse.py::test_parse_placeholder', './repos/sqlparse\\tests\\test_parse.py::test_parse_modulo_not_placeholder', './repos/sqlparse\\tests\\test_parse.py::test_parse_access_symbol', './repos/sqlparse\\tests\\test_parse.py::test_parse_square_brackets_notation_isnt_too_greedy', './repos/sqlparse\\tests\\test_parse.py::test_parse_square_brackets_notation_isnt_too_greedy2', './repos/sqlparse\\tests\\test_parse.py::test_parse_keyword_like_identifier', './repos/sqlparse\\tests\\test_parse.py::test_parse_function_parameter', './repos/sqlparse\\tests\\test_parse.py::test_parse_function_param_single_literal', './repos/sqlparse\\tests\\test_parse.py::test_parse_nested_function', './repos/sqlparse\\tests\\test_parse.py::test_parse_casted_params', './repos/sqlparse\\tests\\test_parse.py::test_parse_div_operator', './repos/sqlparse\\tests\\test_parse.py::test_quoted_identifier', './repos/sqlparse\\tests\\test_parse.py::test_valid_identifier_names', './repos/sqlparse\\tests\\test_parse.py::test_psql_quotation_marks', './repos/sqlparse\\tests\\test_parse.py::test_double_precision_is_builtin', './repos/sqlparse\\tests\\test_parse.py::test_placeholder', './repos/sqlparse\\tests\\test_parse.py::test_scientific_numbers', './repos/sqlparse\\tests\\test_parse.py::test_single_quotes_are_strings', './repos/sqlparse\\tests\\test_parse.py::test_double_quotes_are_identifiers', './repos/sqlparse\\tests\\test_parse.py::test_single_quotes_with_linebreaks', './repos/sqlparse\\tests\\test_parse.py::test_sqlite_identifiers', './repos/sqlparse\\tests\\test_parse.py::test_simple_1d_array_index', './repos/sqlparse\\tests\\test_parse.py::test_2d_array_index', './repos/sqlparse\\tests\\test_parse.py::test_array_index_function_result', './repos/sqlparse\\tests\\test_parse.py::test_schema_qualified_array_index', './repos/sqlparse\\tests\\test_parse.py::test_aliased_array_index', './repos/sqlparse\\tests\\test_parse.py::test_array_literal', './repos/sqlparse\\tests\\test_parse.py::test_typed_array_definition', './repos/sqlparse\\tests\\test_parse.py::test_single_line_comments', './repos/sqlparse\\tests\\test_parse.py::test_names_and_special_names', './repos/sqlparse\\tests\\test_parse.py::test_get_token_at_offset', './repos/sqlparse\\tests\\test_parse.py::test_pprint', './repos/sqlparse\\tests\\test_parse.py::test_wildcard_multiplication', './repos/sqlparse\\tests\\test_parse.py::test_stmt_tokens_parents', './repos/sqlparse\\tests\\test_parse.py::test_dbldollar_as_literal', './repos/sqlparse\\tests\\test_parse.py::test_non_ascii', './repos/sqlparse\\tests\\test_parse.py::test_get_real_name', './repos/sqlparse\\tests\\test_parse.py::test_from_subquery', './repos/sqlparse\\tests\\test_parse.py::test_parenthesis', './repos/sqlparse\\tests\\test_parse.py::test_configurable_keywords', './repos/sqlparse\\tests\\test_parse.py::test_configurable_regex', './repos/sqlparse\\tests\\test_parse.py::test_json_operators', './repos/sqlparse\\tests\\test_regressions.py::test_issue9', './repos/sqlparse\\tests\\test_regressions.py::test_issue13', './repos/sqlparse\\tests\\test_regressions.py::test_issue26', './repos/sqlparse\\tests\\test_regressions.py::test_issue34', './repos/sqlparse\\tests\\test_regressions.py::test_issue35', './repos/sqlparse\\tests\\test_regressions.py::test_issue38', './repos/sqlparse\\tests\\test_regressions.py::test_issue39', './repos/sqlparse\\tests\\test_regressions.py::test_issue40', './repos/sqlparse\\tests\\test_regressions.py::test_issue78', './repos/sqlparse\\tests\\test_regressions.py::test_issue83', './repos/sqlparse\\tests\\test_regressions.py::test_comment_encoding_when_reindent', './repos/sqlparse\\tests\\test_regressions.py::test_parse_sql_with_binary', './repos/sqlparse\\tests\\test_regressions.py::test_dont_alias_keywords', './repos/sqlparse\\tests\\test_regressions.py::test_format_accepts_encoding', './repos/sqlparse\\tests\\test_regressions.py::test_stream', './repos/sqlparse\\tests\\test_regressions.py::test_issue90', './repos/sqlparse\\tests\\test_regressions.py::test_except_formatting', './repos/sqlparse\\tests\\test_regressions.py::test_null_with_as', './repos/sqlparse\\tests\\test_regressions.py::test_issue190_open_file', './repos/sqlparse\\tests\\test_regressions.py::test_issue193_splitting_function', './repos/sqlparse\\tests\\test_regressions.py::test_issue194_splitting_function', './repos/sqlparse\\tests\\test_regressions.py::test_issue186_get_type', './repos/sqlparse\\tests\\test_regressions.py::test_issue212_py2unicode', './repos/sqlparse\\tests\\test_regressions.py::test_issue213_leadingws', './repos/sqlparse\\tests\\test_regressions.py::test_issue227_gettype_cte', './repos/sqlparse\\tests\\test_regressions.py::test_issue207_runaway_format', './repos/sqlparse\\tests\\test_regressions.py::test_token_next_doesnt_ignore_skip_cm', './repos/sqlparse\\tests\\test_regressions.py::test_issue284_as_grouping', './repos/sqlparse\\tests\\test_regressions.py::test_issue315_utf8_by_default', './repos/sqlparse\\tests\\test_regressions.py::test_issue322_concurrently_is_keyword', './repos/sqlparse\\tests\\test_regressions.py::test_issue359_index_error_assignments', './repos/sqlparse\\tests\\test_regressions.py::test_issue469_copy_as_psql_command', './repos/sqlparse\\tests\\test_regressions.py::test_issue484_comments_and_newlines', './repos/sqlparse\\tests\\test_regressions.py::test_issue485_split_multi', './repos/sqlparse\\tests\\test_regressions.py::test_issue489_tzcasts', './repos/sqlparse\\tests\\test_regressions.py::test_issue562_tzcasts', './repos/sqlparse\\tests\\test_regressions.py::test_as_in_parentheses_indents', './repos/sqlparse\\tests\\test_regressions.py::test_format_invalid_where_clause', './repos/sqlparse\\tests\\test_regressions.py::test_splitting_at_and_backticks_issue588', './repos/sqlparse\\tests\\test_regressions.py::test_comment_between_cte_clauses_issue632', './repos/sqlparse\\tests\\test_regressions.py::test_copy_issue672', './repos/sqlparse\\tests\\test_regressions.py::test_primary_key_issue740', './repos/sqlparse\\tests\\test_regressions.py::test_max_recursion', './repos/sqlparse\\tests\\test_split.py::test_split_semicolon', './repos/sqlparse\\tests\\test_split.py::test_split_backslash', './repos/sqlparse\\tests\\test_split.py::test_split_create_function', './repos/sqlparse\\tests\\test_split.py::test_split_dashcomments', './repos/sqlparse\\tests\\test_split.py::test_split_dashcomments_eol', './repos/sqlparse\\tests\\test_split.py::test_split_begintag', './repos/sqlparse\\tests\\test_split.py::test_split_begintag_2', './repos/sqlparse\\tests\\test_split.py::test_split_dropif', './repos/sqlparse\\tests\\test_split.py::test_split_comment_with_umlaut', './repos/sqlparse\\tests\\test_split.py::test_split_comment_end_of_line', './repos/sqlparse\\tests\\test_split.py::test_split_casewhen', './repos/sqlparse\\tests\\test_split.py::test_split_casewhen_procedure', './repos/sqlparse\\tests\\test_split.py::test_split_cursor_declare', './repos/sqlparse\\tests\\test_split.py::test_split_if_function', './repos/sqlparse\\tests\\test_split.py::test_split_stream', './repos/sqlparse\\tests\\test_split.py::test_split_encoding_parsestream', './repos/sqlparse\\tests\\test_split.py::test_split_unicode_parsestream', './repos/sqlparse\\tests\\test_split.py::test_split_simple', './repos/sqlparse\\tests\\test_split.py::test_split_ignores_empty_newlines', './repos/sqlparse\\tests\\test_split.py::test_split_quotes_with_new_line', './repos/sqlparse\\tests\\test_split.py::test_split_mysql_handler_for', './repos/sqlparse\\tests\\test_split.py::test_split_strip_semicolon', './repos/sqlparse\\tests\\test_split.py::test_split_strip_semicolon_procedure', './repos/sqlparse\\tests\\test_split.py::test_split_go', './repos/sqlparse\\tests\\test_split.py::test_split_multiple_case_in_begin', './repos/sqlparse\\tests\\test_tokenize.py::test_tokenize_simple', './repos/sqlparse\\tests\\test_tokenize.py::test_tokenize_backticks', './repos/sqlparse\\tests\\test_tokenize.py::test_tokenize_linebreaks', './repos/sqlparse\\tests\\test_tokenize.py::test_tokenize_inline_keywords', './repos/sqlparse\\tests\\test_tokenize.py::test_tokenize_negative_numbers', './repos/sqlparse\\tests\\test_tokenize.py::test_token_str', './repos/sqlparse\\tests\\test_tokenize.py::test_token_repr', './repos/sqlparse\\tests\\test_tokenize.py::test_token_flatten', './repos/sqlparse\\tests\\test_tokenize.py::test_tokenlist_repr', './repos/sqlparse\\tests\\test_tokenize.py::test_single_quotes', './repos/sqlparse\\tests\\test_tokenize.py::test_tokenlist_first', './repos/sqlparse\\tests\\test_tokenize.py::test_tokenlist_token_matching', './repos/sqlparse\\tests\\test_tokenize.py::test_stream_simple', './repos/sqlparse\\tests\\test_tokenize.py::test_stream_error', './repos/sqlparse\\tests\\test_tokenize.py::test_parse_join', './repos/sqlparse\\tests\\test_tokenize.py::test_parse_union', './repos/sqlparse\\tests\\test_tokenize.py::test_parse_endifloop', './repos/sqlparse\\tests\\test_tokenize.py::test_parse_order', './repos/sqlparse\\tests\\test_tokenize.py::test_parse_identifiers', './repos/sqlparse\\tests\\test_tokenize.py::test_parse_group_by', './repos/sqlparse\\tests\\test_tokenize.py::test_parse_order_by', './repos/sqlparse\\tests\\test_tokenize.py::test_parse_window_as', './repos/sqlparse\\tests\\test_tokenize.py::test_like_and_ilike_parsed_as_comparisons', './repos/sqlparse\\tests\\test_tokenize.py::test_near_like_and_ilike_parsed_appropriately', './repos/sqlparse\\tests\\test_tokenize.py::test_parse_tzcast', './repos/sqlparse\\tests\\test_tokenize.py::test_cli_commands', './repos/sqlparse\\tests\\test_utils.py::test_remove_quotes']","445 Passed, 16 Failed",445,16,"['tests/test_format.py::TestFormatReindent::test_identifier_list', 'tests/test_format.py::TestFormatReindent::test_identifier_list_with_wrap_after', 'tests/test_format.py::TestFormatReindent::test_identifier_list_comment_first', 'tests/test_format.py::TestFormatReindent::test_identifier_list_with_functions', 'tests/test_format.py::TestFormatReindent::test_long_identifier_list_with_functions', 'tests/test_format.py::TestFormatReindent::test_nested_identifier_list', 'tests/test_format.py::TestFormatReindent::test_keywordfunctions', 'tests/test_format.py::TestFormatReindent::test_identifier_and_functions', 'tests/test_format.py::TestFormatReindent::test_insert_values', 'tests/test_format.py::test_format_column_ordering', 'tests/test_format.py::test_having_produces_newline', 'tests/test_format.py::test_format_json_ops', 'tests/test_regressions.py::test_issue40', 'tests/test_regressions.py::test_issue90', 'tests/test_regressions.py::test_null_with_as', 'tests/test_regressions.py::test_issue207_runaway_format']","[""self = <tests.test_format.TestFormatReindent object at 0x00000211EF48CD50>\n\n    def test_identifier_list(self):\n        f = lambda sql: sqlparse.format(sql, reindent=True)\n        s = 'select foo, bar, baz from table1, table2 where 1 = 2'\n>       assert f(s) == '\\n'.join([\n            'select foo,',\n            '       bar,',\n            '       baz',\n            'from table1,',\n            '     table2',\n            'where 1 = 2'])\n\nrepos\\sqlparse\\tests\\test_format.py:468: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:466: in <lambda>\n    f = lambda sql: sqlparse.format(sql, reindent=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return ''.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:44: in run\n    filter_.process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:164: in process\n    self._process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:80: in _process\n    func(tlist)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:160: in _process_default\n    self._process(sgroup)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:80: in _process\n    func(tlist)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <sqlparse.filters.reindent.ReindentFilter object at 0x00000211EF6F20A0>\ntlist = <IdentifierList 'foo, b...' at 0x211EF723BD0>\n\n    def _process_identifierlist(self, tlist):\n        formatted_identifiers = []\n        current_line_length = 0\n        for identifier in tlist.get_identifiers():\n            identifier_str = str(identifier)\n            if current_line_length == 0:\n                formatted_identifiers.append(identifier_str)\n                current_line_length += len(identifier_str)\n>           elif current_line_length + len(identifier_str) + 2 <= self.max_line_length:\nE           AttributeError: 'ReindentFilter' object has no attribute 'max_line_length'\n\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:113: AttributeError"", ""self = <tests.test_format.TestFormatReindent object at 0x00000211EF48CE50>\n\n    def test_identifier_list_with_wrap_after(self):\n        f = lambda sql: sqlparse.format(sql, reindent=True, wrap_after=14)\n        s = 'select foo, bar, baz from table1, table2 where 1 = 2'\n>       assert f(s) == '\\n'.join([\n            'select foo, bar,',\n            '       baz',\n            'from table1, table2',\n            'where 1 = 2'])\n\nrepos\\sqlparse\\tests\\test_format.py:485: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:483: in <lambda>\n    f = lambda sql: sqlparse.format(sql, reindent=True, wrap_after=14)\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return ''.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:44: in run\n    filter_.process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:164: in process\n    self._process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:80: in _process\n    func(tlist)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:160: in _process_default\n    self._process(sgroup)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:80: in _process\n    func(tlist)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <sqlparse.filters.reindent.ReindentFilter object at 0x00000211EF707490>\ntlist = <IdentifierList 'foo, b...' at 0x211EF8B4FD0>\n\n    def _process_identifierlist(self, tlist):\n        formatted_identifiers = []\n        current_line_length = 0\n        for identifier in tlist.get_identifiers():\n            identifier_str = str(identifier)\n            if current_line_length == 0:\n                formatted_identifiers.append(identifier_str)\n                current_line_length += len(identifier_str)\n>           elif current_line_length + len(identifier_str) + 2 <= self.max_line_length:\nE           AttributeError: 'ReindentFilter' object has no attribute 'max_line_length'\n\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:113: AttributeError"", ""self = <tests.test_format.TestFormatReindent object at 0x00000211EF3D64E0>\n\n    def test_identifier_list_comment_first(self):\n        f = lambda sql: sqlparse.format(sql, reindent=True, comma_first=True)\n        # not the 3: It cleans up whitespace too!\n        s = 'select foo, bar, baz from table where foo in (1, 2,3)'\n>       assert f(s) == '\\n'.join([\n            'select foo',\n            '     , bar',\n            '     , baz',\n            'from table',\n            'where foo in (1',\n            '            , 2',\n            '            , 3)'])\n\nrepos\\sqlparse\\tests\\test_format.py:495: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:492: in <lambda>\n    f = lambda sql: sqlparse.format(sql, reindent=True, comma_first=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return ''.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:44: in run\n    filter_.process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:164: in process\n    self._process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:80: in _process\n    func(tlist)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:160: in _process_default\n    self._process(sgroup)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:80: in _process\n    func(tlist)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <sqlparse.filters.reindent.ReindentFilter object at 0x00000211EF707AC0>\ntlist = <IdentifierList 'foo, b...' at 0x211EF8B6CD0>\n\n    def _process_identifierlist(self, tlist):\n        formatted_identifiers = []\n        current_line_length = 0\n        for identifier in tlist.get_identifiers():\n            identifier_str = str(identifier)\n            if current_line_length == 0:\n                formatted_identifiers.append(identifier_str)\n                current_line_length += len(identifier_str)\n>           elif current_line_length + len(identifier_str) + 2 <= self.max_line_length:\nE           AttributeError: 'ReindentFilter' object has no attribute 'max_line_length'\n\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:113: AttributeError"", 'self = <tests.test_format.TestFormatReindent object at 0x00000211EF3D65D0>\n\n    def test_identifier_list_with_functions(self):\n        f = lambda sql: sqlparse.format(sql, reindent=True)\n        s = (""select \'abc\' as foo, coalesce(col1, col2)||col3 as bar,""\n             ""col3 from my_table"")\n>       assert f(s) == \'\\n\'.join([\n            ""select \'abc\' as foo,"",\n            ""       coalesce(col1, col2)||col3 as bar,"",\n            ""       col3"",\n            ""from my_table""])\n\nrepos\\sqlparse\\tests\\test_format.py:508: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:505: in <lambda>\n    f = lambda sql: sqlparse.format(sql, reindent=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return \'\'.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:44: in run\n    filter_.process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:164: in process\n    self._process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:80: in _process\n    func(tlist)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:160: in _process_default\n    self._process(sgroup)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:80: in _process\n    func(tlist)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <sqlparse.filters.reindent.ReindentFilter object at 0x00000211EF7D0100>\ntlist = <IdentifierList \'\'abc\' ...\' at 0x211EF910050>\n\n    def _process_identifierlist(self, tlist):\n        formatted_identifiers = []\n        current_line_length = 0\n        for identifier in tlist.get_identifiers():\n            identifier_str = str(identifier)\n            if current_line_length == 0:\n                formatted_identifiers.append(identifier_str)\n                current_line_length += len(identifier_str)\n>           elif current_line_length + len(identifier_str) + 2 <= self.max_line_length:\nE           AttributeError: \'ReindentFilter\' object has no attribute \'max_line_length\'\n\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:113: AttributeError', 'self = <tests.test_format.TestFormatReindent object at 0x00000211EF41F230>\n\n    def test_long_identifier_list_with_functions(self):\n        f = lambda sql: sqlparse.format(sql, reindent=True, wrap_after=30)\n        s = (""select \'abc\' as foo, json_build_object(\'a\',  a,""\n             ""\'b\', b, \'c\', c, \'d\', d, \'e\', e) as col2""\n             ""col3 from my_table"")\n>       assert f(s) == \'\\n\'.join([\n            ""select \'abc\' as foo,"",\n            ""       json_build_object(\'a\',"",\n            ""         a, \'b\', b, \'c\', c, \'d\', d,"",\n            ""         \'e\', e) as col2col3"",\n            ""from my_table""])\n\nrepos\\sqlparse\\tests\\test_format.py:519: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:515: in <lambda>\n    f = lambda sql: sqlparse.format(sql, reindent=True, wrap_after=30)\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return \'\'.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:44: in run\n    filter_.process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:164: in process\n    self._process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:80: in _process\n    func(tlist)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:160: in _process_default\n    self._process(sgroup)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:80: in _process\n    func(tlist)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <sqlparse.filters.reindent.ReindentFilter object at 0x00000211EC186150>\ntlist = <IdentifierList \'\'abc\' ...\' at 0x211EF3E3E50>\n\n    def _process_identifierlist(self, tlist):\n        formatted_identifiers = []\n        current_line_length = 0\n        for identifier in tlist.get_identifiers():\n            identifier_str = str(identifier)\n            if current_line_length == 0:\n                formatted_identifiers.append(identifier_str)\n                current_line_length += len(identifier_str)\n>           elif current_line_length + len(identifier_str) + 2 <= self.max_line_length:\nE           AttributeError: \'ReindentFilter\' object has no attribute \'max_line_length\'\n\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:113: AttributeError', ""self = <tests.test_format.TestFormatReindent object at 0x00000211EF2C6D50>\n\n    def test_nested_identifier_list(self):\n        # issue4\n        f = lambda sql: sqlparse.format(sql, reindent=True)\n        s = '(foo as bar, bar1, bar2 as bar3, b4 as b5)'\n>       assert f(s) == '\\n'.join([\n            '(foo as bar,',\n            ' bar1,',\n            ' bar2 as bar3,',\n            ' b4 as b5)'])\n\nrepos\\sqlparse\\tests\\test_format.py:549: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:547: in <lambda>\n    f = lambda sql: sqlparse.format(sql, reindent=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return ''.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:44: in run\n    filter_.process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:164: in process\n    self._process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:80: in _process\n    func(tlist)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:160: in _process_default\n    self._process(sgroup)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:80: in _process\n    func(tlist)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:99: in _process_parenthesis\n    self._process_default(tlist, not is_dml_dll)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:160: in _process_default\n    self._process(sgroup)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:80: in _process\n    func(tlist)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <sqlparse.filters.reindent.ReindentFilter object at 0x00000211EC185860>\ntlist = <IdentifierList 'foo as...' at 0x211EF9105D0>\n\n    def _process_identifierlist(self, tlist):\n        formatted_identifiers = []\n        current_line_length = 0\n        for identifier in tlist.get_identifiers():\n            identifier_str = str(identifier)\n            if current_line_length == 0:\n                formatted_identifiers.append(identifier_str)\n                current_line_length += len(identifier_str)\n>           elif current_line_length + len(identifier_str) + 2 <= self.max_line_length:\nE           AttributeError: 'ReindentFilter' object has no attribute 'max_line_length'\n\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:113: AttributeError"", ""self = <tests.test_format.TestFormatReindent object at 0x00000211EF3CD860>\n\n    def test_keywordfunctions(self):\n        # issue36\n        f = lambda sql: sqlparse.format(sql, reindent=True)\n        s = 'select max(a) b, foo, bar'\n>       assert f(s) == '\\n'.join([\n            'select max(a) b,',\n            '       foo,',\n            '       bar'])\n\nrepos\\sqlparse\\tests\\test_format.py:583: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:581: in <lambda>\n    f = lambda sql: sqlparse.format(sql, reindent=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return ''.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:44: in run\n    filter_.process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:164: in process\n    self._process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:80: in _process\n    func(tlist)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:160: in _process_default\n    self._process(sgroup)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:80: in _process\n    func(tlist)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <sqlparse.filters.reindent.ReindentFilter object at 0x00000211EC1CA8E0>\ntlist = <IdentifierList 'max(a)...' at 0x211EF912A50>\n\n    def _process_identifierlist(self, tlist):\n        formatted_identifiers = []\n        current_line_length = 0\n        for identifier in tlist.get_identifiers():\n            identifier_str = str(identifier)\n            if current_line_length == 0:\n                formatted_identifiers.append(identifier_str)\n                current_line_length += len(identifier_str)\n>           elif current_line_length + len(identifier_str) + 2 <= self.max_line_length:\nE           AttributeError: 'ReindentFilter' object has no attribute 'max_line_length'\n\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:113: AttributeError"", ""self = <tests.test_format.TestFormatReindent object at 0x00000211EF3CD910>\n\n    def test_identifier_and_functions(self):\n        # issue45\n        f = lambda sql: sqlparse.format(sql, reindent=True)\n        s = 'select foo.bar, nvl(1) from dual'\n>       assert f(s) == '\\n'.join([\n            'select foo.bar,',\n            '       nvl(1)',\n            'from dual'])\n\nrepos\\sqlparse\\tests\\test_format.py:592: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:590: in <lambda>\n    f = lambda sql: sqlparse.format(sql, reindent=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return ''.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:44: in run\n    filter_.process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:164: in process\n    self._process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:80: in _process\n    func(tlist)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:160: in _process_default\n    self._process(sgroup)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:80: in _process\n    func(tlist)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <sqlparse.filters.reindent.ReindentFilter object at 0x00000211EF14BCD0>\ntlist = <IdentifierList 'foo.ba...' at 0x211EF911350>\n\n    def _process_identifierlist(self, tlist):\n        formatted_identifiers = []\n        current_line_length = 0\n        for identifier in tlist.get_identifiers():\n            identifier_str = str(identifier)\n            if current_line_length == 0:\n                formatted_identifiers.append(identifier_str)\n                current_line_length += len(identifier_str)\n>           elif current_line_length + len(identifier_str) + 2 <= self.max_line_length:\nE           AttributeError: 'ReindentFilter' object has no attribute 'max_line_length'\n\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:113: AttributeError"", ""self = <tests.test_format.TestFormatReindent object at 0x00000211EF492850>\n\n    def test_insert_values(self):\n        # issue 329\n        f = lambda sql: sqlparse.format(sql, reindent=True)\n        s = 'insert into foo values (1, 2)'\n        assert f(s) == '\\n'.join([\n            'insert into foo',\n            'values (1, 2)'])\n    \n        s = 'insert into foo values (1, 2), (3, 4), (5, 6)'\n        assert f(s) == '\\n'.join([\n            'insert into foo',\n            'values (1, 2),',\n            '       (3, 4),',\n            '       (5, 6)'])\n    \n        s = 'insert into foo(a, b) values (1, 2), (3, 4), (5, 6)'\n>       assert f(s) == '\\n'.join([\n            'insert into foo(a, b)',\n            'values (1, 2),',\n            '       (3, 4),',\n            '       (5, 6)'])\n\nrepos\\sqlparse\\tests\\test_format.py:613: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:599: in <lambda>\n    f = lambda sql: sqlparse.format(sql, reindent=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return ''.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:44: in run\n    filter_.process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:164: in process\n    self._process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:80: in _process\n    func(tlist)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:160: in _process_default\n    self._process(sgroup)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:80: in _process\n    func(tlist)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:103: in _process_function\n    self._process_default(tlist)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:160: in _process_default\n    self._process(sgroup)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:80: in _process\n    func(tlist)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:99: in _process_parenthesis\n    self._process_default(tlist, not is_dml_dll)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:160: in _process_default\n    self._process(sgroup)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:80: in _process\n    func(tlist)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <sqlparse.filters.reindent.ReindentFilter object at 0x00000211EF7075F0>\ntlist = <IdentifierList 'a, b' at 0x211EF94CFD0>\n\n    def _process_identifierlist(self, tlist):\n        formatted_identifiers = []\n        current_line_length = 0\n        for identifier in tlist.get_identifiers():\n            identifier_str = str(identifier)\n            if current_line_length == 0:\n                formatted_identifiers.append(identifier_str)\n                current_line_length += len(identifier_str)\n>           elif current_line_length + len(identifier_str) + 2 <= self.max_line_length:\nE           AttributeError: 'ReindentFilter' object has no attribute 'max_line_length'\n\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:113: AttributeError"", ""def test_format_column_ordering():\n        # issue89\n        sql = 'select * from foo order by c1 desc, c2, c3;'\n>       formatted = sqlparse.format(sql, reindent=True)\n\nrepos\\sqlparse\\tests\\test_format.py:695: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return ''.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:44: in run\n    filter_.process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:164: in process\n    self._process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:80: in _process\n    func(tlist)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:160: in _process_default\n    self._process(sgroup)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:80: in _process\n    func(tlist)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <sqlparse.filters.reindent.ReindentFilter object at 0x00000211EF7D0730>\ntlist = <IdentifierList 'c1 des...' at 0x211EF94F8D0>\n\n    def _process_identifierlist(self, tlist):\n        formatted_identifiers = []\n        current_line_length = 0\n        for identifier in tlist.get_identifiers():\n            identifier_str = str(identifier)\n            if current_line_length == 0:\n                formatted_identifiers.append(identifier_str)\n                current_line_length += len(identifier_str)\n>           elif current_line_length + len(identifier_str) + 2 <= self.max_line_length:\nE           AttributeError: 'ReindentFilter' object has no attribute 'max_line_length'\n\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:113: AttributeError"", ""def test_having_produces_newline():\n        sql = ('select * from foo, bar where bar.id = foo.bar_id '\n               'having sum(bar.value) > 100')\n>       formatted = sqlparse.format(sql, reindent=True)\n\nrepos\\sqlparse\\tests\\test_format.py:730: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return ''.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:44: in run\n    filter_.process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:164: in process\n    self._process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:80: in _process\n    func(tlist)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:160: in _process_default\n    self._process(sgroup)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:80: in _process\n    func(tlist)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <sqlparse.filters.reindent.ReindentFilter object at 0x00000211EF7D0AA0>\ntlist = <IdentifierList 'foo, b...' at 0x211EF912DD0>\n\n    def _process_identifierlist(self, tlist):\n        formatted_identifiers = []\n        current_line_length = 0\n        for identifier in tlist.get_identifiers():\n            identifier_str = str(identifier)\n            if current_line_length == 0:\n                formatted_identifiers.append(identifier_str)\n                current_line_length += len(identifier_str)\n>           elif current_line_length + len(identifier_str) + 2 <= self.max_line_length:\nE           AttributeError: 'ReindentFilter' object has no attribute 'max_line_length'\n\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:113: AttributeError"", 'def test_format_json_ops():  # issue542\n>       formatted = sqlparse.format(\n            ""select foo->\'bar\', foo->\'bar\';"", reindent=True)\n\nrepos\\sqlparse\\tests\\test_format.py:753: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return \'\'.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:44: in run\n    filter_.process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:164: in process\n    self._process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:80: in _process\n    func(tlist)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:160: in _process_default\n    self._process(sgroup)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:80: in _process\n    func(tlist)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <sqlparse.filters.reindent.ReindentFilter object at 0x00000211EF7D1860>\ntlist = <IdentifierList \'foo->\'...\' at 0x211EF8F1050>\n\n    def _process_identifierlist(self, tlist):\n        formatted_identifiers = []\n        current_line_length = 0\n        for identifier in tlist.get_identifiers():\n            identifier_str = str(identifier)\n            if current_line_length == 0:\n                formatted_identifiers.append(identifier_str)\n                current_line_length += len(identifier_str)\n>           elif current_line_length + len(identifier_str) + 2 <= self.max_line_length:\nE           AttributeError: \'ReindentFilter\' object has no attribute \'max_line_length\'\n\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:113: AttributeError', ""def test_issue40():\n        # make sure identifier lists in subselects are grouped\n        p = sqlparse.parse('SELECT id, name FROM '\n                           '(SELECT id, name FROM bar) as foo')[0]\n        assert len(p.tokens) == 7\n        assert p.tokens[2].__class__ == sql.IdentifierList\n        assert p.tokens[-1].__class__ == sql.Identifier\n        assert p.tokens[-1].get_name() == 'foo'\n        sp = p.tokens[-1].tokens[0]\n        assert sp.tokens[3].__class__ == sql.IdentifierList\n        # make sure that formatting works as expected\n>       s = sqlparse.format('SELECT id ==  name FROM '\n                            '(SELECT id, name FROM bar)', reindent=True)\n\nrepos\\sqlparse\\tests\\test_regressions.py:86: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return ''.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:44: in run\n    filter_.process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:164: in process\n    self._process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:80: in _process\n    func(tlist)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:160: in _process_default\n    self._process(sgroup)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:80: in _process\n    func(tlist)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:99: in _process_parenthesis\n    self._process_default(tlist, not is_dml_dll)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:160: in _process_default\n    self._process(sgroup)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:80: in _process\n    func(tlist)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <sqlparse.filters.reindent.ReindentFilter object at 0x00000211EF810730>\ntlist = <IdentifierList 'id, na...' at 0x211EF7F8BD0>\n\n    def _process_identifierlist(self, tlist):\n        formatted_identifiers = []\n        current_line_length = 0\n        for identifier in tlist.get_identifiers():\n            identifier_str = str(identifier)\n            if current_line_length == 0:\n                formatted_identifiers.append(identifier_str)\n                current_line_length += len(identifier_str)\n>           elif current_line_length + len(identifier_str) + 2 <= self.max_line_length:\nE           AttributeError: 'ReindentFilter' object has no attribute 'max_line_length'\n\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:113: AttributeError"", 'def test_issue90():\n        sql = (\'UPDATE ""gallery_photo"" SET ""owner_id"" = 4018, ""deleted_at"" = NULL,\'\n               \' ""width"" = NULL, ""height"" = NULL, ""rating_votes"" = 0,\'\n               \' ""rating_score"" = 0, ""thumbnail_width"" = NULL,\'\n               \' ""thumbnail_height"" = NULL, ""price"" = 1, ""description"" = NULL\')\n>       formatted = sqlparse.format(sql, reindent=True)\n\nrepos\\sqlparse\\tests\\test_regressions.py:198: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return \'\'.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:44: in run\n    filter_.process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:164: in process\n    self._process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:80: in _process\n    func(tlist)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:160: in _process_default\n    self._process(sgroup)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:80: in _process\n    func(tlist)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <sqlparse.filters.reindent.ReindentFilter object at 0x00000211EF8264C0>\ntlist = <IdentifierList \'""owner...\' at 0x211EF843F50>\n\n    def _process_identifierlist(self, tlist):\n        formatted_identifiers = []\n        current_line_length = 0\n        for identifier in tlist.get_identifiers():\n            identifier_str = str(identifier)\n            if current_line_length == 0:\n                formatted_identifiers.append(identifier_str)\n                current_line_length += len(identifier_str)\n>           elif current_line_length + len(identifier_str) + 2 <= self.max_line_length:\nE           AttributeError: \'ReindentFilter\' object has no attribute \'max_line_length\'\n\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:113: AttributeError', ""def test_null_with_as():\n        sql = 'SELECT NULL AS c1, NULL AS c2 FROM t1'\n>       formatted = sqlparse.format(sql, reindent=True)\n\nrepos\\sqlparse\\tests\\test_regressions.py:230: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return ''.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:44: in run\n    filter_.process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:164: in process\n    self._process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:80: in _process\n    func(tlist)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:160: in _process_default\n    self._process(sgroup)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:80: in _process\n    func(tlist)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <sqlparse.filters.reindent.ReindentFilter object at 0x00000211EF826AF0>\ntlist = <IdentifierList 'NULL A...' at 0x211EF807750>\n\n    def _process_identifierlist(self, tlist):\n        formatted_identifiers = []\n        current_line_length = 0\n        for identifier in tlist.get_identifiers():\n            identifier_str = str(identifier)\n            if current_line_length == 0:\n                formatted_identifiers.append(identifier_str)\n                current_line_length += len(identifier_str)\n>           elif current_line_length + len(identifier_str) + 2 <= self.max_line_length:\nE           AttributeError: 'ReindentFilter' object has no attribute 'max_line_length'\n\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:113: AttributeError"", ""def test_issue207_runaway_format():\n        sql = 'select 1 from (select 1 as one, 2 as two, 3 from dual) t0'\n>       p = sqlparse.format(sql, reindent=True)\n\nrepos\\sqlparse\\tests\\test_regressions.py:303: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return ''.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:44: in run\n    filter_.process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:164: in process\n    self._process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:80: in _process\n    func(tlist)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:160: in _process_default\n    self._process(sgroup)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:80: in _process\n    func(tlist)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:160: in _process_default\n    self._process(sgroup)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:80: in _process\n    func(tlist)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:99: in _process_parenthesis\n    self._process_default(tlist, not is_dml_dll)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:160: in _process_default\n    self._process(sgroup)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:80: in _process\n    func(tlist)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <sqlparse.filters.reindent.ReindentFilter object at 0x00000211EF827D80>\ntlist = <IdentifierList '1 as o...' at 0x211EF9A5ED0>\n\n    def _process_identifierlist(self, tlist):\n        formatted_identifiers = []\n        current_line_length = 0\n        for identifier in tlist.get_identifiers():\n            identifier_str = str(identifier)\n            if current_line_length == 0:\n                formatted_identifiers.append(identifier_str)\n                current_line_length += len(identifier_str)\n>           elif current_line_length + len(identifier_str) + 2 <= self.max_line_length:\nE           AttributeError: 'ReindentFilter' object has no attribute 'max_line_length'\n\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:113: AttributeError""]",sqlparse/_process_identifierlist,LLM
sqlparse,_process_parenthesis,"def _process_parenthesis(self, tlist):
    ttypes = (T.Keyword.DML, T.Keyword.DDL)
    _, is_dml_dll = tlist.token_next_by(t=ttypes)
    fidx, first = tlist.token_next_by(m=sql.Parenthesis.M_OPEN)
    if first is None:
        return
    with indent(self, 1 if is_dml_dll else 0):
        tlist.tokens.insert(0, self.nl()) if is_dml_dll else None
        with offset(self, self._get_offset(first) + 1):
            self._process_default(tlist, not is_dml_dll)",The _process_parenthesis function in the given Python code snippet aims to handle the processing of parenthesis in a SQL query. It checks for specific types of SQL tokens within the parenthesis and then adjusts the indentation and offset accordingly to ensure proper formatting of the query. It also interacts with the class context by utilizing attributes or methods within the class to determine the indentation level and offset for the processing of the parenthesis.,2,"def _process_parenthesis(self, tlist):
    for token in tlist.tokens:
        if isinstance(token, sql.TokenList):
            self._process_parenthesis(token)
    return tlist","['./repos/sqlparse\\tests', './repos/sqlparse\\tests\\test_cli.py::test_cli_main_empty', './repos/sqlparse\\tests\\test_cli.py::test_parser_empty', './repos/sqlparse\\tests\\test_cli.py::test_main_help', './repos/sqlparse\\tests\\test_cli.py::test_valid_args', './repos/sqlparse\\tests\\test_cli.py::test_invalid_choice', './repos/sqlparse\\tests\\test_cli.py::test_invalid_args', './repos/sqlparse\\tests\\test_cli.py::test_invalid_infile', './repos/sqlparse\\tests\\test_cli.py::test_invalid_outfile', './repos/sqlparse\\tests\\test_cli.py::test_stdout', './repos/sqlparse\\tests\\test_cli.py::test_script', './repos/sqlparse\\tests\\test_cli.py::test_encoding_stdout', './repos/sqlparse\\tests\\test_cli.py::test_encoding_output_file', './repos/sqlparse\\tests\\test_cli.py::test_encoding_stdin', './repos/sqlparse\\tests\\test_cli.py::test_encoding', './repos/sqlparse\\tests\\test_format.py::test_format_column_ordering', './repos/sqlparse\\tests\\test_format.py::test_truncate_strings', './repos/sqlparse\\tests\\test_format.py::test_truncate_strings_invalid_option2', './repos/sqlparse\\tests\\test_format.py::test_truncate_strings_doesnt_truncate_identifiers', './repos/sqlparse\\tests\\test_format.py::test_having_produces_newline', './repos/sqlparse\\tests\\test_format.py::test_format_right_margin_invalid_option', './repos/sqlparse\\tests\\test_format.py::test_format_right_margin', './repos/sqlparse\\tests\\test_format.py::test_format_json_ops', './repos/sqlparse\\tests\\test_format.py::test_compact', './repos/sqlparse\\tests\\test_format.py::test_strip_ws_removes_trailing_ws_in_groups', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_parenthesis', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_assignment', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_typed_literal', './repos/sqlparse\\tests\\test_grouping.py::test_compare_expr', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifiers', './repos/sqlparse\\tests\\test_grouping.py::test_simple_identifiers', './repos/sqlparse\\tests\\test_grouping.py::test_group_identifier_list', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifier_wildcard', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifier_name_wildcard', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifier_invalid', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifier_invalid_in_middle', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifer_as', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifier_as_invalid', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifier_function', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_operation', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifier_list', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifier_list_subquery', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifier_list_case', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifier_list_other', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifier_list_with_inline_comments', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifiers_with_operators', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifier_list_with_order', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_nested_identifier_with_order', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_where', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_where_union', './repos/sqlparse\\tests\\test_grouping.py::test_returning_kw_ends_where_clause', './repos/sqlparse\\tests\\test_grouping.py::test_into_kw_ends_where_clause', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_typecast', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_alias', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_alias_case', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_alias_ctas', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_subquery_no_parens', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_alias_returns_none', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_idlist_function', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_comparison_exclude', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_function', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_function_not_in', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_varchar', './repos/sqlparse\\tests\\test_grouping.py::test_statement_get_type', './repos/sqlparse\\tests\\test_grouping.py::test_identifier_with_operators', './repos/sqlparse\\tests\\test_grouping.py::test_identifier_with_op_trailing_ws', './repos/sqlparse\\tests\\test_grouping.py::test_identifier_with_string_literals', './repos/sqlparse\\tests\\test_grouping.py::test_identifier_consumes_ordering', './repos/sqlparse\\tests\\test_grouping.py::test_comparison_with_keywords', './repos/sqlparse\\tests\\test_grouping.py::test_comparison_with_floats', './repos/sqlparse\\tests\\test_grouping.py::test_comparison_with_parenthesis', './repos/sqlparse\\tests\\test_grouping.py::test_comparison_with_strings', './repos/sqlparse\\tests\\test_grouping.py::test_like_and_ilike_comparison', './repos/sqlparse\\tests\\test_grouping.py::test_comparison_with_functions', './repos/sqlparse\\tests\\test_grouping.py::test_comparison_with_typed_literal', './repos/sqlparse\\tests\\test_grouping.py::test_forloops', './repos/sqlparse\\tests\\test_grouping.py::test_nested_for', './repos/sqlparse\\tests\\test_grouping.py::test_begin', './repos/sqlparse\\tests\\test_grouping.py::test_keyword_followed_by_parenthesis', './repos/sqlparse\\tests\\test_grouping.py::test_nested_begin', './repos/sqlparse\\tests\\test_grouping.py::test_aliased_column_without_as', './repos/sqlparse\\tests\\test_grouping.py::test_qualified_function', './repos/sqlparse\\tests\\test_grouping.py::test_aliased_function_without_as', './repos/sqlparse\\tests\\test_grouping.py::test_aliased_literal_without_as', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_as_cte', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_create_table', './repos/sqlparse\\tests\\test_parse.py::test_parse_tokenize', './repos/sqlparse\\tests\\test_parse.py::test_parse_multistatement', './repos/sqlparse\\tests\\test_parse.py::test_parse_newlines', './repos/sqlparse\\tests\\test_parse.py::test_parse_within', './repos/sqlparse\\tests\\test_parse.py::test_parse_child_of', './repos/sqlparse\\tests\\test_parse.py::test_parse_has_ancestor', './repos/sqlparse\\tests\\test_parse.py::test_parse_float', './repos/sqlparse\\tests\\test_parse.py::test_parse_placeholder', './repos/sqlparse\\tests\\test_parse.py::test_parse_modulo_not_placeholder', './repos/sqlparse\\tests\\test_parse.py::test_parse_access_symbol', './repos/sqlparse\\tests\\test_parse.py::test_parse_square_brackets_notation_isnt_too_greedy', './repos/sqlparse\\tests\\test_parse.py::test_parse_square_brackets_notation_isnt_too_greedy2', './repos/sqlparse\\tests\\test_parse.py::test_parse_keyword_like_identifier', './repos/sqlparse\\tests\\test_parse.py::test_parse_function_parameter', './repos/sqlparse\\tests\\test_parse.py::test_parse_function_param_single_literal', './repos/sqlparse\\tests\\test_parse.py::test_parse_nested_function', './repos/sqlparse\\tests\\test_parse.py::test_parse_casted_params', './repos/sqlparse\\tests\\test_parse.py::test_parse_div_operator', './repos/sqlparse\\tests\\test_parse.py::test_quoted_identifier', './repos/sqlparse\\tests\\test_parse.py::test_valid_identifier_names', './repos/sqlparse\\tests\\test_parse.py::test_psql_quotation_marks', './repos/sqlparse\\tests\\test_parse.py::test_double_precision_is_builtin', './repos/sqlparse\\tests\\test_parse.py::test_placeholder', './repos/sqlparse\\tests\\test_parse.py::test_scientific_numbers', './repos/sqlparse\\tests\\test_parse.py::test_single_quotes_are_strings', './repos/sqlparse\\tests\\test_parse.py::test_double_quotes_are_identifiers', './repos/sqlparse\\tests\\test_parse.py::test_single_quotes_with_linebreaks', './repos/sqlparse\\tests\\test_parse.py::test_sqlite_identifiers', './repos/sqlparse\\tests\\test_parse.py::test_simple_1d_array_index', './repos/sqlparse\\tests\\test_parse.py::test_2d_array_index', './repos/sqlparse\\tests\\test_parse.py::test_array_index_function_result', './repos/sqlparse\\tests\\test_parse.py::test_schema_qualified_array_index', './repos/sqlparse\\tests\\test_parse.py::test_aliased_array_index', './repos/sqlparse\\tests\\test_parse.py::test_array_literal', './repos/sqlparse\\tests\\test_parse.py::test_typed_array_definition', './repos/sqlparse\\tests\\test_parse.py::test_single_line_comments', './repos/sqlparse\\tests\\test_parse.py::test_names_and_special_names', './repos/sqlparse\\tests\\test_parse.py::test_get_token_at_offset', './repos/sqlparse\\tests\\test_parse.py::test_pprint', './repos/sqlparse\\tests\\test_parse.py::test_wildcard_multiplication', './repos/sqlparse\\tests\\test_parse.py::test_stmt_tokens_parents', './repos/sqlparse\\tests\\test_parse.py::test_dbldollar_as_literal', './repos/sqlparse\\tests\\test_parse.py::test_non_ascii', './repos/sqlparse\\tests\\test_parse.py::test_get_real_name', './repos/sqlparse\\tests\\test_parse.py::test_from_subquery', './repos/sqlparse\\tests\\test_parse.py::test_parenthesis', './repos/sqlparse\\tests\\test_parse.py::test_configurable_keywords', './repos/sqlparse\\tests\\test_parse.py::test_configurable_regex', './repos/sqlparse\\tests\\test_parse.py::test_json_operators', './repos/sqlparse\\tests\\test_regressions.py::test_issue9', './repos/sqlparse\\tests\\test_regressions.py::test_issue13', './repos/sqlparse\\tests\\test_regressions.py::test_issue26', './repos/sqlparse\\tests\\test_regressions.py::test_issue34', './repos/sqlparse\\tests\\test_regressions.py::test_issue35', './repos/sqlparse\\tests\\test_regressions.py::test_issue38', './repos/sqlparse\\tests\\test_regressions.py::test_issue39', './repos/sqlparse\\tests\\test_regressions.py::test_issue40', './repos/sqlparse\\tests\\test_regressions.py::test_issue78', './repos/sqlparse\\tests\\test_regressions.py::test_issue83', './repos/sqlparse\\tests\\test_regressions.py::test_comment_encoding_when_reindent', './repos/sqlparse\\tests\\test_regressions.py::test_parse_sql_with_binary', './repos/sqlparse\\tests\\test_regressions.py::test_dont_alias_keywords', './repos/sqlparse\\tests\\test_regressions.py::test_format_accepts_encoding', './repos/sqlparse\\tests\\test_regressions.py::test_stream', './repos/sqlparse\\tests\\test_regressions.py::test_issue90', './repos/sqlparse\\tests\\test_regressions.py::test_except_formatting', './repos/sqlparse\\tests\\test_regressions.py::test_null_with_as', './repos/sqlparse\\tests\\test_regressions.py::test_issue190_open_file', './repos/sqlparse\\tests\\test_regressions.py::test_issue193_splitting_function', './repos/sqlparse\\tests\\test_regressions.py::test_issue194_splitting_function', './repos/sqlparse\\tests\\test_regressions.py::test_issue186_get_type', './repos/sqlparse\\tests\\test_regressions.py::test_issue212_py2unicode', './repos/sqlparse\\tests\\test_regressions.py::test_issue213_leadingws', './repos/sqlparse\\tests\\test_regressions.py::test_issue227_gettype_cte', './repos/sqlparse\\tests\\test_regressions.py::test_issue207_runaway_format', './repos/sqlparse\\tests\\test_regressions.py::test_token_next_doesnt_ignore_skip_cm', './repos/sqlparse\\tests\\test_regressions.py::test_issue284_as_grouping', './repos/sqlparse\\tests\\test_regressions.py::test_issue315_utf8_by_default', './repos/sqlparse\\tests\\test_regressions.py::test_issue322_concurrently_is_keyword', './repos/sqlparse\\tests\\test_regressions.py::test_issue359_index_error_assignments', './repos/sqlparse\\tests\\test_regressions.py::test_issue469_copy_as_psql_command', './repos/sqlparse\\tests\\test_regressions.py::test_issue484_comments_and_newlines', './repos/sqlparse\\tests\\test_regressions.py::test_issue485_split_multi', './repos/sqlparse\\tests\\test_regressions.py::test_issue489_tzcasts', './repos/sqlparse\\tests\\test_regressions.py::test_issue562_tzcasts', './repos/sqlparse\\tests\\test_regressions.py::test_as_in_parentheses_indents', './repos/sqlparse\\tests\\test_regressions.py::test_format_invalid_where_clause', './repos/sqlparse\\tests\\test_regressions.py::test_splitting_at_and_backticks_issue588', './repos/sqlparse\\tests\\test_regressions.py::test_comment_between_cte_clauses_issue632', './repos/sqlparse\\tests\\test_regressions.py::test_copy_issue672', './repos/sqlparse\\tests\\test_regressions.py::test_primary_key_issue740', './repos/sqlparse\\tests\\test_regressions.py::test_max_recursion', './repos/sqlparse\\tests\\test_split.py::test_split_semicolon', './repos/sqlparse\\tests\\test_split.py::test_split_backslash', './repos/sqlparse\\tests\\test_split.py::test_split_create_function', './repos/sqlparse\\tests\\test_split.py::test_split_dashcomments', './repos/sqlparse\\tests\\test_split.py::test_split_dashcomments_eol', './repos/sqlparse\\tests\\test_split.py::test_split_begintag', './repos/sqlparse\\tests\\test_split.py::test_split_begintag_2', './repos/sqlparse\\tests\\test_split.py::test_split_dropif', './repos/sqlparse\\tests\\test_split.py::test_split_comment_with_umlaut', './repos/sqlparse\\tests\\test_split.py::test_split_comment_end_of_line', './repos/sqlparse\\tests\\test_split.py::test_split_casewhen', './repos/sqlparse\\tests\\test_split.py::test_split_casewhen_procedure', './repos/sqlparse\\tests\\test_split.py::test_split_cursor_declare', './repos/sqlparse\\tests\\test_split.py::test_split_if_function', './repos/sqlparse\\tests\\test_split.py::test_split_stream', './repos/sqlparse\\tests\\test_split.py::test_split_encoding_parsestream', './repos/sqlparse\\tests\\test_split.py::test_split_unicode_parsestream', './repos/sqlparse\\tests\\test_split.py::test_split_simple', './repos/sqlparse\\tests\\test_split.py::test_split_ignores_empty_newlines', './repos/sqlparse\\tests\\test_split.py::test_split_quotes_with_new_line', './repos/sqlparse\\tests\\test_split.py::test_split_mysql_handler_for', './repos/sqlparse\\tests\\test_split.py::test_split_strip_semicolon', './repos/sqlparse\\tests\\test_split.py::test_split_strip_semicolon_procedure', './repos/sqlparse\\tests\\test_split.py::test_split_go', './repos/sqlparse\\tests\\test_split.py::test_split_multiple_case_in_begin', './repos/sqlparse\\tests\\test_tokenize.py::test_tokenize_simple', './repos/sqlparse\\tests\\test_tokenize.py::test_tokenize_backticks', './repos/sqlparse\\tests\\test_tokenize.py::test_tokenize_linebreaks', './repos/sqlparse\\tests\\test_tokenize.py::test_tokenize_inline_keywords', './repos/sqlparse\\tests\\test_tokenize.py::test_tokenize_negative_numbers', './repos/sqlparse\\tests\\test_tokenize.py::test_token_str', './repos/sqlparse\\tests\\test_tokenize.py::test_token_repr', './repos/sqlparse\\tests\\test_tokenize.py::test_token_flatten', './repos/sqlparse\\tests\\test_tokenize.py::test_tokenlist_repr', './repos/sqlparse\\tests\\test_tokenize.py::test_single_quotes', './repos/sqlparse\\tests\\test_tokenize.py::test_tokenlist_first', './repos/sqlparse\\tests\\test_tokenize.py::test_tokenlist_token_matching', './repos/sqlparse\\tests\\test_tokenize.py::test_stream_simple', './repos/sqlparse\\tests\\test_tokenize.py::test_stream_error', './repos/sqlparse\\tests\\test_tokenize.py::test_parse_join', './repos/sqlparse\\tests\\test_tokenize.py::test_parse_union', './repos/sqlparse\\tests\\test_tokenize.py::test_parse_endifloop', './repos/sqlparse\\tests\\test_tokenize.py::test_parse_order', './repos/sqlparse\\tests\\test_tokenize.py::test_parse_identifiers', './repos/sqlparse\\tests\\test_tokenize.py::test_parse_group_by', './repos/sqlparse\\tests\\test_tokenize.py::test_parse_order_by', './repos/sqlparse\\tests\\test_tokenize.py::test_parse_window_as', './repos/sqlparse\\tests\\test_tokenize.py::test_like_and_ilike_parsed_as_comparisons', './repos/sqlparse\\tests\\test_tokenize.py::test_near_like_and_ilike_parsed_appropriately', './repos/sqlparse\\tests\\test_tokenize.py::test_parse_tzcast', './repos/sqlparse\\tests\\test_tokenize.py::test_cli_commands', './repos/sqlparse\\tests\\test_utils.py::test_remove_quotes']","453 Passed, 8 Failed",453,8,"['tests/test_format.py::TestFormatReindent::test_parenthesis', 'tests/test_format.py::TestFormatReindent::test_where', 'tests/test_format.py::TestFormatReindent::test_identifier_list_comment_first', 'tests/test_format.py::TestFormatReindent::test_long_identifier_list_with_functions', 'tests/test_format.py::TestFormatReindent::test_nested_identifier_list', 'tests/test_regressions.py::test_issue40', 'tests/test_regressions.py::test_issue207_runaway_format', 'tests/test_regressions.py::test_issue562_tzcasts']","[""self = <tests.test_format.TestFormatReindent object at 0x0000012B7D9004D0>\n\n    def test_parenthesis(self):\n        f = lambda sql: sqlparse.format(sql, reindent=True)\n        s = 'select count(*) from (select * from foo);'\n>       assert f(s) == '\\n'.join([\n            'select count(*)',\n            'from',\n            '  (select *',\n            '   from foo);'])\nE       AssertionError: assert 'select count... * from foo);' == 'select count...   from foo);'\nE         \nE           select count(*)\nE         + from (select * from foo);\nE         - from\nE         -   (select *\nE         -    from foo);\n\nrepos\\sqlparse\\tests\\test_format.py:413: AssertionError"", ""self = <tests.test_format.TestFormatReindent object at 0x0000012B7D73BDF0>\n\n    def test_where(self):\n        f = lambda sql: sqlparse.format(sql, reindent=True)\n        s = 'select * from foo where bar = 1 and baz = 2 or bzz = 3;'\n        assert f(s) == '\\n'.join([\n            'select *',\n            'from foo',\n            'where bar = 1',\n            '  and baz = 2',\n            '  or bzz = 3;'])\n    \n        s = 'select * from foo where bar = 1 and (baz = 2 or bzz = 3);'\n>       assert f(s) == '\\n'.join([\n            'select *',\n            'from foo',\n            'where bar = 1',\n            '  and (baz = 2',\n            '       or bzz = 3);'])\nE       AssertionError: assert 'select *\\nfr... or bzz = 3);' == 'select *\\nfr... or bzz = 3);'\nE         \nE           select *\nE           from foo\nE           where bar = 1\nE         +   and (baz = 2 or bzz = 3);\nE         -   and (baz = 2\nE         -        or bzz = 3);\n\nrepos\\sqlparse\\tests\\test_format.py:435: AssertionError"", ""self = <tests.test_format.TestFormatReindent object at 0x0000012B7D8124E0>\n\n    def test_identifier_list_comment_first(self):\n        f = lambda sql: sqlparse.format(sql, reindent=True, comma_first=True)\n        # not the 3: It cleans up whitespace too!\n        s = 'select foo, bar, baz from table where foo in (1, 2,3)'\n>       assert f(s) == '\\n'.join([\n            'select foo',\n            '     , bar',\n            '     , baz',\n            'from table',\n            'where foo in (1',\n            '            , 2',\n            '            , 3)'])\nE       AssertionError: assert 'select foo\\n...o in (1, 2,3)' == 'select foo\\n...         , 3)'\nE         \nE           select foo\nE                , bar\nE                , baz\nE           from table\nE         - where foo in (1\nE         ?                ^...\nE         \nE         ...Full output truncated (4 lines hidden), use '-vv' to show\n\nrepos\\sqlparse\\tests\\test_format.py:495: AssertionError"", 'self = <tests.test_format.TestFormatReindent object at 0x0000012B7D85F230>\n\n    def test_long_identifier_list_with_functions(self):\n        f = lambda sql: sqlparse.format(sql, reindent=True, wrap_after=30)\n        s = (""select \'abc\' as foo, json_build_object(\'a\',  a,""\n             ""\'b\', b, \'c\', c, \'d\', d, \'e\', e) as col2""\n             ""col3 from my_table"")\n>       assert f(s) == \'\\n\'.join([\n            ""select \'abc\' as foo,"",\n            ""       json_build_object(\'a\',"",\n            ""         a, \'b\', b, \'c\', c, \'d\', d,"",\n            ""         \'e\', e) as col2col3"",\n            ""from my_table""])\nE       assert ""select \'abc\'...from my_table"" == ""select \'abc\'...from my_table""\nE         \nE           select \'abc\' as foo,\nE         +        json_build_object(\'a\', a,\'b\', b, \'c\', c, \'d\', d, \'e\', e) as col2col3\nE         -        json_build_object(\'a\',\nE         -          a, \'b\', b, \'c\', c, \'d\', d,\nE         -          \'e\', e) as col2col3\nE           from my_table\n\nrepos\\sqlparse\\tests\\test_format.py:519: AssertionError', ""self = <tests.test_format.TestFormatReindent object at 0x0000012B7D703410>\n\n    def test_nested_identifier_list(self):\n        # issue4\n        f = lambda sql: sqlparse.format(sql, reindent=True)\n        s = '(foo as bar, bar1, bar2 as bar3, b4 as b5)'\n>       assert f(s) == '\\n'.join([\n            '(foo as bar,',\n            ' bar1,',\n            ' bar2 as bar3,',\n            ' b4 as b5)'])\nE       AssertionError: assert '(foo as bar,...r3, b4 as b5)' == '(foo as bar,...,\\n b4 as b5)'\nE         \nE         + (foo as bar, bar1, bar2 as bar3, b4 as b5)\nE         - (foo as bar,\nE         -  bar1,\nE         -  bar2 as bar3,\nE         -  b4 as b5)\n\nrepos\\sqlparse\\tests\\test_format.py:549: AssertionError"", ""def test_issue40():\n        # make sure identifier lists in subselects are grouped\n        p = sqlparse.parse('SELECT id, name FROM '\n                           '(SELECT id, name FROM bar) as foo')[0]\n        assert len(p.tokens) == 7\n        assert p.tokens[2].__class__ == sql.IdentifierList\n        assert p.tokens[-1].__class__ == sql.Identifier\n        assert p.tokens[-1].get_name() == 'foo'\n        sp = p.tokens[-1].tokens[0]\n        assert sp.tokens[3].__class__ == sql.IdentifierList\n        # make sure that formatting works as expected\n        s = sqlparse.format('SELECT id ==  name FROM '\n                            '(SELECT id, name FROM bar)', reindent=True)\n>       assert s == '\\n'.join([\n            'SELECT id == name',\n            'FROM',\n            '  (SELECT id,',\n            '          name',\n            '   FROM bar)'])\nE       AssertionError: assert 'SELECT id ==...ame FROM bar)' == 'SELECT id ==...n   FROM bar)'\nE         \nE           SELECT id == name\nE         + FROM (SELECT id, name FROM bar)\nE         - FROM\nE         -   (SELECT id,\nE         -           name\nE         -    FROM bar)\n\nrepos\\sqlparse\\tests\\test_regressions.py:88: AssertionError"", 'def test_issue207_runaway_format():\n        sql = \'select 1 from (select 1 as one, 2 as two, 3 from dual) t0\'\n        p = sqlparse.format(sql, reindent=True)\n>       assert p == \'\\n\'.join([\n            ""select 1"",\n            ""from"",\n            ""  (select 1 as one,"",\n            ""          2 as two,"",\n            ""          3"",\n            ""   from dual) t0""])\nE       AssertionError: assert \'select 1\\nfr...from dual) t0\' == \'select 1\\nfr...from dual) t0\'\nE         \nE           select 1\nE         + from (select 1 as one, 2 as two, 3 from dual) t0\nE         - from\nE         -   (select 1 as one,\nE         -           2 as two,\nE         -           3\nE         -    from dual) t0\n\nrepos\\sqlparse\\tests\\test_regressions.py:304: AssertionError', 'def test_issue562_tzcasts():\n        # Test that whitespace between \'from\' and \'bar\' is retained\n        formatted = sqlparse.format(\n            \'SELECT f(HOUR from bar AT TIME ZONE \\\'UTC\\\') from foo\', reindent=True\n        )\n>       assert formatted == \\\n               \'SELECT f(HOUR\\n         from bar AT TIME ZONE \\\'UTC\\\')\\nfrom foo\'\nE       assert ""SELECT f(HOU...C\')\\nfrom foo"" == ""SELECT f(HOU...C\')\\nfrom foo""\nE         \nE         + SELECT f(HOUR from bar AT TIME ZONE \'UTC\')\nE         - SELECT f(HOUR\nE         -          from bar AT TIME ZONE \'UTC\')\nE           from foo\n\nrepos\\sqlparse\\tests\\test_regressions.py:413: AssertionError']",sqlparse/_process_parenthesis,LLM
sqlparse,_process_parenthesis,"def _process_parenthesis(self, tlist):
    ttypes = (T.Keyword.DML, T.Keyword.DDL)
    _, is_dml_dll = tlist.token_next_by(t=ttypes)
    fidx, first = tlist.token_next_by(m=sql.Parenthesis.M_OPEN)
    if first is None:
        return
    with indent(self, 1 if is_dml_dll else 0):
        tlist.tokens.insert(0, self.nl()) if is_dml_dll else None
        with offset(self, self._get_offset(first) + 1):
            self._process_default(tlist, not is_dml_dll)",The _process_parenthesis function in the given Python code snippet aims to handle the processing of parenthesis in a SQL query. It checks for specific types of SQL tokens within the parenthesis and then adjusts the indentation and offset accordingly to ensure proper formatting of the query. It also interacts with the class context by utilizing attributes or methods within the class to determine the indentation level and offset for the processing of the parenthesis.,3,"def _process_parenthesis(self, tlist):
    for token in tlist.tokens:
        if isinstance(token, sql.IdentifierList):
            self.indentation += 1
            self.offset += 1
            self._process_parenthesis(token)
            self.indentation -= 1
            self.offset -= 1
        elif isinstance(token, sql.Where):
            self.offset += 1
            self._process_parenthesis(token)
            self.offset -= 1
        # Add more conditions for other SQL tokens as needed
        # Adjust indentation and offset accordingly
        # Ensure proper formatting of the query
        # Utilize attributes and methods within the class context for indentation level and offset calculations","['./repos/sqlparse\\tests', './repos/sqlparse\\tests\\test_cli.py::test_cli_main_empty', './repos/sqlparse\\tests\\test_cli.py::test_parser_empty', './repos/sqlparse\\tests\\test_cli.py::test_main_help', './repos/sqlparse\\tests\\test_cli.py::test_valid_args', './repos/sqlparse\\tests\\test_cli.py::test_invalid_choice', './repos/sqlparse\\tests\\test_cli.py::test_invalid_args', './repos/sqlparse\\tests\\test_cli.py::test_invalid_infile', './repos/sqlparse\\tests\\test_cli.py::test_invalid_outfile', './repos/sqlparse\\tests\\test_cli.py::test_stdout', './repos/sqlparse\\tests\\test_cli.py::test_script', './repos/sqlparse\\tests\\test_cli.py::test_encoding_stdout', './repos/sqlparse\\tests\\test_cli.py::test_encoding_output_file', './repos/sqlparse\\tests\\test_cli.py::test_encoding_stdin', './repos/sqlparse\\tests\\test_cli.py::test_encoding', './repos/sqlparse\\tests\\test_format.py::test_format_column_ordering', './repos/sqlparse\\tests\\test_format.py::test_truncate_strings', './repos/sqlparse\\tests\\test_format.py::test_truncate_strings_invalid_option2', './repos/sqlparse\\tests\\test_format.py::test_truncate_strings_doesnt_truncate_identifiers', './repos/sqlparse\\tests\\test_format.py::test_having_produces_newline', './repos/sqlparse\\tests\\test_format.py::test_format_right_margin_invalid_option', './repos/sqlparse\\tests\\test_format.py::test_format_right_margin', './repos/sqlparse\\tests\\test_format.py::test_format_json_ops', './repos/sqlparse\\tests\\test_format.py::test_compact', './repos/sqlparse\\tests\\test_format.py::test_strip_ws_removes_trailing_ws_in_groups', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_parenthesis', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_assignment', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_typed_literal', './repos/sqlparse\\tests\\test_grouping.py::test_compare_expr', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifiers', './repos/sqlparse\\tests\\test_grouping.py::test_simple_identifiers', './repos/sqlparse\\tests\\test_grouping.py::test_group_identifier_list', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifier_wildcard', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifier_name_wildcard', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifier_invalid', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifier_invalid_in_middle', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifer_as', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifier_as_invalid', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifier_function', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_operation', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifier_list', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifier_list_subquery', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifier_list_case', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifier_list_other', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifier_list_with_inline_comments', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifiers_with_operators', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifier_list_with_order', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_nested_identifier_with_order', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_where', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_where_union', './repos/sqlparse\\tests\\test_grouping.py::test_returning_kw_ends_where_clause', './repos/sqlparse\\tests\\test_grouping.py::test_into_kw_ends_where_clause', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_typecast', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_alias', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_alias_case', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_alias_ctas', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_subquery_no_parens', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_alias_returns_none', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_idlist_function', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_comparison_exclude', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_function', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_function_not_in', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_varchar', './repos/sqlparse\\tests\\test_grouping.py::test_statement_get_type', './repos/sqlparse\\tests\\test_grouping.py::test_identifier_with_operators', './repos/sqlparse\\tests\\test_grouping.py::test_identifier_with_op_trailing_ws', './repos/sqlparse\\tests\\test_grouping.py::test_identifier_with_string_literals', './repos/sqlparse\\tests\\test_grouping.py::test_identifier_consumes_ordering', './repos/sqlparse\\tests\\test_grouping.py::test_comparison_with_keywords', './repos/sqlparse\\tests\\test_grouping.py::test_comparison_with_floats', './repos/sqlparse\\tests\\test_grouping.py::test_comparison_with_parenthesis', './repos/sqlparse\\tests\\test_grouping.py::test_comparison_with_strings', './repos/sqlparse\\tests\\test_grouping.py::test_like_and_ilike_comparison', './repos/sqlparse\\tests\\test_grouping.py::test_comparison_with_functions', './repos/sqlparse\\tests\\test_grouping.py::test_comparison_with_typed_literal', './repos/sqlparse\\tests\\test_grouping.py::test_forloops', './repos/sqlparse\\tests\\test_grouping.py::test_nested_for', './repos/sqlparse\\tests\\test_grouping.py::test_begin', './repos/sqlparse\\tests\\test_grouping.py::test_keyword_followed_by_parenthesis', './repos/sqlparse\\tests\\test_grouping.py::test_nested_begin', './repos/sqlparse\\tests\\test_grouping.py::test_aliased_column_without_as', './repos/sqlparse\\tests\\test_grouping.py::test_qualified_function', './repos/sqlparse\\tests\\test_grouping.py::test_aliased_function_without_as', './repos/sqlparse\\tests\\test_grouping.py::test_aliased_literal_without_as', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_as_cte', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_create_table', './repos/sqlparse\\tests\\test_parse.py::test_parse_tokenize', './repos/sqlparse\\tests\\test_parse.py::test_parse_multistatement', './repos/sqlparse\\tests\\test_parse.py::test_parse_newlines', './repos/sqlparse\\tests\\test_parse.py::test_parse_within', './repos/sqlparse\\tests\\test_parse.py::test_parse_child_of', './repos/sqlparse\\tests\\test_parse.py::test_parse_has_ancestor', './repos/sqlparse\\tests\\test_parse.py::test_parse_float', './repos/sqlparse\\tests\\test_parse.py::test_parse_placeholder', './repos/sqlparse\\tests\\test_parse.py::test_parse_modulo_not_placeholder', './repos/sqlparse\\tests\\test_parse.py::test_parse_access_symbol', './repos/sqlparse\\tests\\test_parse.py::test_parse_square_brackets_notation_isnt_too_greedy', './repos/sqlparse\\tests\\test_parse.py::test_parse_square_brackets_notation_isnt_too_greedy2', './repos/sqlparse\\tests\\test_parse.py::test_parse_keyword_like_identifier', './repos/sqlparse\\tests\\test_parse.py::test_parse_function_parameter', './repos/sqlparse\\tests\\test_parse.py::test_parse_function_param_single_literal', './repos/sqlparse\\tests\\test_parse.py::test_parse_nested_function', './repos/sqlparse\\tests\\test_parse.py::test_parse_casted_params', './repos/sqlparse\\tests\\test_parse.py::test_parse_div_operator', './repos/sqlparse\\tests\\test_parse.py::test_quoted_identifier', './repos/sqlparse\\tests\\test_parse.py::test_valid_identifier_names', './repos/sqlparse\\tests\\test_parse.py::test_psql_quotation_marks', './repos/sqlparse\\tests\\test_parse.py::test_double_precision_is_builtin', './repos/sqlparse\\tests\\test_parse.py::test_placeholder', './repos/sqlparse\\tests\\test_parse.py::test_scientific_numbers', './repos/sqlparse\\tests\\test_parse.py::test_single_quotes_are_strings', './repos/sqlparse\\tests\\test_parse.py::test_double_quotes_are_identifiers', './repos/sqlparse\\tests\\test_parse.py::test_single_quotes_with_linebreaks', './repos/sqlparse\\tests\\test_parse.py::test_sqlite_identifiers', './repos/sqlparse\\tests\\test_parse.py::test_simple_1d_array_index', './repos/sqlparse\\tests\\test_parse.py::test_2d_array_index', './repos/sqlparse\\tests\\test_parse.py::test_array_index_function_result', './repos/sqlparse\\tests\\test_parse.py::test_schema_qualified_array_index', './repos/sqlparse\\tests\\test_parse.py::test_aliased_array_index', './repos/sqlparse\\tests\\test_parse.py::test_array_literal', './repos/sqlparse\\tests\\test_parse.py::test_typed_array_definition', './repos/sqlparse\\tests\\test_parse.py::test_single_line_comments', './repos/sqlparse\\tests\\test_parse.py::test_names_and_special_names', './repos/sqlparse\\tests\\test_parse.py::test_get_token_at_offset', './repos/sqlparse\\tests\\test_parse.py::test_pprint', './repos/sqlparse\\tests\\test_parse.py::test_wildcard_multiplication', './repos/sqlparse\\tests\\test_parse.py::test_stmt_tokens_parents', './repos/sqlparse\\tests\\test_parse.py::test_dbldollar_as_literal', './repos/sqlparse\\tests\\test_parse.py::test_non_ascii', './repos/sqlparse\\tests\\test_parse.py::test_get_real_name', './repos/sqlparse\\tests\\test_parse.py::test_from_subquery', './repos/sqlparse\\tests\\test_parse.py::test_parenthesis', './repos/sqlparse\\tests\\test_parse.py::test_configurable_keywords', './repos/sqlparse\\tests\\test_parse.py::test_configurable_regex', './repos/sqlparse\\tests\\test_parse.py::test_json_operators', './repos/sqlparse\\tests\\test_regressions.py::test_issue9', './repos/sqlparse\\tests\\test_regressions.py::test_issue13', './repos/sqlparse\\tests\\test_regressions.py::test_issue26', './repos/sqlparse\\tests\\test_regressions.py::test_issue34', './repos/sqlparse\\tests\\test_regressions.py::test_issue35', './repos/sqlparse\\tests\\test_regressions.py::test_issue38', './repos/sqlparse\\tests\\test_regressions.py::test_issue39', './repos/sqlparse\\tests\\test_regressions.py::test_issue40', './repos/sqlparse\\tests\\test_regressions.py::test_issue78', './repos/sqlparse\\tests\\test_regressions.py::test_issue83', './repos/sqlparse\\tests\\test_regressions.py::test_comment_encoding_when_reindent', './repos/sqlparse\\tests\\test_regressions.py::test_parse_sql_with_binary', './repos/sqlparse\\tests\\test_regressions.py::test_dont_alias_keywords', './repos/sqlparse\\tests\\test_regressions.py::test_format_accepts_encoding', './repos/sqlparse\\tests\\test_regressions.py::test_stream', './repos/sqlparse\\tests\\test_regressions.py::test_issue90', './repos/sqlparse\\tests\\test_regressions.py::test_except_formatting', './repos/sqlparse\\tests\\test_regressions.py::test_null_with_as', './repos/sqlparse\\tests\\test_regressions.py::test_issue190_open_file', './repos/sqlparse\\tests\\test_regressions.py::test_issue193_splitting_function', './repos/sqlparse\\tests\\test_regressions.py::test_issue194_splitting_function', './repos/sqlparse\\tests\\test_regressions.py::test_issue186_get_type', './repos/sqlparse\\tests\\test_regressions.py::test_issue212_py2unicode', './repos/sqlparse\\tests\\test_regressions.py::test_issue213_leadingws', './repos/sqlparse\\tests\\test_regressions.py::test_issue227_gettype_cte', './repos/sqlparse\\tests\\test_regressions.py::test_issue207_runaway_format', './repos/sqlparse\\tests\\test_regressions.py::test_token_next_doesnt_ignore_skip_cm', './repos/sqlparse\\tests\\test_regressions.py::test_issue284_as_grouping', './repos/sqlparse\\tests\\test_regressions.py::test_issue315_utf8_by_default', './repos/sqlparse\\tests\\test_regressions.py::test_issue322_concurrently_is_keyword', './repos/sqlparse\\tests\\test_regressions.py::test_issue359_index_error_assignments', './repos/sqlparse\\tests\\test_regressions.py::test_issue469_copy_as_psql_command', './repos/sqlparse\\tests\\test_regressions.py::test_issue484_comments_and_newlines', './repos/sqlparse\\tests\\test_regressions.py::test_issue485_split_multi', './repos/sqlparse\\tests\\test_regressions.py::test_issue489_tzcasts', './repos/sqlparse\\tests\\test_regressions.py::test_issue562_tzcasts', './repos/sqlparse\\tests\\test_regressions.py::test_as_in_parentheses_indents', './repos/sqlparse\\tests\\test_regressions.py::test_format_invalid_where_clause', './repos/sqlparse\\tests\\test_regressions.py::test_splitting_at_and_backticks_issue588', './repos/sqlparse\\tests\\test_regressions.py::test_comment_between_cte_clauses_issue632', './repos/sqlparse\\tests\\test_regressions.py::test_copy_issue672', './repos/sqlparse\\tests\\test_regressions.py::test_primary_key_issue740', './repos/sqlparse\\tests\\test_regressions.py::test_max_recursion', './repos/sqlparse\\tests\\test_split.py::test_split_semicolon', './repos/sqlparse\\tests\\test_split.py::test_split_backslash', './repos/sqlparse\\tests\\test_split.py::test_split_create_function', './repos/sqlparse\\tests\\test_split.py::test_split_dashcomments', './repos/sqlparse\\tests\\test_split.py::test_split_dashcomments_eol', './repos/sqlparse\\tests\\test_split.py::test_split_begintag', './repos/sqlparse\\tests\\test_split.py::test_split_begintag_2', './repos/sqlparse\\tests\\test_split.py::test_split_dropif', './repos/sqlparse\\tests\\test_split.py::test_split_comment_with_umlaut', './repos/sqlparse\\tests\\test_split.py::test_split_comment_end_of_line', './repos/sqlparse\\tests\\test_split.py::test_split_casewhen', './repos/sqlparse\\tests\\test_split.py::test_split_casewhen_procedure', './repos/sqlparse\\tests\\test_split.py::test_split_cursor_declare', './repos/sqlparse\\tests\\test_split.py::test_split_if_function', './repos/sqlparse\\tests\\test_split.py::test_split_stream', './repos/sqlparse\\tests\\test_split.py::test_split_encoding_parsestream', './repos/sqlparse\\tests\\test_split.py::test_split_unicode_parsestream', './repos/sqlparse\\tests\\test_split.py::test_split_simple', './repos/sqlparse\\tests\\test_split.py::test_split_ignores_empty_newlines', './repos/sqlparse\\tests\\test_split.py::test_split_quotes_with_new_line', './repos/sqlparse\\tests\\test_split.py::test_split_mysql_handler_for', './repos/sqlparse\\tests\\test_split.py::test_split_strip_semicolon', './repos/sqlparse\\tests\\test_split.py::test_split_strip_semicolon_procedure', './repos/sqlparse\\tests\\test_split.py::test_split_go', './repos/sqlparse\\tests\\test_split.py::test_split_multiple_case_in_begin', './repos/sqlparse\\tests\\test_tokenize.py::test_tokenize_simple', './repos/sqlparse\\tests\\test_tokenize.py::test_tokenize_backticks', './repos/sqlparse\\tests\\test_tokenize.py::test_tokenize_linebreaks', './repos/sqlparse\\tests\\test_tokenize.py::test_tokenize_inline_keywords', './repos/sqlparse\\tests\\test_tokenize.py::test_tokenize_negative_numbers', './repos/sqlparse\\tests\\test_tokenize.py::test_token_str', './repos/sqlparse\\tests\\test_tokenize.py::test_token_repr', './repos/sqlparse\\tests\\test_tokenize.py::test_token_flatten', './repos/sqlparse\\tests\\test_tokenize.py::test_tokenlist_repr', './repos/sqlparse\\tests\\test_tokenize.py::test_single_quotes', './repos/sqlparse\\tests\\test_tokenize.py::test_tokenlist_first', './repos/sqlparse\\tests\\test_tokenize.py::test_tokenlist_token_matching', './repos/sqlparse\\tests\\test_tokenize.py::test_stream_simple', './repos/sqlparse\\tests\\test_tokenize.py::test_stream_error', './repos/sqlparse\\tests\\test_tokenize.py::test_parse_join', './repos/sqlparse\\tests\\test_tokenize.py::test_parse_union', './repos/sqlparse\\tests\\test_tokenize.py::test_parse_endifloop', './repos/sqlparse\\tests\\test_tokenize.py::test_parse_order', './repos/sqlparse\\tests\\test_tokenize.py::test_parse_identifiers', './repos/sqlparse\\tests\\test_tokenize.py::test_parse_group_by', './repos/sqlparse\\tests\\test_tokenize.py::test_parse_order_by', './repos/sqlparse\\tests\\test_tokenize.py::test_parse_window_as', './repos/sqlparse\\tests\\test_tokenize.py::test_like_and_ilike_parsed_as_comparisons', './repos/sqlparse\\tests\\test_tokenize.py::test_near_like_and_ilike_parsed_appropriately', './repos/sqlparse\\tests\\test_tokenize.py::test_parse_tzcast', './repos/sqlparse\\tests\\test_tokenize.py::test_cli_commands', './repos/sqlparse\\tests\\test_utils.py::test_remove_quotes']","451 Passed, 10 Failed",451,10,"['tests/test_format.py::TestFormatReindent::test_parenthesis', 'tests/test_format.py::TestFormatReindent::test_where', 'tests/test_format.py::TestFormatReindent::test_identifier_list_comment_first', 'tests/test_format.py::TestFormatReindent::test_identifier_list_with_functions', 'tests/test_format.py::TestFormatReindent::test_long_identifier_list_with_functions', 'tests/test_format.py::TestFormatReindent::test_nested_identifier_list', 'tests/test_format.py::TestFormatReindent::test_insert_values', 'tests/test_regressions.py::test_issue40', 'tests/test_regressions.py::test_issue207_runaway_format', 'tests/test_regressions.py::test_issue562_tzcasts']","[""self = <tests.test_format.TestFormatReindent object at 0x00000278EE8004D0>\n\n    def test_parenthesis(self):\n        f = lambda sql: sqlparse.format(sql, reindent=True)\n        s = 'select count(*) from (select * from foo);'\n>       assert f(s) == '\\n'.join([\n            'select count(*)',\n            'from',\n            '  (select *',\n            '   from foo);'])\nE       AssertionError: assert 'select count... * from foo);' == 'select count...   from foo);'\nE         \nE           select count(*)\nE         + from (select * from foo);\nE         - from\nE         -   (select *\nE         -    from foo);\n\nrepos\\sqlparse\\tests\\test_format.py:413: AssertionError"", ""self = <tests.test_format.TestFormatReindent object at 0x00000278EE63BDF0>\n\n    def test_where(self):\n        f = lambda sql: sqlparse.format(sql, reindent=True)\n        s = 'select * from foo where bar = 1 and baz = 2 or bzz = 3;'\n        assert f(s) == '\\n'.join([\n            'select *',\n            'from foo',\n            'where bar = 1',\n            '  and baz = 2',\n            '  or bzz = 3;'])\n    \n        s = 'select * from foo where bar = 1 and (baz = 2 or bzz = 3);'\n>       assert f(s) == '\\n'.join([\n            'select *',\n            'from foo',\n            'where bar = 1',\n            '  and (baz = 2',\n            '       or bzz = 3);'])\nE       AssertionError: assert 'select *\\nfr... or bzz = 3);' == 'select *\\nfr... or bzz = 3);'\nE         \nE           select *\nE           from foo\nE           where bar = 1\nE         +   and (baz = 2 or bzz = 3);\nE         -   and (baz = 2\nE         -        or bzz = 3);\n\nrepos\\sqlparse\\tests\\test_format.py:435: AssertionError"", ""self = <tests.test_format.TestFormatReindent object at 0x00000278EE7164E0>\n\n    def test_identifier_list_comment_first(self):\n        f = lambda sql: sqlparse.format(sql, reindent=True, comma_first=True)\n        # not the 3: It cleans up whitespace too!\n        s = 'select foo, bar, baz from table where foo in (1, 2,3)'\n>       assert f(s) == '\\n'.join([\n            'select foo',\n            '     , bar',\n            '     , baz',\n            'from table',\n            'where foo in (1',\n            '            , 2',\n            '            , 3)'])\n\nrepos\\sqlparse\\tests\\test_format.py:495: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:492: in <lambda>\n    f = lambda sql: sqlparse.format(sql, reindent=True, comma_first=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return ''.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:44: in run\n    filter_.process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:197: in process\n    self._process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:80: in _process\n    func(tlist)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:193: in _process_default\n    self._process(sgroup)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:80: in _process\n    func(tlist)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:88: in _process_where\n    self._process_default(tlist)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:193: in _process_default\n    self._process(sgroup)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:80: in _process\n    func(tlist)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <sqlparse.filters.reindent.ReindentFilter object at 0x00000278EE81BAD0>\ntlist = <Parenthesis '(1, 2,...' at 0x278EEA62BD0>\n\n    def _process_parenthesis(self, tlist):\n        for token in tlist.tokens:\n            if isinstance(token, sql.IdentifierList):\n>               self.indentation += 1\nE               AttributeError: 'ReindentFilter' object has no attribute 'indentation'\n\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:93: AttributeError"", 'self = <tests.test_format.TestFormatReindent object at 0x00000278EE7165D0>\n\n    def test_identifier_list_with_functions(self):\n        f = lambda sql: sqlparse.format(sql, reindent=True)\n        s = (""select \'abc\' as foo, coalesce(col1, col2)||col3 as bar,""\n             ""col3 from my_table"")\n>       assert f(s) == \'\\n\'.join([\n            ""select \'abc\' as foo,"",\n            ""       coalesce(col1, col2)||col3 as bar,"",\n            ""       col3"",\n            ""from my_table""])\n\nrepos\\sqlparse\\tests\\test_format.py:508: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:505: in <lambda>\n    f = lambda sql: sqlparse.format(sql, reindent=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return \'\'.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:44: in run\n    filter_.process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:197: in process\n    self._process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:80: in _process\n    func(tlist)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:193: in _process_default\n    self._process(sgroup)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:80: in _process\n    func(tlist)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:153: in _process_identifierlist\n    self._process_default(tlist)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:193: in _process_default\n    self._process(sgroup)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:80: in _process\n    func(tlist)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:193: in _process_default\n    self._process(sgroup)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:80: in _process\n    func(tlist)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:193: in _process_default\n    self._process(sgroup)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:80: in _process\n    func(tlist)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:105: in _process_function\n    self._process_default(tlist)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:193: in _process_default\n    self._process(sgroup)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:80: in _process\n    func(tlist)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <sqlparse.filters.reindent.ReindentFilter object at 0x00000278EEA47B70>\ntlist = <Parenthesis \'(col1,...\' at 0x278EEA61650>\n\n    def _process_parenthesis(self, tlist):\n        for token in tlist.tokens:\n            if isinstance(token, sql.IdentifierList):\n>               self.indentation += 1\nE               AttributeError: \'ReindentFilter\' object has no attribute \'indentation\'\n\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:93: AttributeError', 'self = <tests.test_format.TestFormatReindent object at 0x00000278EE763230>\n\n    def test_long_identifier_list_with_functions(self):\n        f = lambda sql: sqlparse.format(sql, reindent=True, wrap_after=30)\n        s = (""select \'abc\' as foo, json_build_object(\'a\',  a,""\n             ""\'b\', b, \'c\', c, \'d\', d, \'e\', e) as col2""\n             ""col3 from my_table"")\n>       assert f(s) == \'\\n\'.join([\n            ""select \'abc\' as foo,"",\n            ""       json_build_object(\'a\',"",\n            ""         a, \'b\', b, \'c\', c, \'d\', d,"",\n            ""         \'e\', e) as col2col3"",\n            ""from my_table""])\n\nrepos\\sqlparse\\tests\\test_format.py:519: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:515: in <lambda>\n    f = lambda sql: sqlparse.format(sql, reindent=True, wrap_after=30)\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return \'\'.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:44: in run\n    filter_.process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:197: in process\n    self._process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:80: in _process\n    func(tlist)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:193: in _process_default\n    self._process(sgroup)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:80: in _process\n    func(tlist)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:153: in _process_identifierlist\n    self._process_default(tlist)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:193: in _process_default\n    self._process(sgroup)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:80: in _process\n    func(tlist)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:193: in _process_default\n    self._process(sgroup)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:80: in _process\n    func(tlist)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:105: in _process_function\n    self._process_default(tlist)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:193: in _process_default\n    self._process(sgroup)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:80: in _process\n    func(tlist)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <sqlparse.filters.reindent.ReindentFilter object at 0x00000278EEBE83C0>\ntlist = <Parenthesis \'(\'a\', ...\' at 0x278EEA4E050>\n\n    def _process_parenthesis(self, tlist):\n        for token in tlist.tokens:\n            if isinstance(token, sql.IdentifierList):\n>               self.indentation += 1\nE               AttributeError: \'ReindentFilter\' object has no attribute \'indentation\'\n\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:93: AttributeError', ""self = <tests.test_format.TestFormatReindent object at 0x00000278EE607350>\n\n    def test_nested_identifier_list(self):\n        # issue4\n        f = lambda sql: sqlparse.format(sql, reindent=True)\n        s = '(foo as bar, bar1, bar2 as bar3, b4 as b5)'\n>       assert f(s) == '\\n'.join([\n            '(foo as bar,',\n            ' bar1,',\n            ' bar2 as bar3,',\n            ' b4 as b5)'])\n\nrepos\\sqlparse\\tests\\test_format.py:549: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:547: in <lambda>\n    f = lambda sql: sqlparse.format(sql, reindent=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return ''.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:44: in run\n    filter_.process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:197: in process\n    self._process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:80: in _process\n    func(tlist)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:193: in _process_default\n    self._process(sgroup)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:80: in _process\n    func(tlist)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <sqlparse.filters.reindent.ReindentFilter object at 0x00000278EEA33A10>\ntlist = <Parenthesis '(foo a...' at 0x278EEA61650>\n\n    def _process_parenthesis(self, tlist):\n        for token in tlist.tokens:\n            if isinstance(token, sql.IdentifierList):\n>               self.indentation += 1\nE               AttributeError: 'ReindentFilter' object has no attribute 'indentation'\n\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:93: AttributeError"", ""self = <tests.test_format.TestFormatReindent object at 0x00000278EE7D2850>\n\n    def test_insert_values(self):\n        # issue 329\n        f = lambda sql: sqlparse.format(sql, reindent=True)\n        s = 'insert into foo values (1, 2)'\n        assert f(s) == '\\n'.join([\n            'insert into foo',\n            'values (1, 2)'])\n    \n        s = 'insert into foo values (1, 2), (3, 4), (5, 6)'\n        assert f(s) == '\\n'.join([\n            'insert into foo',\n            'values (1, 2),',\n            '       (3, 4),',\n            '       (5, 6)'])\n    \n        s = 'insert into foo(a, b) values (1, 2), (3, 4), (5, 6)'\n>       assert f(s) == '\\n'.join([\n            'insert into foo(a, b)',\n            'values (1, 2),',\n            '       (3, 4),',\n            '       (5, 6)'])\n\nrepos\\sqlparse\\tests\\test_format.py:613: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:599: in <lambda>\n    f = lambda sql: sqlparse.format(sql, reindent=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return ''.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:44: in run\n    filter_.process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:197: in process\n    self._process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:80: in _process\n    func(tlist)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:193: in _process_default\n    self._process(sgroup)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:80: in _process\n    func(tlist)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:105: in _process_function\n    self._process_default(tlist)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:193: in _process_default\n    self._process(sgroup)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:80: in _process\n    func(tlist)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <sqlparse.filters.reindent.ReindentFilter object at 0x00000278EB505700>\ntlist = <Parenthesis '(a, b)' at 0x278EEB92750>\n\n    def _process_parenthesis(self, tlist):\n        for token in tlist.tokens:\n            if isinstance(token, sql.IdentifierList):\n>               self.indentation += 1\nE               AttributeError: 'ReindentFilter' object has no attribute 'indentation'\n\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:93: AttributeError"", ""def test_issue40():\n        # make sure identifier lists in subselects are grouped\n        p = sqlparse.parse('SELECT id, name FROM '\n                           '(SELECT id, name FROM bar) as foo')[0]\n        assert len(p.tokens) == 7\n        assert p.tokens[2].__class__ == sql.IdentifierList\n        assert p.tokens[-1].__class__ == sql.Identifier\n        assert p.tokens[-1].get_name() == 'foo'\n        sp = p.tokens[-1].tokens[0]\n        assert sp.tokens[3].__class__ == sql.IdentifierList\n        # make sure that formatting works as expected\n>       s = sqlparse.format('SELECT id ==  name FROM '\n                            '(SELECT id, name FROM bar)', reindent=True)\n\nrepos\\sqlparse\\tests\\test_regressions.py:86: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return ''.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:44: in run\n    filter_.process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:197: in process\n    self._process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:80: in _process\n    func(tlist)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:193: in _process_default\n    self._process(sgroup)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:80: in _process\n    func(tlist)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <sqlparse.filters.reindent.ReindentFilter object at 0x00000278EEB98260>\ntlist = <Parenthesis '(SELEC...' at 0x278EEBCCFD0>\n\n    def _process_parenthesis(self, tlist):\n        for token in tlist.tokens:\n            if isinstance(token, sql.IdentifierList):\n>               self.indentation += 1\nE               AttributeError: 'ReindentFilter' object has no attribute 'indentation'\n\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:93: AttributeError"", ""def test_issue207_runaway_format():\n        sql = 'select 1 from (select 1 as one, 2 as two, 3 from dual) t0'\n>       p = sqlparse.format(sql, reindent=True)\n\nrepos\\sqlparse\\tests\\test_regressions.py:303: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return ''.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:44: in run\n    filter_.process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:197: in process\n    self._process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:80: in _process\n    func(tlist)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:193: in _process_default\n    self._process(sgroup)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:80: in _process\n    func(tlist)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:193: in _process_default\n    self._process(sgroup)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:80: in _process\n    func(tlist)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <sqlparse.filters.reindent.ReindentFilter object at 0x00000278EEB63540>\ntlist = <Parenthesis '(selec...' at 0x278EEBA4FD0>\n\n    def _process_parenthesis(self, tlist):\n        for token in tlist.tokens:\n            if isinstance(token, sql.IdentifierList):\n>               self.indentation += 1\nE               AttributeError: 'ReindentFilter' object has no attribute 'indentation'\n\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:93: AttributeError"", 'def test_issue562_tzcasts():\n        # Test that whitespace between \'from\' and \'bar\' is retained\n        formatted = sqlparse.format(\n            \'SELECT f(HOUR from bar AT TIME ZONE \\\'UTC\\\') from foo\', reindent=True\n        )\n>       assert formatted == \\\n               \'SELECT f(HOUR\\n         from bar AT TIME ZONE \\\'UTC\\\')\\nfrom foo\'\nE       assert ""SELECT f(HOU...C\')\\nfrom foo"" == ""SELECT f(HOU...C\')\\nfrom foo""\nE         \nE         + SELECT f(HOUR from bar AT TIME ZONE \'UTC\')\nE         - SELECT f(HOUR\nE         -          from bar AT TIME ZONE \'UTC\')\nE           from foo\n\nrepos\\sqlparse\\tests\\test_regressions.py:413: AssertionError']",sqlparse/_process_parenthesis,LLM
sqlparse,_process_where,"def _process_where(self, tlist):
    tidx, token = tlist.token_next_by(m=(T.Keyword, 'WHERE'))
    if not token:
        return
    tlist.insert_before(tidx, self.nl())
    with indent(self):
        self._process_default(tlist)","The goal of the `_process_where` function is to handle the processing of a SQL WHERE clause within a SQL query. It identifies the WHERE keyword in the token list, adds a newline before it, and then calls another method `_process_default` to handle the default processing of the WHERE clause. This function is likely part of a larger SQL query processing class and is responsible for specifically dealing with the WHERE clause.",1,"def _process_where(self, tlist):
    where_index = tlist.index('WHERE')
    tlist.insert(where_index, '\n')
    return self._process_default(tlist)","['./repos/sqlparse\\tests', './repos/sqlparse\\tests\\test_cli.py::test_cli_main_empty', './repos/sqlparse\\tests\\test_cli.py::test_parser_empty', './repos/sqlparse\\tests\\test_cli.py::test_main_help', './repos/sqlparse\\tests\\test_cli.py::test_valid_args', './repos/sqlparse\\tests\\test_cli.py::test_invalid_choice', './repos/sqlparse\\tests\\test_cli.py::test_invalid_args', './repos/sqlparse\\tests\\test_cli.py::test_invalid_infile', './repos/sqlparse\\tests\\test_cli.py::test_invalid_outfile', './repos/sqlparse\\tests\\test_cli.py::test_stdout', './repos/sqlparse\\tests\\test_cli.py::test_script', './repos/sqlparse\\tests\\test_cli.py::test_encoding_stdout', './repos/sqlparse\\tests\\test_cli.py::test_encoding_output_file', './repos/sqlparse\\tests\\test_cli.py::test_encoding_stdin', './repos/sqlparse\\tests\\test_cli.py::test_encoding', './repos/sqlparse\\tests\\test_format.py::test_format_column_ordering', './repos/sqlparse\\tests\\test_format.py::test_truncate_strings', './repos/sqlparse\\tests\\test_format.py::test_truncate_strings_invalid_option2', './repos/sqlparse\\tests\\test_format.py::test_truncate_strings_doesnt_truncate_identifiers', './repos/sqlparse\\tests\\test_format.py::test_having_produces_newline', './repos/sqlparse\\tests\\test_format.py::test_format_right_margin_invalid_option', './repos/sqlparse\\tests\\test_format.py::test_format_right_margin', './repos/sqlparse\\tests\\test_format.py::test_format_json_ops', './repos/sqlparse\\tests\\test_format.py::test_compact', './repos/sqlparse\\tests\\test_format.py::test_strip_ws_removes_trailing_ws_in_groups', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_parenthesis', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_assignment', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_typed_literal', './repos/sqlparse\\tests\\test_grouping.py::test_compare_expr', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifiers', './repos/sqlparse\\tests\\test_grouping.py::test_simple_identifiers', './repos/sqlparse\\tests\\test_grouping.py::test_group_identifier_list', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifier_wildcard', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifier_name_wildcard', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifier_invalid', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifier_invalid_in_middle', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifer_as', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifier_as_invalid', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifier_function', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_operation', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifier_list', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifier_list_subquery', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifier_list_case', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifier_list_other', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifier_list_with_inline_comments', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifiers_with_operators', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifier_list_with_order', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_nested_identifier_with_order', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_where', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_where_union', './repos/sqlparse\\tests\\test_grouping.py::test_returning_kw_ends_where_clause', './repos/sqlparse\\tests\\test_grouping.py::test_into_kw_ends_where_clause', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_typecast', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_alias', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_alias_case', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_alias_ctas', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_subquery_no_parens', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_alias_returns_none', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_idlist_function', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_comparison_exclude', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_function', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_function_not_in', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_varchar', './repos/sqlparse\\tests\\test_grouping.py::test_statement_get_type', './repos/sqlparse\\tests\\test_grouping.py::test_identifier_with_operators', './repos/sqlparse\\tests\\test_grouping.py::test_identifier_with_op_trailing_ws', './repos/sqlparse\\tests\\test_grouping.py::test_identifier_with_string_literals', './repos/sqlparse\\tests\\test_grouping.py::test_identifier_consumes_ordering', './repos/sqlparse\\tests\\test_grouping.py::test_comparison_with_keywords', './repos/sqlparse\\tests\\test_grouping.py::test_comparison_with_floats', './repos/sqlparse\\tests\\test_grouping.py::test_comparison_with_parenthesis', './repos/sqlparse\\tests\\test_grouping.py::test_comparison_with_strings', './repos/sqlparse\\tests\\test_grouping.py::test_like_and_ilike_comparison', './repos/sqlparse\\tests\\test_grouping.py::test_comparison_with_functions', './repos/sqlparse\\tests\\test_grouping.py::test_comparison_with_typed_literal', './repos/sqlparse\\tests\\test_grouping.py::test_forloops', './repos/sqlparse\\tests\\test_grouping.py::test_nested_for', './repos/sqlparse\\tests\\test_grouping.py::test_begin', './repos/sqlparse\\tests\\test_grouping.py::test_keyword_followed_by_parenthesis', './repos/sqlparse\\tests\\test_grouping.py::test_nested_begin', './repos/sqlparse\\tests\\test_grouping.py::test_aliased_column_without_as', './repos/sqlparse\\tests\\test_grouping.py::test_qualified_function', './repos/sqlparse\\tests\\test_grouping.py::test_aliased_function_without_as', './repos/sqlparse\\tests\\test_grouping.py::test_aliased_literal_without_as', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_as_cte', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_create_table', './repos/sqlparse\\tests\\test_parse.py::test_parse_tokenize', './repos/sqlparse\\tests\\test_parse.py::test_parse_multistatement', './repos/sqlparse\\tests\\test_parse.py::test_parse_newlines', './repos/sqlparse\\tests\\test_parse.py::test_parse_within', './repos/sqlparse\\tests\\test_parse.py::test_parse_child_of', './repos/sqlparse\\tests\\test_parse.py::test_parse_has_ancestor', './repos/sqlparse\\tests\\test_parse.py::test_parse_float', './repos/sqlparse\\tests\\test_parse.py::test_parse_placeholder', './repos/sqlparse\\tests\\test_parse.py::test_parse_modulo_not_placeholder', './repos/sqlparse\\tests\\test_parse.py::test_parse_access_symbol', './repos/sqlparse\\tests\\test_parse.py::test_parse_square_brackets_notation_isnt_too_greedy', './repos/sqlparse\\tests\\test_parse.py::test_parse_square_brackets_notation_isnt_too_greedy2', './repos/sqlparse\\tests\\test_parse.py::test_parse_keyword_like_identifier', './repos/sqlparse\\tests\\test_parse.py::test_parse_function_parameter', './repos/sqlparse\\tests\\test_parse.py::test_parse_function_param_single_literal', './repos/sqlparse\\tests\\test_parse.py::test_parse_nested_function', './repos/sqlparse\\tests\\test_parse.py::test_parse_casted_params', './repos/sqlparse\\tests\\test_parse.py::test_parse_div_operator', './repos/sqlparse\\tests\\test_parse.py::test_quoted_identifier', './repos/sqlparse\\tests\\test_parse.py::test_valid_identifier_names', './repos/sqlparse\\tests\\test_parse.py::test_psql_quotation_marks', './repos/sqlparse\\tests\\test_parse.py::test_double_precision_is_builtin', './repos/sqlparse\\tests\\test_parse.py::test_placeholder', './repos/sqlparse\\tests\\test_parse.py::test_scientific_numbers', './repos/sqlparse\\tests\\test_parse.py::test_single_quotes_are_strings', './repos/sqlparse\\tests\\test_parse.py::test_double_quotes_are_identifiers', './repos/sqlparse\\tests\\test_parse.py::test_single_quotes_with_linebreaks', './repos/sqlparse\\tests\\test_parse.py::test_sqlite_identifiers', './repos/sqlparse\\tests\\test_parse.py::test_simple_1d_array_index', './repos/sqlparse\\tests\\test_parse.py::test_2d_array_index', './repos/sqlparse\\tests\\test_parse.py::test_array_index_function_result', './repos/sqlparse\\tests\\test_parse.py::test_schema_qualified_array_index', './repos/sqlparse\\tests\\test_parse.py::test_aliased_array_index', './repos/sqlparse\\tests\\test_parse.py::test_array_literal', './repos/sqlparse\\tests\\test_parse.py::test_typed_array_definition', './repos/sqlparse\\tests\\test_parse.py::test_single_line_comments', './repos/sqlparse\\tests\\test_parse.py::test_names_and_special_names', './repos/sqlparse\\tests\\test_parse.py::test_get_token_at_offset', './repos/sqlparse\\tests\\test_parse.py::test_pprint', './repos/sqlparse\\tests\\test_parse.py::test_wildcard_multiplication', './repos/sqlparse\\tests\\test_parse.py::test_stmt_tokens_parents', './repos/sqlparse\\tests\\test_parse.py::test_dbldollar_as_literal', './repos/sqlparse\\tests\\test_parse.py::test_non_ascii', './repos/sqlparse\\tests\\test_parse.py::test_get_real_name', './repos/sqlparse\\tests\\test_parse.py::test_from_subquery', './repos/sqlparse\\tests\\test_parse.py::test_parenthesis', './repos/sqlparse\\tests\\test_parse.py::test_configurable_keywords', './repos/sqlparse\\tests\\test_parse.py::test_configurable_regex', './repos/sqlparse\\tests\\test_parse.py::test_json_operators', './repos/sqlparse\\tests\\test_regressions.py::test_issue9', './repos/sqlparse\\tests\\test_regressions.py::test_issue13', './repos/sqlparse\\tests\\test_regressions.py::test_issue26', './repos/sqlparse\\tests\\test_regressions.py::test_issue34', './repos/sqlparse\\tests\\test_regressions.py::test_issue35', './repos/sqlparse\\tests\\test_regressions.py::test_issue38', './repos/sqlparse\\tests\\test_regressions.py::test_issue39', './repos/sqlparse\\tests\\test_regressions.py::test_issue40', './repos/sqlparse\\tests\\test_regressions.py::test_issue78', './repos/sqlparse\\tests\\test_regressions.py::test_issue83', './repos/sqlparse\\tests\\test_regressions.py::test_comment_encoding_when_reindent', './repos/sqlparse\\tests\\test_regressions.py::test_parse_sql_with_binary', './repos/sqlparse\\tests\\test_regressions.py::test_dont_alias_keywords', './repos/sqlparse\\tests\\test_regressions.py::test_format_accepts_encoding', './repos/sqlparse\\tests\\test_regressions.py::test_stream', './repos/sqlparse\\tests\\test_regressions.py::test_issue90', './repos/sqlparse\\tests\\test_regressions.py::test_except_formatting', './repos/sqlparse\\tests\\test_regressions.py::test_null_with_as', './repos/sqlparse\\tests\\test_regressions.py::test_issue190_open_file', './repos/sqlparse\\tests\\test_regressions.py::test_issue193_splitting_function', './repos/sqlparse\\tests\\test_regressions.py::test_issue194_splitting_function', './repos/sqlparse\\tests\\test_regressions.py::test_issue186_get_type', './repos/sqlparse\\tests\\test_regressions.py::test_issue212_py2unicode', './repos/sqlparse\\tests\\test_regressions.py::test_issue213_leadingws', './repos/sqlparse\\tests\\test_regressions.py::test_issue227_gettype_cte', './repos/sqlparse\\tests\\test_regressions.py::test_issue207_runaway_format', './repos/sqlparse\\tests\\test_regressions.py::test_token_next_doesnt_ignore_skip_cm', './repos/sqlparse\\tests\\test_regressions.py::test_issue284_as_grouping', './repos/sqlparse\\tests\\test_regressions.py::test_issue315_utf8_by_default', './repos/sqlparse\\tests\\test_regressions.py::test_issue322_concurrently_is_keyword', './repos/sqlparse\\tests\\test_regressions.py::test_issue359_index_error_assignments', './repos/sqlparse\\tests\\test_regressions.py::test_issue469_copy_as_psql_command', './repos/sqlparse\\tests\\test_regressions.py::test_issue484_comments_and_newlines', './repos/sqlparse\\tests\\test_regressions.py::test_issue485_split_multi', './repos/sqlparse\\tests\\test_regressions.py::test_issue489_tzcasts', './repos/sqlparse\\tests\\test_regressions.py::test_issue562_tzcasts', './repos/sqlparse\\tests\\test_regressions.py::test_as_in_parentheses_indents', './repos/sqlparse\\tests\\test_regressions.py::test_format_invalid_where_clause', './repos/sqlparse\\tests\\test_regressions.py::test_splitting_at_and_backticks_issue588', './repos/sqlparse\\tests\\test_regressions.py::test_comment_between_cte_clauses_issue632', './repos/sqlparse\\tests\\test_regressions.py::test_copy_issue672', './repos/sqlparse\\tests\\test_regressions.py::test_primary_key_issue740', './repos/sqlparse\\tests\\test_regressions.py::test_max_recursion', './repos/sqlparse\\tests\\test_split.py::test_split_semicolon', './repos/sqlparse\\tests\\test_split.py::test_split_backslash', './repos/sqlparse\\tests\\test_split.py::test_split_create_function', './repos/sqlparse\\tests\\test_split.py::test_split_dashcomments', './repos/sqlparse\\tests\\test_split.py::test_split_dashcomments_eol', './repos/sqlparse\\tests\\test_split.py::test_split_begintag', './repos/sqlparse\\tests\\test_split.py::test_split_begintag_2', './repos/sqlparse\\tests\\test_split.py::test_split_dropif', './repos/sqlparse\\tests\\test_split.py::test_split_comment_with_umlaut', './repos/sqlparse\\tests\\test_split.py::test_split_comment_end_of_line', './repos/sqlparse\\tests\\test_split.py::test_split_casewhen', './repos/sqlparse\\tests\\test_split.py::test_split_casewhen_procedure', './repos/sqlparse\\tests\\test_split.py::test_split_cursor_declare', './repos/sqlparse\\tests\\test_split.py::test_split_if_function', './repos/sqlparse\\tests\\test_split.py::test_split_stream', './repos/sqlparse\\tests\\test_split.py::test_split_encoding_parsestream', './repos/sqlparse\\tests\\test_split.py::test_split_unicode_parsestream', './repos/sqlparse\\tests\\test_split.py::test_split_simple', './repos/sqlparse\\tests\\test_split.py::test_split_ignores_empty_newlines', './repos/sqlparse\\tests\\test_split.py::test_split_quotes_with_new_line', './repos/sqlparse\\tests\\test_split.py::test_split_mysql_handler_for', './repos/sqlparse\\tests\\test_split.py::test_split_strip_semicolon', './repos/sqlparse\\tests\\test_split.py::test_split_strip_semicolon_procedure', './repos/sqlparse\\tests\\test_split.py::test_split_go', './repos/sqlparse\\tests\\test_split.py::test_split_multiple_case_in_begin', './repos/sqlparse\\tests\\test_tokenize.py::test_tokenize_simple', './repos/sqlparse\\tests\\test_tokenize.py::test_tokenize_backticks', './repos/sqlparse\\tests\\test_tokenize.py::test_tokenize_linebreaks', './repos/sqlparse\\tests\\test_tokenize.py::test_tokenize_inline_keywords', './repos/sqlparse\\tests\\test_tokenize.py::test_tokenize_negative_numbers', './repos/sqlparse\\tests\\test_tokenize.py::test_token_str', './repos/sqlparse\\tests\\test_tokenize.py::test_token_repr', './repos/sqlparse\\tests\\test_tokenize.py::test_token_flatten', './repos/sqlparse\\tests\\test_tokenize.py::test_tokenlist_repr', './repos/sqlparse\\tests\\test_tokenize.py::test_single_quotes', './repos/sqlparse\\tests\\test_tokenize.py::test_tokenlist_first', './repos/sqlparse\\tests\\test_tokenize.py::test_tokenlist_token_matching', './repos/sqlparse\\tests\\test_tokenize.py::test_stream_simple', './repos/sqlparse\\tests\\test_tokenize.py::test_stream_error', './repos/sqlparse\\tests\\test_tokenize.py::test_parse_join', './repos/sqlparse\\tests\\test_tokenize.py::test_parse_union', './repos/sqlparse\\tests\\test_tokenize.py::test_parse_endifloop', './repos/sqlparse\\tests\\test_tokenize.py::test_parse_order', './repos/sqlparse\\tests\\test_tokenize.py::test_parse_identifiers', './repos/sqlparse\\tests\\test_tokenize.py::test_parse_group_by', './repos/sqlparse\\tests\\test_tokenize.py::test_parse_order_by', './repos/sqlparse\\tests\\test_tokenize.py::test_parse_window_as', './repos/sqlparse\\tests\\test_tokenize.py::test_like_and_ilike_parsed_as_comparisons', './repos/sqlparse\\tests\\test_tokenize.py::test_near_like_and_ilike_parsed_appropriately', './repos/sqlparse\\tests\\test_tokenize.py::test_parse_tzcast', './repos/sqlparse\\tests\\test_tokenize.py::test_cli_commands', './repos/sqlparse\\tests\\test_utils.py::test_remove_quotes']","450 Passed, 11 Failed",450,11,"['tests/test_format.py::TestFormatReindent::test_where', 'tests/test_format.py::TestFormatReindent::test_identifier_list', 'tests/test_format.py::TestFormatReindent::test_identifier_list_with_wrap_after', 'tests/test_format.py::TestFormatReindent::test_identifier_list_comment_first', 'tests/test_format.py::TestFormatReindent::test_duplicate_linebreaks', 'tests/test_format.py::test_having_produces_newline', 'tests/test_regressions.py::test_issue35', 'tests/test_regressions.py::test_parse_sql_with_binary', 'tests/test_regressions.py::test_except_formatting', 'tests/test_regressions.py::test_issue315_utf8_by_default', 'tests/test_regressions.py::test_format_invalid_where_clause']","[""self = <tests.test_format.TestFormatReindent object at 0x00000254E381BDF0>\n\n    def test_where(self):\n        f = lambda sql: sqlparse.format(sql, reindent=True)\n        s = 'select * from foo where bar = 1 and baz = 2 or bzz = 3;'\n>       assert f(s) == '\\n'.join([\n            'select *',\n            'from foo',\n            'where bar = 1',\n            '  and baz = 2',\n            '  or bzz = 3;'])\n\nrepos\\sqlparse\\tests\\test_format.py:427: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:425: in <lambda>\n    f = lambda sql: sqlparse.format(sql, reindent=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return ''.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:44: in run\n    filter_.process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:192: in process\n    self._process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:80: in _process\n    func(tlist)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:188: in _process_default\n    self._process(sgroup)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:80: in _process\n    func(tlist)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <sqlparse.filters.reindent.ReindentFilter object at 0x00000254E2EBEC10>\ntlist = <Where 'where ...' at 0x254E3C69BD0>\n\n    def _process_where(self, tlist):\n>       where_index = tlist.index('WHERE')\nE       AttributeError: 'Where' object has no attribute 'index'\n\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:83: AttributeError"", ""self = <tests.test_format.TestFormatReindent object at 0x00000254E39A8D50>\n\n    def test_identifier_list(self):\n        f = lambda sql: sqlparse.format(sql, reindent=True)\n        s = 'select foo, bar, baz from table1, table2 where 1 = 2'\n>       assert f(s) == '\\n'.join([\n            'select foo,',\n            '       bar,',\n            '       baz',\n            'from table1,',\n            '     table2',\n            'where 1 = 2'])\n\nrepos\\sqlparse\\tests\\test_format.py:468: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:466: in <lambda>\n    f = lambda sql: sqlparse.format(sql, reindent=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return ''.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:44: in run\n    filter_.process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:192: in process\n    self._process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:80: in _process\n    func(tlist)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:188: in _process_default\n    self._process(sgroup)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:80: in _process\n    func(tlist)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <sqlparse.filters.reindent.ReindentFilter object at 0x00000254E3C271D0>\ntlist = <Where 'where ...' at 0x254E3C3D650>\n\n    def _process_where(self, tlist):\n>       where_index = tlist.index('WHERE')\nE       AttributeError: 'Where' object has no attribute 'index'\n\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:83: AttributeError"", ""self = <tests.test_format.TestFormatReindent object at 0x00000254E39A8E50>\n\n    def test_identifier_list_with_wrap_after(self):\n        f = lambda sql: sqlparse.format(sql, reindent=True, wrap_after=14)\n        s = 'select foo, bar, baz from table1, table2 where 1 = 2'\n>       assert f(s) == '\\n'.join([\n            'select foo, bar,',\n            '       baz',\n            'from table1, table2',\n            'where 1 = 2'])\n\nrepos\\sqlparse\\tests\\test_format.py:485: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:483: in <lambda>\n    f = lambda sql: sqlparse.format(sql, reindent=True, wrap_after=14)\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return ''.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:44: in run\n    filter_.process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:192: in process\n    self._process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:80: in _process\n    func(tlist)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:188: in _process_default\n    self._process(sgroup)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:80: in _process\n    func(tlist)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <sqlparse.filters.reindent.ReindentFilter object at 0x00000254E3C27800>\ntlist = <Where 'where ...' at 0x254E3C3F850>\n\n    def _process_where(self, tlist):\n>       where_index = tlist.index('WHERE')\nE       AttributeError: 'Where' object has no attribute 'index'\n\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:83: AttributeError"", ""self = <tests.test_format.TestFormatReindent object at 0x00000254E38EE4E0>\n\n    def test_identifier_list_comment_first(self):\n        f = lambda sql: sqlparse.format(sql, reindent=True, comma_first=True)\n        # not the 3: It cleans up whitespace too!\n        s = 'select foo, bar, baz from table where foo in (1, 2,3)'\n>       assert f(s) == '\\n'.join([\n            'select foo',\n            '     , bar',\n            '     , baz',\n            'from table',\n            'where foo in (1',\n            '            , 2',\n            '            , 3)'])\n\nrepos\\sqlparse\\tests\\test_format.py:495: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:492: in <lambda>\n    f = lambda sql: sqlparse.format(sql, reindent=True, comma_first=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return ''.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:44: in run\n    filter_.process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:192: in process\n    self._process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:80: in _process\n    func(tlist)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:188: in _process_default\n    self._process(sgroup)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:80: in _process\n    func(tlist)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <sqlparse.filters.reindent.ReindentFilter object at 0x00000254E3C27D80>\ntlist = <Where 'where ...' at 0x254E3C3DB50>\n\n    def _process_where(self, tlist):\n>       where_index = tlist.index('WHERE')\nE       AttributeError: 'Where' object has no attribute 'index'\n\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:83: AttributeError"", ""self = <tests.test_format.TestFormatReindent object at 0x00000254E37E7890>\n\n    def test_duplicate_linebreaks(self):\n        # issue3\n        f = lambda sql: sqlparse.format(sql, reindent=True)\n        s = 'select c1 -- column1\\nfrom foo'\n        assert f(s) == '\\n'.join([\n            'select c1 -- column1',\n            'from foo'])\n        s = 'select c1 -- column1\\nfrom foo'\n        r = sqlparse.format(s, reindent=True, strip_comments=True)\n        assert r == '\\n'.join([\n            'select c1',\n            'from foo'])\n        s = 'select c1\\nfrom foo\\norder by c1'\n        assert f(s) == '\\n'.join([\n            'select c1',\n            'from foo',\n            'order by c1'])\n        s = 'select c1 from t1 where (c1 = 1) order by c1'\n>       assert f(s) == '\\n'.join([\n            'select c1',\n            'from t1',\n            'where (c1 = 1)',\n            'order by c1'])\n\nrepos\\sqlparse\\tests\\test_format.py:573: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:557: in <lambda>\n    f = lambda sql: sqlparse.format(sql, reindent=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return ''.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:44: in run\n    filter_.process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:192: in process\n    self._process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:80: in _process\n    func(tlist)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:188: in _process_default\n    self._process(sgroup)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:80: in _process\n    func(tlist)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <sqlparse.filters.reindent.ReindentFilter object at 0x00000254E3ABB490>\ntlist = <Where 'where ...' at 0x254E3CEA2D0>\n\n    def _process_where(self, tlist):\n>       where_index = tlist.index('WHERE')\nE       AttributeError: 'Where' object has no attribute 'index'\n\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:83: AttributeError"", ""def test_having_produces_newline():\n        sql = ('select * from foo, bar where bar.id = foo.bar_id '\n               'having sum(bar.value) > 100')\n>       formatted = sqlparse.format(sql, reindent=True)\n\nrepos\\sqlparse\\tests\\test_format.py:730: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return ''.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:44: in run\n    filter_.process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:192: in process\n    self._process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:80: in _process\n    func(tlist)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:188: in _process_default\n    self._process(sgroup)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:80: in _process\n    func(tlist)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <sqlparse.filters.reindent.ReindentFilter object at 0x00000254E3CFC730>\ntlist = <Where 'where ...' at 0x254E3CEBAD0>\n\n    def _process_where(self, tlist):\n>       where_index = tlist.index('WHERE')\nE       AttributeError: 'Where' object has no attribute 'index'\n\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:83: AttributeError"", 'def test_issue35():\n        # missing space before LIMIT. Updated for #321\n>       sql = sqlparse.format(""select * from foo where bar = 1 limit 1"",\n                              reindent=True)\n\nrepos\\sqlparse\\tests\\test_regressions.py:48: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return \'\'.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:44: in run\n    filter_.process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:192: in process\n    self._process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:80: in _process\n    func(tlist)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:188: in _process_default\n    self._process(sgroup)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:80: in _process\n    func(tlist)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <sqlparse.filters.reindent.ReindentFilter object at 0x00000254E3D4FAC0>\ntlist = <Where \'where ...\' at 0x254E3DD20D0>\n\n    def _process_where(self, tlist):\n>       where_index = tlist.index(\'WHERE\')\nE       AttributeError: \'Where\' object has no attribute \'index\'\n\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:83: AttributeError', 'def test_parse_sql_with_binary():\n        # See https://github.com/andialbrecht/sqlparse/pull/88\n        # digest = \'\x82|Ë\x0eê\x8aplL4¡h\x91øN{\'\n        digest = \'\\x82|\\xcb\\x0e\\xea\\x8aplL4\\xa1h\\x91\\xf8N{\'\n        sql = f""select * from foo where bar = \'{digest}\'""\n>       formatted = sqlparse.format(sql, reindent=True)\n\nrepos\\sqlparse\\tests\\test_regressions.py:163: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return \'\'.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:44: in run\n    filter_.process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:192: in process\n    self._process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:80: in _process\n    func(tlist)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:188: in _process_default\n    self._process(sgroup)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:80: in _process\n    func(tlist)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <sqlparse.filters.reindent.ReindentFilter object at 0x00000254E3D5D7B0>\ntlist = <Where \'where ...\' at 0x254E3D9CB50>\n\n    def _process_where(self, tlist):\n>       where_index = tlist.index(\'WHERE\')\nE       AttributeError: \'Where\' object has no attribute \'index\'\n\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:83: AttributeError', ""def test_except_formatting():\n        sql = 'SELECT 1 FROM foo WHERE 2 = 3 EXCEPT SELECT 2 FROM bar WHERE 1 = 2'\n>       formatted = sqlparse.format(sql, reindent=True)\n\nrepos\\sqlparse\\tests\\test_regressions.py:216: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return ''.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:44: in run\n    filter_.process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:192: in process\n    self._process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:80: in _process\n    func(tlist)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:188: in _process_default\n    self._process(sgroup)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:80: in _process\n    func(tlist)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <sqlparse.filters.reindent.ReindentFilter object at 0x00000254E3D5E570>\ntlist = <Where 'WHERE ...' at 0x254E3DCABD0>\n\n    def _process_where(self, tlist):\n>       where_index = tlist.index('WHERE')\nE       AttributeError: 'Where' object has no attribute 'index'\n\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:83: AttributeError"", 'def test_issue315_utf8_by_default():\n        # Make sure the lexer can handle utf-8 string by default correctly\n        # digest = \'齐天大圣.カラフルな雲.사랑해요\'\n        # The digest contains Chinese, Japanese and Korean characters\n        # All in \'utf-8\' encoding.\n        digest = (\n            \'\\xe9\\xbd\\x90\\xe5\\xa4\\xa9\\xe5\\xa4\\xa7\\xe5\\x9c\\xa3.\'\n            \'\\xe3\\x82\\xab\\xe3\\x83\\xa9\\xe3\\x83\\x95\\xe3\\x83\\xab\\xe3\\x81\\xaa\\xe9\'\n            \'\\x9b\\xb2.\'\n            \'\\xec\\x82\\xac\\xeb\\x9e\\x91\\xed\\x95\\xb4\\xec\\x9a\\x94\'\n        )\n        sql = f""select * from foo where bar = \'{digest}\'""\n>       formatted = sqlparse.format(sql, reindent=True)\n\nrepos\\sqlparse\\tests\\test_regressions.py:340: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return \'\'.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:44: in run\n    filter_.process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:192: in process\n    self._process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:80: in _process\n    func(tlist)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:188: in _process_default\n    self._process(sgroup)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:80: in _process\n    func(tlist)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <sqlparse.filters.reindent.ReindentFilter object at 0x00000254E3D90310>\ntlist = <Where \'where ...\' at 0x254E3D55950>\n\n    def _process_where(self, tlist):\n>       where_index = tlist.index(\'WHERE\')\nE       AttributeError: \'Where\' object has no attribute \'index\'\n\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:83: AttributeError', ""def test_format_invalid_where_clause():\n        # did raise ValueError\n>       formatted = sqlparse.format('where, foo', reindent=True)\n\nrepos\\sqlparse\\tests\\test_regressions.py:425: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return ''.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:44: in run\n    filter_.process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:192: in process\n    self._process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:80: in _process\n    func(tlist)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:188: in _process_default\n    self._process(sgroup)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:80: in _process\n    func(tlist)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <sqlparse.filters.reindent.ReindentFilter object at 0x00000254E3D91A70>\ntlist = <Where 'where,...' at 0x254E3E8EA50>\n\n    def _process_where(self, tlist):\n>       where_index = tlist.index('WHERE')\nE       AttributeError: 'Where' object has no attribute 'index'\n\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:83: AttributeError""]",sqlparse/_process_where,LLM
sqlparse,build_filter_stack,"def build_filter_stack(stack, options):
    """"""Setup and return a filter stack.

    Args:
      stack: :class:`~sqlparse.filters.FilterStack` instance
      options: Dictionary with options validated by validate_options.
    """"""
    if options.get('keyword_case'):
        stack.preprocess.append(filters.KeywordCaseFilter(options['keyword_case']))
    if options.get('identifier_case'):
        stack.preprocess.append(filters.IdentifierCaseFilter(options['identifier_case']))
    if options.get('truncate_strings'):
        stack.preprocess.append(filters.TruncateStringFilter(width=options['truncate_strings'], char=options['truncate_char']))
    if options.get('use_space_around_operators', False):
        stack.enable_grouping()
        stack.stmtprocess.append(filters.SpacesAroundOperatorsFilter())
    if options.get('strip_comments'):
        stack.enable_grouping()
        stack.stmtprocess.append(filters.StripCommentsFilter())
    if options.get('strip_whitespace') or options.get('reindent'):
        stack.enable_grouping()
        stack.stmtprocess.append(filters.StripWhitespaceFilter())
    if options.get('reindent'):
        stack.enable_grouping()
        stack.stmtprocess.append(filters.ReindentFilter(char=options['indent_char'], width=options['indent_width'], indent_after_first=options['indent_after_first'], indent_columns=options['indent_columns'], wrap_after=options['wrap_after'], comma_first=options['comma_first'], compact=options['compact']))
    if options.get('reindent_aligned', False):
        stack.enable_grouping()
        stack.stmtprocess.append(filters.AlignedIndentFilter(char=options['indent_char']))
    if options.get('right_margin'):
        stack.enable_grouping()
        stack.stmtprocess.append(filters.RightMarginFilter(width=options['right_margin']))
    if options.get('output_format'):
        frmt = options['output_format']
        if frmt.lower() == 'php':
            fltr = filters.OutputPHPFilter()
        elif frmt.lower() == 'python':
            fltr = filters.OutputPythonFilter()
        else:
            fltr = None
        if fltr is not None:
            stack.postprocess.append(fltr)
    return stack","The function `build_filter_stack` is responsible for setting up and returning a filter stack based on the provided options. It adds various filters to the filter stack based on the options such as keyword case, identifier case, string truncation, spacing around operators, comment stripping, whitespace stripping, reindentation, alignment, right margin, and output format. The function allows for customization of the SQL formatting process by applying different filters based on the specified options.",2,"def build_filter_stack(stack, options):
    if options.get('keyword_case') == 'uppercase':
        stack.append(uppercase_keyword_filter)
    elif options.get('keyword_case') == 'lowercase':
        stack.append(lowercase_keyword_filter)
    
    if options.get('identifier_case') == 'uppercase':
        stack.append(uppercase_identifier_filter)
    elif options.get('identifier_case') == 'lowercase':
        stack.append(lowercase_identifier_filter)
    
    if options.get('string_truncation'):
        stack.append(string_truncation_filter)
    
    if options.get('spacing_around_operators'):
        stack.append(spacing_around_operators_filter)
    
    if options.get('strip_comments'):
        stack.append(strip_comments_filter)
    
    if options.get('strip_whitespace'):
        stack.append(strip_whitespace_filter)
    
    if options.get('reindent'):
        stack.append(reindent_filter)
    
    if options.get('alignment'):
        stack.append(align_filter)
    
    if options.get('right_margin'):
        stack.append(right_margin_filter)
    
    if options.get('output_format') == 'json':
        stack.append(json_output_filter)
    
    return stack","['./repos/sqlparse\\tests', './repos/sqlparse\\tests\\test_cli.py::test_cli_main_empty', './repos/sqlparse\\tests\\test_cli.py::test_parser_empty', './repos/sqlparse\\tests\\test_cli.py::test_main_help', './repos/sqlparse\\tests\\test_cli.py::test_valid_args', './repos/sqlparse\\tests\\test_cli.py::test_invalid_choice', './repos/sqlparse\\tests\\test_cli.py::test_invalid_args', './repos/sqlparse\\tests\\test_cli.py::test_invalid_infile', './repos/sqlparse\\tests\\test_cli.py::test_invalid_outfile', './repos/sqlparse\\tests\\test_cli.py::test_stdout', './repos/sqlparse\\tests\\test_cli.py::test_script', './repos/sqlparse\\tests\\test_cli.py::test_encoding_stdout', './repos/sqlparse\\tests\\test_cli.py::test_encoding_output_file', './repos/sqlparse\\tests\\test_cli.py::test_encoding_stdin', './repos/sqlparse\\tests\\test_cli.py::test_encoding', './repos/sqlparse\\tests\\test_format.py::test_format_column_ordering', './repos/sqlparse\\tests\\test_format.py::test_truncate_strings', './repos/sqlparse\\tests\\test_format.py::test_truncate_strings_invalid_option2', './repos/sqlparse\\tests\\test_format.py::test_truncate_strings_doesnt_truncate_identifiers', './repos/sqlparse\\tests\\test_format.py::test_having_produces_newline', './repos/sqlparse\\tests\\test_format.py::test_format_right_margin_invalid_option', './repos/sqlparse\\tests\\test_format.py::test_format_right_margin', './repos/sqlparse\\tests\\test_format.py::test_format_json_ops', './repos/sqlparse\\tests\\test_format.py::test_compact', './repos/sqlparse\\tests\\test_format.py::test_strip_ws_removes_trailing_ws_in_groups', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_parenthesis', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_assignment', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_typed_literal', './repos/sqlparse\\tests\\test_grouping.py::test_compare_expr', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifiers', './repos/sqlparse\\tests\\test_grouping.py::test_simple_identifiers', './repos/sqlparse\\tests\\test_grouping.py::test_group_identifier_list', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifier_wildcard', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifier_name_wildcard', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifier_invalid', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifier_invalid_in_middle', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifer_as', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifier_as_invalid', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifier_function', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_operation', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifier_list', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifier_list_subquery', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifier_list_case', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifier_list_other', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifier_list_with_inline_comments', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifiers_with_operators', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifier_list_with_order', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_nested_identifier_with_order', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_where', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_where_union', './repos/sqlparse\\tests\\test_grouping.py::test_returning_kw_ends_where_clause', './repos/sqlparse\\tests\\test_grouping.py::test_into_kw_ends_where_clause', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_typecast', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_alias', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_alias_case', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_alias_ctas', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_subquery_no_parens', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_alias_returns_none', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_idlist_function', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_comparison_exclude', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_function', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_function_not_in', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_varchar', './repos/sqlparse\\tests\\test_grouping.py::test_statement_get_type', './repos/sqlparse\\tests\\test_grouping.py::test_identifier_with_operators', './repos/sqlparse\\tests\\test_grouping.py::test_identifier_with_op_trailing_ws', './repos/sqlparse\\tests\\test_grouping.py::test_identifier_with_string_literals', './repos/sqlparse\\tests\\test_grouping.py::test_identifier_consumes_ordering', './repos/sqlparse\\tests\\test_grouping.py::test_comparison_with_keywords', './repos/sqlparse\\tests\\test_grouping.py::test_comparison_with_floats', './repos/sqlparse\\tests\\test_grouping.py::test_comparison_with_parenthesis', './repos/sqlparse\\tests\\test_grouping.py::test_comparison_with_strings', './repos/sqlparse\\tests\\test_grouping.py::test_like_and_ilike_comparison', './repos/sqlparse\\tests\\test_grouping.py::test_comparison_with_functions', './repos/sqlparse\\tests\\test_grouping.py::test_comparison_with_typed_literal', './repos/sqlparse\\tests\\test_grouping.py::test_forloops', './repos/sqlparse\\tests\\test_grouping.py::test_nested_for', './repos/sqlparse\\tests\\test_grouping.py::test_begin', './repos/sqlparse\\tests\\test_grouping.py::test_keyword_followed_by_parenthesis', './repos/sqlparse\\tests\\test_grouping.py::test_nested_begin', './repos/sqlparse\\tests\\test_grouping.py::test_aliased_column_without_as', './repos/sqlparse\\tests\\test_grouping.py::test_qualified_function', './repos/sqlparse\\tests\\test_grouping.py::test_aliased_function_without_as', './repos/sqlparse\\tests\\test_grouping.py::test_aliased_literal_without_as', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_as_cte', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_create_table', './repos/sqlparse\\tests\\test_parse.py::test_parse_tokenize', './repos/sqlparse\\tests\\test_parse.py::test_parse_multistatement', './repos/sqlparse\\tests\\test_parse.py::test_parse_newlines', './repos/sqlparse\\tests\\test_parse.py::test_parse_within', './repos/sqlparse\\tests\\test_parse.py::test_parse_child_of', './repos/sqlparse\\tests\\test_parse.py::test_parse_has_ancestor', './repos/sqlparse\\tests\\test_parse.py::test_parse_float', './repos/sqlparse\\tests\\test_parse.py::test_parse_placeholder', './repos/sqlparse\\tests\\test_parse.py::test_parse_modulo_not_placeholder', './repos/sqlparse\\tests\\test_parse.py::test_parse_access_symbol', './repos/sqlparse\\tests\\test_parse.py::test_parse_square_brackets_notation_isnt_too_greedy', './repos/sqlparse\\tests\\test_parse.py::test_parse_square_brackets_notation_isnt_too_greedy2', './repos/sqlparse\\tests\\test_parse.py::test_parse_keyword_like_identifier', './repos/sqlparse\\tests\\test_parse.py::test_parse_function_parameter', './repos/sqlparse\\tests\\test_parse.py::test_parse_function_param_single_literal', './repos/sqlparse\\tests\\test_parse.py::test_parse_nested_function', './repos/sqlparse\\tests\\test_parse.py::test_parse_casted_params', './repos/sqlparse\\tests\\test_parse.py::test_parse_div_operator', './repos/sqlparse\\tests\\test_parse.py::test_quoted_identifier', './repos/sqlparse\\tests\\test_parse.py::test_valid_identifier_names', './repos/sqlparse\\tests\\test_parse.py::test_psql_quotation_marks', './repos/sqlparse\\tests\\test_parse.py::test_double_precision_is_builtin', './repos/sqlparse\\tests\\test_parse.py::test_placeholder', './repos/sqlparse\\tests\\test_parse.py::test_scientific_numbers', './repos/sqlparse\\tests\\test_parse.py::test_single_quotes_are_strings', './repos/sqlparse\\tests\\test_parse.py::test_double_quotes_are_identifiers', './repos/sqlparse\\tests\\test_parse.py::test_single_quotes_with_linebreaks', './repos/sqlparse\\tests\\test_parse.py::test_sqlite_identifiers', './repos/sqlparse\\tests\\test_parse.py::test_simple_1d_array_index', './repos/sqlparse\\tests\\test_parse.py::test_2d_array_index', './repos/sqlparse\\tests\\test_parse.py::test_array_index_function_result', './repos/sqlparse\\tests\\test_parse.py::test_schema_qualified_array_index', './repos/sqlparse\\tests\\test_parse.py::test_aliased_array_index', './repos/sqlparse\\tests\\test_parse.py::test_array_literal', './repos/sqlparse\\tests\\test_parse.py::test_typed_array_definition', './repos/sqlparse\\tests\\test_parse.py::test_single_line_comments', './repos/sqlparse\\tests\\test_parse.py::test_names_and_special_names', './repos/sqlparse\\tests\\test_parse.py::test_get_token_at_offset', './repos/sqlparse\\tests\\test_parse.py::test_pprint', './repos/sqlparse\\tests\\test_parse.py::test_wildcard_multiplication', './repos/sqlparse\\tests\\test_parse.py::test_stmt_tokens_parents', './repos/sqlparse\\tests\\test_parse.py::test_dbldollar_as_literal', './repos/sqlparse\\tests\\test_parse.py::test_non_ascii', './repos/sqlparse\\tests\\test_parse.py::test_get_real_name', './repos/sqlparse\\tests\\test_parse.py::test_from_subquery', './repos/sqlparse\\tests\\test_parse.py::test_parenthesis', './repos/sqlparse\\tests\\test_parse.py::test_configurable_keywords', './repos/sqlparse\\tests\\test_parse.py::test_configurable_regex', './repos/sqlparse\\tests\\test_parse.py::test_json_operators', './repos/sqlparse\\tests\\test_regressions.py::test_issue9', './repos/sqlparse\\tests\\test_regressions.py::test_issue13', './repos/sqlparse\\tests\\test_regressions.py::test_issue26', './repos/sqlparse\\tests\\test_regressions.py::test_issue34', './repos/sqlparse\\tests\\test_regressions.py::test_issue35', './repos/sqlparse\\tests\\test_regressions.py::test_issue38', './repos/sqlparse\\tests\\test_regressions.py::test_issue39', './repos/sqlparse\\tests\\test_regressions.py::test_issue40', './repos/sqlparse\\tests\\test_regressions.py::test_issue78', './repos/sqlparse\\tests\\test_regressions.py::test_issue83', './repos/sqlparse\\tests\\test_regressions.py::test_comment_encoding_when_reindent', './repos/sqlparse\\tests\\test_regressions.py::test_parse_sql_with_binary', './repos/sqlparse\\tests\\test_regressions.py::test_dont_alias_keywords', './repos/sqlparse\\tests\\test_regressions.py::test_format_accepts_encoding', './repos/sqlparse\\tests\\test_regressions.py::test_stream', './repos/sqlparse\\tests\\test_regressions.py::test_issue90', './repos/sqlparse\\tests\\test_regressions.py::test_except_formatting', './repos/sqlparse\\tests\\test_regressions.py::test_null_with_as', './repos/sqlparse\\tests\\test_regressions.py::test_issue190_open_file', './repos/sqlparse\\tests\\test_regressions.py::test_issue193_splitting_function', './repos/sqlparse\\tests\\test_regressions.py::test_issue194_splitting_function', './repos/sqlparse\\tests\\test_regressions.py::test_issue186_get_type', './repos/sqlparse\\tests\\test_regressions.py::test_issue212_py2unicode', './repos/sqlparse\\tests\\test_regressions.py::test_issue213_leadingws', './repos/sqlparse\\tests\\test_regressions.py::test_issue227_gettype_cte', './repos/sqlparse\\tests\\test_regressions.py::test_issue207_runaway_format', './repos/sqlparse\\tests\\test_regressions.py::test_token_next_doesnt_ignore_skip_cm', './repos/sqlparse\\tests\\test_regressions.py::test_issue284_as_grouping', './repos/sqlparse\\tests\\test_regressions.py::test_issue315_utf8_by_default', './repos/sqlparse\\tests\\test_regressions.py::test_issue322_concurrently_is_keyword', './repos/sqlparse\\tests\\test_regressions.py::test_issue359_index_error_assignments', './repos/sqlparse\\tests\\test_regressions.py::test_issue469_copy_as_psql_command', './repos/sqlparse\\tests\\test_regressions.py::test_issue484_comments_and_newlines', './repos/sqlparse\\tests\\test_regressions.py::test_issue485_split_multi', './repos/sqlparse\\tests\\test_regressions.py::test_issue489_tzcasts', './repos/sqlparse\\tests\\test_regressions.py::test_issue562_tzcasts', './repos/sqlparse\\tests\\test_regressions.py::test_as_in_parentheses_indents', './repos/sqlparse\\tests\\test_regressions.py::test_format_invalid_where_clause', './repos/sqlparse\\tests\\test_regressions.py::test_splitting_at_and_backticks_issue588', './repos/sqlparse\\tests\\test_regressions.py::test_comment_between_cte_clauses_issue632', './repos/sqlparse\\tests\\test_regressions.py::test_copy_issue672', './repos/sqlparse\\tests\\test_regressions.py::test_primary_key_issue740', './repos/sqlparse\\tests\\test_regressions.py::test_max_recursion', './repos/sqlparse\\tests\\test_split.py::test_split_semicolon', './repos/sqlparse\\tests\\test_split.py::test_split_backslash', './repos/sqlparse\\tests\\test_split.py::test_split_create_function', './repos/sqlparse\\tests\\test_split.py::test_split_dashcomments', './repos/sqlparse\\tests\\test_split.py::test_split_dashcomments_eol', './repos/sqlparse\\tests\\test_split.py::test_split_begintag', './repos/sqlparse\\tests\\test_split.py::test_split_begintag_2', './repos/sqlparse\\tests\\test_split.py::test_split_dropif', './repos/sqlparse\\tests\\test_split.py::test_split_comment_with_umlaut', './repos/sqlparse\\tests\\test_split.py::test_split_comment_end_of_line', './repos/sqlparse\\tests\\test_split.py::test_split_casewhen', './repos/sqlparse\\tests\\test_split.py::test_split_casewhen_procedure', './repos/sqlparse\\tests\\test_split.py::test_split_cursor_declare', './repos/sqlparse\\tests\\test_split.py::test_split_if_function', './repos/sqlparse\\tests\\test_split.py::test_split_stream', './repos/sqlparse\\tests\\test_split.py::test_split_encoding_parsestream', './repos/sqlparse\\tests\\test_split.py::test_split_unicode_parsestream', './repos/sqlparse\\tests\\test_split.py::test_split_simple', './repos/sqlparse\\tests\\test_split.py::test_split_ignores_empty_newlines', './repos/sqlparse\\tests\\test_split.py::test_split_quotes_with_new_line', './repos/sqlparse\\tests\\test_split.py::test_split_mysql_handler_for', './repos/sqlparse\\tests\\test_split.py::test_split_strip_semicolon', './repos/sqlparse\\tests\\test_split.py::test_split_strip_semicolon_procedure', './repos/sqlparse\\tests\\test_split.py::test_split_go', './repos/sqlparse\\tests\\test_split.py::test_split_multiple_case_in_begin', './repos/sqlparse\\tests\\test_tokenize.py::test_tokenize_simple', './repos/sqlparse\\tests\\test_tokenize.py::test_tokenize_backticks', './repos/sqlparse\\tests\\test_tokenize.py::test_tokenize_linebreaks', './repos/sqlparse\\tests\\test_tokenize.py::test_tokenize_inline_keywords', './repos/sqlparse\\tests\\test_tokenize.py::test_tokenize_negative_numbers', './repos/sqlparse\\tests\\test_tokenize.py::test_token_str', './repos/sqlparse\\tests\\test_tokenize.py::test_token_repr', './repos/sqlparse\\tests\\test_tokenize.py::test_token_flatten', './repos/sqlparse\\tests\\test_tokenize.py::test_tokenlist_repr', './repos/sqlparse\\tests\\test_tokenize.py::test_single_quotes', './repos/sqlparse\\tests\\test_tokenize.py::test_tokenlist_first', './repos/sqlparse\\tests\\test_tokenize.py::test_tokenlist_token_matching', './repos/sqlparse\\tests\\test_tokenize.py::test_stream_simple', './repos/sqlparse\\tests\\test_tokenize.py::test_stream_error', './repos/sqlparse\\tests\\test_tokenize.py::test_parse_join', './repos/sqlparse\\tests\\test_tokenize.py::test_parse_union', './repos/sqlparse\\tests\\test_tokenize.py::test_parse_endifloop', './repos/sqlparse\\tests\\test_tokenize.py::test_parse_order', './repos/sqlparse\\tests\\test_tokenize.py::test_parse_identifiers', './repos/sqlparse\\tests\\test_tokenize.py::test_parse_group_by', './repos/sqlparse\\tests\\test_tokenize.py::test_parse_order_by', './repos/sqlparse\\tests\\test_tokenize.py::test_parse_window_as', './repos/sqlparse\\tests\\test_tokenize.py::test_like_and_ilike_parsed_as_comparisons', './repos/sqlparse\\tests\\test_tokenize.py::test_near_like_and_ilike_parsed_appropriately', './repos/sqlparse\\tests\\test_tokenize.py::test_parse_tzcast', './repos/sqlparse\\tests\\test_tokenize.py::test_cli_commands', './repos/sqlparse\\tests\\test_utils.py::test_remove_quotes']","395 Passed, 66 Failed",395,66,"['tests/test_cli.py::test_valid_args', 'tests/test_format.py::TestFormat::test_keywordcase', 'tests/test_format.py::TestFormat::test_identifiercase', 'tests/test_format.py::TestFormat::test_strip_comments_single', 'tests/test_format.py::TestFormat::test_strip_comments_multi', 'tests/test_format.py::TestFormat::test_strip_comments_preserves_linebreak', 'tests/test_format.py::TestFormat::test_strip_comments_preserves_whitespace', 'tests/test_format.py::TestFormat::test_strip_comments_preserves_hint', 'tests/test_format.py::TestFormat::test_strip_ws', 'tests/test_format.py::TestFormat::test_preserve_ws', 'tests/test_format.py::TestFormatReindentAligned::test_basic', 'tests/test_format.py::TestFormatReindentAligned::test_joins', 'tests/test_format.py::TestFormatReindentAligned::test_case_statement', 'tests/test_format.py::TestFormatReindentAligned::test_case_statement_with_between', 'tests/test_format.py::TestFormatReindentAligned::test_group_by', 'tests/test_format.py::TestFormatReindentAligned::test_group_by_subquery', 'tests/test_format.py::TestFormatReindentAligned::test_window_functions', 'tests/test_format.py::TestSpacesAroundOperators::test_basic', 'tests/test_format.py::TestSpacesAroundOperators::test_bools', 'tests/test_format.py::TestSpacesAroundOperators::test_nested', 'tests/test_format.py::TestSpacesAroundOperators::test_wildcard_vs_mult', 'tests/test_format.py::TestFormatReindent::test_stmts', 'tests/test_format.py::TestFormatReindent::test_keywords', 'tests/test_format.py::TestFormatReindent::test_keywords_between', 'tests/test_format.py::TestFormatReindent::test_parenthesis', 'tests/test_format.py::TestFormatReindent::test_where', 'tests/test_format.py::TestFormatReindent::test_join', 'tests/test_format.py::TestFormatReindent::test_identifier_list', 'tests/test_format.py::TestFormatReindent::test_identifier_list_with_wrap_after', 'tests/test_format.py::TestFormatReindent::test_identifier_list_comment_first', 'tests/test_format.py::TestFormatReindent::test_identifier_list_with_functions', 'tests/test_format.py::TestFormatReindent::test_long_identifier_list_with_functions', 'tests/test_format.py::TestFormatReindent::test_case', 'tests/test_format.py::TestFormatReindent::test_case2', 'tests/test_format.py::TestFormatReindent::test_nested_identifier_list', 'tests/test_format.py::TestFormatReindent::test_duplicate_linebreaks', 'tests/test_format.py::TestFormatReindent::test_keywordfunctions', 'tests/test_format.py::TestFormatReindent::test_identifier_and_functions', 'tests/test_format.py::TestFormatReindent::test_insert_values', 'tests/test_format.py::TestOutputFormat::test_python', 'tests/test_format.py::TestOutputFormat::test_python_multiple_statements', 'tests/test_format.py::TestOutputFormat::test_php', 'tests/test_format.py::test_format_column_ordering', 'tests/test_format.py::test_truncate_strings', 'tests/test_format.py::test_having_produces_newline', 'tests/test_format.py::test_format_json_ops', 'tests/test_format.py::test_compact[case when foo then 1 else bar end-case\\n    when foo then 1\\n    else bar\\nend-case when foo then 1 else bar end]', 'tests/test_format.py::test_strip_ws_removes_trailing_ws_in_groups', 'tests/test_regressions.py::test_issue35', 'tests/test_regressions.py::test_issue38', 'tests/test_regressions.py::test_issue40', 'tests/test_regressions.py::test_comment_encoding_when_reindent', 'tests/test_regressions.py::test_parse_sql_with_binary', 'tests/test_regressions.py::test_format_accepts_encoding', 'tests/test_regressions.py::test_issue90', 'tests/test_regressions.py::test_except_formatting', 'tests/test_regressions.py::test_null_with_as', 'tests/test_regressions.py::test_issue213_leadingws', 'tests/test_regressions.py::test_issue207_runaway_format', 'tests/test_regressions.py::test_issue315_utf8_by_default', 'tests/test_regressions.py::test_issue359_index_error_assignments[SELECT @min_price:=MIN(price), @max_price:=MAX(price) FROM shop;]', 'tests/test_regressions.py::test_issue359_index_error_assignments[SELECT @min_price:=MIN(price), @max_price:=MAX(price) FROM shop]', 'tests/test_regressions.py::test_issue469_copy_as_psql_command', 'tests/test_regressions.py::test_issue562_tzcasts', 'tests/test_regressions.py::test_as_in_parentheses_indents', 'tests/test_regressions.py::test_format_invalid_where_clause']","[""filepath = <function filepath.<locals>.make_filepath at 0x0000025AB4FFE660>\n\n    def test_valid_args(filepath):\n        # test doesn't abort\n        path = filepath('function.sql')\n>       assert sqlparse.cli.main([path, '-r']) is not None\n\nrepos\\sqlparse\\tests\\test_cli.py:30: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\cli.py:198: in main\n    s = sqlparse.format(data, **formatter_opts)\nrepos\\sqlparse\\sqlparse\\__init__.py:57: in format\n    stack = formatter.build_filter_stack(stack, options)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nstack = <sqlparse.engine.filter_stack.FilterStack object at 0x0000025AB46AEBA0>\noptions = {'comma_first': False, 'compact': False, 'filename': 'C:\\\\Users\\\\serine.sefardjelah\\\\OneDrive\\\\travail_PFE\\\\clean\\\\repos\\\\sqlparse\\\\tests\\\\files\\\\function.sql', 'identifier_case': None, ...}\n\n    def build_filter_stack(stack, options):\n        if options.get('keyword_case') == 'uppercase':\n            stack.append(uppercase_keyword_filter)\n        elif options.get('keyword_case') == 'lowercase':\n            stack.append(lowercase_keyword_filter)\n        if options.get('identifier_case') == 'uppercase':\n            stack.append(uppercase_identifier_filter)\n        elif options.get('identifier_case') == 'lowercase':\n            stack.append(lowercase_identifier_filter)\n        if options.get('string_truncation'):\n            stack.append(string_truncation_filter)\n        if options.get('spacing_around_operators'):\n            stack.append(spacing_around_operators_filter)\n        if options.get('strip_comments'):\n            stack.append(strip_comments_filter)\n        if options.get('strip_whitespace'):\n>           stack.append(strip_whitespace_filter)\nE           AttributeError: 'FilterStack' object has no attribute 'append'\n\nrepos\\sqlparse\\sqlparse\\formatter.py:113: AttributeError"", ""self = <tests.test_format.TestFormat object at 0x0000025AB4CBA210>\n\n    def test_keywordcase(self):\n        sql = 'select * from bar; -- select foo\\n'\n        res = sqlparse.format(sql, keyword_case='upper')\n>       assert res == 'SELECT * FROM bar; -- select foo\\n'\nE       AssertionError: assert 'select * fro... select foo\\n' == 'SELECT * FRO... select foo\\n'\nE         \nE         - SELECT * FROM bar; -- select foo\nE         + select * from bar; -- select foo\n\nrepos\\sqlparse\\tests\\test_format.py:11: AssertionError"", ""self = <tests.test_format.TestFormat object at 0x0000025AB4CA6FD0>\n\n    def test_identifiercase(self):\n        sql = 'select * from bar; -- select foo\\n'\n        res = sqlparse.format(sql, identifier_case='upper')\n>       assert res == 'select * from BAR; -- select foo\\n'\nE       AssertionError: assert 'select * fro... select foo\\n' == 'select * fro... select foo\\n'\nE         \nE         - select * from BAR; -- select foo\nE         ?               ^^^\nE         + select * from bar; -- select foo\nE         ?               ^^^\n\nrepos\\sqlparse\\tests\\test_format.py:25: AssertionError"", ""self = <tests.test_format.TestFormat object at 0x0000025AB4C9BCE0>\n\n    def test_strip_comments_single(self):\n        sql = 'select *-- statement starts here\\nfrom foo'\n>       res = sqlparse.format(sql, strip_comments=True)\n\nrepos\\sqlparse\\tests\\test_format.py:43: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:57: in format\n    stack = formatter.build_filter_stack(stack, options)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nstack = <sqlparse.engine.filter_stack.FilterStack object at 0x0000025AB4F391D0>\noptions = {'comma_first': False, 'compact': False, 'indent_after_first': False, 'indent_char': ' ', ...}\n\n    def build_filter_stack(stack, options):\n        if options.get('keyword_case') == 'uppercase':\n            stack.append(uppercase_keyword_filter)\n        elif options.get('keyword_case') == 'lowercase':\n            stack.append(lowercase_keyword_filter)\n        if options.get('identifier_case') == 'uppercase':\n            stack.append(uppercase_identifier_filter)\n        elif options.get('identifier_case') == 'lowercase':\n            stack.append(lowercase_identifier_filter)\n        if options.get('string_truncation'):\n            stack.append(string_truncation_filter)\n        if options.get('spacing_around_operators'):\n            stack.append(spacing_around_operators_filter)\n        if options.get('strip_comments'):\n>           stack.append(strip_comments_filter)\nE           AttributeError: 'FilterStack' object has no attribute 'append'\n\nrepos\\sqlparse\\sqlparse\\formatter.py:111: AttributeError"", ""self = <tests.test_format.TestFormat object at 0x0000025AB4E28A50>\n\n    def test_strip_comments_multi(self):\n        sql = '/* sql starts here */\\nselect'\n>       res = sqlparse.format(sql, strip_comments=True)\n\nrepos\\sqlparse\\tests\\test_format.py:72: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:57: in format\n    stack = formatter.build_filter_stack(stack, options)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nstack = <sqlparse.engine.filter_stack.FilterStack object at 0x0000025AB4F3A210>\noptions = {'comma_first': False, 'compact': False, 'indent_after_first': False, 'indent_char': ' ', ...}\n\n    def build_filter_stack(stack, options):\n        if options.get('keyword_case') == 'uppercase':\n            stack.append(uppercase_keyword_filter)\n        elif options.get('keyword_case') == 'lowercase':\n            stack.append(lowercase_keyword_filter)\n        if options.get('identifier_case') == 'uppercase':\n            stack.append(uppercase_identifier_filter)\n        elif options.get('identifier_case') == 'lowercase':\n            stack.append(lowercase_identifier_filter)\n        if options.get('string_truncation'):\n            stack.append(string_truncation_filter)\n        if options.get('spacing_around_operators'):\n            stack.append(spacing_around_operators_filter)\n        if options.get('strip_comments'):\n>           stack.append(strip_comments_filter)\nE           AttributeError: 'FilterStack' object has no attribute 'append'\n\nrepos\\sqlparse\\sqlparse\\formatter.py:111: AttributeError"", ""self = <tests.test_format.TestFormat object at 0x0000025AB4E28B50>\n\n    def test_strip_comments_preserves_linebreak(self):\n        sql = 'select * -- a comment\\r\\nfrom foo'\n>       res = sqlparse.format(sql, strip_comments=True)\n\nrepos\\sqlparse\\tests\\test_format.py:89: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:57: in format\n    stack = formatter.build_filter_stack(stack, options)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nstack = <sqlparse.engine.filter_stack.FilterStack object at 0x0000025AB4F3A350>\noptions = {'comma_first': False, 'compact': False, 'indent_after_first': False, 'indent_char': ' ', ...}\n\n    def build_filter_stack(stack, options):\n        if options.get('keyword_case') == 'uppercase':\n            stack.append(uppercase_keyword_filter)\n        elif options.get('keyword_case') == 'lowercase':\n            stack.append(lowercase_keyword_filter)\n        if options.get('identifier_case') == 'uppercase':\n            stack.append(uppercase_identifier_filter)\n        elif options.get('identifier_case') == 'lowercase':\n            stack.append(lowercase_identifier_filter)\n        if options.get('string_truncation'):\n            stack.append(string_truncation_filter)\n        if options.get('spacing_around_operators'):\n            stack.append(spacing_around_operators_filter)\n        if options.get('strip_comments'):\n>           stack.append(strip_comments_filter)\nE           AttributeError: 'FilterStack' object has no attribute 'append'\n\nrepos\\sqlparse\\sqlparse\\formatter.py:111: AttributeError"", ""self = <tests.test_format.TestFormat object at 0x0000025AB4D6E3F0>\n\n    def test_strip_comments_preserves_whitespace(self):\n        sql = 'SELECT 1/*bar*/ AS foo'  # see issue772\n>       res = sqlparse.format(sql, strip_comments=True)\n\nrepos\\sqlparse\\tests\\test_format.py:106: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:57: in format\n    stack = formatter.build_filter_stack(stack, options)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nstack = <sqlparse.engine.filter_stack.FilterStack object at 0x0000025AB4F3A5D0>\noptions = {'comma_first': False, 'compact': False, 'indent_after_first': False, 'indent_char': ' ', ...}\n\n    def build_filter_stack(stack, options):\n        if options.get('keyword_case') == 'uppercase':\n            stack.append(uppercase_keyword_filter)\n        elif options.get('keyword_case') == 'lowercase':\n            stack.append(lowercase_keyword_filter)\n        if options.get('identifier_case') == 'uppercase':\n            stack.append(uppercase_identifier_filter)\n        elif options.get('identifier_case') == 'lowercase':\n            stack.append(lowercase_identifier_filter)\n        if options.get('string_truncation'):\n            stack.append(string_truncation_filter)\n        if options.get('spacing_around_operators'):\n            stack.append(spacing_around_operators_filter)\n        if options.get('strip_comments'):\n>           stack.append(strip_comments_filter)\nE           AttributeError: 'FilterStack' object has no attribute 'append'\n\nrepos\\sqlparse\\sqlparse\\formatter.py:111: AttributeError"", ""self = <tests.test_format.TestFormat object at 0x0000025AB4D6E4E0>\n\n    def test_strip_comments_preserves_hint(self):\n        sql = 'select --+full(u)'\n>       res = sqlparse.format(sql, strip_comments=True)\n\nrepos\\sqlparse\\tests\\test_format.py:111: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:57: in format\n    stack = formatter.build_filter_stack(stack, options)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nstack = <sqlparse.engine.filter_stack.FilterStack object at 0x0000025AB4F3A210>\noptions = {'comma_first': False, 'compact': False, 'indent_after_first': False, 'indent_char': ' ', ...}\n\n    def build_filter_stack(stack, options):\n        if options.get('keyword_case') == 'uppercase':\n            stack.append(uppercase_keyword_filter)\n        elif options.get('keyword_case') == 'lowercase':\n            stack.append(lowercase_keyword_filter)\n        if options.get('identifier_case') == 'uppercase':\n            stack.append(uppercase_identifier_filter)\n        elif options.get('identifier_case') == 'lowercase':\n            stack.append(lowercase_identifier_filter)\n        if options.get('string_truncation'):\n            stack.append(string_truncation_filter)\n        if options.get('spacing_around_operators'):\n            stack.append(spacing_around_operators_filter)\n        if options.get('strip_comments'):\n>           stack.append(strip_comments_filter)\nE           AttributeError: 'FilterStack' object has no attribute 'append'\n\nrepos\\sqlparse\\sqlparse\\formatter.py:111: AttributeError"", ""self = <tests.test_format.TestFormat object at 0x0000025AB4E40830>\n\n    def test_strip_ws(self):\n        f = lambda sql: sqlparse.format(sql, strip_whitespace=True)\n        s = 'select\\n* from      foo\\n\\twhere  ( 1 = 2 )\\n'\n>       assert f(s) == 'select * from foo where (1 = 2)'\n\nrepos\\sqlparse\\tests\\test_format.py:132: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:130: in <lambda>\n    f = lambda sql: sqlparse.format(sql, strip_whitespace=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:57: in format\n    stack = formatter.build_filter_stack(stack, options)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nstack = <sqlparse.engine.filter_stack.FilterStack object at 0x0000025AB4F3A350>\noptions = {'comma_first': False, 'compact': False, 'indent_after_first': False, 'indent_char': ' ', ...}\n\n    def build_filter_stack(stack, options):\n        if options.get('keyword_case') == 'uppercase':\n            stack.append(uppercase_keyword_filter)\n        elif options.get('keyword_case') == 'lowercase':\n            stack.append(lowercase_keyword_filter)\n        if options.get('identifier_case') == 'uppercase':\n            stack.append(uppercase_identifier_filter)\n        elif options.get('identifier_case') == 'lowercase':\n            stack.append(lowercase_identifier_filter)\n        if options.get('string_truncation'):\n            stack.append(string_truncation_filter)\n        if options.get('spacing_around_operators'):\n            stack.append(spacing_around_operators_filter)\n        if options.get('strip_comments'):\n            stack.append(strip_comments_filter)\n        if options.get('strip_whitespace'):\n>           stack.append(strip_whitespace_filter)\nE           AttributeError: 'FilterStack' object has no attribute 'append'\n\nrepos\\sqlparse\\sqlparse\\formatter.py:113: AttributeError"", ""self = <tests.test_format.TestFormat object at 0x0000025AB4DE5570>\n\n    def test_preserve_ws(self):\n        # preserve at least one whitespace after subgroups\n        f = lambda sql: sqlparse.format(sql, strip_whitespace=True)\n        s = 'select\\n* /* foo */  from bar '\n>       assert f(s) == 'select * /* foo */ from bar'\n\nrepos\\sqlparse\\tests\\test_format.py:145: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:143: in <lambda>\n    f = lambda sql: sqlparse.format(sql, strip_whitespace=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:57: in format\n    stack = formatter.build_filter_stack(stack, options)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nstack = <sqlparse.engine.filter_stack.FilterStack object at 0x0000025AB4F3A490>\noptions = {'comma_first': False, 'compact': False, 'indent_after_first': False, 'indent_char': ' ', ...}\n\n    def build_filter_stack(stack, options):\n        if options.get('keyword_case') == 'uppercase':\n            stack.append(uppercase_keyword_filter)\n        elif options.get('keyword_case') == 'lowercase':\n            stack.append(lowercase_keyword_filter)\n        if options.get('identifier_case') == 'uppercase':\n            stack.append(uppercase_identifier_filter)\n        elif options.get('identifier_case') == 'lowercase':\n            stack.append(lowercase_identifier_filter)\n        if options.get('string_truncation'):\n            stack.append(string_truncation_filter)\n        if options.get('spacing_around_operators'):\n            stack.append(spacing_around_operators_filter)\n        if options.get('strip_comments'):\n            stack.append(strip_comments_filter)\n        if options.get('strip_whitespace'):\n>           stack.append(strip_whitespace_filter)\nE           AttributeError: 'FilterStack' object has no attribute 'append'\n\nrepos\\sqlparse\\sqlparse\\formatter.py:113: AttributeError"", 'self = <tests.test_format.TestFormatReindentAligned object at 0x0000025AB4CBA990>\n\n    def test_basic(self):\n        sql = """"""\n            select a, b as bb,c from table\n            join (select a * 2 as a from new_table) other\n            on table.a = other.a\n            where c is true\n            and b between 3 and 4\n            or d is \'blue\'\n            limit 10\n            """"""\n    \n>       assert self.formatter(sql) == \'\\n\'.join([\n            \'select a,\',\n            \'       b as bb,\',\n            \'       c\',\n            \'  from table\',\n            \'  join (\',\n            \'        select a * 2 as a\',\n            \'          from new_table\',\n            \'       ) other\',\n            \'    on table.a = other.a\',\n            \' where c is true\',\n            \'   and b between 3 and 4\',\n            ""    or d is \'blue\'"",\n            \' limit 10\'])\n\nrepos\\sqlparse\\tests\\test_format.py:182: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:169: in formatter\n    return sqlparse.format(sql, reindent_aligned=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:57: in format\n    stack = formatter.build_filter_stack(stack, options)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nstack = <sqlparse.engine.filter_stack.FilterStack object at 0x0000025AB4F39A90>\noptions = {\'comma_first\': False, \'compact\': False, \'indent_after_first\': False, \'indent_char\': \' \', ...}\n\n    def build_filter_stack(stack, options):\n        if options.get(\'keyword_case\') == \'uppercase\':\n            stack.append(uppercase_keyword_filter)\n        elif options.get(\'keyword_case\') == \'lowercase\':\n            stack.append(lowercase_keyword_filter)\n        if options.get(\'identifier_case\') == \'uppercase\':\n            stack.append(uppercase_identifier_filter)\n        elif options.get(\'identifier_case\') == \'lowercase\':\n            stack.append(lowercase_identifier_filter)\n        if options.get(\'string_truncation\'):\n            stack.append(string_truncation_filter)\n        if options.get(\'spacing_around_operators\'):\n            stack.append(spacing_around_operators_filter)\n        if options.get(\'strip_comments\'):\n            stack.append(strip_comments_filter)\n        if options.get(\'strip_whitespace\'):\n>           stack.append(strip_whitespace_filter)\nE           AttributeError: \'FilterStack\' object has no attribute \'append\'\n\nrepos\\sqlparse\\sqlparse\\formatter.py:113: AttributeError', 'self = <tests.test_format.TestFormatReindentAligned object at 0x0000025AB4CB9E50>\n\n    def test_joins(self):\n        sql = """"""\n            select * from a\n            join b on a.one = b.one\n            left join c on c.two = a.two and c.three = a.three\n            full outer join d on d.three = a.three\n            cross join e on e.four = a.four\n            join f using (one, two, three)\n            """"""\n>       assert self.formatter(sql) == \'\\n\'.join([\n            \'select *\',\n            \'  from a\',\n            \'  join b\',\n            \'    on a.one = b.one\',\n            \'  left join c\',\n            \'    on c.two = a.two\',\n            \'   and c.three = a.three\',\n            \'  full outer join d\',\n            \'    on d.three = a.three\',\n            \' cross join e\',\n            \'    on e.four = a.four\',\n            \'  join f using (one, two, three)\'])\n\nrepos\\sqlparse\\tests\\test_format.py:206: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:169: in formatter\n    return sqlparse.format(sql, reindent_aligned=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:57: in format\n    stack = formatter.build_filter_stack(stack, options)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nstack = <sqlparse.engine.filter_stack.FilterStack object at 0x0000025AB4F39450>\noptions = {\'comma_first\': False, \'compact\': False, \'indent_after_first\': False, \'indent_char\': \' \', ...}\n\n    def build_filter_stack(stack, options):\n        if options.get(\'keyword_case\') == \'uppercase\':\n            stack.append(uppercase_keyword_filter)\n        elif options.get(\'keyword_case\') == \'lowercase\':\n            stack.append(lowercase_keyword_filter)\n        if options.get(\'identifier_case\') == \'uppercase\':\n            stack.append(uppercase_identifier_filter)\n        elif options.get(\'identifier_case\') == \'lowercase\':\n            stack.append(lowercase_identifier_filter)\n        if options.get(\'string_truncation\'):\n            stack.append(string_truncation_filter)\n        if options.get(\'spacing_around_operators\'):\n            stack.append(spacing_around_operators_filter)\n        if options.get(\'strip_comments\'):\n            stack.append(strip_comments_filter)\n        if options.get(\'strip_whitespace\'):\n>           stack.append(strip_whitespace_filter)\nE           AttributeError: \'FilterStack\' object has no attribute \'append\'\n\nrepos\\sqlparse\\sqlparse\\formatter.py:113: AttributeError', 'self = <tests.test_format.TestFormatReindentAligned object at 0x0000025AB4CA7CE0>\n\n    def test_case_statement(self):\n        sql = """"""\n            select a,\n            case when a = 0\n            then 1\n            when bb = 1 then 1\n            when c = 2 then 2\n            else 0 end as d,\n            extra_col\n            from table\n            where c is true\n            and b between 3 and 4\n            """"""\n>       assert self.formatter(sql) == \'\\n\'.join([\n            \'select a,\',\n            \'       case when a = 0  then 1\',\n            \'            when bb = 1 then 1\',\n            \'            when c = 2  then 2\',\n            \'            else 0\',\n            \'             end as d,\',\n            \'       extra_col\',\n            \'  from table\',\n            \' where c is true\',\n            \'   and b between 3 and 4\'])\n\nrepos\\sqlparse\\tests\\test_format.py:233: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:169: in formatter\n    return sqlparse.format(sql, reindent_aligned=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:57: in format\n    stack = formatter.build_filter_stack(stack, options)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nstack = <sqlparse.engine.filter_stack.FilterStack object at 0x0000025AB4F39F90>\noptions = {\'comma_first\': False, \'compact\': False, \'indent_after_first\': False, \'indent_char\': \' \', ...}\n\n    def build_filter_stack(stack, options):\n        if options.get(\'keyword_case\') == \'uppercase\':\n            stack.append(uppercase_keyword_filter)\n        elif options.get(\'keyword_case\') == \'lowercase\':\n            stack.append(lowercase_keyword_filter)\n        if options.get(\'identifier_case\') == \'uppercase\':\n            stack.append(uppercase_identifier_filter)\n        elif options.get(\'identifier_case\') == \'lowercase\':\n            stack.append(lowercase_identifier_filter)\n        if options.get(\'string_truncation\'):\n            stack.append(string_truncation_filter)\n        if options.get(\'spacing_around_operators\'):\n            stack.append(spacing_around_operators_filter)\n        if options.get(\'strip_comments\'):\n            stack.append(strip_comments_filter)\n        if options.get(\'strip_whitespace\'):\n>           stack.append(strip_whitespace_filter)\nE           AttributeError: \'FilterStack\' object has no attribute \'append\'\n\nrepos\\sqlparse\\sqlparse\\formatter.py:113: AttributeError', 'self = <tests.test_format.TestFormatReindentAligned object at 0x0000025AB4CA7BB0>\n\n    def test_case_statement_with_between(self):\n        sql = """"""\n            select a,\n            case when a = 0\n            then 1\n            when bb = 1 then 1\n            when c = 2 then 2\n            when d between 3 and 5 then 3\n            else 0 end as d,\n            extra_col\n            from table\n            where c is true\n            and b between 3 and 4\n            """"""\n>       assert self.formatter(sql) == \'\\n\'.join([\n            \'select a,\',\n            \'       case when a = 0             then 1\',\n            \'            when bb = 1            then 1\',\n            \'            when c = 2             then 2\',\n            \'            when d between 3 and 5 then 3\',\n            \'            else 0\',\n            \'             end as d,\',\n            \'       extra_col\',\n            \'  from table\',\n            \' where c is true\',\n            \'   and b between 3 and 4\'])\n\nrepos\\sqlparse\\tests\\test_format.py:259: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:169: in formatter\n    return sqlparse.format(sql, reindent_aligned=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:57: in format\n    stack = formatter.build_filter_stack(stack, options)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nstack = <sqlparse.engine.filter_stack.FilterStack object at 0x0000025AB4F3AAD0>\noptions = {\'comma_first\': False, \'compact\': False, \'indent_after_first\': False, \'indent_char\': \' \', ...}\n\n    def build_filter_stack(stack, options):\n        if options.get(\'keyword_case\') == \'uppercase\':\n            stack.append(uppercase_keyword_filter)\n        elif options.get(\'keyword_case\') == \'lowercase\':\n            stack.append(lowercase_keyword_filter)\n        if options.get(\'identifier_case\') == \'uppercase\':\n            stack.append(uppercase_identifier_filter)\n        elif options.get(\'identifier_case\') == \'lowercase\':\n            stack.append(lowercase_identifier_filter)\n        if options.get(\'string_truncation\'):\n            stack.append(string_truncation_filter)\n        if options.get(\'spacing_around_operators\'):\n            stack.append(spacing_around_operators_filter)\n        if options.get(\'strip_comments\'):\n            stack.append(strip_comments_filter)\n        if options.get(\'strip_whitespace\'):\n>           stack.append(strip_whitespace_filter)\nE           AttributeError: \'FilterStack\' object has no attribute \'append\'\n\nrepos\\sqlparse\\sqlparse\\formatter.py:113: AttributeError', 'self = <tests.test_format.TestFormatReindentAligned object at 0x0000025AB4E3A7B0>\n\n    def test_group_by(self):\n        sql = """"""\n            select a, b, c, sum(x) as sum_x, count(y) as cnt_y\n            from table\n            group by a,b,c\n            having sum(x) > 1\n            and count(y) > 5\n            order by 3,2,1\n            """"""\n>       assert self.formatter(sql) == \'\\n\'.join([\n            \'select a,\',\n            \'       b,\',\n            \'       c,\',\n            \'       sum(x) as sum_x,\',\n            \'       count(y) as cnt_y\',\n            \'  from table\',\n            \' group by a,\',\n            \'          b,\',\n            \'          c\',\n            \'having sum(x) > 1\',\n            \'   and count(y) > 5\',\n            \' order by 3,\',\n            \'          2,\',\n            \'          1\'])\n\nrepos\\sqlparse\\tests\\test_format.py:281: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:169: in formatter\n    return sqlparse.format(sql, reindent_aligned=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:57: in format\n    stack = formatter.build_filter_stack(stack, options)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nstack = <sqlparse.engine.filter_stack.FilterStack object at 0x0000025AB4F39450>\noptions = {\'comma_first\': False, \'compact\': False, \'indent_after_first\': False, \'indent_char\': \' \', ...}\n\n    def build_filter_stack(stack, options):\n        if options.get(\'keyword_case\') == \'uppercase\':\n            stack.append(uppercase_keyword_filter)\n        elif options.get(\'keyword_case\') == \'lowercase\':\n            stack.append(lowercase_keyword_filter)\n        if options.get(\'identifier_case\') == \'uppercase\':\n            stack.append(uppercase_identifier_filter)\n        elif options.get(\'identifier_case\') == \'lowercase\':\n            stack.append(lowercase_identifier_filter)\n        if options.get(\'string_truncation\'):\n            stack.append(string_truncation_filter)\n        if options.get(\'spacing_around_operators\'):\n            stack.append(spacing_around_operators_filter)\n        if options.get(\'strip_comments\'):\n            stack.append(strip_comments_filter)\n        if options.get(\'strip_whitespace\'):\n>           stack.append(strip_whitespace_filter)\nE           AttributeError: \'FilterStack\' object has no attribute \'append\'\n\nrepos\\sqlparse\\sqlparse\\formatter.py:113: AttributeError', 'self = <tests.test_format.TestFormatReindentAligned object at 0x0000025AB4C9B790>\n\n    def test_group_by_subquery(self):\n        # TODO: add subquery alias when test_identifier_list_subquery fixed\n        sql = """"""\n            select *, sum_b + 2 as mod_sum\n            from (\n              select a, sum(b) as sum_b\n              from table\n              group by a,z)\n            order by 1,2\n            """"""\n>       assert self.formatter(sql) == \'\\n\'.join([\n            \'select *,\',\n            \'       sum_b + 2 as mod_sum\',\n            \'  from (\',\n            \'        select a,\',\n            \'               sum(b) as sum_b\',\n            \'          from table\',\n            \'         group by a,\',\n            \'                  z\',\n            \'       )\',\n            \' order by 1,\',\n            \'          2\'])\n\nrepos\\sqlparse\\tests\\test_format.py:307: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:169: in formatter\n    return sqlparse.format(sql, reindent_aligned=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:57: in format\n    stack = formatter.build_filter_stack(stack, options)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nstack = <sqlparse.engine.filter_stack.FilterStack object at 0x0000025AB4F39310>\noptions = {\'comma_first\': False, \'compact\': False, \'indent_after_first\': False, \'indent_char\': \' \', ...}\n\n    def build_filter_stack(stack, options):\n        if options.get(\'keyword_case\') == \'uppercase\':\n            stack.append(uppercase_keyword_filter)\n        elif options.get(\'keyword_case\') == \'lowercase\':\n            stack.append(lowercase_keyword_filter)\n        if options.get(\'identifier_case\') == \'uppercase\':\n            stack.append(uppercase_identifier_filter)\n        elif options.get(\'identifier_case\') == \'lowercase\':\n            stack.append(lowercase_identifier_filter)\n        if options.get(\'string_truncation\'):\n            stack.append(string_truncation_filter)\n        if options.get(\'spacing_around_operators\'):\n            stack.append(spacing_around_operators_filter)\n        if options.get(\'strip_comments\'):\n            stack.append(strip_comments_filter)\n        if options.get(\'strip_whitespace\'):\n>           stack.append(strip_whitespace_filter)\nE           AttributeError: \'FilterStack\' object has no attribute \'append\'\n\nrepos\\sqlparse\\sqlparse\\formatter.py:113: AttributeError', 'self = <tests.test_format.TestFormatReindentAligned object at 0x0000025AB4C9BDF0>\n\n    def test_window_functions(self):\n        sql = """"""\n            select a,\n            SUM(a) OVER (PARTITION BY b ORDER BY c ROWS\n            BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) as sum_a,\n            ROW_NUMBER() OVER\n            (PARTITION BY b, c ORDER BY d DESC) as row_num\n            from table""""""\n>       assert self.formatter(sql) == \'\\n\'.join([\n            \'select a,\',\n            \'       SUM(a) OVER (PARTITION BY b ORDER BY c ROWS \'\n            \'BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) as sum_a,\',\n            \'       ROW_NUMBER() OVER \'\n            \'(PARTITION BY b, c ORDER BY d DESC) as row_num\',\n            \'  from table\'])\n\nrepos\\sqlparse\\tests\\test_format.py:328: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:169: in formatter\n    return sqlparse.format(sql, reindent_aligned=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:57: in format\n    stack = formatter.build_filter_stack(stack, options)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nstack = <sqlparse.engine.filter_stack.FilterStack object at 0x0000025AB4F396D0>\noptions = {\'comma_first\': False, \'compact\': False, \'indent_after_first\': False, \'indent_char\': \' \', ...}\n\n    def build_filter_stack(stack, options):\n        if options.get(\'keyword_case\') == \'uppercase\':\n            stack.append(uppercase_keyword_filter)\n        elif options.get(\'keyword_case\') == \'lowercase\':\n            stack.append(lowercase_keyword_filter)\n        if options.get(\'identifier_case\') == \'uppercase\':\n            stack.append(uppercase_identifier_filter)\n        elif options.get(\'identifier_case\') == \'lowercase\':\n            stack.append(lowercase_identifier_filter)\n        if options.get(\'string_truncation\'):\n            stack.append(string_truncation_filter)\n        if options.get(\'spacing_around_operators\'):\n            stack.append(spacing_around_operators_filter)\n        if options.get(\'strip_comments\'):\n            stack.append(strip_comments_filter)\n        if options.get(\'strip_whitespace\'):\n>           stack.append(strip_whitespace_filter)\nE           AttributeError: \'FilterStack\' object has no attribute \'append\'\n\nrepos\\sqlparse\\sqlparse\\formatter.py:113: AttributeError', ""self = <tests.test_format.TestSpacesAroundOperators object at 0x0000025AB4CBAAD0>\n\n    def test_basic(self):\n        sql = ('select a+b as d from table '\n               'where (c-d)%2= 1 and e> 3.0/4 and z^2 <100')\n>       assert self.formatter(sql) == (\n            'select a + b as d from table '\n            'where (c - d) % 2 = 1 and e > 3.0 / 4 and z ^ 2 < 100')\nE       AssertionError: assert 'select a+b a... and z^2 <100' == 'select a + b...d z ^ 2 < 100'\nE         \nE         - select a + b as d from table where (c - d) % 2 = 1 and e > 3.0 / 4 and z ^ 2 < 100\nE         ?         - -                          - -  - - -         -     - -       - -   -\nE         + select a+b as d from table where (c-d)%2= 1 and e> 3.0/4 and z^2 <100\n\nrepos\\sqlparse\\tests\\test_format.py:345: AssertionError"", ""self = <tests.test_format.TestSpacesAroundOperators object at 0x0000025AB4CBAC10>\n\n    def test_bools(self):\n        sql = 'select * from table where a &&b or c||d'\n>       assert self.formatter(\n            sql) == 'select * from table where a && b or c || d'\nE       AssertionError: assert 'select * fro...a &&b or c||d' == 'select * fro...& b or c || d'\nE         \nE         - select * from table where a && b or c || d\nE         ?                               -      -  -\nE         + select * from table where a &&b or c||d\n\nrepos\\sqlparse\\tests\\test_format.py:351: AssertionError"", ""self = <tests.test_format.TestSpacesAroundOperators object at 0x0000025AB4CA7E10>\n\n    def test_nested(self):\n        sql = 'select *, case when a-b then c end from table'\n>       assert self.formatter(\n            sql) == 'select *, case when a - b then c end from table'\nE       AssertionError: assert 'select *, ca...nd from table' == 'select *, ca...nd from table'\nE         \nE         - select *, case when a - b then c end from table\nE         ?                      - -\nE         + select *, case when a-b then c end from table\n\nrepos\\sqlparse\\tests\\test_format.py:356: AssertionError"", ""self = <tests.test_format.TestSpacesAroundOperators object at 0x0000025AB4E54050>\n\n    def test_wildcard_vs_mult(self):\n        sql = 'select a*b-c from table'\n>       assert self.formatter(sql) == 'select a * b - c from table'\nE       AssertionError: assert 'select a*b-c from table' == 'select a * b - c from table'\nE         \nE         - select a * b - c from table\nE         ?         - - - -\nE         + select a*b-c from table\n\nrepos\\sqlparse\\tests\\test_format.py:361: AssertionError"", ""self = <tests.test_format.TestFormatReindent object at 0x0000025AB4CBAE90>\n\n    def test_stmts(self):\n        f = lambda sql: sqlparse.format(sql, reindent=True)\n        s = 'select foo; select bar'\n>       assert f(s) == 'select foo;\\n\\nselect bar'\n\nrepos\\sqlparse\\tests\\test_format.py:384: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:382: in <lambda>\n    f = lambda sql: sqlparse.format(sql, reindent=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:57: in format\n    stack = formatter.build_filter_stack(stack, options)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nstack = <sqlparse.engine.filter_stack.FilterStack object at 0x0000025AB4F3A850>\noptions = {'comma_first': False, 'compact': False, 'indent_after_first': False, 'indent_char': ' ', ...}\n\n    def build_filter_stack(stack, options):\n        if options.get('keyword_case') == 'uppercase':\n            stack.append(uppercase_keyword_filter)\n        elif options.get('keyword_case') == 'lowercase':\n            stack.append(lowercase_keyword_filter)\n        if options.get('identifier_case') == 'uppercase':\n            stack.append(uppercase_identifier_filter)\n        elif options.get('identifier_case') == 'lowercase':\n            stack.append(lowercase_identifier_filter)\n        if options.get('string_truncation'):\n            stack.append(string_truncation_filter)\n        if options.get('spacing_around_operators'):\n            stack.append(spacing_around_operators_filter)\n        if options.get('strip_comments'):\n            stack.append(strip_comments_filter)\n        if options.get('strip_whitespace'):\n>           stack.append(strip_whitespace_filter)\nE           AttributeError: 'FilterStack' object has no attribute 'append'\n\nrepos\\sqlparse\\sqlparse\\formatter.py:113: AttributeError"", ""self = <tests.test_format.TestFormatReindent object at 0x0000025AB4E54180>\n\n    def test_keywords(self):\n        f = lambda sql: sqlparse.format(sql, reindent=True)\n        s = 'select * from foo union select * from bar;'\n>       assert f(s) == '\\n'.join([\n            'select *',\n            'from foo',\n            'union',\n            'select *',\n            'from bar;'])\n\nrepos\\sqlparse\\tests\\test_format.py:393: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:391: in <lambda>\n    f = lambda sql: sqlparse.format(sql, reindent=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:57: in format\n    stack = formatter.build_filter_stack(stack, options)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nstack = <sqlparse.engine.filter_stack.FilterStack object at 0x0000025AB4F3A210>\noptions = {'comma_first': False, 'compact': False, 'indent_after_first': False, 'indent_char': ' ', ...}\n\n    def build_filter_stack(stack, options):\n        if options.get('keyword_case') == 'uppercase':\n            stack.append(uppercase_keyword_filter)\n        elif options.get('keyword_case') == 'lowercase':\n            stack.append(lowercase_keyword_filter)\n        if options.get('identifier_case') == 'uppercase':\n            stack.append(uppercase_identifier_filter)\n        elif options.get('identifier_case') == 'lowercase':\n            stack.append(lowercase_identifier_filter)\n        if options.get('string_truncation'):\n            stack.append(string_truncation_filter)\n        if options.get('spacing_around_operators'):\n            stack.append(spacing_around_operators_filter)\n        if options.get('strip_comments'):\n            stack.append(strip_comments_filter)\n        if options.get('strip_whitespace'):\n>           stack.append(strip_whitespace_filter)\nE           AttributeError: 'FilterStack' object has no attribute 'append'\n\nrepos\\sqlparse\\sqlparse\\formatter.py:113: AttributeError"", ""self = <tests.test_format.TestFormatReindent object at 0x0000025AB4E542B0>\n\n    def test_keywords_between(self):\n        # issue 14\n        # don't break AND after BETWEEN\n        f = lambda sql: sqlparse.format(sql, reindent=True)\n        s = 'and foo between 1 and 2 and bar = 3'\n>       assert f(s) == '\\n'.join([\n            '',\n            'and foo between 1 and 2',\n            'and bar = 3'])\n\nrepos\\sqlparse\\tests\\test_format.py:405: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:403: in <lambda>\n    f = lambda sql: sqlparse.format(sql, reindent=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:57: in format\n    stack = formatter.build_filter_stack(stack, options)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nstack = <sqlparse.engine.filter_stack.FilterStack object at 0x0000025AB4F39310>\noptions = {'comma_first': False, 'compact': False, 'indent_after_first': False, 'indent_char': ' ', ...}\n\n    def build_filter_stack(stack, options):\n        if options.get('keyword_case') == 'uppercase':\n            stack.append(uppercase_keyword_filter)\n        elif options.get('keyword_case') == 'lowercase':\n            stack.append(lowercase_keyword_filter)\n        if options.get('identifier_case') == 'uppercase':\n            stack.append(uppercase_identifier_filter)\n        elif options.get('identifier_case') == 'lowercase':\n            stack.append(lowercase_identifier_filter)\n        if options.get('string_truncation'):\n            stack.append(string_truncation_filter)\n        if options.get('spacing_around_operators'):\n            stack.append(spacing_around_operators_filter)\n        if options.get('strip_comments'):\n            stack.append(strip_comments_filter)\n        if options.get('strip_whitespace'):\n>           stack.append(strip_whitespace_filter)\nE           AttributeError: 'FilterStack' object has no attribute 'append'\n\nrepos\\sqlparse\\sqlparse\\formatter.py:113: AttributeError"", ""self = <tests.test_format.TestFormatReindent object at 0x0000025AB4E60290>\n\n    def test_parenthesis(self):\n        f = lambda sql: sqlparse.format(sql, reindent=True)\n        s = 'select count(*) from (select * from foo);'\n>       assert f(s) == '\\n'.join([\n            'select count(*)',\n            'from',\n            '  (select *',\n            '   from foo);'])\n\nrepos\\sqlparse\\tests\\test_format.py:413: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:411: in <lambda>\n    f = lambda sql: sqlparse.format(sql, reindent=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:57: in format\n    stack = formatter.build_filter_stack(stack, options)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nstack = <sqlparse.engine.filter_stack.FilterStack object at 0x0000025AB4F3AE90>\noptions = {'comma_first': False, 'compact': False, 'indent_after_first': False, 'indent_char': ' ', ...}\n\n    def build_filter_stack(stack, options):\n        if options.get('keyword_case') == 'uppercase':\n            stack.append(uppercase_keyword_filter)\n        elif options.get('keyword_case') == 'lowercase':\n            stack.append(lowercase_keyword_filter)\n        if options.get('identifier_case') == 'uppercase':\n            stack.append(uppercase_identifier_filter)\n        elif options.get('identifier_case') == 'lowercase':\n            stack.append(lowercase_identifier_filter)\n        if options.get('string_truncation'):\n            stack.append(string_truncation_filter)\n        if options.get('spacing_around_operators'):\n            stack.append(spacing_around_operators_filter)\n        if options.get('strip_comments'):\n            stack.append(strip_comments_filter)\n        if options.get('strip_whitespace'):\n>           stack.append(strip_whitespace_filter)\nE           AttributeError: 'FilterStack' object has no attribute 'append'\n\nrepos\\sqlparse\\sqlparse\\formatter.py:113: AttributeError"", ""self = <tests.test_format.TestFormatReindent object at 0x0000025AB4C9BF00>\n\n    def test_where(self):\n        f = lambda sql: sqlparse.format(sql, reindent=True)\n        s = 'select * from foo where bar = 1 and baz = 2 or bzz = 3;'\n>       assert f(s) == '\\n'.join([\n            'select *',\n            'from foo',\n            'where bar = 1',\n            '  and baz = 2',\n            '  or bzz = 3;'])\n\nrepos\\sqlparse\\tests\\test_format.py:427: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:425: in <lambda>\n    f = lambda sql: sqlparse.format(sql, reindent=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:57: in format\n    stack = formatter.build_filter_stack(stack, options)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nstack = <sqlparse.engine.filter_stack.FilterStack object at 0x0000025AB4F3AAD0>\noptions = {'comma_first': False, 'compact': False, 'indent_after_first': False, 'indent_char': ' ', ...}\n\n    def build_filter_stack(stack, options):\n        if options.get('keyword_case') == 'uppercase':\n            stack.append(uppercase_keyword_filter)\n        elif options.get('keyword_case') == 'lowercase':\n            stack.append(lowercase_keyword_filter)\n        if options.get('identifier_case') == 'uppercase':\n            stack.append(uppercase_identifier_filter)\n        elif options.get('identifier_case') == 'lowercase':\n            stack.append(lowercase_identifier_filter)\n        if options.get('string_truncation'):\n            stack.append(string_truncation_filter)\n        if options.get('spacing_around_operators'):\n            stack.append(spacing_around_operators_filter)\n        if options.get('strip_comments'):\n            stack.append(strip_comments_filter)\n        if options.get('strip_whitespace'):\n>           stack.append(strip_whitespace_filter)\nE           AttributeError: 'FilterStack' object has no attribute 'append'\n\nrepos\\sqlparse\\sqlparse\\formatter.py:113: AttributeError"", ""self = <tests.test_format.TestFormatReindent object at 0x0000025AB4E64050>\n\n    def test_join(self):\n        f = lambda sql: sqlparse.format(sql, reindent=True)\n        s = 'select * from foo join bar on 1 = 2'\n>       assert f(s) == '\\n'.join([\n            'select *',\n            'from foo',\n            'join bar on 1 = 2'])\n\nrepos\\sqlparse\\tests\\test_format.py:445: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:443: in <lambda>\n    f = lambda sql: sqlparse.format(sql, reindent=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:57: in format\n    stack = formatter.build_filter_stack(stack, options)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nstack = <sqlparse.engine.filter_stack.FilterStack object at 0x0000025AB4F3B250>\noptions = {'comma_first': False, 'compact': False, 'indent_after_first': False, 'indent_char': ' ', ...}\n\n    def build_filter_stack(stack, options):\n        if options.get('keyword_case') == 'uppercase':\n            stack.append(uppercase_keyword_filter)\n        elif options.get('keyword_case') == 'lowercase':\n            stack.append(lowercase_keyword_filter)\n        if options.get('identifier_case') == 'uppercase':\n            stack.append(uppercase_identifier_filter)\n        elif options.get('identifier_case') == 'lowercase':\n            stack.append(lowercase_identifier_filter)\n        if options.get('string_truncation'):\n            stack.append(string_truncation_filter)\n        if options.get('spacing_around_operators'):\n            stack.append(spacing_around_operators_filter)\n        if options.get('strip_comments'):\n            stack.append(strip_comments_filter)\n        if options.get('strip_whitespace'):\n>           stack.append(strip_whitespace_filter)\nE           AttributeError: 'FilterStack' object has no attribute 'append'\n\nrepos\\sqlparse\\sqlparse\\formatter.py:113: AttributeError"", ""self = <tests.test_format.TestFormatReindent object at 0x0000025AB4E28C50>\n\n    def test_identifier_list(self):\n        f = lambda sql: sqlparse.format(sql, reindent=True)\n        s = 'select foo, bar, baz from table1, table2 where 1 = 2'\n>       assert f(s) == '\\n'.join([\n            'select foo,',\n            '       bar,',\n            '       baz',\n            'from table1,',\n            '     table2',\n            'where 1 = 2'])\n\nrepos\\sqlparse\\tests\\test_format.py:468: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:466: in <lambda>\n    f = lambda sql: sqlparse.format(sql, reindent=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:57: in format\n    stack = formatter.build_filter_stack(stack, options)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nstack = <sqlparse.engine.filter_stack.FilterStack object at 0x0000025AB4F3B610>\noptions = {'comma_first': False, 'compact': False, 'indent_after_first': False, 'indent_char': ' ', ...}\n\n    def build_filter_stack(stack, options):\n        if options.get('keyword_case') == 'uppercase':\n            stack.append(uppercase_keyword_filter)\n        elif options.get('keyword_case') == 'lowercase':\n            stack.append(lowercase_keyword_filter)\n        if options.get('identifier_case') == 'uppercase':\n            stack.append(uppercase_identifier_filter)\n        elif options.get('identifier_case') == 'lowercase':\n            stack.append(lowercase_identifier_filter)\n        if options.get('string_truncation'):\n            stack.append(string_truncation_filter)\n        if options.get('spacing_around_operators'):\n            stack.append(spacing_around_operators_filter)\n        if options.get('strip_comments'):\n            stack.append(strip_comments_filter)\n        if options.get('strip_whitespace'):\n>           stack.append(strip_whitespace_filter)\nE           AttributeError: 'FilterStack' object has no attribute 'append'\n\nrepos\\sqlparse\\sqlparse\\formatter.py:113: AttributeError"", ""self = <tests.test_format.TestFormatReindent object at 0x0000025AB4E28D50>\n\n    def test_identifier_list_with_wrap_after(self):\n        f = lambda sql: sqlparse.format(sql, reindent=True, wrap_after=14)\n        s = 'select foo, bar, baz from table1, table2 where 1 = 2'\n>       assert f(s) == '\\n'.join([\n            'select foo, bar,',\n            '       baz',\n            'from table1, table2',\n            'where 1 = 2'])\n\nrepos\\sqlparse\\tests\\test_format.py:485: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:483: in <lambda>\n    f = lambda sql: sqlparse.format(sql, reindent=True, wrap_after=14)\nrepos\\sqlparse\\sqlparse\\__init__.py:57: in format\n    stack = formatter.build_filter_stack(stack, options)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nstack = <sqlparse.engine.filter_stack.FilterStack object at 0x0000025AB4F3AAD0>\noptions = {'comma_first': False, 'compact': False, 'indent_after_first': False, 'indent_char': ' ', ...}\n\n    def build_filter_stack(stack, options):\n        if options.get('keyword_case') == 'uppercase':\n            stack.append(uppercase_keyword_filter)\n        elif options.get('keyword_case') == 'lowercase':\n            stack.append(lowercase_keyword_filter)\n        if options.get('identifier_case') == 'uppercase':\n            stack.append(uppercase_identifier_filter)\n        elif options.get('identifier_case') == 'lowercase':\n            stack.append(lowercase_identifier_filter)\n        if options.get('string_truncation'):\n            stack.append(string_truncation_filter)\n        if options.get('spacing_around_operators'):\n            stack.append(spacing_around_operators_filter)\n        if options.get('strip_comments'):\n            stack.append(strip_comments_filter)\n        if options.get('strip_whitespace'):\n>           stack.append(strip_whitespace_filter)\nE           AttributeError: 'FilterStack' object has no attribute 'append'\n\nrepos\\sqlparse\\sqlparse\\formatter.py:113: AttributeError"", ""self = <tests.test_format.TestFormatReindent object at 0x0000025AB4D6E5D0>\n\n    def test_identifier_list_comment_first(self):\n        f = lambda sql: sqlparse.format(sql, reindent=True, comma_first=True)\n        # not the 3: It cleans up whitespace too!\n        s = 'select foo, bar, baz from table where foo in (1, 2,3)'\n>       assert f(s) == '\\n'.join([\n            'select foo',\n            '     , bar',\n            '     , baz',\n            'from table',\n            'where foo in (1',\n            '            , 2',\n            '            , 3)'])\n\nrepos\\sqlparse\\tests\\test_format.py:495: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:492: in <lambda>\n    f = lambda sql: sqlparse.format(sql, reindent=True, comma_first=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:57: in format\n    stack = formatter.build_filter_stack(stack, options)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nstack = <sqlparse.engine.filter_stack.FilterStack object at 0x0000025AB4F396D0>\noptions = {'comma_first': True, 'compact': False, 'indent_after_first': False, 'indent_char': ' ', ...}\n\n    def build_filter_stack(stack, options):\n        if options.get('keyword_case') == 'uppercase':\n            stack.append(uppercase_keyword_filter)\n        elif options.get('keyword_case') == 'lowercase':\n            stack.append(lowercase_keyword_filter)\n        if options.get('identifier_case') == 'uppercase':\n            stack.append(uppercase_identifier_filter)\n        elif options.get('identifier_case') == 'lowercase':\n            stack.append(lowercase_identifier_filter)\n        if options.get('string_truncation'):\n            stack.append(string_truncation_filter)\n        if options.get('spacing_around_operators'):\n            stack.append(spacing_around_operators_filter)\n        if options.get('strip_comments'):\n            stack.append(strip_comments_filter)\n        if options.get('strip_whitespace'):\n>           stack.append(strip_whitespace_filter)\nE           AttributeError: 'FilterStack' object has no attribute 'append'\n\nrepos\\sqlparse\\sqlparse\\formatter.py:113: AttributeError"", 'self = <tests.test_format.TestFormatReindent object at 0x0000025AB4D6E6C0>\n\n    def test_identifier_list_with_functions(self):\n        f = lambda sql: sqlparse.format(sql, reindent=True)\n        s = (""select \'abc\' as foo, coalesce(col1, col2)||col3 as bar,""\n             ""col3 from my_table"")\n>       assert f(s) == \'\\n\'.join([\n            ""select \'abc\' as foo,"",\n            ""       coalesce(col1, col2)||col3 as bar,"",\n            ""       col3"",\n            ""from my_table""])\n\nrepos\\sqlparse\\tests\\test_format.py:508: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:505: in <lambda>\n    f = lambda sql: sqlparse.format(sql, reindent=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:57: in format\n    stack = formatter.build_filter_stack(stack, options)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nstack = <sqlparse.engine.filter_stack.FilterStack object at 0x0000025AB4F3AFD0>\noptions = {\'comma_first\': False, \'compact\': False, \'indent_after_first\': False, \'indent_char\': \' \', ...}\n\n    def build_filter_stack(stack, options):\n        if options.get(\'keyword_case\') == \'uppercase\':\n            stack.append(uppercase_keyword_filter)\n        elif options.get(\'keyword_case\') == \'lowercase\':\n            stack.append(lowercase_keyword_filter)\n        if options.get(\'identifier_case\') == \'uppercase\':\n            stack.append(uppercase_identifier_filter)\n        elif options.get(\'identifier_case\') == \'lowercase\':\n            stack.append(lowercase_identifier_filter)\n        if options.get(\'string_truncation\'):\n            stack.append(string_truncation_filter)\n        if options.get(\'spacing_around_operators\'):\n            stack.append(spacing_around_operators_filter)\n        if options.get(\'strip_comments\'):\n            stack.append(strip_comments_filter)\n        if options.get(\'strip_whitespace\'):\n>           stack.append(strip_whitespace_filter)\nE           AttributeError: \'FilterStack\' object has no attribute \'append\'\n\nrepos\\sqlparse\\sqlparse\\formatter.py:113: AttributeError', 'self = <tests.test_format.TestFormatReindent object at 0x0000025AB4DBC3D0>\n\n    def test_long_identifier_list_with_functions(self):\n        f = lambda sql: sqlparse.format(sql, reindent=True, wrap_after=30)\n        s = (""select \'abc\' as foo, json_build_object(\'a\',  a,""\n             ""\'b\', b, \'c\', c, \'d\', d, \'e\', e) as col2""\n             ""col3 from my_table"")\n>       assert f(s) == \'\\n\'.join([\n            ""select \'abc\' as foo,"",\n            ""       json_build_object(\'a\',"",\n            ""         a, \'b\', b, \'c\', c, \'d\', d,"",\n            ""         \'e\', e) as col2col3"",\n            ""from my_table""])\n\nrepos\\sqlparse\\tests\\test_format.py:519: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:515: in <lambda>\n    f = lambda sql: sqlparse.format(sql, reindent=True, wrap_after=30)\nrepos\\sqlparse\\sqlparse\\__init__.py:57: in format\n    stack = formatter.build_filter_stack(stack, options)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nstack = <sqlparse.engine.filter_stack.FilterStack object at 0x0000025AB4F3A350>\noptions = {\'comma_first\': False, \'compact\': False, \'indent_after_first\': False, \'indent_char\': \' \', ...}\n\n    def build_filter_stack(stack, options):\n        if options.get(\'keyword_case\') == \'uppercase\':\n            stack.append(uppercase_keyword_filter)\n        elif options.get(\'keyword_case\') == \'lowercase\':\n            stack.append(lowercase_keyword_filter)\n        if options.get(\'identifier_case\') == \'uppercase\':\n            stack.append(uppercase_identifier_filter)\n        elif options.get(\'identifier_case\') == \'lowercase\':\n            stack.append(lowercase_identifier_filter)\n        if options.get(\'string_truncation\'):\n            stack.append(string_truncation_filter)\n        if options.get(\'spacing_around_operators\'):\n            stack.append(spacing_around_operators_filter)\n        if options.get(\'strip_comments\'):\n            stack.append(strip_comments_filter)\n        if options.get(\'strip_whitespace\'):\n>           stack.append(strip_whitespace_filter)\nE           AttributeError: \'FilterStack\' object has no attribute \'append\'\n\nrepos\\sqlparse\\sqlparse\\formatter.py:113: AttributeError', ""self = <tests.test_format.TestFormatReindent object at 0x0000025AB4DBC2F0>\n\n    def test_case(self):\n        f = lambda sql: sqlparse.format(sql, reindent=True)\n        s = 'case when foo = 1 then 2 when foo = 3 then 4 else 5 end'\n>       assert f(s) == '\\n'.join([\n            'case',\n            '    when foo = 1 then 2',\n            '    when foo = 3 then 4',\n            '    else 5',\n            'end'])\n\nrepos\\sqlparse\\tests\\test_format.py:529: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:527: in <lambda>\n    f = lambda sql: sqlparse.format(sql, reindent=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:57: in format\n    stack = formatter.build_filter_stack(stack, options)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nstack = <sqlparse.engine.filter_stack.FilterStack object at 0x0000025AB4F3B390>\noptions = {'comma_first': False, 'compact': False, 'indent_after_first': False, 'indent_char': ' ', ...}\n\n    def build_filter_stack(stack, options):\n        if options.get('keyword_case') == 'uppercase':\n            stack.append(uppercase_keyword_filter)\n        elif options.get('keyword_case') == 'lowercase':\n            stack.append(lowercase_keyword_filter)\n        if options.get('identifier_case') == 'uppercase':\n            stack.append(uppercase_identifier_filter)\n        elif options.get('identifier_case') == 'lowercase':\n            stack.append(lowercase_identifier_filter)\n        if options.get('string_truncation'):\n            stack.append(string_truncation_filter)\n        if options.get('spacing_around_operators'):\n            stack.append(spacing_around_operators_filter)\n        if options.get('strip_comments'):\n            stack.append(strip_comments_filter)\n        if options.get('strip_whitespace'):\n>           stack.append(strip_whitespace_filter)\nE           AttributeError: 'FilterStack' object has no attribute 'append'\n\nrepos\\sqlparse\\sqlparse\\formatter.py:113: AttributeError"", ""self = <tests.test_format.TestFormatReindent object at 0x0000025AB4DE5F30>\n\n    def test_case2(self):\n        f = lambda sql: sqlparse.format(sql, reindent=True)\n        s = 'case(foo) when bar = 1 then 2 else 3 end'\n>       assert f(s) == '\\n'.join([\n            'case(foo)',\n            '    when bar = 1 then 2',\n            '    else 3',\n            'end'])\n\nrepos\\sqlparse\\tests\\test_format.py:539: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:537: in <lambda>\n    f = lambda sql: sqlparse.format(sql, reindent=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:57: in format\n    stack = formatter.build_filter_stack(stack, options)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nstack = <sqlparse.engine.filter_stack.FilterStack object at 0x0000025AB4F3BD90>\noptions = {'comma_first': False, 'compact': False, 'indent_after_first': False, 'indent_char': ' ', ...}\n\n    def build_filter_stack(stack, options):\n        if options.get('keyword_case') == 'uppercase':\n            stack.append(uppercase_keyword_filter)\n        elif options.get('keyword_case') == 'lowercase':\n            stack.append(lowercase_keyword_filter)\n        if options.get('identifier_case') == 'uppercase':\n            stack.append(uppercase_identifier_filter)\n        elif options.get('identifier_case') == 'lowercase':\n            stack.append(lowercase_identifier_filter)\n        if options.get('string_truncation'):\n            stack.append(string_truncation_filter)\n        if options.get('spacing_around_operators'):\n            stack.append(spacing_around_operators_filter)\n        if options.get('strip_comments'):\n            stack.append(strip_comments_filter)\n        if options.get('strip_whitespace'):\n>           stack.append(strip_whitespace_filter)\nE           AttributeError: 'FilterStack' object has no attribute 'append'\n\nrepos\\sqlparse\\sqlparse\\formatter.py:113: AttributeError"", ""self = <tests.test_format.TestFormatReindent object at 0x0000025AB4C62B10>\n\n    def test_nested_identifier_list(self):\n        # issue4\n        f = lambda sql: sqlparse.format(sql, reindent=True)\n        s = '(foo as bar, bar1, bar2 as bar3, b4 as b5)'\n>       assert f(s) == '\\n'.join([\n            '(foo as bar,',\n            ' bar1,',\n            ' bar2 as bar3,',\n            ' b4 as b5)'])\n\nrepos\\sqlparse\\tests\\test_format.py:549: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:547: in <lambda>\n    f = lambda sql: sqlparse.format(sql, reindent=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:57: in format\n    stack = formatter.build_filter_stack(stack, options)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nstack = <sqlparse.engine.filter_stack.FilterStack object at 0x0000025AB4F39450>\noptions = {'comma_first': False, 'compact': False, 'indent_after_first': False, 'indent_char': ' ', ...}\n\n    def build_filter_stack(stack, options):\n        if options.get('keyword_case') == 'uppercase':\n            stack.append(uppercase_keyword_filter)\n        elif options.get('keyword_case') == 'lowercase':\n            stack.append(lowercase_keyword_filter)\n        if options.get('identifier_case') == 'uppercase':\n            stack.append(uppercase_identifier_filter)\n        elif options.get('identifier_case') == 'lowercase':\n            stack.append(lowercase_identifier_filter)\n        if options.get('string_truncation'):\n            stack.append(string_truncation_filter)\n        if options.get('spacing_around_operators'):\n            stack.append(spacing_around_operators_filter)\n        if options.get('strip_comments'):\n            stack.append(strip_comments_filter)\n        if options.get('strip_whitespace'):\n>           stack.append(strip_whitespace_filter)\nE           AttributeError: 'FilterStack' object has no attribute 'append'\n\nrepos\\sqlparse\\sqlparse\\formatter.py:113: AttributeError"", ""self = <tests.test_format.TestFormatReindent object at 0x0000025AB4C637D0>\n\n    def test_duplicate_linebreaks(self):\n        # issue3\n        f = lambda sql: sqlparse.format(sql, reindent=True)\n        s = 'select c1 -- column1\\nfrom foo'\n>       assert f(s) == '\\n'.join([\n            'select c1 -- column1',\n            'from foo'])\n\nrepos\\sqlparse\\tests\\test_format.py:559: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:557: in <lambda>\n    f = lambda sql: sqlparse.format(sql, reindent=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:57: in format\n    stack = formatter.build_filter_stack(stack, options)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nstack = <sqlparse.engine.filter_stack.FilterStack object at 0x0000025AB4F3AD50>\noptions = {'comma_first': False, 'compact': False, 'indent_after_first': False, 'indent_char': ' ', ...}\n\n    def build_filter_stack(stack, options):\n        if options.get('keyword_case') == 'uppercase':\n            stack.append(uppercase_keyword_filter)\n        elif options.get('keyword_case') == 'lowercase':\n            stack.append(lowercase_keyword_filter)\n        if options.get('identifier_case') == 'uppercase':\n            stack.append(uppercase_identifier_filter)\n        elif options.get('identifier_case') == 'lowercase':\n            stack.append(lowercase_identifier_filter)\n        if options.get('string_truncation'):\n            stack.append(string_truncation_filter)\n        if options.get('spacing_around_operators'):\n            stack.append(spacing_around_operators_filter)\n        if options.get('strip_comments'):\n            stack.append(strip_comments_filter)\n        if options.get('strip_whitespace'):\n>           stack.append(strip_whitespace_filter)\nE           AttributeError: 'FilterStack' object has no attribute 'append'\n\nrepos\\sqlparse\\sqlparse\\formatter.py:113: AttributeError"", ""self = <tests.test_format.TestFormatReindent object at 0x0000025AB4D697B0>\n\n    def test_keywordfunctions(self):\n        # issue36\n        f = lambda sql: sqlparse.format(sql, reindent=True)\n        s = 'select max(a) b, foo, bar'\n>       assert f(s) == '\\n'.join([\n            'select max(a) b,',\n            '       foo,',\n            '       bar'])\n\nrepos\\sqlparse\\tests\\test_format.py:583: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:581: in <lambda>\n    f = lambda sql: sqlparse.format(sql, reindent=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:57: in format\n    stack = formatter.build_filter_stack(stack, options)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nstack = <sqlparse.engine.filter_stack.FilterStack object at 0x0000025AB4F39310>\noptions = {'comma_first': False, 'compact': False, 'indent_after_first': False, 'indent_char': ' ', ...}\n\n    def build_filter_stack(stack, options):\n        if options.get('keyword_case') == 'uppercase':\n            stack.append(uppercase_keyword_filter)\n        elif options.get('keyword_case') == 'lowercase':\n            stack.append(lowercase_keyword_filter)\n        if options.get('identifier_case') == 'uppercase':\n            stack.append(uppercase_identifier_filter)\n        elif options.get('identifier_case') == 'lowercase':\n            stack.append(lowercase_identifier_filter)\n        if options.get('string_truncation'):\n            stack.append(string_truncation_filter)\n        if options.get('spacing_around_operators'):\n            stack.append(spacing_around_operators_filter)\n        if options.get('strip_comments'):\n            stack.append(strip_comments_filter)\n        if options.get('strip_whitespace'):\n>           stack.append(strip_whitespace_filter)\nE           AttributeError: 'FilterStack' object has no attribute 'append'\n\nrepos\\sqlparse\\sqlparse\\formatter.py:113: AttributeError"", ""self = <tests.test_format.TestFormatReindent object at 0x0000025AB4D69860>\n\n    def test_identifier_and_functions(self):\n        # issue45\n        f = lambda sql: sqlparse.format(sql, reindent=True)\n        s = 'select foo.bar, nvl(1) from dual'\n>       assert f(s) == '\\n'.join([\n            'select foo.bar,',\n            '       nvl(1)',\n            'from dual'])\n\nrepos\\sqlparse\\tests\\test_format.py:592: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:590: in <lambda>\n    f = lambda sql: sqlparse.format(sql, reindent=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:57: in format\n    stack = formatter.build_filter_stack(stack, options)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nstack = <sqlparse.engine.filter_stack.FilterStack object at 0x0000025AB4F3AAD0>\noptions = {'comma_first': False, 'compact': False, 'indent_after_first': False, 'indent_char': ' ', ...}\n\n    def build_filter_stack(stack, options):\n        if options.get('keyword_case') == 'uppercase':\n            stack.append(uppercase_keyword_filter)\n        elif options.get('keyword_case') == 'lowercase':\n            stack.append(lowercase_keyword_filter)\n        if options.get('identifier_case') == 'uppercase':\n            stack.append(uppercase_identifier_filter)\n        elif options.get('identifier_case') == 'lowercase':\n            stack.append(lowercase_identifier_filter)\n        if options.get('string_truncation'):\n            stack.append(string_truncation_filter)\n        if options.get('spacing_around_operators'):\n            stack.append(spacing_around_operators_filter)\n        if options.get('strip_comments'):\n            stack.append(strip_comments_filter)\n        if options.get('strip_whitespace'):\n>           stack.append(strip_whitespace_filter)\nE           AttributeError: 'FilterStack' object has no attribute 'append'\n\nrepos\\sqlparse\\sqlparse\\formatter.py:113: AttributeError"", ""self = <tests.test_format.TestFormatReindent object at 0x0000025AB4E1AA30>\n\n    def test_insert_values(self):\n        # issue 329\n        f = lambda sql: sqlparse.format(sql, reindent=True)\n        s = 'insert into foo values (1, 2)'\n>       assert f(s) == '\\n'.join([\n            'insert into foo',\n            'values (1, 2)'])\n\nrepos\\sqlparse\\tests\\test_format.py:601: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:599: in <lambda>\n    f = lambda sql: sqlparse.format(sql, reindent=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:57: in format\n    stack = formatter.build_filter_stack(stack, options)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nstack = <sqlparse.engine.filter_stack.FilterStack object at 0x0000025AB4F3B610>\noptions = {'comma_first': False, 'compact': False, 'indent_after_first': False, 'indent_char': ' ', ...}\n\n    def build_filter_stack(stack, options):\n        if options.get('keyword_case') == 'uppercase':\n            stack.append(uppercase_keyword_filter)\n        elif options.get('keyword_case') == 'lowercase':\n            stack.append(lowercase_keyword_filter)\n        if options.get('identifier_case') == 'uppercase':\n            stack.append(uppercase_identifier_filter)\n        elif options.get('identifier_case') == 'lowercase':\n            stack.append(lowercase_identifier_filter)\n        if options.get('string_truncation'):\n            stack.append(string_truncation_filter)\n        if options.get('spacing_around_operators'):\n            stack.append(spacing_around_operators_filter)\n        if options.get('strip_comments'):\n            stack.append(strip_comments_filter)\n        if options.get('strip_whitespace'):\n>           stack.append(strip_whitespace_filter)\nE           AttributeError: 'FilterStack' object has no attribute 'append'\n\nrepos\\sqlparse\\sqlparse\\formatter.py:113: AttributeError"", 'self = <tests.test_format.TestOutputFormat object at 0x0000025AB4CBAFD0>\n\n    def test_python(self):\n        sql = \'select * from foo;\'\n        f = lambda sql: sqlparse.format(sql, output_format=\'python\')\n>       assert f(sql) == ""sql = \'select * from foo;\'""\nE       assert \'select * from foo;\' == ""sql = \'select * from foo;\'""\nE         \nE         - sql = \'select * from foo;\'\nE         ? -------                  -\nE         + select * from foo;\n\nrepos\\sqlparse\\tests\\test_format.py:645: AssertionError', 'self = <tests.test_format.TestOutputFormat object at 0x0000025AB4CBB110>\n\n    def test_python_multiple_statements(self):\n        sql = \'select * from foo; select 1 from dual\'\n        f = lambda sql: sqlparse.format(sql, output_format=\'python\')\n>       assert f(sql) == \'\\n\'.join([\n            ""sql = \'select * from foo; \'"",\n            ""sql2 = \'select 1 from dual\'""])\nE       assert \'select * fro...t 1 from dual\' == ""sql = \'selec... 1 from dual\'""\nE         \nE         + select * from foo;select 1 from dual\nE         - sql = \'select * from foo; \'\nE         - sql2 = \'select 1 from dual\'\n\nrepos\\sqlparse\\tests\\test_format.py:655: AssertionError', 'self = <tests.test_format.TestOutputFormat object at 0x0000025AB4E54510>\n\n    def test_php(self):\n        sql = \'select * from foo;\'\n        f = lambda sql: sqlparse.format(sql, output_format=\'php\')\n>       assert f(sql) == \'$sql = ""select * from foo;"";\'\nE       assert \'select * from foo;\' == \'$sql = ""select * from foo;"";\'\nE         \nE         - $sql = ""select * from foo;"";\nE         ? --------                  --\nE         + select * from foo;\n\nrepos\\sqlparse\\tests\\test_format.py:673: AssertionError', ""def test_format_column_ordering():\n        # issue89\n        sql = 'select * from foo order by c1 desc, c2, c3;'\n>       formatted = sqlparse.format(sql, reindent=True)\n\nrepos\\sqlparse\\tests\\test_format.py:695: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:57: in format\n    stack = formatter.build_filter_stack(stack, options)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nstack = <sqlparse.engine.filter_stack.FilterStack object at 0x0000025AB4F3B110>\noptions = {'comma_first': False, 'compact': False, 'indent_after_first': False, 'indent_char': ' ', ...}\n\n    def build_filter_stack(stack, options):\n        if options.get('keyword_case') == 'uppercase':\n            stack.append(uppercase_keyword_filter)\n        elif options.get('keyword_case') == 'lowercase':\n            stack.append(lowercase_keyword_filter)\n        if options.get('identifier_case') == 'uppercase':\n            stack.append(uppercase_identifier_filter)\n        elif options.get('identifier_case') == 'lowercase':\n            stack.append(lowercase_identifier_filter)\n        if options.get('string_truncation'):\n            stack.append(string_truncation_filter)\n        if options.get('spacing_around_operators'):\n            stack.append(spacing_around_operators_filter)\n        if options.get('strip_comments'):\n            stack.append(strip_comments_filter)\n        if options.get('strip_whitespace'):\n>           stack.append(strip_whitespace_filter)\nE           AttributeError: 'FilterStack' object has no attribute 'append'\n\nrepos\\sqlparse\\sqlparse\\formatter.py:113: AttributeError"", 'def test_truncate_strings():\n        sql = ""update foo set value = \'{}\';"".format(\'x\' * 1000)\n        formatted = sqlparse.format(sql, truncate_strings=10)\n>       assert formatted == ""update foo set value = \'xxxxxxxxxx[...]\';""\nE       assert ""update foo s...xxxxxxxxxxx\';"" == ""update foo s...xxxxxx[...]\';""\nE         \nE         - update foo set value = \'xxxxxxxxxx[...]\';\nE         + update foo set value = \'xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx...\nE         \nE         ...Full output truncated (1 line hidden), use \'-vv\' to show\n\nrepos\\sqlparse\\tests\\test_format.py:708: AssertionError', ""def test_having_produces_newline():\n        sql = ('select * from foo, bar where bar.id = foo.bar_id '\n               'having sum(bar.value) > 100')\n>       formatted = sqlparse.format(sql, reindent=True)\n\nrepos\\sqlparse\\tests\\test_format.py:730: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:57: in format\n    stack = formatter.build_filter_stack(stack, options)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nstack = <sqlparse.engine.filter_stack.FilterStack object at 0x0000025AB4F3AD50>\noptions = {'comma_first': False, 'compact': False, 'indent_after_first': False, 'indent_char': ' ', ...}\n\n    def build_filter_stack(stack, options):\n        if options.get('keyword_case') == 'uppercase':\n            stack.append(uppercase_keyword_filter)\n        elif options.get('keyword_case') == 'lowercase':\n            stack.append(lowercase_keyword_filter)\n        if options.get('identifier_case') == 'uppercase':\n            stack.append(uppercase_identifier_filter)\n        elif options.get('identifier_case') == 'lowercase':\n            stack.append(lowercase_identifier_filter)\n        if options.get('string_truncation'):\n            stack.append(string_truncation_filter)\n        if options.get('spacing_around_operators'):\n            stack.append(spacing_around_operators_filter)\n        if options.get('strip_comments'):\n            stack.append(strip_comments_filter)\n        if options.get('strip_whitespace'):\n>           stack.append(strip_whitespace_filter)\nE           AttributeError: 'FilterStack' object has no attribute 'append'\n\nrepos\\sqlparse\\sqlparse\\formatter.py:113: AttributeError"", 'def test_format_json_ops():  # issue542\n>       formatted = sqlparse.format(\n            ""select foo->\'bar\', foo->\'bar\';"", reindent=True)\n\nrepos\\sqlparse\\tests\\test_format.py:753: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:57: in format\n    stack = formatter.build_filter_stack(stack, options)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nstack = <sqlparse.engine.filter_stack.FilterStack object at 0x0000025AB4F3A490>\noptions = {\'comma_first\': False, \'compact\': False, \'indent_after_first\': False, \'indent_char\': \' \', ...}\n\n    def build_filter_stack(stack, options):\n        if options.get(\'keyword_case\') == \'uppercase\':\n            stack.append(uppercase_keyword_filter)\n        elif options.get(\'keyword_case\') == \'lowercase\':\n            stack.append(lowercase_keyword_filter)\n        if options.get(\'identifier_case\') == \'uppercase\':\n            stack.append(uppercase_identifier_filter)\n        elif options.get(\'identifier_case\') == \'lowercase\':\n            stack.append(lowercase_identifier_filter)\n        if options.get(\'string_truncation\'):\n            stack.append(string_truncation_filter)\n        if options.get(\'spacing_around_operators\'):\n            stack.append(spacing_around_operators_filter)\n        if options.get(\'strip_comments\'):\n            stack.append(strip_comments_filter)\n        if options.get(\'strip_whitespace\'):\n>           stack.append(strip_whitespace_filter)\nE           AttributeError: \'FilterStack\' object has no attribute \'append\'\n\nrepos\\sqlparse\\sqlparse\\formatter.py:113: AttributeError', ""sql = 'case when foo then 1 else bar end'\nexpected_normal = 'case\\n    when foo then 1\\n    else bar\\nend'\nexpected_compact = 'case when foo then 1 else bar end'\n\n    @pytest.mark.parametrize('sql, expected_normal, expected_compact', [\n        ('case when foo then 1 else bar end',\n         'case\\n    when foo then 1\\n    else bar\\nend',\n         'case when foo then 1 else bar end')])\n    def test_compact(sql, expected_normal, expected_compact):  # issue783\n>       formatted_normal = sqlparse.format(sql, reindent=True)\n\nrepos\\sqlparse\\tests\\test_format.py:764: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:57: in format\n    stack = formatter.build_filter_stack(stack, options)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nstack = <sqlparse.engine.filter_stack.FilterStack object at 0x0000025AB4F396D0>\noptions = {'comma_first': False, 'compact': False, 'indent_after_first': False, 'indent_char': ' ', ...}\n\n    def build_filter_stack(stack, options):\n        if options.get('keyword_case') == 'uppercase':\n            stack.append(uppercase_keyword_filter)\n        elif options.get('keyword_case') == 'lowercase':\n            stack.append(lowercase_keyword_filter)\n        if options.get('identifier_case') == 'uppercase':\n            stack.append(uppercase_identifier_filter)\n        elif options.get('identifier_case') == 'lowercase':\n            stack.append(lowercase_identifier_filter)\n        if options.get('string_truncation'):\n            stack.append(string_truncation_filter)\n        if options.get('spacing_around_operators'):\n            stack.append(spacing_around_operators_filter)\n        if options.get('strip_comments'):\n            stack.append(strip_comments_filter)\n        if options.get('strip_whitespace'):\n>           stack.append(strip_whitespace_filter)\nE           AttributeError: 'FilterStack' object has no attribute 'append'\n\nrepos\\sqlparse\\sqlparse\\formatter.py:113: AttributeError"", ""def test_strip_ws_removes_trailing_ws_in_groups():  # issue782\n>       formatted = sqlparse.format('( where foo = bar  ) from',\n                                    strip_whitespace=True)\n\nrepos\\sqlparse\\tests\\test_format.py:771: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:57: in format\n    stack = formatter.build_filter_stack(stack, options)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nstack = <sqlparse.engine.filter_stack.FilterStack object at 0x0000025AB4F3A350>\noptions = {'comma_first': False, 'compact': False, 'indent_after_first': False, 'indent_char': ' ', ...}\n\n    def build_filter_stack(stack, options):\n        if options.get('keyword_case') == 'uppercase':\n            stack.append(uppercase_keyword_filter)\n        elif options.get('keyword_case') == 'lowercase':\n            stack.append(lowercase_keyword_filter)\n        if options.get('identifier_case') == 'uppercase':\n            stack.append(uppercase_identifier_filter)\n        elif options.get('identifier_case') == 'lowercase':\n            stack.append(lowercase_identifier_filter)\n        if options.get('string_truncation'):\n            stack.append(string_truncation_filter)\n        if options.get('spacing_around_operators'):\n            stack.append(spacing_around_operators_filter)\n        if options.get('strip_comments'):\n            stack.append(strip_comments_filter)\n        if options.get('strip_whitespace'):\n>           stack.append(strip_whitespace_filter)\nE           AttributeError: 'FilterStack' object has no attribute 'append'\n\nrepos\\sqlparse\\sqlparse\\formatter.py:113: AttributeError"", 'def test_issue35():\n        # missing space before LIMIT. Updated for #321\n>       sql = sqlparse.format(""select * from foo where bar = 1 limit 1"",\n                              reindent=True)\n\nrepos\\sqlparse\\tests\\test_regressions.py:48: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:57: in format\n    stack = formatter.build_filter_stack(stack, options)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nstack = <sqlparse.engine.filter_stack.FilterStack object at 0x0000025AB4F3AE90>\noptions = {\'comma_first\': False, \'compact\': False, \'indent_after_first\': False, \'indent_char\': \' \', ...}\n\n    def build_filter_stack(stack, options):\n        if options.get(\'keyword_case\') == \'uppercase\':\n            stack.append(uppercase_keyword_filter)\n        elif options.get(\'keyword_case\') == \'lowercase\':\n            stack.append(lowercase_keyword_filter)\n        if options.get(\'identifier_case\') == \'uppercase\':\n            stack.append(uppercase_identifier_filter)\n        elif options.get(\'identifier_case\') == \'lowercase\':\n            stack.append(lowercase_identifier_filter)\n        if options.get(\'string_truncation\'):\n            stack.append(string_truncation_filter)\n        if options.get(\'spacing_around_operators\'):\n            stack.append(spacing_around_operators_filter)\n        if options.get(\'strip_comments\'):\n            stack.append(strip_comments_filter)\n        if options.get(\'strip_whitespace\'):\n>           stack.append(strip_whitespace_filter)\nE           AttributeError: \'FilterStack\' object has no attribute \'append\'\n\nrepos\\sqlparse\\sqlparse\\formatter.py:113: AttributeError', 'def test_issue38():\n>       sql = sqlparse.format(""SELECT foo; -- comment"", strip_comments=True)\n\nrepos\\sqlparse\\tests\\test_regressions.py:58: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:57: in format\n    stack = formatter.build_filter_stack(stack, options)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nstack = <sqlparse.engine.filter_stack.FilterStack object at 0x0000025AB4F39310>\noptions = {\'comma_first\': False, \'compact\': False, \'indent_after_first\': False, \'indent_char\': \' \', ...}\n\n    def build_filter_stack(stack, options):\n        if options.get(\'keyword_case\') == \'uppercase\':\n            stack.append(uppercase_keyword_filter)\n        elif options.get(\'keyword_case\') == \'lowercase\':\n            stack.append(lowercase_keyword_filter)\n        if options.get(\'identifier_case\') == \'uppercase\':\n            stack.append(uppercase_identifier_filter)\n        elif options.get(\'identifier_case\') == \'lowercase\':\n            stack.append(lowercase_identifier_filter)\n        if options.get(\'string_truncation\'):\n            stack.append(string_truncation_filter)\n        if options.get(\'spacing_around_operators\'):\n            stack.append(spacing_around_operators_filter)\n        if options.get(\'strip_comments\'):\n>           stack.append(strip_comments_filter)\nE           AttributeError: \'FilterStack\' object has no attribute \'append\'\n\nrepos\\sqlparse\\sqlparse\\formatter.py:111: AttributeError', ""def test_issue40():\n        # make sure identifier lists in subselects are grouped\n        p = sqlparse.parse('SELECT id, name FROM '\n                           '(SELECT id, name FROM bar) as foo')[0]\n        assert len(p.tokens) == 7\n        assert p.tokens[2].__class__ == sql.IdentifierList\n        assert p.tokens[-1].__class__ == sql.Identifier\n        assert p.tokens[-1].get_name() == 'foo'\n        sp = p.tokens[-1].tokens[0]\n        assert sp.tokens[3].__class__ == sql.IdentifierList\n        # make sure that formatting works as expected\n>       s = sqlparse.format('SELECT id ==  name FROM '\n                            '(SELECT id, name FROM bar)', reindent=True)\n\nrepos\\sqlparse\\tests\\test_regressions.py:86: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:57: in format\n    stack = formatter.build_filter_stack(stack, options)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nstack = <sqlparse.engine.filter_stack.FilterStack object at 0x0000025AB4F3B110>\noptions = {'comma_first': False, 'compact': False, 'indent_after_first': False, 'indent_char': ' ', ...}\n\n    def build_filter_stack(stack, options):\n        if options.get('keyword_case') == 'uppercase':\n            stack.append(uppercase_keyword_filter)\n        elif options.get('keyword_case') == 'lowercase':\n            stack.append(lowercase_keyword_filter)\n        if options.get('identifier_case') == 'uppercase':\n            stack.append(uppercase_identifier_filter)\n        elif options.get('identifier_case') == 'lowercase':\n            stack.append(lowercase_identifier_filter)\n        if options.get('string_truncation'):\n            stack.append(string_truncation_filter)\n        if options.get('spacing_around_operators'):\n            stack.append(spacing_around_operators_filter)\n        if options.get('strip_comments'):\n            stack.append(strip_comments_filter)\n        if options.get('strip_whitespace'):\n>           stack.append(strip_whitespace_filter)\nE           AttributeError: 'FilterStack' object has no attribute 'append'\n\nrepos\\sqlparse\\sqlparse\\formatter.py:113: AttributeError"", ""def test_comment_encoding_when_reindent():\n        # There was an UnicodeEncodeError in the reindent filter that\n        # casted every comment followed by a keyword to str.\n        sql = 'select foo -- Comment containing Ümläuts\\nfrom bar'\n>       formatted = sqlparse.format(sql, reindent=True)\n\nrepos\\sqlparse\\tests\\test_regressions.py:154: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:57: in format\n    stack = formatter.build_filter_stack(stack, options)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nstack = <sqlparse.engine.filter_stack.FilterStack object at 0x0000025AB4F3A710>\noptions = {'comma_first': False, 'compact': False, 'indent_after_first': False, 'indent_char': ' ', ...}\n\n    def build_filter_stack(stack, options):\n        if options.get('keyword_case') == 'uppercase':\n            stack.append(uppercase_keyword_filter)\n        elif options.get('keyword_case') == 'lowercase':\n            stack.append(lowercase_keyword_filter)\n        if options.get('identifier_case') == 'uppercase':\n            stack.append(uppercase_identifier_filter)\n        elif options.get('identifier_case') == 'lowercase':\n            stack.append(lowercase_identifier_filter)\n        if options.get('string_truncation'):\n            stack.append(string_truncation_filter)\n        if options.get('spacing_around_operators'):\n            stack.append(spacing_around_operators_filter)\n        if options.get('strip_comments'):\n            stack.append(strip_comments_filter)\n        if options.get('strip_whitespace'):\n>           stack.append(strip_whitespace_filter)\nE           AttributeError: 'FilterStack' object has no attribute 'append'\n\nrepos\\sqlparse\\sqlparse\\formatter.py:113: AttributeError"", 'def test_parse_sql_with_binary():\n        # See https://github.com/andialbrecht/sqlparse/pull/88\n        # digest = \'\x82|Ë\x0eê\x8aplL4¡h\x91øN{\'\n        digest = \'\\x82|\\xcb\\x0e\\xea\\x8aplL4\\xa1h\\x91\\xf8N{\'\n        sql = f""select * from foo where bar = \'{digest}\'""\n>       formatted = sqlparse.format(sql, reindent=True)\n\nrepos\\sqlparse\\tests\\test_regressions.py:163: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:57: in format\n    stack = formatter.build_filter_stack(stack, options)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nstack = <sqlparse.engine.filter_stack.FilterStack object at 0x0000025AB4F3AD50>\noptions = {\'comma_first\': False, \'compact\': False, \'indent_after_first\': False, \'indent_char\': \' \', ...}\n\n    def build_filter_stack(stack, options):\n        if options.get(\'keyword_case\') == \'uppercase\':\n            stack.append(uppercase_keyword_filter)\n        elif options.get(\'keyword_case\') == \'lowercase\':\n            stack.append(lowercase_keyword_filter)\n        if options.get(\'identifier_case\') == \'uppercase\':\n            stack.append(uppercase_identifier_filter)\n        elif options.get(\'identifier_case\') == \'lowercase\':\n            stack.append(lowercase_identifier_filter)\n        if options.get(\'string_truncation\'):\n            stack.append(string_truncation_filter)\n        if options.get(\'spacing_around_operators\'):\n            stack.append(spacing_around_operators_filter)\n        if options.get(\'strip_comments\'):\n            stack.append(strip_comments_filter)\n        if options.get(\'strip_whitespace\'):\n>           stack.append(strip_whitespace_filter)\nE           AttributeError: \'FilterStack\' object has no attribute \'append\'\n\nrepos\\sqlparse\\sqlparse\\formatter.py:113: AttributeError', ""load_file = <function load_file.<locals>.make_load_file at 0x0000025AB52D3740>\n\n    def test_format_accepts_encoding(load_file):\n        # issue20\n        sql = load_file('test_cp1251.sql', 'cp1251')\n>       formatted = sqlparse.format(sql, reindent=True, encoding='cp1251')\n\nrepos\\sqlparse\\tests\\test_regressions.py:181: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:57: in format\n    stack = formatter.build_filter_stack(stack, options)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nstack = <sqlparse.engine.filter_stack.FilterStack object at 0x0000025AB4F3A210>\noptions = {'comma_first': False, 'compact': False, 'indent_after_first': False, 'indent_char': ' ', ...}\n\n    def build_filter_stack(stack, options):\n        if options.get('keyword_case') == 'uppercase':\n            stack.append(uppercase_keyword_filter)\n        elif options.get('keyword_case') == 'lowercase':\n            stack.append(lowercase_keyword_filter)\n        if options.get('identifier_case') == 'uppercase':\n            stack.append(uppercase_identifier_filter)\n        elif options.get('identifier_case') == 'lowercase':\n            stack.append(lowercase_identifier_filter)\n        if options.get('string_truncation'):\n            stack.append(string_truncation_filter)\n        if options.get('spacing_around_operators'):\n            stack.append(spacing_around_operators_filter)\n        if options.get('strip_comments'):\n            stack.append(strip_comments_filter)\n        if options.get('strip_whitespace'):\n>           stack.append(strip_whitespace_filter)\nE           AttributeError: 'FilterStack' object has no attribute 'append'\n\nrepos\\sqlparse\\sqlparse\\formatter.py:113: AttributeError"", 'def test_issue90():\n        sql = (\'UPDATE ""gallery_photo"" SET ""owner_id"" = 4018, ""deleted_at"" = NULL,\'\n               \' ""width"" = NULL, ""height"" = NULL, ""rating_votes"" = 0,\'\n               \' ""rating_score"" = 0, ""thumbnail_width"" = NULL,\'\n               \' ""thumbnail_height"" = NULL, ""price"" = 1, ""description"" = NULL\')\n>       formatted = sqlparse.format(sql, reindent=True)\n\nrepos\\sqlparse\\tests\\test_regressions.py:198: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:57: in format\n    stack = formatter.build_filter_stack(stack, options)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nstack = <sqlparse.engine.filter_stack.FilterStack object at 0x0000025AB4F3AAD0>\noptions = {\'comma_first\': False, \'compact\': False, \'indent_after_first\': False, \'indent_char\': \' \', ...}\n\n    def build_filter_stack(stack, options):\n        if options.get(\'keyword_case\') == \'uppercase\':\n            stack.append(uppercase_keyword_filter)\n        elif options.get(\'keyword_case\') == \'lowercase\':\n            stack.append(lowercase_keyword_filter)\n        if options.get(\'identifier_case\') == \'uppercase\':\n            stack.append(uppercase_identifier_filter)\n        elif options.get(\'identifier_case\') == \'lowercase\':\n            stack.append(lowercase_identifier_filter)\n        if options.get(\'string_truncation\'):\n            stack.append(string_truncation_filter)\n        if options.get(\'spacing_around_operators\'):\n            stack.append(spacing_around_operators_filter)\n        if options.get(\'strip_comments\'):\n            stack.append(strip_comments_filter)\n        if options.get(\'strip_whitespace\'):\n>           stack.append(strip_whitespace_filter)\nE           AttributeError: \'FilterStack\' object has no attribute \'append\'\n\nrepos\\sqlparse\\sqlparse\\formatter.py:113: AttributeError', ""def test_except_formatting():\n        sql = 'SELECT 1 FROM foo WHERE 2 = 3 EXCEPT SELECT 2 FROM bar WHERE 1 = 2'\n>       formatted = sqlparse.format(sql, reindent=True)\n\nrepos\\sqlparse\\tests\\test_regressions.py:216: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:57: in format\n    stack = formatter.build_filter_stack(stack, options)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nstack = <sqlparse.engine.filter_stack.FilterStack object at 0x0000025AB4F3A490>\noptions = {'comma_first': False, 'compact': False, 'indent_after_first': False, 'indent_char': ' ', ...}\n\n    def build_filter_stack(stack, options):\n        if options.get('keyword_case') == 'uppercase':\n            stack.append(uppercase_keyword_filter)\n        elif options.get('keyword_case') == 'lowercase':\n            stack.append(lowercase_keyword_filter)\n        if options.get('identifier_case') == 'uppercase':\n            stack.append(uppercase_identifier_filter)\n        elif options.get('identifier_case') == 'lowercase':\n            stack.append(lowercase_identifier_filter)\n        if options.get('string_truncation'):\n            stack.append(string_truncation_filter)\n        if options.get('spacing_around_operators'):\n            stack.append(spacing_around_operators_filter)\n        if options.get('strip_comments'):\n            stack.append(strip_comments_filter)\n        if options.get('strip_whitespace'):\n>           stack.append(strip_whitespace_filter)\nE           AttributeError: 'FilterStack' object has no attribute 'append'\n\nrepos\\sqlparse\\sqlparse\\formatter.py:113: AttributeError"", ""def test_null_with_as():\n        sql = 'SELECT NULL AS c1, NULL AS c2 FROM t1'\n>       formatted = sqlparse.format(sql, reindent=True)\n\nrepos\\sqlparse\\tests\\test_regressions.py:230: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:57: in format\n    stack = formatter.build_filter_stack(stack, options)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nstack = <sqlparse.engine.filter_stack.FilterStack object at 0x0000025AB4F396D0>\noptions = {'comma_first': False, 'compact': False, 'indent_after_first': False, 'indent_char': ' ', ...}\n\n    def build_filter_stack(stack, options):\n        if options.get('keyword_case') == 'uppercase':\n            stack.append(uppercase_keyword_filter)\n        elif options.get('keyword_case') == 'lowercase':\n            stack.append(lowercase_keyword_filter)\n        if options.get('identifier_case') == 'uppercase':\n            stack.append(uppercase_identifier_filter)\n        elif options.get('identifier_case') == 'lowercase':\n            stack.append(lowercase_identifier_filter)\n        if options.get('string_truncation'):\n            stack.append(string_truncation_filter)\n        if options.get('spacing_around_operators'):\n            stack.append(spacing_around_operators_filter)\n        if options.get('strip_comments'):\n            stack.append(strip_comments_filter)\n        if options.get('strip_whitespace'):\n>           stack.append(strip_whitespace_filter)\nE           AttributeError: 'FilterStack' object has no attribute 'append'\n\nrepos\\sqlparse\\sqlparse\\formatter.py:113: AttributeError"", 'def test_issue213_leadingws():\n        sql = "" select * from foo""\n>       assert sqlparse.format(sql, strip_whitespace=True) == ""select * from foo""\n\nrepos\\sqlparse\\tests\\test_regressions.py:285: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:57: in format\n    stack = formatter.build_filter_stack(stack, options)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nstack = <sqlparse.engine.filter_stack.FilterStack object at 0x0000025AB4F3A350>\noptions = {\'comma_first\': False, \'compact\': False, \'indent_after_first\': False, \'indent_char\': \' \', ...}\n\n    def build_filter_stack(stack, options):\n        if options.get(\'keyword_case\') == \'uppercase\':\n            stack.append(uppercase_keyword_filter)\n        elif options.get(\'keyword_case\') == \'lowercase\':\n            stack.append(lowercase_keyword_filter)\n        if options.get(\'identifier_case\') == \'uppercase\':\n            stack.append(uppercase_identifier_filter)\n        elif options.get(\'identifier_case\') == \'lowercase\':\n            stack.append(lowercase_identifier_filter)\n        if options.get(\'string_truncation\'):\n            stack.append(string_truncation_filter)\n        if options.get(\'spacing_around_operators\'):\n            stack.append(spacing_around_operators_filter)\n        if options.get(\'strip_comments\'):\n            stack.append(strip_comments_filter)\n        if options.get(\'strip_whitespace\'):\n>           stack.append(strip_whitespace_filter)\nE           AttributeError: \'FilterStack\' object has no attribute \'append\'\n\nrepos\\sqlparse\\sqlparse\\formatter.py:113: AttributeError', ""def test_issue207_runaway_format():\n        sql = 'select 1 from (select 1 as one, 2 as two, 3 from dual) t0'\n>       p = sqlparse.format(sql, reindent=True)\n\nrepos\\sqlparse\\tests\\test_regressions.py:303: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:57: in format\n    stack = formatter.build_filter_stack(stack, options)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nstack = <sqlparse.engine.filter_stack.FilterStack object at 0x0000025AB4F3BED0>\noptions = {'comma_first': False, 'compact': False, 'indent_after_first': False, 'indent_char': ' ', ...}\n\n    def build_filter_stack(stack, options):\n        if options.get('keyword_case') == 'uppercase':\n            stack.append(uppercase_keyword_filter)\n        elif options.get('keyword_case') == 'lowercase':\n            stack.append(lowercase_keyword_filter)\n        if options.get('identifier_case') == 'uppercase':\n            stack.append(uppercase_identifier_filter)\n        elif options.get('identifier_case') == 'lowercase':\n            stack.append(lowercase_identifier_filter)\n        if options.get('string_truncation'):\n            stack.append(string_truncation_filter)\n        if options.get('spacing_around_operators'):\n            stack.append(spacing_around_operators_filter)\n        if options.get('strip_comments'):\n            stack.append(strip_comments_filter)\n        if options.get('strip_whitespace'):\n>           stack.append(strip_whitespace_filter)\nE           AttributeError: 'FilterStack' object has no attribute 'append'\n\nrepos\\sqlparse\\sqlparse\\formatter.py:113: AttributeError"", 'def test_issue315_utf8_by_default():\n        # Make sure the lexer can handle utf-8 string by default correctly\n        # digest = \'齐天大圣.カラフルな雲.사랑해요\'\n        # The digest contains Chinese, Japanese and Korean characters\n        # All in \'utf-8\' encoding.\n        digest = (\n            \'\\xe9\\xbd\\x90\\xe5\\xa4\\xa9\\xe5\\xa4\\xa7\\xe5\\x9c\\xa3.\'\n            \'\\xe3\\x82\\xab\\xe3\\x83\\xa9\\xe3\\x83\\x95\\xe3\\x83\\xab\\xe3\\x81\\xaa\\xe9\'\n            \'\\x9b\\xb2.\'\n            \'\\xec\\x82\\xac\\xeb\\x9e\\x91\\xed\\x95\\xb4\\xec\\x9a\\x94\'\n        )\n        sql = f""select * from foo where bar = \'{digest}\'""\n>       formatted = sqlparse.format(sql, reindent=True)\n\nrepos\\sqlparse\\tests\\test_regressions.py:340: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:57: in format\n    stack = formatter.build_filter_stack(stack, options)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nstack = <sqlparse.engine.filter_stack.FilterStack object at 0x0000025AB4F3B750>\noptions = {\'comma_first\': False, \'compact\': False, \'indent_after_first\': False, \'indent_char\': \' \', ...}\n\n    def build_filter_stack(stack, options):\n        if options.get(\'keyword_case\') == \'uppercase\':\n            stack.append(uppercase_keyword_filter)\n        elif options.get(\'keyword_case\') == \'lowercase\':\n            stack.append(lowercase_keyword_filter)\n        if options.get(\'identifier_case\') == \'uppercase\':\n            stack.append(uppercase_identifier_filter)\n        elif options.get(\'identifier_case\') == \'lowercase\':\n            stack.append(lowercase_identifier_filter)\n        if options.get(\'string_truncation\'):\n            stack.append(string_truncation_filter)\n        if options.get(\'spacing_around_operators\'):\n            stack.append(spacing_around_operators_filter)\n        if options.get(\'strip_comments\'):\n            stack.append(strip_comments_filter)\n        if options.get(\'strip_whitespace\'):\n>           stack.append(strip_whitespace_filter)\nE           AttributeError: \'FilterStack\' object has no attribute \'append\'\n\nrepos\\sqlparse\\sqlparse\\formatter.py:113: AttributeError', ""s = 'SELECT @min_price:=MIN(price), @max_price:=MAX(price) FROM shop;'\n\n    @pytest.mark.parametrize('s', [\n        'SELECT @min_price:=MIN(price), @max_price:=MAX(price) FROM shop;',\n        'SELECT @min_price:=MIN(price), @max_price:=MAX(price) FROM shop',\n    \n    ])\n    def test_issue359_index_error_assignments(s):\n        sqlparse.parse(s)\n>       sqlparse.format(s, strip_comments=True)\n\nrepos\\sqlparse\\tests\\test_regressions.py:365: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:57: in format\n    stack = formatter.build_filter_stack(stack, options)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nstack = <sqlparse.engine.filter_stack.FilterStack object at 0x0000025AB4F39450>\noptions = {'comma_first': False, 'compact': False, 'indent_after_first': False, 'indent_char': ' ', ...}\n\n    def build_filter_stack(stack, options):\n        if options.get('keyword_case') == 'uppercase':\n            stack.append(uppercase_keyword_filter)\n        elif options.get('keyword_case') == 'lowercase':\n            stack.append(lowercase_keyword_filter)\n        if options.get('identifier_case') == 'uppercase':\n            stack.append(uppercase_identifier_filter)\n        elif options.get('identifier_case') == 'lowercase':\n            stack.append(lowercase_identifier_filter)\n        if options.get('string_truncation'):\n            stack.append(string_truncation_filter)\n        if options.get('spacing_around_operators'):\n            stack.append(spacing_around_operators_filter)\n        if options.get('strip_comments'):\n>           stack.append(strip_comments_filter)\nE           AttributeError: 'FilterStack' object has no attribute 'append'\n\nrepos\\sqlparse\\sqlparse\\formatter.py:111: AttributeError"", ""s = 'SELECT @min_price:=MIN(price), @max_price:=MAX(price) FROM shop'\n\n    @pytest.mark.parametrize('s', [\n        'SELECT @min_price:=MIN(price), @max_price:=MAX(price) FROM shop;',\n        'SELECT @min_price:=MIN(price), @max_price:=MAX(price) FROM shop',\n    \n    ])\n    def test_issue359_index_error_assignments(s):\n        sqlparse.parse(s)\n>       sqlparse.format(s, strip_comments=True)\n\nrepos\\sqlparse\\tests\\test_regressions.py:365: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:57: in format\n    stack = formatter.build_filter_stack(stack, options)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nstack = <sqlparse.engine.filter_stack.FilterStack object at 0x0000025AB4F39310>\noptions = {'comma_first': False, 'compact': False, 'indent_after_first': False, 'indent_char': ' ', ...}\n\n    def build_filter_stack(stack, options):\n        if options.get('keyword_case') == 'uppercase':\n            stack.append(uppercase_keyword_filter)\n        elif options.get('keyword_case') == 'lowercase':\n            stack.append(lowercase_keyword_filter)\n        if options.get('identifier_case') == 'uppercase':\n            stack.append(uppercase_identifier_filter)\n        elif options.get('identifier_case') == 'lowercase':\n            stack.append(lowercase_identifier_filter)\n        if options.get('string_truncation'):\n            stack.append(string_truncation_filter)\n        if options.get('spacing_around_operators'):\n            stack.append(spacing_around_operators_filter)\n        if options.get('strip_comments'):\n>           stack.append(strip_comments_filter)\nE           AttributeError: 'FilterStack' object has no attribute 'append'\n\nrepos\\sqlparse\\sqlparse\\formatter.py:111: AttributeError"", ""def test_issue469_copy_as_psql_command():\n        formatted = sqlparse.format(\n            '\\\\copy select * from foo',\n            keyword_case='upper', identifier_case='capitalize')\n>       assert formatted == '\\\\copy SELECT * FROM Foo'\nE       AssertionError: assert '\\\\copy select * from foo' == '\\\\copy SELECT * FROM Foo'\nE         \nE         - \\copy SELECT * FROM Foo\nE         + \\copy select * from foo\n\nrepos\\sqlparse\\tests\\test_regressions.py:372: AssertionError"", ""def test_issue562_tzcasts():\n        # Test that whitespace between 'from' and 'bar' is retained\n>       formatted = sqlparse.format(\n            'SELECT f(HOUR from bar AT TIME ZONE \\'UTC\\') from foo', reindent=True\n        )\n\nrepos\\sqlparse\\tests\\test_regressions.py:410: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:57: in format\n    stack = formatter.build_filter_stack(stack, options)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nstack = <sqlparse.engine.filter_stack.FilterStack object at 0x0000025AB4F3A490>\noptions = {'comma_first': False, 'compact': False, 'indent_after_first': False, 'indent_char': ' ', ...}\n\n    def build_filter_stack(stack, options):\n        if options.get('keyword_case') == 'uppercase':\n            stack.append(uppercase_keyword_filter)\n        elif options.get('keyword_case') == 'lowercase':\n            stack.append(lowercase_keyword_filter)\n        if options.get('identifier_case') == 'uppercase':\n            stack.append(uppercase_identifier_filter)\n        elif options.get('identifier_case') == 'lowercase':\n            stack.append(lowercase_identifier_filter)\n        if options.get('string_truncation'):\n            stack.append(string_truncation_filter)\n        if options.get('spacing_around_operators'):\n            stack.append(spacing_around_operators_filter)\n        if options.get('strip_comments'):\n            stack.append(strip_comments_filter)\n        if options.get('strip_whitespace'):\n>           stack.append(strip_whitespace_filter)\nE           AttributeError: 'FilterStack' object has no attribute 'append'\n\nrepos\\sqlparse\\sqlparse\\formatter.py:113: AttributeError"", ""def test_as_in_parentheses_indents():\n        # did raise NoneType has no attribute is_group in _process_parentheses\n>       formatted = sqlparse.format('(as foo)', reindent=True)\n\nrepos\\sqlparse\\tests\\test_regressions.py:419: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:57: in format\n    stack = formatter.build_filter_stack(stack, options)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nstack = <sqlparse.engine.filter_stack.FilterStack object at 0x0000025AB4F3AD50>\noptions = {'comma_first': False, 'compact': False, 'indent_after_first': False, 'indent_char': ' ', ...}\n\n    def build_filter_stack(stack, options):\n        if options.get('keyword_case') == 'uppercase':\n            stack.append(uppercase_keyword_filter)\n        elif options.get('keyword_case') == 'lowercase':\n            stack.append(lowercase_keyword_filter)\n        if options.get('identifier_case') == 'uppercase':\n            stack.append(uppercase_identifier_filter)\n        elif options.get('identifier_case') == 'lowercase':\n            stack.append(lowercase_identifier_filter)\n        if options.get('string_truncation'):\n            stack.append(string_truncation_filter)\n        if options.get('spacing_around_operators'):\n            stack.append(spacing_around_operators_filter)\n        if options.get('strip_comments'):\n            stack.append(strip_comments_filter)\n        if options.get('strip_whitespace'):\n>           stack.append(strip_whitespace_filter)\nE           AttributeError: 'FilterStack' object has no attribute 'append'\n\nrepos\\sqlparse\\sqlparse\\formatter.py:113: AttributeError"", ""def test_format_invalid_where_clause():\n        # did raise ValueError\n>       formatted = sqlparse.format('where, foo', reindent=True)\n\nrepos\\sqlparse\\tests\\test_regressions.py:425: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:57: in format\n    stack = formatter.build_filter_stack(stack, options)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nstack = <sqlparse.engine.filter_stack.FilterStack object at 0x0000025AB52FC2D0>\noptions = {'comma_first': False, 'compact': False, 'indent_after_first': False, 'indent_char': ' ', ...}\n\n    def build_filter_stack(stack, options):\n        if options.get('keyword_case') == 'uppercase':\n            stack.append(uppercase_keyword_filter)\n        elif options.get('keyword_case') == 'lowercase':\n            stack.append(lowercase_keyword_filter)\n        if options.get('identifier_case') == 'uppercase':\n            stack.append(uppercase_identifier_filter)\n        elif options.get('identifier_case') == 'lowercase':\n            stack.append(lowercase_identifier_filter)\n        if options.get('string_truncation'):\n            stack.append(string_truncation_filter)\n        if options.get('spacing_around_operators'):\n            stack.append(spacing_around_operators_filter)\n        if options.get('strip_comments'):\n            stack.append(strip_comments_filter)\n        if options.get('strip_whitespace'):\n>           stack.append(strip_whitespace_filter)\nE           AttributeError: 'FilterStack' object has no attribute 'append'\n\nrepos\\sqlparse\\sqlparse\\formatter.py:113: AttributeError""]",sqlparse/build_filter_stack,LLM
sqlparse,group_arrays,"def group_arrays(tlist):
    sqlcls = (sql.SquareBrackets, sql.Identifier, sql.Function)
    ttypes = (T.Name, T.String.Symbol)

    def match(token):
        return isinstance(token, sql.SquareBrackets)

    def valid_prev(token):
        return imt(token, i=sqlcls, t=ttypes)

    def valid_next(token):
        return True

    def post(tlist, pidx, tidx, nidx):
        return (pidx, tidx)
    _group(tlist, sql.Identifier, match, valid_prev, valid_next, post, extend=True, recurse=False)",The goal of the function `group_arrays` is to organize a list of tokens into groups based on certain criteria. The function likely takes a list of tokens as input and then processes them to identify and group specific types of tokens together. The function may involve checking for certain token types or patterns within the list and then grouping them accordingly. This grouping process helps in organizing and structuring the tokens for further processing or analysis.,3,"def group_arrays(tlist):
    grouped_tokens = {}
    
    for token in tlist:
        token_type = type(token).__name__
        
        if token_type not in grouped_tokens:
            grouped_tokens[token_type] = []
        
        grouped_tokens[token_type].append(token)
    
    return grouped_tokens","['./repos/sqlparse\\tests', './repos/sqlparse\\tests\\test_cli.py::test_cli_main_empty', './repos/sqlparse\\tests\\test_cli.py::test_parser_empty', './repos/sqlparse\\tests\\test_cli.py::test_main_help', './repos/sqlparse\\tests\\test_cli.py::test_valid_args', './repos/sqlparse\\tests\\test_cli.py::test_invalid_choice', './repos/sqlparse\\tests\\test_cli.py::test_invalid_args', './repos/sqlparse\\tests\\test_cli.py::test_invalid_infile', './repos/sqlparse\\tests\\test_cli.py::test_invalid_outfile', './repos/sqlparse\\tests\\test_cli.py::test_stdout', './repos/sqlparse\\tests\\test_cli.py::test_script', './repos/sqlparse\\tests\\test_cli.py::test_encoding_stdout', './repos/sqlparse\\tests\\test_cli.py::test_encoding_output_file', './repos/sqlparse\\tests\\test_cli.py::test_encoding_stdin', './repos/sqlparse\\tests\\test_cli.py::test_encoding', './repos/sqlparse\\tests\\test_format.py::test_format_column_ordering', './repos/sqlparse\\tests\\test_format.py::test_truncate_strings', './repos/sqlparse\\tests\\test_format.py::test_truncate_strings_invalid_option2', './repos/sqlparse\\tests\\test_format.py::test_truncate_strings_doesnt_truncate_identifiers', './repos/sqlparse\\tests\\test_format.py::test_having_produces_newline', './repos/sqlparse\\tests\\test_format.py::test_format_right_margin_invalid_option', './repos/sqlparse\\tests\\test_format.py::test_format_right_margin', './repos/sqlparse\\tests\\test_format.py::test_format_json_ops', './repos/sqlparse\\tests\\test_format.py::test_compact', './repos/sqlparse\\tests\\test_format.py::test_strip_ws_removes_trailing_ws_in_groups', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_parenthesis', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_assignment', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_typed_literal', './repos/sqlparse\\tests\\test_grouping.py::test_compare_expr', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifiers', './repos/sqlparse\\tests\\test_grouping.py::test_simple_identifiers', './repos/sqlparse\\tests\\test_grouping.py::test_group_identifier_list', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifier_wildcard', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifier_name_wildcard', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifier_invalid', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifier_invalid_in_middle', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifer_as', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifier_as_invalid', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifier_function', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_operation', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifier_list', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifier_list_subquery', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifier_list_case', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifier_list_other', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifier_list_with_inline_comments', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifiers_with_operators', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifier_list_with_order', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_nested_identifier_with_order', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_where', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_where_union', './repos/sqlparse\\tests\\test_grouping.py::test_returning_kw_ends_where_clause', './repos/sqlparse\\tests\\test_grouping.py::test_into_kw_ends_where_clause', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_typecast', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_alias', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_alias_case', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_alias_ctas', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_subquery_no_parens', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_alias_returns_none', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_idlist_function', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_comparison_exclude', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_function', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_function_not_in', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_varchar', './repos/sqlparse\\tests\\test_grouping.py::test_statement_get_type', './repos/sqlparse\\tests\\test_grouping.py::test_identifier_with_operators', './repos/sqlparse\\tests\\test_grouping.py::test_identifier_with_op_trailing_ws', './repos/sqlparse\\tests\\test_grouping.py::test_identifier_with_string_literals', './repos/sqlparse\\tests\\test_grouping.py::test_identifier_consumes_ordering', './repos/sqlparse\\tests\\test_grouping.py::test_comparison_with_keywords', './repos/sqlparse\\tests\\test_grouping.py::test_comparison_with_floats', './repos/sqlparse\\tests\\test_grouping.py::test_comparison_with_parenthesis', './repos/sqlparse\\tests\\test_grouping.py::test_comparison_with_strings', './repos/sqlparse\\tests\\test_grouping.py::test_like_and_ilike_comparison', './repos/sqlparse\\tests\\test_grouping.py::test_comparison_with_functions', './repos/sqlparse\\tests\\test_grouping.py::test_comparison_with_typed_literal', './repos/sqlparse\\tests\\test_grouping.py::test_forloops', './repos/sqlparse\\tests\\test_grouping.py::test_nested_for', './repos/sqlparse\\tests\\test_grouping.py::test_begin', './repos/sqlparse\\tests\\test_grouping.py::test_keyword_followed_by_parenthesis', './repos/sqlparse\\tests\\test_grouping.py::test_nested_begin', './repos/sqlparse\\tests\\test_grouping.py::test_aliased_column_without_as', './repos/sqlparse\\tests\\test_grouping.py::test_qualified_function', './repos/sqlparse\\tests\\test_grouping.py::test_aliased_function_without_as', './repos/sqlparse\\tests\\test_grouping.py::test_aliased_literal_without_as', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_as_cte', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_create_table', './repos/sqlparse\\tests\\test_parse.py::test_parse_tokenize', './repos/sqlparse\\tests\\test_parse.py::test_parse_multistatement', './repos/sqlparse\\tests\\test_parse.py::test_parse_newlines', './repos/sqlparse\\tests\\test_parse.py::test_parse_within', './repos/sqlparse\\tests\\test_parse.py::test_parse_child_of', './repos/sqlparse\\tests\\test_parse.py::test_parse_has_ancestor', './repos/sqlparse\\tests\\test_parse.py::test_parse_float', './repos/sqlparse\\tests\\test_parse.py::test_parse_placeholder', './repos/sqlparse\\tests\\test_parse.py::test_parse_modulo_not_placeholder', './repos/sqlparse\\tests\\test_parse.py::test_parse_access_symbol', './repos/sqlparse\\tests\\test_parse.py::test_parse_square_brackets_notation_isnt_too_greedy', './repos/sqlparse\\tests\\test_parse.py::test_parse_square_brackets_notation_isnt_too_greedy2', './repos/sqlparse\\tests\\test_parse.py::test_parse_keyword_like_identifier', './repos/sqlparse\\tests\\test_parse.py::test_parse_function_parameter', './repos/sqlparse\\tests\\test_parse.py::test_parse_function_param_single_literal', './repos/sqlparse\\tests\\test_parse.py::test_parse_nested_function', './repos/sqlparse\\tests\\test_parse.py::test_parse_casted_params', './repos/sqlparse\\tests\\test_parse.py::test_parse_div_operator', './repos/sqlparse\\tests\\test_parse.py::test_quoted_identifier', './repos/sqlparse\\tests\\test_parse.py::test_valid_identifier_names', './repos/sqlparse\\tests\\test_parse.py::test_psql_quotation_marks', './repos/sqlparse\\tests\\test_parse.py::test_double_precision_is_builtin', './repos/sqlparse\\tests\\test_parse.py::test_placeholder', './repos/sqlparse\\tests\\test_parse.py::test_scientific_numbers', './repos/sqlparse\\tests\\test_parse.py::test_single_quotes_are_strings', './repos/sqlparse\\tests\\test_parse.py::test_double_quotes_are_identifiers', './repos/sqlparse\\tests\\test_parse.py::test_single_quotes_with_linebreaks', './repos/sqlparse\\tests\\test_parse.py::test_sqlite_identifiers', './repos/sqlparse\\tests\\test_parse.py::test_simple_1d_array_index', './repos/sqlparse\\tests\\test_parse.py::test_2d_array_index', './repos/sqlparse\\tests\\test_parse.py::test_array_index_function_result', './repos/sqlparse\\tests\\test_parse.py::test_schema_qualified_array_index', './repos/sqlparse\\tests\\test_parse.py::test_aliased_array_index', './repos/sqlparse\\tests\\test_parse.py::test_array_literal', './repos/sqlparse\\tests\\test_parse.py::test_typed_array_definition', './repos/sqlparse\\tests\\test_parse.py::test_single_line_comments', './repos/sqlparse\\tests\\test_parse.py::test_names_and_special_names', './repos/sqlparse\\tests\\test_parse.py::test_get_token_at_offset', './repos/sqlparse\\tests\\test_parse.py::test_pprint', './repos/sqlparse\\tests\\test_parse.py::test_wildcard_multiplication', './repos/sqlparse\\tests\\test_parse.py::test_stmt_tokens_parents', './repos/sqlparse\\tests\\test_parse.py::test_dbldollar_as_literal', './repos/sqlparse\\tests\\test_parse.py::test_non_ascii', './repos/sqlparse\\tests\\test_parse.py::test_get_real_name', './repos/sqlparse\\tests\\test_parse.py::test_from_subquery', './repos/sqlparse\\tests\\test_parse.py::test_parenthesis', './repos/sqlparse\\tests\\test_parse.py::test_configurable_keywords', './repos/sqlparse\\tests\\test_parse.py::test_configurable_regex', './repos/sqlparse\\tests\\test_parse.py::test_json_operators', './repos/sqlparse\\tests\\test_regressions.py::test_issue9', './repos/sqlparse\\tests\\test_regressions.py::test_issue13', './repos/sqlparse\\tests\\test_regressions.py::test_issue26', './repos/sqlparse\\tests\\test_regressions.py::test_issue34', './repos/sqlparse\\tests\\test_regressions.py::test_issue35', './repos/sqlparse\\tests\\test_regressions.py::test_issue38', './repos/sqlparse\\tests\\test_regressions.py::test_issue39', './repos/sqlparse\\tests\\test_regressions.py::test_issue40', './repos/sqlparse\\tests\\test_regressions.py::test_issue78', './repos/sqlparse\\tests\\test_regressions.py::test_issue83', './repos/sqlparse\\tests\\test_regressions.py::test_comment_encoding_when_reindent', './repos/sqlparse\\tests\\test_regressions.py::test_parse_sql_with_binary', './repos/sqlparse\\tests\\test_regressions.py::test_dont_alias_keywords', './repos/sqlparse\\tests\\test_regressions.py::test_format_accepts_encoding', './repos/sqlparse\\tests\\test_regressions.py::test_stream', './repos/sqlparse\\tests\\test_regressions.py::test_issue90', './repos/sqlparse\\tests\\test_regressions.py::test_except_formatting', './repos/sqlparse\\tests\\test_regressions.py::test_null_with_as', './repos/sqlparse\\tests\\test_regressions.py::test_issue190_open_file', './repos/sqlparse\\tests\\test_regressions.py::test_issue193_splitting_function', './repos/sqlparse\\tests\\test_regressions.py::test_issue194_splitting_function', './repos/sqlparse\\tests\\test_regressions.py::test_issue186_get_type', './repos/sqlparse\\tests\\test_regressions.py::test_issue212_py2unicode', './repos/sqlparse\\tests\\test_regressions.py::test_issue213_leadingws', './repos/sqlparse\\tests\\test_regressions.py::test_issue227_gettype_cte', './repos/sqlparse\\tests\\test_regressions.py::test_issue207_runaway_format', './repos/sqlparse\\tests\\test_regressions.py::test_token_next_doesnt_ignore_skip_cm', './repos/sqlparse\\tests\\test_regressions.py::test_issue284_as_grouping', './repos/sqlparse\\tests\\test_regressions.py::test_issue315_utf8_by_default', './repos/sqlparse\\tests\\test_regressions.py::test_issue322_concurrently_is_keyword', './repos/sqlparse\\tests\\test_regressions.py::test_issue359_index_error_assignments', './repos/sqlparse\\tests\\test_regressions.py::test_issue469_copy_as_psql_command', './repos/sqlparse\\tests\\test_regressions.py::test_issue484_comments_and_newlines', './repos/sqlparse\\tests\\test_regressions.py::test_issue485_split_multi', './repos/sqlparse\\tests\\test_regressions.py::test_issue489_tzcasts', './repos/sqlparse\\tests\\test_regressions.py::test_issue562_tzcasts', './repos/sqlparse\\tests\\test_regressions.py::test_as_in_parentheses_indents', './repos/sqlparse\\tests\\test_regressions.py::test_format_invalid_where_clause', './repos/sqlparse\\tests\\test_regressions.py::test_splitting_at_and_backticks_issue588', './repos/sqlparse\\tests\\test_regressions.py::test_comment_between_cte_clauses_issue632', './repos/sqlparse\\tests\\test_regressions.py::test_copy_issue672', './repos/sqlparse\\tests\\test_regressions.py::test_primary_key_issue740', './repos/sqlparse\\tests\\test_regressions.py::test_max_recursion', './repos/sqlparse\\tests\\test_split.py::test_split_semicolon', './repos/sqlparse\\tests\\test_split.py::test_split_backslash', './repos/sqlparse\\tests\\test_split.py::test_split_create_function', './repos/sqlparse\\tests\\test_split.py::test_split_dashcomments', './repos/sqlparse\\tests\\test_split.py::test_split_dashcomments_eol', './repos/sqlparse\\tests\\test_split.py::test_split_begintag', './repos/sqlparse\\tests\\test_split.py::test_split_begintag_2', './repos/sqlparse\\tests\\test_split.py::test_split_dropif', './repos/sqlparse\\tests\\test_split.py::test_split_comment_with_umlaut', './repos/sqlparse\\tests\\test_split.py::test_split_comment_end_of_line', './repos/sqlparse\\tests\\test_split.py::test_split_casewhen', './repos/sqlparse\\tests\\test_split.py::test_split_casewhen_procedure', './repos/sqlparse\\tests\\test_split.py::test_split_cursor_declare', './repos/sqlparse\\tests\\test_split.py::test_split_if_function', './repos/sqlparse\\tests\\test_split.py::test_split_stream', './repos/sqlparse\\tests\\test_split.py::test_split_encoding_parsestream', './repos/sqlparse\\tests\\test_split.py::test_split_unicode_parsestream', './repos/sqlparse\\tests\\test_split.py::test_split_simple', './repos/sqlparse\\tests\\test_split.py::test_split_ignores_empty_newlines', './repos/sqlparse\\tests\\test_split.py::test_split_quotes_with_new_line', './repos/sqlparse\\tests\\test_split.py::test_split_mysql_handler_for', './repos/sqlparse\\tests\\test_split.py::test_split_strip_semicolon', './repos/sqlparse\\tests\\test_split.py::test_split_strip_semicolon_procedure', './repos/sqlparse\\tests\\test_split.py::test_split_go', './repos/sqlparse\\tests\\test_split.py::test_split_multiple_case_in_begin', './repos/sqlparse\\tests\\test_tokenize.py::test_tokenize_simple', './repos/sqlparse\\tests\\test_tokenize.py::test_tokenize_backticks', './repos/sqlparse\\tests\\test_tokenize.py::test_tokenize_linebreaks', './repos/sqlparse\\tests\\test_tokenize.py::test_tokenize_inline_keywords', './repos/sqlparse\\tests\\test_tokenize.py::test_tokenize_negative_numbers', './repos/sqlparse\\tests\\test_tokenize.py::test_token_str', './repos/sqlparse\\tests\\test_tokenize.py::test_token_repr', './repos/sqlparse\\tests\\test_tokenize.py::test_token_flatten', './repos/sqlparse\\tests\\test_tokenize.py::test_tokenlist_repr', './repos/sqlparse\\tests\\test_tokenize.py::test_single_quotes', './repos/sqlparse\\tests\\test_tokenize.py::test_tokenlist_first', './repos/sqlparse\\tests\\test_tokenize.py::test_tokenlist_token_matching', './repos/sqlparse\\tests\\test_tokenize.py::test_stream_simple', './repos/sqlparse\\tests\\test_tokenize.py::test_stream_error', './repos/sqlparse\\tests\\test_tokenize.py::test_parse_join', './repos/sqlparse\\tests\\test_tokenize.py::test_parse_union', './repos/sqlparse\\tests\\test_tokenize.py::test_parse_endifloop', './repos/sqlparse\\tests\\test_tokenize.py::test_parse_order', './repos/sqlparse\\tests\\test_tokenize.py::test_parse_identifiers', './repos/sqlparse\\tests\\test_tokenize.py::test_parse_group_by', './repos/sqlparse\\tests\\test_tokenize.py::test_parse_order_by', './repos/sqlparse\\tests\\test_tokenize.py::test_parse_window_as', './repos/sqlparse\\tests\\test_tokenize.py::test_like_and_ilike_parsed_as_comparisons', './repos/sqlparse\\tests\\test_tokenize.py::test_near_like_and_ilike_parsed_appropriately', './repos/sqlparse\\tests\\test_tokenize.py::test_parse_tzcast', './repos/sqlparse\\tests\\test_tokenize.py::test_cli_commands', './repos/sqlparse\\tests\\test_utils.py::test_remove_quotes']","456 Passed, 5 Failed",456,5,"['tests/test_parse.py::test_simple_1d_array_index', 'tests/test_parse.py::test_2d_array_index', 'tests/test_parse.py::test_array_index_function_result', 'tests/test_parse.py::test_schema_qualified_array_index', 'tests/test_parse.py::test_aliased_array_index']","[""def test_simple_1d_array_index():\n        p = sqlparse.parse('col[1]')[0].tokens\n>       assert len(p) == 1\nE       AssertionError: assert 2 == 1\nE        +  where 2 = len([<Identifier 'col' at 0x24357CB81D0>, <SquareBrackets '[1]' at 0x24357CB8150>])\n\nrepos\\sqlparse\\tests\\test_parse.py:258: AssertionError"", ""def test_2d_array_index():\n        p = sqlparse.parse('col[x][(y+1)*2]')[0].tokens\n>       assert len(p) == 1\nE       AssertionError: assert 3 == 1\nE        +  where 3 = len([<Identifier 'col' at 0x24357D08BD0>, <SquareBrackets '[x]' at 0x24357D09AD0>, <SquareBrackets '[(y+1)...' at 0x24357D094D0>])\n\nrepos\\sqlparse\\tests\\test_parse.py:268: AssertionError"", ""def test_array_index_function_result():\n        p = sqlparse.parse('somefunc()[1]')[0].tokens\n>       assert len(p) == 1\nE       AssertionError: assert 2 == 1\nE        +  where 2 = len([<Function 'somefu...' at 0x24357B7F4D0>, <SquareBrackets '[1]' at 0x24357B7F9D0>])\n\nrepos\\sqlparse\\tests\\test_parse.py:275: AssertionError"", ""def test_schema_qualified_array_index():\n        p = sqlparse.parse('schem.col[1]')[0].tokens\n>       assert len(p) == 1\nE       AssertionError: assert 2 == 1\nE        +  where 2 = len([<Identifier 'schem....' at 0x24357D0A8D0>, <SquareBrackets '[1]' at 0x24357D0B0D0>])\n\nrepos\\sqlparse\\tests\\test_parse.py:281: AssertionError"", ""def test_aliased_array_index():\n        p = sqlparse.parse('col[1] x')[0].tokens\n>       assert len(p) == 1\nE       AssertionError: assert 4 == 1\nE        +  where 4 = len([<Identifier 'col' at 0x2435783BED0>, <SquareBrackets '[1]' at 0x2435783BC50>, <Whitespace ' ' at 0x24357B46800>, <Identifier 'x' at 0x2435783BE50>])\n\nrepos\\sqlparse\\tests\\test_parse.py:289: AssertionError""]",sqlparse/group_arrays,LLM
sqlparse,group_functions,"@recurse(sql.Function)
def group_functions(tlist):
    has_create = False
    has_table = False
    has_as = False
    for tmp_token in tlist.tokens:
        if tmp_token.value.upper() == 'CREATE':
            has_create = True
        if tmp_token.value.upper() == 'TABLE':
            has_table = True
        if tmp_token.value == 'AS':
            has_as = True
    if has_create and has_table and (not has_as):
        return
    tidx, token = tlist.token_next_by(t=T.Name)
    while token:
        nidx, next_ = tlist.token_next(tidx)
        if isinstance(next_, sql.Parenthesis):
            over_idx, over = tlist.token_next(nidx)
            if over and isinstance(over, sql.Over):
                eidx = over_idx
            else:
                eidx = nidx
            tlist.group_tokens(sql.Function, tidx, eidx)
        tidx, token = tlist.token_next_by(t=T.Name, idx=tidx)","The goal of this function is to group together SQL functions in a list of tokens, based on certain conditions such as the presence of keywords like 'CREATE', 'TABLE', and 'AS'. It iterates through the tokens in the list and groups together consecutive function tokens that are followed by parentheses, potentially separating them from other tokens in the list. This function helps in organizing and parsing SQL statements by identifying and grouping related function components.",1,"def group_functions(tlist):
    grouped_functions = []
    current_group = []

    for i, token in enumerate(tlist):
        current_group.append(token)

        if token == 'CREATE' or token == 'TABLE' or token == 'AS':
            if i+1 < len(tlist) and tlist[i+1] == '(':
                grouped_functions.append(current_group)
                current_group = []

    if current_group:
        grouped_functions.append(current_group)

    return grouped_functions","['./repos/sqlparse\\tests', './repos/sqlparse\\tests\\test_cli.py::test_cli_main_empty', './repos/sqlparse\\tests\\test_cli.py::test_parser_empty', './repos/sqlparse\\tests\\test_cli.py::test_main_help', './repos/sqlparse\\tests\\test_cli.py::test_valid_args', './repos/sqlparse\\tests\\test_cli.py::test_invalid_choice', './repos/sqlparse\\tests\\test_cli.py::test_invalid_args', './repos/sqlparse\\tests\\test_cli.py::test_invalid_infile', './repos/sqlparse\\tests\\test_cli.py::test_invalid_outfile', './repos/sqlparse\\tests\\test_cli.py::test_stdout', './repos/sqlparse\\tests\\test_cli.py::test_script', './repos/sqlparse\\tests\\test_cli.py::test_encoding_stdout', './repos/sqlparse\\tests\\test_cli.py::test_encoding_output_file', './repos/sqlparse\\tests\\test_cli.py::test_encoding_stdin', './repos/sqlparse\\tests\\test_cli.py::test_encoding', './repos/sqlparse\\tests\\test_format.py::test_format_column_ordering', './repos/sqlparse\\tests\\test_format.py::test_truncate_strings', './repos/sqlparse\\tests\\test_format.py::test_truncate_strings_invalid_option2', './repos/sqlparse\\tests\\test_format.py::test_truncate_strings_doesnt_truncate_identifiers', './repos/sqlparse\\tests\\test_format.py::test_having_produces_newline', './repos/sqlparse\\tests\\test_format.py::test_format_right_margin_invalid_option', './repos/sqlparse\\tests\\test_format.py::test_format_right_margin', './repos/sqlparse\\tests\\test_format.py::test_format_json_ops', './repos/sqlparse\\tests\\test_format.py::test_compact', './repos/sqlparse\\tests\\test_format.py::test_strip_ws_removes_trailing_ws_in_groups', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_parenthesis', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_assignment', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_typed_literal', './repos/sqlparse\\tests\\test_grouping.py::test_compare_expr', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifiers', './repos/sqlparse\\tests\\test_grouping.py::test_simple_identifiers', './repos/sqlparse\\tests\\test_grouping.py::test_group_identifier_list', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifier_wildcard', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifier_name_wildcard', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifier_invalid', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifier_invalid_in_middle', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifer_as', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifier_as_invalid', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifier_function', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_operation', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifier_list', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifier_list_subquery', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifier_list_case', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifier_list_other', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifier_list_with_inline_comments', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifiers_with_operators', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifier_list_with_order', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_nested_identifier_with_order', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_where', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_where_union', './repos/sqlparse\\tests\\test_grouping.py::test_returning_kw_ends_where_clause', './repos/sqlparse\\tests\\test_grouping.py::test_into_kw_ends_where_clause', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_typecast', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_alias', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_alias_case', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_alias_ctas', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_subquery_no_parens', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_alias_returns_none', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_idlist_function', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_comparison_exclude', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_function', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_function_not_in', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_varchar', './repos/sqlparse\\tests\\test_grouping.py::test_statement_get_type', './repos/sqlparse\\tests\\test_grouping.py::test_identifier_with_operators', './repos/sqlparse\\tests\\test_grouping.py::test_identifier_with_op_trailing_ws', './repos/sqlparse\\tests\\test_grouping.py::test_identifier_with_string_literals', './repos/sqlparse\\tests\\test_grouping.py::test_identifier_consumes_ordering', './repos/sqlparse\\tests\\test_grouping.py::test_comparison_with_keywords', './repos/sqlparse\\tests\\test_grouping.py::test_comparison_with_floats', './repos/sqlparse\\tests\\test_grouping.py::test_comparison_with_parenthesis', './repos/sqlparse\\tests\\test_grouping.py::test_comparison_with_strings', './repos/sqlparse\\tests\\test_grouping.py::test_like_and_ilike_comparison', './repos/sqlparse\\tests\\test_grouping.py::test_comparison_with_functions', './repos/sqlparse\\tests\\test_grouping.py::test_comparison_with_typed_literal', './repos/sqlparse\\tests\\test_grouping.py::test_forloops', './repos/sqlparse\\tests\\test_grouping.py::test_nested_for', './repos/sqlparse\\tests\\test_grouping.py::test_begin', './repos/sqlparse\\tests\\test_grouping.py::test_keyword_followed_by_parenthesis', './repos/sqlparse\\tests\\test_grouping.py::test_nested_begin', './repos/sqlparse\\tests\\test_grouping.py::test_aliased_column_without_as', './repos/sqlparse\\tests\\test_grouping.py::test_qualified_function', './repos/sqlparse\\tests\\test_grouping.py::test_aliased_function_without_as', './repos/sqlparse\\tests\\test_grouping.py::test_aliased_literal_without_as', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_as_cte', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_create_table', './repos/sqlparse\\tests\\test_parse.py::test_parse_tokenize', './repos/sqlparse\\tests\\test_parse.py::test_parse_multistatement', './repos/sqlparse\\tests\\test_parse.py::test_parse_newlines', './repos/sqlparse\\tests\\test_parse.py::test_parse_within', './repos/sqlparse\\tests\\test_parse.py::test_parse_child_of', './repos/sqlparse\\tests\\test_parse.py::test_parse_has_ancestor', './repos/sqlparse\\tests\\test_parse.py::test_parse_float', './repos/sqlparse\\tests\\test_parse.py::test_parse_placeholder', './repos/sqlparse\\tests\\test_parse.py::test_parse_modulo_not_placeholder', './repos/sqlparse\\tests\\test_parse.py::test_parse_access_symbol', './repos/sqlparse\\tests\\test_parse.py::test_parse_square_brackets_notation_isnt_too_greedy', './repos/sqlparse\\tests\\test_parse.py::test_parse_square_brackets_notation_isnt_too_greedy2', './repos/sqlparse\\tests\\test_parse.py::test_parse_keyword_like_identifier', './repos/sqlparse\\tests\\test_parse.py::test_parse_function_parameter', './repos/sqlparse\\tests\\test_parse.py::test_parse_function_param_single_literal', './repos/sqlparse\\tests\\test_parse.py::test_parse_nested_function', './repos/sqlparse\\tests\\test_parse.py::test_parse_casted_params', './repos/sqlparse\\tests\\test_parse.py::test_parse_div_operator', './repos/sqlparse\\tests\\test_parse.py::test_quoted_identifier', './repos/sqlparse\\tests\\test_parse.py::test_valid_identifier_names', './repos/sqlparse\\tests\\test_parse.py::test_psql_quotation_marks', './repos/sqlparse\\tests\\test_parse.py::test_double_precision_is_builtin', './repos/sqlparse\\tests\\test_parse.py::test_placeholder', './repos/sqlparse\\tests\\test_parse.py::test_scientific_numbers', './repos/sqlparse\\tests\\test_parse.py::test_single_quotes_are_strings', './repos/sqlparse\\tests\\test_parse.py::test_double_quotes_are_identifiers', './repos/sqlparse\\tests\\test_parse.py::test_single_quotes_with_linebreaks', './repos/sqlparse\\tests\\test_parse.py::test_sqlite_identifiers', './repos/sqlparse\\tests\\test_parse.py::test_simple_1d_array_index', './repos/sqlparse\\tests\\test_parse.py::test_2d_array_index', './repos/sqlparse\\tests\\test_parse.py::test_array_index_function_result', './repos/sqlparse\\tests\\test_parse.py::test_schema_qualified_array_index', './repos/sqlparse\\tests\\test_parse.py::test_aliased_array_index', './repos/sqlparse\\tests\\test_parse.py::test_array_literal', './repos/sqlparse\\tests\\test_parse.py::test_typed_array_definition', './repos/sqlparse\\tests\\test_parse.py::test_single_line_comments', './repos/sqlparse\\tests\\test_parse.py::test_names_and_special_names', './repos/sqlparse\\tests\\test_parse.py::test_get_token_at_offset', './repos/sqlparse\\tests\\test_parse.py::test_pprint', './repos/sqlparse\\tests\\test_parse.py::test_wildcard_multiplication', './repos/sqlparse\\tests\\test_parse.py::test_stmt_tokens_parents', './repos/sqlparse\\tests\\test_parse.py::test_dbldollar_as_literal', './repos/sqlparse\\tests\\test_parse.py::test_non_ascii', './repos/sqlparse\\tests\\test_parse.py::test_get_real_name', './repos/sqlparse\\tests\\test_parse.py::test_from_subquery', './repos/sqlparse\\tests\\test_parse.py::test_parenthesis', './repos/sqlparse\\tests\\test_parse.py::test_configurable_keywords', './repos/sqlparse\\tests\\test_parse.py::test_configurable_regex', './repos/sqlparse\\tests\\test_parse.py::test_json_operators', './repos/sqlparse\\tests\\test_regressions.py::test_issue9', './repos/sqlparse\\tests\\test_regressions.py::test_issue13', './repos/sqlparse\\tests\\test_regressions.py::test_issue26', './repos/sqlparse\\tests\\test_regressions.py::test_issue34', './repos/sqlparse\\tests\\test_regressions.py::test_issue35', './repos/sqlparse\\tests\\test_regressions.py::test_issue38', './repos/sqlparse\\tests\\test_regressions.py::test_issue39', './repos/sqlparse\\tests\\test_regressions.py::test_issue40', './repos/sqlparse\\tests\\test_regressions.py::test_issue78', './repos/sqlparse\\tests\\test_regressions.py::test_issue83', './repos/sqlparse\\tests\\test_regressions.py::test_comment_encoding_when_reindent', './repos/sqlparse\\tests\\test_regressions.py::test_parse_sql_with_binary', './repos/sqlparse\\tests\\test_regressions.py::test_dont_alias_keywords', './repos/sqlparse\\tests\\test_regressions.py::test_format_accepts_encoding', './repos/sqlparse\\tests\\test_regressions.py::test_stream', './repos/sqlparse\\tests\\test_regressions.py::test_issue90', './repos/sqlparse\\tests\\test_regressions.py::test_except_formatting', './repos/sqlparse\\tests\\test_regressions.py::test_null_with_as', './repos/sqlparse\\tests\\test_regressions.py::test_issue190_open_file', './repos/sqlparse\\tests\\test_regressions.py::test_issue193_splitting_function', './repos/sqlparse\\tests\\test_regressions.py::test_issue194_splitting_function', './repos/sqlparse\\tests\\test_regressions.py::test_issue186_get_type', './repos/sqlparse\\tests\\test_regressions.py::test_issue212_py2unicode', './repos/sqlparse\\tests\\test_regressions.py::test_issue213_leadingws', './repos/sqlparse\\tests\\test_regressions.py::test_issue227_gettype_cte', './repos/sqlparse\\tests\\test_regressions.py::test_issue207_runaway_format', './repos/sqlparse\\tests\\test_regressions.py::test_token_next_doesnt_ignore_skip_cm', './repos/sqlparse\\tests\\test_regressions.py::test_issue284_as_grouping', './repos/sqlparse\\tests\\test_regressions.py::test_issue315_utf8_by_default', './repos/sqlparse\\tests\\test_regressions.py::test_issue322_concurrently_is_keyword', './repos/sqlparse\\tests\\test_regressions.py::test_issue359_index_error_assignments', './repos/sqlparse\\tests\\test_regressions.py::test_issue469_copy_as_psql_command', './repos/sqlparse\\tests\\test_regressions.py::test_issue484_comments_and_newlines', './repos/sqlparse\\tests\\test_regressions.py::test_issue485_split_multi', './repos/sqlparse\\tests\\test_regressions.py::test_issue489_tzcasts', './repos/sqlparse\\tests\\test_regressions.py::test_issue562_tzcasts', './repos/sqlparse\\tests\\test_regressions.py::test_as_in_parentheses_indents', './repos/sqlparse\\tests\\test_regressions.py::test_format_invalid_where_clause', './repos/sqlparse\\tests\\test_regressions.py::test_splitting_at_and_backticks_issue588', './repos/sqlparse\\tests\\test_regressions.py::test_comment_between_cte_clauses_issue632', './repos/sqlparse\\tests\\test_regressions.py::test_copy_issue672', './repos/sqlparse\\tests\\test_regressions.py::test_primary_key_issue740', './repos/sqlparse\\tests\\test_regressions.py::test_max_recursion', './repos/sqlparse\\tests\\test_split.py::test_split_semicolon', './repos/sqlparse\\tests\\test_split.py::test_split_backslash', './repos/sqlparse\\tests\\test_split.py::test_split_create_function', './repos/sqlparse\\tests\\test_split.py::test_split_dashcomments', './repos/sqlparse\\tests\\test_split.py::test_split_dashcomments_eol', './repos/sqlparse\\tests\\test_split.py::test_split_begintag', './repos/sqlparse\\tests\\test_split.py::test_split_begintag_2', './repos/sqlparse\\tests\\test_split.py::test_split_dropif', './repos/sqlparse\\tests\\test_split.py::test_split_comment_with_umlaut', './repos/sqlparse\\tests\\test_split.py::test_split_comment_end_of_line', './repos/sqlparse\\tests\\test_split.py::test_split_casewhen', './repos/sqlparse\\tests\\test_split.py::test_split_casewhen_procedure', './repos/sqlparse\\tests\\test_split.py::test_split_cursor_declare', './repos/sqlparse\\tests\\test_split.py::test_split_if_function', './repos/sqlparse\\tests\\test_split.py::test_split_stream', './repos/sqlparse\\tests\\test_split.py::test_split_encoding_parsestream', './repos/sqlparse\\tests\\test_split.py::test_split_unicode_parsestream', './repos/sqlparse\\tests\\test_split.py::test_split_simple', './repos/sqlparse\\tests\\test_split.py::test_split_ignores_empty_newlines', './repos/sqlparse\\tests\\test_split.py::test_split_quotes_with_new_line', './repos/sqlparse\\tests\\test_split.py::test_split_mysql_handler_for', './repos/sqlparse\\tests\\test_split.py::test_split_strip_semicolon', './repos/sqlparse\\tests\\test_split.py::test_split_strip_semicolon_procedure', './repos/sqlparse\\tests\\test_split.py::test_split_go', './repos/sqlparse\\tests\\test_split.py::test_split_multiple_case_in_begin', './repos/sqlparse\\tests\\test_tokenize.py::test_tokenize_simple', './repos/sqlparse\\tests\\test_tokenize.py::test_tokenize_backticks', './repos/sqlparse\\tests\\test_tokenize.py::test_tokenize_linebreaks', './repos/sqlparse\\tests\\test_tokenize.py::test_tokenize_inline_keywords', './repos/sqlparse\\tests\\test_tokenize.py::test_tokenize_negative_numbers', './repos/sqlparse\\tests\\test_tokenize.py::test_token_str', './repos/sqlparse\\tests\\test_tokenize.py::test_token_repr', './repos/sqlparse\\tests\\test_tokenize.py::test_token_flatten', './repos/sqlparse\\tests\\test_tokenize.py::test_tokenlist_repr', './repos/sqlparse\\tests\\test_tokenize.py::test_single_quotes', './repos/sqlparse\\tests\\test_tokenize.py::test_tokenlist_first', './repos/sqlparse\\tests\\test_tokenize.py::test_tokenlist_token_matching', './repos/sqlparse\\tests\\test_tokenize.py::test_stream_simple', './repos/sqlparse\\tests\\test_tokenize.py::test_stream_error', './repos/sqlparse\\tests\\test_tokenize.py::test_parse_join', './repos/sqlparse\\tests\\test_tokenize.py::test_parse_union', './repos/sqlparse\\tests\\test_tokenize.py::test_parse_endifloop', './repos/sqlparse\\tests\\test_tokenize.py::test_parse_order', './repos/sqlparse\\tests\\test_tokenize.py::test_parse_identifiers', './repos/sqlparse\\tests\\test_tokenize.py::test_parse_group_by', './repos/sqlparse\\tests\\test_tokenize.py::test_parse_order_by', './repos/sqlparse\\tests\\test_tokenize.py::test_parse_window_as', './repos/sqlparse\\tests\\test_tokenize.py::test_like_and_ilike_parsed_as_comparisons', './repos/sqlparse\\tests\\test_tokenize.py::test_near_like_and_ilike_parsed_appropriately', './repos/sqlparse\\tests\\test_tokenize.py::test_parse_tzcast', './repos/sqlparse\\tests\\test_tokenize.py::test_cli_commands', './repos/sqlparse\\tests\\test_utils.py::test_remove_quotes']","439 Passed, 22 Failed",439,22,"['tests/test_format.py::TestFormatReindent::test_identifier_list_with_functions', 'tests/test_format.py::TestFormatReindent::test_long_identifier_list_with_functions', 'tests/test_format.py::TestFormatReindent::test_keywordfunctions', 'tests/test_format.py::TestFormatReindent::test_insert_values', 'tests/test_grouping.py::test_grouping_identifiers', 'tests/test_grouping.py::test_group_identifier_list[sum(a), sum(b)]', 'tests/test_grouping.py::test_group_identifier_list[sum(a)/count(b) as x, y]', 'tests/test_grouping.py::test_group_identifier_list[sum(a)::integer/count(b) as x, y]', 'tests/test_grouping.py::test_grouping_identifier_function', 'tests/test_grouping.py::test_grouping_alias_ctas', 'tests/test_grouping.py::test_grouping_idlist_function', 'tests/test_grouping.py::test_grouping_function', 'tests/test_grouping.py::test_grouping_varchar', 'tests/test_grouping.py::test_comparison_with_functions', 'tests/test_grouping.py::test_aliased_function_without_as', 'tests/test_parse.py::test_parse_within', 'tests/test_parse.py::test_parse_function_parameter', 'tests/test_parse.py::test_parse_function_param_single_literal', 'tests/test_parse.py::test_parse_nested_function', 'tests/test_parse.py::test_parse_casted_params', 'tests/test_parse.py::test_array_index_function_result', 'tests/test_regressions.py::test_issue322_concurrently_is_keyword']","['self = <tests.test_format.TestFormatReindent object at 0x000001F038D9E5D0>\n\n    def test_identifier_list_with_functions(self):\n        f = lambda sql: sqlparse.format(sql, reindent=True)\n        s = (""select \'abc\' as foo, coalesce(col1, col2)||col3 as bar,""\n             ""col3 from my_table"")\n>       assert f(s) == \'\\n\'.join([\n            ""select \'abc\' as foo,"",\n            ""       coalesce(col1, col2)||col3 as bar,"",\n            ""       col3"",\n            ""from my_table""])\nE       assert ""select \'abc\'...from my_table"" == ""select \'abc\'...from my_table""\nE         \nE           select \'abc\' as foo,\nE         -        coalesce(col1, col2)||col3 as bar,\nE         +        coalesce(col1,\nE         +                 col2)||col3 as bar,\nE                  col3\nE           from my_table\n\nrepos\\sqlparse\\tests\\test_format.py:508: AssertionError', 'self = <tests.test_format.TestFormatReindent object at 0x000001F038DEF150>\n\n    def test_long_identifier_list_with_functions(self):\n        f = lambda sql: sqlparse.format(sql, reindent=True, wrap_after=30)\n        s = (""select \'abc\' as foo, json_build_object(\'a\',  a,""\n             ""\'b\', b, \'c\', c, \'d\', d, \'e\', e) as col2""\n             ""col3 from my_table"")\n>       assert f(s) == \'\\n\'.join([\n            ""select \'abc\' as foo,"",\n            ""       json_build_object(\'a\',"",\n            ""         a, \'b\', b, \'c\', c, \'d\', d,"",\n            ""         \'e\', e) as col2col3"",\n            ""from my_table""])\nE       assert ""select \'abc\'...from my_table"" == ""select \'abc\'...from my_table""\nE         \nE           select \'abc\' as foo,\nE         -        json_build_object(\'a\',\nE         +        json_build_object(\'a\', a,\nE         ?                              +++\nE         -          a, \'b\', b, \'c\', c, \'d\', d,\nE         +                          \'b\', b,...\nE         \nE         ...Full output truncated (6 lines hidden), use \'-vv\' to show\n\nrepos\\sqlparse\\tests\\test_format.py:519: AssertionError', ""self = <tests.test_format.TestFormatReindent object at 0x000001F038D99910>\n\n    def test_keywordfunctions(self):\n        # issue36\n        f = lambda sql: sqlparse.format(sql, reindent=True)\n        s = 'select max(a) b, foo, bar'\n>       assert f(s) == '\\n'.join([\n            'select max(a) b,',\n            '       foo,',\n            '       bar'])\nE       AssertionError: assert 'select max(a...          bar' == 'select max(a...,\\n       bar'\nE         \nE           select max(a) b,\nE         -        foo,\nE         +           foo,\nE         ? +++\nE         -        bar\nE         +           bar\nE         ? +++\n\nrepos\\sqlparse\\tests\\test_format.py:583: AssertionError"", ""self = <tests.test_format.TestFormatReindent object at 0x000001F038E2A990>\n\n    def test_insert_values(self):\n        # issue 329\n        f = lambda sql: sqlparse.format(sql, reindent=True)\n        s = 'insert into foo values (1, 2)'\n        assert f(s) == '\\n'.join([\n            'insert into foo',\n            'values (1, 2)'])\n    \n        s = 'insert into foo values (1, 2), (3, 4), (5, 6)'\n        assert f(s) == '\\n'.join([\n            'insert into foo',\n            'values (1, 2),',\n            '       (3, 4),',\n            '       (5, 6)'])\n    \n        s = 'insert into foo(a, b) values (1, 2), (3, 4), (5, 6)'\n>       assert f(s) == '\\n'.join([\n            'insert into foo(a, b)',\n            'values (1, 2),',\n            '       (3, 4),',\n            '       (5, 6)'])\nE       AssertionError: assert 'insert into ...       (5, 6)' == 'insert into ...       (5, 6)'\nE         \nE         - insert into foo(a, b)\nE         ?                   ---\nE         + insert into foo(a,\nE         +                 b)\nE           values (1, 2),\nE                  (3, 4),\nE                  (5, 6)\n\nrepos\\sqlparse\\tests\\test_format.py:613: AssertionError"", 'def test_grouping_identifiers():\n        s = \'select foo.bar from ""myscheme"".""table"" where fail. order\'\n        parsed = sqlparse.parse(s)[0]\n        assert str(parsed) == s\n        assert isinstance(parsed.tokens[2], sql.Identifier)\n        assert isinstance(parsed.tokens[6], sql.Identifier)\n        assert isinstance(parsed.tokens[8], sql.Where)\n        s = \'select * from foo where foo.id = 1\'\n        parsed = sqlparse.parse(s)[0]\n        assert str(parsed) == s\n        assert isinstance(parsed.tokens[-1].tokens[-1].tokens[0], sql.Identifier)\n        s = \'select * from (select ""foo"".""id"" from foo)\'\n        parsed = sqlparse.parse(s)[0]\n        assert str(parsed) == s\n        assert isinstance(parsed.tokens[-1].tokens[3], sql.Identifier)\n    \n        for s in [""INSERT INTO `test` VALUES(\'foo\', \'bar\');"",\n                  ""INSERT INTO `test` VALUES(1, 2), (3, 4), (5, 6);"",\n                  ""INSERT INTO `test(a, b)` VALUES(1, 2), (3, 4), (5, 6);""]:\n            parsed = sqlparse.parse(s)[0]\n            types = [l.ttype for l in parsed.tokens if not l.is_whitespace]\n            assert types == [T.DML, T.Keyword, None, None, T.Punctuation]\n            assert isinstance(parsed.tokens[6], sql.Values)\n    \n        s = ""select 1.0*(a+b) as col, sum(c)/sum(d) from myschema.mytable""\n        parsed = sqlparse.parse(s)[0]\n>       assert len(parsed.tokens) == 7\nE       AssertionError: assert 9 == 7\nE        +  where 9 = len([<DML \'select\' at 0x1F0390EBDC0>, <Whitespace \' \' at 0x1F0390EBEE0>, <IdentifierList \'1.0*(a...\' at 0x1F0391DD050>, <Operation \'(c)/sum\' at 0x1F0391DCE50>, <Parenthesis \'(d)\' at 0x1F0391DC8D0>, <Whitespace \' \' at 0x1F0390F4A60>, ...])\nE        +    where [<DML \'select\' at 0x1F0390EBDC0>, <Whitespace \' \' at 0x1F0390EBEE0>, <IdentifierList \'1.0*(a...\' at 0x1F0391DD050>, <Operation \'(c)/sum\' at 0x1F0391DCE50>, <Parenthesis \'(d)\' at 0x1F0391DC8D0>, <Whitespace \' \' at 0x1F0390F4A60>, ...] = <Statement \'select...\' at 0x1F0391DC750>.tokens\n\nrepos\\sqlparse\\tests\\test_grouping.py:87: AssertionError', ""s = 'sum(a), sum(b)'\n\n    @pytest.mark.parametrize('s', [\n        'foo, bar',\n        'sum(a), sum(b)',\n        'sum(a) as x, b as y',\n        'sum(a)::integer, b',\n        'sum(a)/count(b) as x, y',\n        'sum(a)::integer as x, y',\n        'sum(a)::integer/count(b) as x, y',  # issue297\n    ])\n    def test_group_identifier_list(s):\n        parsed = sqlparse.parse(s)[0]\n>       assert isinstance(parsed.tokens[0], sql.IdentifierList)\nE       AssertionError: assert False\nE        +  where False = isinstance(<Identifier 'sum' at 0x1F0390EFD50>, <class 'sqlparse.sql.IdentifierList'>)\nE        +    where <class 'sqlparse.sql.IdentifierList'> = sql.IdentifierList\n\nrepos\\sqlparse\\tests\\test_grouping.py:120: AssertionError"", ""s = 'sum(a)/count(b) as x, y'\n\n    @pytest.mark.parametrize('s', [\n        'foo, bar',\n        'sum(a), sum(b)',\n        'sum(a) as x, b as y',\n        'sum(a)::integer, b',\n        'sum(a)/count(b) as x, y',\n        'sum(a)::integer as x, y',\n        'sum(a)::integer/count(b) as x, y',  # issue297\n    ])\n    def test_group_identifier_list(s):\n        parsed = sqlparse.parse(s)[0]\n>       assert isinstance(parsed.tokens[0], sql.IdentifierList)\nE       AssertionError: assert False\nE        +  where False = isinstance(<Identifier 'sum' at 0x1F039186450>, <class 'sqlparse.sql.IdentifierList'>)\nE        +    where <class 'sqlparse.sql.IdentifierList'> = sql.IdentifierList\n\nrepos\\sqlparse\\tests\\test_grouping.py:120: AssertionError"", ""s = 'sum(a)::integer/count(b) as x, y'\n\n    @pytest.mark.parametrize('s', [\n        'foo, bar',\n        'sum(a), sum(b)',\n        'sum(a) as x, b as y',\n        'sum(a)::integer, b',\n        'sum(a)/count(b) as x, y',\n        'sum(a)::integer as x, y',\n        'sum(a)::integer/count(b) as x, y',  # issue297\n    ])\n    def test_group_identifier_list(s):\n        parsed = sqlparse.parse(s)[0]\n>       assert isinstance(parsed.tokens[0], sql.IdentifierList)\nE       AssertionError: assert False\nE        +  where False = isinstance(<Identifier 'sum' at 0x1F0392624D0>, <class 'sqlparse.sql.IdentifierList'>)\nE        +    where <class 'sqlparse.sql.IdentifierList'> = sql.IdentifierList\n\nrepos\\sqlparse\\tests\\test_grouping.py:120: AssertionError"", ""def test_grouping_identifier_function():\n        p = sqlparse.parse('foo() as bar')[0]\n        assert isinstance(p.tokens[0], sql.Identifier)\n>       assert isinstance(p.tokens[0].tokens[0], sql.Function)\nE       AssertionError: assert False\nE        +  where False = isinstance(<Name 'foo' at 0x1F0390F80A0>, <class 'sqlparse.sql.Function'>)\nE        +    where <class 'sqlparse.sql.Function'> = sql.Function\n\nrepos\\sqlparse\\tests\\test_grouping.py:176: AssertionError"", ""def test_grouping_alias_ctas():\n        p = sqlparse.parse('CREATE TABLE tbl1 AS SELECT coalesce(t1.col1, 0) AS col1 FROM t1')[0]\n>       assert p.tokens[10].get_alias() == 'col1'\nE       AssertionError: assert None == 'col1'\nE        +  where None = get_alias()\nE        +    where get_alias = <Identifier 'coales...' at 0x1F0392F6C50>.get_alias\n\nrepos\\sqlparse\\tests\\test_grouping.py:344: AssertionError"", ""def test_grouping_idlist_function():\n        # see issue10 too\n        p = sqlparse.parse('foo(1) x, bar')[0]\n>       assert isinstance(p.tokens[0], sql.IdentifierList)\nE       AssertionError: assert False\nE        +  where False = isinstance(<Identifier 'foo' at 0x1F0392F2D50>, <class 'sqlparse.sql.IdentifierList'>)\nE        +    where <class 'sqlparse.sql.IdentifierList'> = sql.IdentifierList\n\nrepos\\sqlparse\\tests\\test_grouping.py:368: AssertionError"", ""def test_grouping_function():\n        p = sqlparse.parse('foo()')[0]\n>       assert isinstance(p.tokens[0], sql.Function)\nE       AssertionError: assert False\nE        +  where False = isinstance(<Identifier 'foo' at 0x1F0392F2050>, <class 'sqlparse.sql.Function'>)\nE        +    where <class 'sqlparse.sql.Function'> = sql.Function\n\nrepos\\sqlparse\\tests\\test_grouping.py:384: AssertionError"", 'def test_grouping_varchar():\n        p = sqlparse.parse(\'""text"" Varchar(50) NOT NULL\')[0]\n>       assert isinstance(p.tokens[2], sql.Function)\nE       AssertionError: assert False\nE        +  where False = isinstance(<Whitespace \' \' at 0x1F039103D00>, <class \'sqlparse.sql.Function\'>)\nE        +    where <class \'sqlparse.sql.Function\'> = sql.Function\n\nrepos\\sqlparse\\tests\\test_grouping.py:408: AssertionError', ""def test_comparison_with_functions():\n        # issue230\n        p = sqlparse.parse('foo = DATE(bar.baz)')[0]\n>       assert len(p.tokens) == 1\nE       AssertionError: assert 2 == 1\nE        +  where 2 = len([<Comparison 'foo = ...' at 0x1F039210150>, <Parenthesis '(bar.b...' at 0x1F039210050>])\nE        +    where [<Comparison 'foo = ...' at 0x1F039210150>, <Parenthesis '(bar.b...' at 0x1F039210050>] = <Statement 'foo = ...' at 0x1F0391EFDD0>.tokens\n\nrepos\\sqlparse\\tests\\test_grouping.py:554: AssertionError"", ""def test_aliased_function_without_as():\n        p = sqlparse.parse('foo() bar')[0].tokens[0]\n        assert p.get_parent_name() is None\n        assert p.get_real_name() == 'foo'\n>       assert p.get_alias() == 'bar'\nE       AssertionError: assert None == 'bar'\nE        +  where None = get_alias()\nE        +    where get_alias = <Identifier 'foo' at 0x1F0392116D0>.get_alias\n\nrepos\\sqlparse\\tests\\test_grouping.py:656: AssertionError"", ""def test_parse_within():\n        s = 'foo(col1, col2)'\n        p = sqlparse.parse(s)[0]\n>       col1 = p.tokens[0].tokens[1].tokens[1].tokens[0]\nE       IndexError: list index out of range\n\nrepos\\sqlparse\\tests\\test_parse.py:39: IndexError"", ""def test_parse_function_parameter():\n        # see issue94\n>       t = sqlparse.parse('abs(some_col)')[0].tokens[0].get_parameters()\nE       AttributeError: 'Identifier' object has no attribute 'get_parameters'\n\nrepos\\sqlparse\\tests\\test_parse.py:119: AttributeError"", ""def test_parse_function_param_single_literal():\n>       t = sqlparse.parse('foo(5)')[0].tokens[0].get_parameters()\nE       AttributeError: 'Identifier' object has no attribute 'get_parameters'\n\nrepos\\sqlparse\\tests\\test_parse.py:125: AttributeError"", ""def test_parse_nested_function():\n>       t = sqlparse.parse('foo(bar(5))')[0].tokens[0].get_parameters()\nE       AttributeError: 'Identifier' object has no attribute 'get_parameters'\n\nrepos\\sqlparse\\tests\\test_parse.py:131: AttributeError"", 'def test_parse_casted_params():\n>       t = sqlparse.parse(""foo(DATE \'2023-11-14\', TIMESTAMP \'2023-11-15\')"")[0].tokens[0].get_parameters()\nE       AttributeError: \'Identifier\' object has no attribute \'get_parameters\'\n\nrepos\\sqlparse\\tests\\test_parse.py:137: AttributeError', ""def test_array_index_function_result():\n        p = sqlparse.parse('somefunc()[1]')[0].tokens\n>       assert len(p) == 1\nE       AssertionError: assert 3 == 1\nE        +  where 3 = len([<Identifier 'somefu...' at 0x1F0391C48D0>, <Parenthesis '()' at 0x1F0391C4850>, <SquareBrackets '[1]' at 0x1F0391C46D0>])\n\nrepos\\sqlparse\\tests\\test_parse.py:275: AssertionError"", ""def test_issue322_concurrently_is_keyword():\n        s = 'CREATE INDEX CONCURRENTLY myindex ON mytable(col1);'\n        p = sqlparse.parse(s)[0]\n    \n>       assert len(p.tokens) == 12\nE       AssertionError: assert 13 == 12\nE        +  where 13 = len([<DDL 'CREATE' at 0x1F039274400>, <Whitespace ' ' at 0x1F039274460>, <Keyword 'INDEX' at 0x1F0392744C0>, <Whitespace ' ' at 0x1F039274520>, <Keyword 'CONCUR...' at 0x1F039274580>, <Whitespace ' ' at 0x1F0392745E0>, ...])\nE        +    where [<DDL 'CREATE' at 0x1F039274400>, <Whitespace ' ' at 0x1F039274460>, <Keyword 'INDEX' at 0x1F0392744C0>, <Whitespace ' ' at 0x1F039274520>, <Keyword 'CONCUR...' at 0x1F039274580>, <Whitespace ' ' at 0x1F0392745E0>, ...] = <Statement 'CREATE...' at 0x1F0392036D0>.tokens\n\nrepos\\sqlparse\\tests\\test_regressions.py:349: AssertionError""]",sqlparse/group_functions,LLM
sqlparse,group_typecasts,"def group_typecasts(tlist):

    def match(token):
        return token.match(T.Punctuation, '::')

    def valid(token):
        return token is not None

    def post(tlist, pidx, tidx, nidx):
        return (pidx, nidx)
    valid_prev = valid_next = valid
    _group(tlist, sql.Identifier, match, valid_prev, valid_next, post)",The function `group_typecasts` is intended to group certain tokens in a list based on specific criteria. It appears to involve matching and validating tokens in the list to then perform a grouping operation. The goal of the function seems to be to organize and manipulate tokens in a given list in a structured way.,1,"def group_typecasts(tlist):
    grouped_tokens = {}
    
    for token in tlist:
        if token.isdigit():
            if 'numbers' not in grouped_tokens:
                grouped_tokens['numbers'] = []
            grouped_tokens['numbers'].append(token)
        elif token.isalpha():
            if 'letters' not in grouped_tokens:
                grouped_tokens['letters'] = []
            grouped_tokens['letters'].append(token)
        else:
            if 'special_chars' not in grouped_tokens:
                grouped_tokens['special_chars'] = []
            grouped_tokens['special_chars'].append(token)
    
    return grouped_tokens","['./repos/sqlparse\\tests', './repos/sqlparse\\tests\\test_cli.py::test_cli_main_empty', './repos/sqlparse\\tests\\test_cli.py::test_parser_empty', './repos/sqlparse\\tests\\test_cli.py::test_main_help', './repos/sqlparse\\tests\\test_cli.py::test_valid_args', './repos/sqlparse\\tests\\test_cli.py::test_invalid_choice', './repos/sqlparse\\tests\\test_cli.py::test_invalid_args', './repos/sqlparse\\tests\\test_cli.py::test_invalid_infile', './repos/sqlparse\\tests\\test_cli.py::test_invalid_outfile', './repos/sqlparse\\tests\\test_cli.py::test_stdout', './repos/sqlparse\\tests\\test_cli.py::test_script', './repos/sqlparse\\tests\\test_cli.py::test_encoding_stdout', './repos/sqlparse\\tests\\test_cli.py::test_encoding_output_file', './repos/sqlparse\\tests\\test_cli.py::test_encoding_stdin', './repos/sqlparse\\tests\\test_cli.py::test_encoding', './repos/sqlparse\\tests\\test_format.py::test_format_column_ordering', './repos/sqlparse\\tests\\test_format.py::test_truncate_strings', './repos/sqlparse\\tests\\test_format.py::test_truncate_strings_invalid_option2', './repos/sqlparse\\tests\\test_format.py::test_truncate_strings_doesnt_truncate_identifiers', './repos/sqlparse\\tests\\test_format.py::test_having_produces_newline', './repos/sqlparse\\tests\\test_format.py::test_format_right_margin_invalid_option', './repos/sqlparse\\tests\\test_format.py::test_format_right_margin', './repos/sqlparse\\tests\\test_format.py::test_format_json_ops', './repos/sqlparse\\tests\\test_format.py::test_compact', './repos/sqlparse\\tests\\test_format.py::test_strip_ws_removes_trailing_ws_in_groups', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_parenthesis', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_assignment', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_typed_literal', './repos/sqlparse\\tests\\test_grouping.py::test_compare_expr', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifiers', './repos/sqlparse\\tests\\test_grouping.py::test_simple_identifiers', './repos/sqlparse\\tests\\test_grouping.py::test_group_identifier_list', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifier_wildcard', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifier_name_wildcard', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifier_invalid', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifier_invalid_in_middle', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifer_as', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifier_as_invalid', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifier_function', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_operation', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifier_list', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifier_list_subquery', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifier_list_case', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifier_list_other', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifier_list_with_inline_comments', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifiers_with_operators', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifier_list_with_order', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_nested_identifier_with_order', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_where', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_where_union', './repos/sqlparse\\tests\\test_grouping.py::test_returning_kw_ends_where_clause', './repos/sqlparse\\tests\\test_grouping.py::test_into_kw_ends_where_clause', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_typecast', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_alias', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_alias_case', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_alias_ctas', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_subquery_no_parens', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_alias_returns_none', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_idlist_function', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_comparison_exclude', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_function', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_function_not_in', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_varchar', './repos/sqlparse\\tests\\test_grouping.py::test_statement_get_type', './repos/sqlparse\\tests\\test_grouping.py::test_identifier_with_operators', './repos/sqlparse\\tests\\test_grouping.py::test_identifier_with_op_trailing_ws', './repos/sqlparse\\tests\\test_grouping.py::test_identifier_with_string_literals', './repos/sqlparse\\tests\\test_grouping.py::test_identifier_consumes_ordering', './repos/sqlparse\\tests\\test_grouping.py::test_comparison_with_keywords', './repos/sqlparse\\tests\\test_grouping.py::test_comparison_with_floats', './repos/sqlparse\\tests\\test_grouping.py::test_comparison_with_parenthesis', './repos/sqlparse\\tests\\test_grouping.py::test_comparison_with_strings', './repos/sqlparse\\tests\\test_grouping.py::test_like_and_ilike_comparison', './repos/sqlparse\\tests\\test_grouping.py::test_comparison_with_functions', './repos/sqlparse\\tests\\test_grouping.py::test_comparison_with_typed_literal', './repos/sqlparse\\tests\\test_grouping.py::test_forloops', './repos/sqlparse\\tests\\test_grouping.py::test_nested_for', './repos/sqlparse\\tests\\test_grouping.py::test_begin', './repos/sqlparse\\tests\\test_grouping.py::test_keyword_followed_by_parenthesis', './repos/sqlparse\\tests\\test_grouping.py::test_nested_begin', './repos/sqlparse\\tests\\test_grouping.py::test_aliased_column_without_as', './repos/sqlparse\\tests\\test_grouping.py::test_qualified_function', './repos/sqlparse\\tests\\test_grouping.py::test_aliased_function_without_as', './repos/sqlparse\\tests\\test_grouping.py::test_aliased_literal_without_as', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_as_cte', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_create_table', './repos/sqlparse\\tests\\test_parse.py::test_parse_tokenize', './repos/sqlparse\\tests\\test_parse.py::test_parse_multistatement', './repos/sqlparse\\tests\\test_parse.py::test_parse_newlines', './repos/sqlparse\\tests\\test_parse.py::test_parse_within', './repos/sqlparse\\tests\\test_parse.py::test_parse_child_of', './repos/sqlparse\\tests\\test_parse.py::test_parse_has_ancestor', './repos/sqlparse\\tests\\test_parse.py::test_parse_float', './repos/sqlparse\\tests\\test_parse.py::test_parse_placeholder', './repos/sqlparse\\tests\\test_parse.py::test_parse_modulo_not_placeholder', './repos/sqlparse\\tests\\test_parse.py::test_parse_access_symbol', './repos/sqlparse\\tests\\test_parse.py::test_parse_square_brackets_notation_isnt_too_greedy', './repos/sqlparse\\tests\\test_parse.py::test_parse_square_brackets_notation_isnt_too_greedy2', './repos/sqlparse\\tests\\test_parse.py::test_parse_keyword_like_identifier', './repos/sqlparse\\tests\\test_parse.py::test_parse_function_parameter', './repos/sqlparse\\tests\\test_parse.py::test_parse_function_param_single_literal', './repos/sqlparse\\tests\\test_parse.py::test_parse_nested_function', './repos/sqlparse\\tests\\test_parse.py::test_parse_casted_params', './repos/sqlparse\\tests\\test_parse.py::test_parse_div_operator', './repos/sqlparse\\tests\\test_parse.py::test_quoted_identifier', './repos/sqlparse\\tests\\test_parse.py::test_valid_identifier_names', './repos/sqlparse\\tests\\test_parse.py::test_psql_quotation_marks', './repos/sqlparse\\tests\\test_parse.py::test_double_precision_is_builtin', './repos/sqlparse\\tests\\test_parse.py::test_placeholder', './repos/sqlparse\\tests\\test_parse.py::test_scientific_numbers', './repos/sqlparse\\tests\\test_parse.py::test_single_quotes_are_strings', './repos/sqlparse\\tests\\test_parse.py::test_double_quotes_are_identifiers', './repos/sqlparse\\tests\\test_parse.py::test_single_quotes_with_linebreaks', './repos/sqlparse\\tests\\test_parse.py::test_sqlite_identifiers', './repos/sqlparse\\tests\\test_parse.py::test_simple_1d_array_index', './repos/sqlparse\\tests\\test_parse.py::test_2d_array_index', './repos/sqlparse\\tests\\test_parse.py::test_array_index_function_result', './repos/sqlparse\\tests\\test_parse.py::test_schema_qualified_array_index', './repos/sqlparse\\tests\\test_parse.py::test_aliased_array_index', './repos/sqlparse\\tests\\test_parse.py::test_array_literal', './repos/sqlparse\\tests\\test_parse.py::test_typed_array_definition', './repos/sqlparse\\tests\\test_parse.py::test_single_line_comments', './repos/sqlparse\\tests\\test_parse.py::test_names_and_special_names', './repos/sqlparse\\tests\\test_parse.py::test_get_token_at_offset', './repos/sqlparse\\tests\\test_parse.py::test_pprint', './repos/sqlparse\\tests\\test_parse.py::test_wildcard_multiplication', './repos/sqlparse\\tests\\test_parse.py::test_stmt_tokens_parents', './repos/sqlparse\\tests\\test_parse.py::test_dbldollar_as_literal', './repos/sqlparse\\tests\\test_parse.py::test_non_ascii', './repos/sqlparse\\tests\\test_parse.py::test_get_real_name', './repos/sqlparse\\tests\\test_parse.py::test_from_subquery', './repos/sqlparse\\tests\\test_parse.py::test_parenthesis', './repos/sqlparse\\tests\\test_parse.py::test_configurable_keywords', './repos/sqlparse\\tests\\test_parse.py::test_configurable_regex', './repos/sqlparse\\tests\\test_parse.py::test_json_operators', './repos/sqlparse\\tests\\test_regressions.py::test_issue9', './repos/sqlparse\\tests\\test_regressions.py::test_issue13', './repos/sqlparse\\tests\\test_regressions.py::test_issue26', './repos/sqlparse\\tests\\test_regressions.py::test_issue34', './repos/sqlparse\\tests\\test_regressions.py::test_issue35', './repos/sqlparse\\tests\\test_regressions.py::test_issue38', './repos/sqlparse\\tests\\test_regressions.py::test_issue39', './repos/sqlparse\\tests\\test_regressions.py::test_issue40', './repos/sqlparse\\tests\\test_regressions.py::test_issue78', './repos/sqlparse\\tests\\test_regressions.py::test_issue83', './repos/sqlparse\\tests\\test_regressions.py::test_comment_encoding_when_reindent', './repos/sqlparse\\tests\\test_regressions.py::test_parse_sql_with_binary', './repos/sqlparse\\tests\\test_regressions.py::test_dont_alias_keywords', './repos/sqlparse\\tests\\test_regressions.py::test_format_accepts_encoding', './repos/sqlparse\\tests\\test_regressions.py::test_stream', './repos/sqlparse\\tests\\test_regressions.py::test_issue90', './repos/sqlparse\\tests\\test_regressions.py::test_except_formatting', './repos/sqlparse\\tests\\test_regressions.py::test_null_with_as', './repos/sqlparse\\tests\\test_regressions.py::test_issue190_open_file', './repos/sqlparse\\tests\\test_regressions.py::test_issue193_splitting_function', './repos/sqlparse\\tests\\test_regressions.py::test_issue194_splitting_function', './repos/sqlparse\\tests\\test_regressions.py::test_issue186_get_type', './repos/sqlparse\\tests\\test_regressions.py::test_issue212_py2unicode', './repos/sqlparse\\tests\\test_regressions.py::test_issue213_leadingws', './repos/sqlparse\\tests\\test_regressions.py::test_issue227_gettype_cte', './repos/sqlparse\\tests\\test_regressions.py::test_issue207_runaway_format', './repos/sqlparse\\tests\\test_regressions.py::test_token_next_doesnt_ignore_skip_cm', './repos/sqlparse\\tests\\test_regressions.py::test_issue284_as_grouping', './repos/sqlparse\\tests\\test_regressions.py::test_issue315_utf8_by_default', './repos/sqlparse\\tests\\test_regressions.py::test_issue322_concurrently_is_keyword', './repos/sqlparse\\tests\\test_regressions.py::test_issue359_index_error_assignments', './repos/sqlparse\\tests\\test_regressions.py::test_issue469_copy_as_psql_command', './repos/sqlparse\\tests\\test_regressions.py::test_issue484_comments_and_newlines', './repos/sqlparse\\tests\\test_regressions.py::test_issue485_split_multi', './repos/sqlparse\\tests\\test_regressions.py::test_issue489_tzcasts', './repos/sqlparse\\tests\\test_regressions.py::test_issue562_tzcasts', './repos/sqlparse\\tests\\test_regressions.py::test_as_in_parentheses_indents', './repos/sqlparse\\tests\\test_regressions.py::test_format_invalid_where_clause', './repos/sqlparse\\tests\\test_regressions.py::test_splitting_at_and_backticks_issue588', './repos/sqlparse\\tests\\test_regressions.py::test_comment_between_cte_clauses_issue632', './repos/sqlparse\\tests\\test_regressions.py::test_copy_issue672', './repos/sqlparse\\tests\\test_regressions.py::test_primary_key_issue740', './repos/sqlparse\\tests\\test_regressions.py::test_max_recursion', './repos/sqlparse\\tests\\test_split.py::test_split_semicolon', './repos/sqlparse\\tests\\test_split.py::test_split_backslash', './repos/sqlparse\\tests\\test_split.py::test_split_create_function', './repos/sqlparse\\tests\\test_split.py::test_split_dashcomments', './repos/sqlparse\\tests\\test_split.py::test_split_dashcomments_eol', './repos/sqlparse\\tests\\test_split.py::test_split_begintag', './repos/sqlparse\\tests\\test_split.py::test_split_begintag_2', './repos/sqlparse\\tests\\test_split.py::test_split_dropif', './repos/sqlparse\\tests\\test_split.py::test_split_comment_with_umlaut', './repos/sqlparse\\tests\\test_split.py::test_split_comment_end_of_line', './repos/sqlparse\\tests\\test_split.py::test_split_casewhen', './repos/sqlparse\\tests\\test_split.py::test_split_casewhen_procedure', './repos/sqlparse\\tests\\test_split.py::test_split_cursor_declare', './repos/sqlparse\\tests\\test_split.py::test_split_if_function', './repos/sqlparse\\tests\\test_split.py::test_split_stream', './repos/sqlparse\\tests\\test_split.py::test_split_encoding_parsestream', './repos/sqlparse\\tests\\test_split.py::test_split_unicode_parsestream', './repos/sqlparse\\tests\\test_split.py::test_split_simple', './repos/sqlparse\\tests\\test_split.py::test_split_ignores_empty_newlines', './repos/sqlparse\\tests\\test_split.py::test_split_quotes_with_new_line', './repos/sqlparse\\tests\\test_split.py::test_split_mysql_handler_for', './repos/sqlparse\\tests\\test_split.py::test_split_strip_semicolon', './repos/sqlparse\\tests\\test_split.py::test_split_strip_semicolon_procedure', './repos/sqlparse\\tests\\test_split.py::test_split_go', './repos/sqlparse\\tests\\test_split.py::test_split_multiple_case_in_begin', './repos/sqlparse\\tests\\test_tokenize.py::test_tokenize_simple', './repos/sqlparse\\tests\\test_tokenize.py::test_tokenize_backticks', './repos/sqlparse\\tests\\test_tokenize.py::test_tokenize_linebreaks', './repos/sqlparse\\tests\\test_tokenize.py::test_tokenize_inline_keywords', './repos/sqlparse\\tests\\test_tokenize.py::test_tokenize_negative_numbers', './repos/sqlparse\\tests\\test_tokenize.py::test_token_str', './repos/sqlparse\\tests\\test_tokenize.py::test_token_repr', './repos/sqlparse\\tests\\test_tokenize.py::test_token_flatten', './repos/sqlparse\\tests\\test_tokenize.py::test_tokenlist_repr', './repos/sqlparse\\tests\\test_tokenize.py::test_single_quotes', './repos/sqlparse\\tests\\test_tokenize.py::test_tokenlist_first', './repos/sqlparse\\tests\\test_tokenize.py::test_tokenlist_token_matching', './repos/sqlparse\\tests\\test_tokenize.py::test_stream_simple', './repos/sqlparse\\tests\\test_tokenize.py::test_stream_error', './repos/sqlparse\\tests\\test_tokenize.py::test_parse_join', './repos/sqlparse\\tests\\test_tokenize.py::test_parse_union', './repos/sqlparse\\tests\\test_tokenize.py::test_parse_endifloop', './repos/sqlparse\\tests\\test_tokenize.py::test_parse_order', './repos/sqlparse\\tests\\test_tokenize.py::test_parse_identifiers', './repos/sqlparse\\tests\\test_tokenize.py::test_parse_group_by', './repos/sqlparse\\tests\\test_tokenize.py::test_parse_order_by', './repos/sqlparse\\tests\\test_tokenize.py::test_parse_window_as', './repos/sqlparse\\tests\\test_tokenize.py::test_like_and_ilike_parsed_as_comparisons', './repos/sqlparse\\tests\\test_tokenize.py::test_near_like_and_ilike_parsed_appropriately', './repos/sqlparse\\tests\\test_tokenize.py::test_parse_tzcast', './repos/sqlparse\\tests\\test_tokenize.py::test_cli_commands', './repos/sqlparse\\tests\\test_utils.py::test_remove_quotes']","88 Passed, 373 Failed",88,373,"['tests/test_cli.py::test_valid_args', 'tests/test_format.py::TestFormat::test_strip_comments_single', 'tests/test_format.py::TestFormat::test_strip_comments_multi', 'tests/test_format.py::TestFormat::test_strip_comments_preserves_linebreak', 'tests/test_format.py::TestFormat::test_strip_comments_preserves_whitespace', 'tests/test_format.py::TestFormat::test_strip_comments_preserves_hint', 'tests/test_format.py::TestFormat::test_strip_ws', 'tests/test_format.py::TestFormat::test_preserve_ws', 'tests/test_format.py::TestFormatReindentAligned::test_basic', 'tests/test_format.py::TestFormatReindentAligned::test_joins', 'tests/test_format.py::TestFormatReindentAligned::test_case_statement', 'tests/test_format.py::TestFormatReindentAligned::test_case_statement_with_between', 'tests/test_format.py::TestFormatReindentAligned::test_group_by', 'tests/test_format.py::TestFormatReindentAligned::test_group_by_subquery', 'tests/test_format.py::TestFormatReindentAligned::test_window_functions', 'tests/test_format.py::TestSpacesAroundOperators::test_basic', 'tests/test_format.py::TestSpacesAroundOperators::test_bools', 'tests/test_format.py::TestSpacesAroundOperators::test_nested', 'tests/test_format.py::TestSpacesAroundOperators::test_wildcard_vs_mult', 'tests/test_format.py::TestFormatReindent::test_stmts', 'tests/test_format.py::TestFormatReindent::test_keywords', 'tests/test_format.py::TestFormatReindent::test_keywords_between', 'tests/test_format.py::TestFormatReindent::test_parenthesis', 'tests/test_format.py::TestFormatReindent::test_where', 'tests/test_format.py::TestFormatReindent::test_join', 'tests/test_format.py::TestFormatReindent::test_identifier_list', 'tests/test_format.py::TestFormatReindent::test_identifier_list_with_wrap_after', 'tests/test_format.py::TestFormatReindent::test_identifier_list_comment_first', 'tests/test_format.py::TestFormatReindent::test_identifier_list_with_functions', 'tests/test_format.py::TestFormatReindent::test_long_identifier_list_with_functions', 'tests/test_format.py::TestFormatReindent::test_case', 'tests/test_format.py::TestFormatReindent::test_case2', 'tests/test_format.py::TestFormatReindent::test_nested_identifier_list', 'tests/test_format.py::TestFormatReindent::test_duplicate_linebreaks', 'tests/test_format.py::TestFormatReindent::test_keywordfunctions', 'tests/test_format.py::TestFormatReindent::test_identifier_and_functions', 'tests/test_format.py::TestFormatReindent::test_insert_values', 'tests/test_format.py::TestOutputFormat::test_python', 'tests/test_format.py::TestOutputFormat::test_php', 'tests/test_format.py::test_format_column_ordering', 'tests/test_format.py::test_having_produces_newline', 'tests/test_format.py::test_format_json_ops', 'tests/test_format.py::test_compact[case when foo then 1 else bar end-case\\n    when foo then 1\\n    else bar\\nend-case when foo then 1 else bar end]', 'tests/test_format.py::test_strip_ws_removes_trailing_ws_in_groups', 'tests/test_grouping.py::test_grouping_parenthesis', 'tests/test_grouping.py::test_grouping_assignment[foo := 1;]', 'tests/test_grouping.py::test_grouping_assignment[foo := 1]', ""tests/test_grouping.py::test_grouping_typed_literal[x > DATE '2020-01-01']"", ""tests/test_grouping.py::test_grouping_typed_literal[x > TIMESTAMP '2020-01-01 00:00:00']"", 'tests/test_grouping.py::test_compare_expr[select a from b where c < d + e-Identifier-Identifier]', ""tests/test_grouping.py::test_compare_expr[select a from b where c < d + interval '1 day'-Identifier-TypedLiteral]"", ""tests/test_grouping.py::test_compare_expr[select a from b where c < d + interval '6' month-Identifier-TypedLiteral]"", ""tests/test_grouping.py::test_compare_expr[select a from b where c < current_timestamp - interval '1 day'-Token-TypedLiteral]"", 'tests/test_grouping.py::test_grouping_identifiers', 'tests/test_grouping.py::test_simple_identifiers[1 as f]', 'tests/test_grouping.py::test_simple_identifiers[foo as f]', 'tests/test_grouping.py::test_simple_identifiers[foo f]', 'tests/test_grouping.py::test_simple_identifiers[1/2 as f]', 'tests/test_grouping.py::test_simple_identifiers[1/2 f]', 'tests/test_grouping.py::test_simple_identifiers[1<2 as f]', 'tests/test_grouping.py::test_simple_identifiers[1<2 f]', 'tests/test_grouping.py::test_group_identifier_list[foo, bar]', 'tests/test_grouping.py::test_group_identifier_list[sum(a), sum(b)]', 'tests/test_grouping.py::test_group_identifier_list[sum(a) as x, b as y]', 'tests/test_grouping.py::test_group_identifier_list[sum(a)::integer, b]', 'tests/test_grouping.py::test_group_identifier_list[sum(a)/count(b) as x, y]', 'tests/test_grouping.py::test_group_identifier_list[sum(a)::integer as x, y]', 'tests/test_grouping.py::test_group_identifier_list[sum(a)::integer/count(b) as x, y]', 'tests/test_grouping.py::test_grouping_identifier_wildcard', 'tests/test_grouping.py::test_grouping_identifier_name_wildcard', 'tests/test_grouping.py::test_grouping_identifier_invalid', 'tests/test_grouping.py::test_grouping_identifier_invalid_in_middle', 'tests/test_grouping.py::test_grouping_identifer_as[foo as (select *)]', 'tests/test_grouping.py::test_grouping_identifer_as[foo as(select *)]', 'tests/test_grouping.py::test_grouping_identifier_as_invalid', 'tests/test_grouping.py::test_grouping_identifier_function', 'tests/test_grouping.py::test_grouping_operation[foo+100]', 'tests/test_grouping.py::test_grouping_operation[foo + 100]', 'tests/test_grouping.py::test_grouping_operation[foo*100]', 'tests/test_grouping.py::test_grouping_identifier_list', 'tests/test_grouping.py::test_grouping_identifier_list_subquery', 'tests/test_grouping.py::test_grouping_identifier_list_case', 'tests/test_grouping.py::test_grouping_identifier_list_other', 'tests/test_grouping.py::test_grouping_identifier_list_with_inline_comments', 'tests/test_grouping.py::test_grouping_identifiers_with_operators', 'tests/test_grouping.py::test_grouping_identifier_list_with_order', 'tests/test_grouping.py::test_grouping_nested_identifier_with_order', 'tests/test_grouping.py::test_grouping_where', 'tests/test_grouping.py::test_grouping_where_union[select 1 where 1 = 2 union select 2]', 'tests/test_grouping.py::test_grouping_where_union[select 1 where 1 = 2 union all select 2]', 'tests/test_grouping.py::test_returning_kw_ends_where_clause', 'tests/test_grouping.py::test_into_kw_ends_where_clause', 'tests/test_grouping.py::test_grouping_typecast[select foo::integer from bar-integer]', 'tests/test_grouping.py::test_grouping_typecast[select (current_database())::information_schema.sql_identifier-information_schema.sql_identifier]', 'tests/test_grouping.py::test_grouping_alias', 'tests/test_grouping.py::test_grouping_alias_case', 'tests/test_grouping.py::test_grouping_alias_ctas', 'tests/test_grouping.py::test_grouping_subquery_no_parens', 'tests/test_grouping.py::test_grouping_alias_returns_none[foo.bar]', 'tests/test_grouping.py::test_grouping_alias_returns_none[x, y]', 'tests/test_grouping.py::test_grouping_alias_returns_none[x > y]', 'tests/test_grouping.py::test_grouping_alias_returns_none[x / y]', 'tests/test_grouping.py::test_grouping_idlist_function', 'tests/test_grouping.py::test_grouping_comparison_exclude', 'tests/test_grouping.py::test_grouping_function', 'tests/test_grouping.py::test_grouping_function_not_in', 'tests/test_grouping.py::test_grouping_varchar', 'tests/test_grouping.py::test_statement_get_type', 'tests/test_grouping.py::test_identifier_with_operators', 'tests/test_grouping.py::test_identifier_with_op_trailing_ws', 'tests/test_grouping.py::test_identifier_with_string_literals', 'tests/test_grouping.py::test_identifier_consumes_ordering', 'tests/test_grouping.py::test_comparison_with_keywords', 'tests/test_grouping.py::test_comparison_with_floats', 'tests/test_grouping.py::test_comparison_with_parenthesis', 'tests/test_grouping.py::test_comparison_with_strings[=]', 'tests/test_grouping.py::test_comparison_with_strings[!=]', 'tests/test_grouping.py::test_comparison_with_strings[>]', 'tests/test_grouping.py::test_comparison_with_strings[<]', 'tests/test_grouping.py::test_comparison_with_strings[<=]', 'tests/test_grouping.py::test_comparison_with_strings[>=]', 'tests/test_grouping.py::test_comparison_with_strings[~]', 'tests/test_grouping.py::test_comparison_with_strings[~~]', 'tests/test_grouping.py::test_comparison_with_strings[!~~]', 'tests/test_grouping.py::test_comparison_with_strings[LIKE]', 'tests/test_grouping.py::test_comparison_with_strings[NOT LIKE]', 'tests/test_grouping.py::test_comparison_with_strings[ILIKE]', 'tests/test_grouping.py::test_comparison_with_strings[NOT ILIKE]', 'tests/test_grouping.py::test_like_and_ilike_comparison', 'tests/test_grouping.py::test_comparison_with_functions', 'tests/test_grouping.py::test_comparison_with_typed_literal', 'tests/test_grouping.py::test_forloops[FOR]', 'tests/test_grouping.py::test_forloops[FOREACH]', 'tests/test_grouping.py::test_nested_for', 'tests/test_grouping.py::test_begin', 'tests/test_grouping.py::test_keyword_followed_by_parenthesis', 'tests/test_grouping.py::test_nested_begin', 'tests/test_grouping.py::test_aliased_column_without_as', 'tests/test_grouping.py::test_qualified_function', 'tests/test_grouping.py::test_aliased_function_without_as', 'tests/test_grouping.py::test_aliased_literal_without_as', 'tests/test_grouping.py::test_grouping_as_cte', 'tests/test_grouping.py::test_grouping_create_table', 'tests/test_parse.py::test_parse_tokenize', 'tests/test_parse.py::test_parse_multistatement', 'tests/test_parse.py::test_parse_newlines[select\\n*from foo;]', 'tests/test_parse.py::test_parse_newlines[select\\r\\n*from foo]', 'tests/test_parse.py::test_parse_newlines[select\\r*from foo]', 'tests/test_parse.py::test_parse_newlines[select\\r\\n*from foo\\n]', 'tests/test_parse.py::test_parse_within', 'tests/test_parse.py::test_parse_child_of', 'tests/test_parse.py::test_parse_has_ancestor', 'tests/test_parse.py::test_parse_float[.5]', 'tests/test_parse.py::test_parse_float[.51]', 'tests/test_parse.py::test_parse_float[1.5]', 'tests/test_parse.py::test_parse_float[12.5]', 'tests/test_parse.py::test_parse_placeholder[select * from foo where user = ?-?]', 'tests/test_parse.py::test_parse_placeholder[select * from foo where user = :1-:1]', 'tests/test_parse.py::test_parse_placeholder[select * from foo where user = :name-:name]', 'tests/test_parse.py::test_parse_placeholder[select * from foo where user = %s-%s]', 'tests/test_parse.py::test_parse_placeholder[select * from foo where user = $a-$a]', 'tests/test_parse.py::test_parse_access_symbol', 'tests/test_parse.py::test_parse_square_brackets_notation_isnt_too_greedy', 'tests/test_parse.py::test_parse_square_brackets_notation_isnt_too_greedy2', 'tests/test_parse.py::test_parse_keyword_like_identifier', 'tests/test_parse.py::test_parse_function_parameter', 'tests/test_parse.py::test_parse_function_param_single_literal', 'tests/test_parse.py::test_parse_nested_function', 'tests/test_parse.py::test_parse_casted_params', 'tests/test_parse.py::test_parse_div_operator', 'tests/test_parse.py::test_quoted_identifier', 'tests/test_parse.py::test_valid_identifier_names[foo]', 'tests/test_parse.py::test_valid_identifier_names[_foo]', 'tests/test_parse.py::test_valid_identifier_names[1_data]', 'tests/test_parse.py::test_valid_identifier_names[\\u696d\\u8005\\u540d\\u7a31]', 'tests/test_parse.py::test_double_precision_is_builtin', 'tests/test_parse.py::test_placeholder[?]', 'tests/test_parse.py::test_placeholder[:1]', 'tests/test_parse.py::test_placeholder[:foo]', 'tests/test_parse.py::test_placeholder[%s]', 'tests/test_parse.py::test_placeholder[%(foo)s]', 'tests/test_parse.py::test_scientific_numbers[6.67428E-8-expected0]', 'tests/test_parse.py::test_scientific_numbers[1.988e33-expected1]', 'tests/test_parse.py::test_scientific_numbers[1e-12-expected2]', 'tests/test_parse.py::test_scientific_numbers[e1-None]', 'tests/test_parse.py::test_single_quotes_are_strings', 'tests/test_parse.py::test_double_quotes_are_identifiers', 'tests/test_parse.py::test_single_quotes_with_linebreaks', 'tests/test_parse.py::test_sqlite_identifiers', 'tests/test_parse.py::test_simple_1d_array_index', 'tests/test_parse.py::test_2d_array_index', 'tests/test_parse.py::test_array_index_function_result', 'tests/test_parse.py::test_schema_qualified_array_index', 'tests/test_parse.py::test_aliased_array_index', 'tests/test_parse.py::test_array_literal', 'tests/test_parse.py::test_typed_array_definition', 'tests/test_parse.py::test_single_line_comments[select 1 -- foo]', 'tests/test_parse.py::test_single_line_comments[select 1 # foo]', 'tests/test_parse.py::test_names_and_special_names[foo]', 'tests/test_parse.py::test_names_and_special_names[@foo]', 'tests/test_parse.py::test_names_and_special_names[#foo]', 'tests/test_parse.py::test_names_and_special_names[##foo]', 'tests/test_parse.py::test_get_token_at_offset', 'tests/test_parse.py::test_pprint', 'tests/test_parse.py::test_wildcard_multiplication', 'tests/test_parse.py::test_stmt_tokens_parents', 'tests/test_parse.py::test_dbldollar_as_literal[$$foo$$-True]', 'tests/test_parse.py::test_dbldollar_as_literal[$_$foo$_$-True]', 'tests/test_parse.py::test_dbldollar_as_literal[$token$ foo $token$-True]', 'tests/test_parse.py::test_dbldollar_as_literal[$_$ foo $token$bar$token$ baz$_$-True]', 'tests/test_parse.py::test_dbldollar_as_literal[$A$ foo $B$-False]', 'tests/test_parse.py::test_non_ascii', 'tests/test_parse.py::test_get_real_name', 'tests/test_parse.py::test_from_subquery', 'tests/test_parse.py::test_parenthesis', 'tests/test_parse.py::test_configurable_keywords', 'tests/test_parse.py::test_configurable_regex', 'tests/test_parse.py::test_json_operators[->]', 'tests/test_parse.py::test_json_operators[->>]', 'tests/test_parse.py::test_json_operators[#>]', 'tests/test_parse.py::test_json_operators[#>>]', 'tests/test_parse.py::test_json_operators[@>]', 'tests/test_parse.py::test_json_operators[<@]', 'tests/test_parse.py::test_json_operators[||]', 'tests/test_parse.py::test_json_operators[-]', 'tests/test_parse.py::test_json_operators[#-]', 'tests/test_regressions.py::test_issue9', 'tests/test_regressions.py::test_issue13', 'tests/test_regressions.py::test_issue26[--hello]', 'tests/test_regressions.py::test_issue26[-- hello]', 'tests/test_regressions.py::test_issue26[--hello\\n]', 'tests/test_regressions.py::test_issue26[--]', 'tests/test_regressions.py::test_issue26[--\\n]', 'tests/test_regressions.py::test_issue34[create]', 'tests/test_regressions.py::test_issue34[CREATE]', 'tests/test_regressions.py::test_issue35', 'tests/test_regressions.py::test_issue38', 'tests/test_regressions.py::test_issue39', 'tests/test_regressions.py::test_issue40', 'tests/test_regressions.py::test_issue78[get_name-z-select x.y::text as z from foo]', 'tests/test_regressions.py::test_issue78[get_name-z-select x.y::text as ""z"" from foo]', 'tests/test_regressions.py::test_issue78[get_name-z-select x.""y""::text as z from foo]', 'tests/test_regressions.py::test_issue78[get_name-z-select x.""y""::text as ""z"" from foo]', 'tests/test_regressions.py::test_issue78[get_name-z-select ""x"".y::text as z from foo]', 'tests/test_regressions.py::test_issue78[get_name-z-select ""x"".y::text as ""z"" from foo]', 'tests/test_regressions.py::test_issue78[get_name-z-select ""x"".""y""::text as z from foo]', 'tests/test_regressions.py::test_issue78[get_name-z-select ""x"".""y""::text as ""z"" from foo]', 'tests/test_regressions.py::test_issue78[get_real_name-y-select x.y::text as z from foo]', 'tests/test_regressions.py::test_issue78[get_real_name-y-select x.y::text as ""z"" from foo]', 'tests/test_regressions.py::test_issue78[get_real_name-y-select x.""y""::text as z from foo]', 'tests/test_regressions.py::test_issue78[get_real_name-y-select x.""y""::text as ""z"" from foo]', 'tests/test_regressions.py::test_issue78[get_real_name-y-select ""x"".y::text as z from foo]', 'tests/test_regressions.py::test_issue78[get_real_name-y-select ""x"".y::text as ""z"" from foo]', 'tests/test_regressions.py::test_issue78[get_real_name-y-select ""x"".""y""::text as z from foo]', 'tests/test_regressions.py::test_issue78[get_real_name-y-select ""x"".""y""::text as ""z"" from foo]', 'tests/test_regressions.py::test_issue78[get_parent_name-x-select x.y::text as z from foo]', 'tests/test_regressions.py::test_issue78[get_parent_name-x-select x.y::text as ""z"" from foo]', 'tests/test_regressions.py::test_issue78[get_parent_name-x-select x.""y""::text as z from foo]', 'tests/test_regressions.py::test_issue78[get_parent_name-x-select x.""y""::text as ""z"" from foo]', 'tests/test_regressions.py::test_issue78[get_parent_name-x-select ""x"".y::text as z from foo]', 'tests/test_regressions.py::test_issue78[get_parent_name-x-select ""x"".y::text as ""z"" from foo]', 'tests/test_regressions.py::test_issue78[get_parent_name-x-select ""x"".""y""::text as z from foo]', 'tests/test_regressions.py::test_issue78[get_parent_name-x-select ""x"".""y""::text as ""z"" from foo]', 'tests/test_regressions.py::test_issue78[get_alias-z-select x.y::text as z from foo]', 'tests/test_regressions.py::test_issue78[get_alias-z-select x.y::text as ""z"" from foo]', 'tests/test_regressions.py::test_issue78[get_alias-z-select x.""y""::text as z from foo]', 'tests/test_regressions.py::test_issue78[get_alias-z-select x.""y""::text as ""z"" from foo]', 'tests/test_regressions.py::test_issue78[get_alias-z-select ""x"".y::text as z from foo]', 'tests/test_regressions.py::test_issue78[get_alias-z-select ""x"".y::text as ""z"" from foo]', 'tests/test_regressions.py::test_issue78[get_alias-z-select ""x"".""y""::text as z from foo]', 'tests/test_regressions.py::test_issue78[get_alias-z-select ""x"".""y""::text as ""z"" from foo]', 'tests/test_regressions.py::test_issue78[get_typecast-text-select x.y::text as z from foo]', 'tests/test_regressions.py::test_issue78[get_typecast-text-select x.y::text as ""z"" from foo]', 'tests/test_regressions.py::test_issue78[get_typecast-text-select x.""y""::text as z from foo]', 'tests/test_regressions.py::test_issue78[get_typecast-text-select x.""y""::text as ""z"" from foo]', 'tests/test_regressions.py::test_issue78[get_typecast-text-select ""x"".y::text as z from foo]', 'tests/test_regressions.py::test_issue78[get_typecast-text-select ""x"".y::text as ""z"" from foo]', 'tests/test_regressions.py::test_issue78[get_typecast-text-select ""x"".""y""::text as z from foo]', 'tests/test_regressions.py::test_issue78[get_typecast-text-select ""x"".""y""::text as ""z"" from foo]', 'tests/test_regressions.py::test_comment_encoding_when_reindent', 'tests/test_regressions.py::test_parse_sql_with_binary', 'tests/test_regressions.py::test_dont_alias_keywords', 'tests/test_regressions.py::test_format_accepts_encoding', 'tests/test_regressions.py::test_stream', 'tests/test_regressions.py::test_issue90', 'tests/test_regressions.py::test_except_formatting', 'tests/test_regressions.py::test_null_with_as', 'tests/test_regressions.py::test_issue190_open_file', 'tests/test_regressions.py::test_issue186_get_type', 'tests/test_regressions.py::test_issue213_leadingws', 'tests/test_regressions.py::test_issue227_gettype_cte', 'tests/test_regressions.py::test_issue207_runaway_format', 'tests/test_regressions.py::test_token_next_doesnt_ignore_skip_cm', 'tests/test_regressions.py::test_issue284_as_grouping[SELECT x AS]', 'tests/test_regressions.py::test_issue284_as_grouping[AS]', 'tests/test_regressions.py::test_issue315_utf8_by_default', 'tests/test_regressions.py::test_issue322_concurrently_is_keyword', 'tests/test_regressions.py::test_issue359_index_error_assignments[SELECT @min_price:=MIN(price), @max_price:=MAX(price) FROM shop;]', 'tests/test_regressions.py::test_issue359_index_error_assignments[SELECT @min_price:=MIN(price), @max_price:=MAX(price) FROM shop]', 'tests/test_regressions.py::test_issue489_tzcasts', 'tests/test_regressions.py::test_issue562_tzcasts', 'tests/test_regressions.py::test_as_in_parentheses_indents', 'tests/test_regressions.py::test_format_invalid_where_clause', 'tests/test_regressions.py::test_comment_between_cte_clauses_issue632', 'tests/test_regressions.py::test_copy_issue672', 'tests/test_regressions.py::test_primary_key_issue740', 'tests/test_split.py::test_split_semicolon', 'tests/test_split.py::test_split_backslash', 'tests/test_split.py::test_split_create_function[function.sql]', 'tests/test_split.py::test_split_create_function[function_psql.sql]', 'tests/test_split.py::test_split_create_function[function_psql2.sql]', 'tests/test_split.py::test_split_create_function[function_psql3.sql]', 'tests/test_split.py::test_split_create_function[function_psql4.sql]', 'tests/test_split.py::test_split_dashcomments', 'tests/test_split.py::test_split_dashcomments_eol[select foo; -- comment\\n]', 'tests/test_split.py::test_split_dashcomments_eol[select foo; -- comment\\r]', 'tests/test_split.py::test_split_dashcomments_eol[select foo; -- comment\\r\\n]', 'tests/test_split.py::test_split_dashcomments_eol[select foo; -- comment]', 'tests/test_split.py::test_split_begintag', 'tests/test_split.py::test_split_begintag_2', 'tests/test_split.py::test_split_dropif', 'tests/test_split.py::test_split_comment_with_umlaut', 'tests/test_split.py::test_split_comment_end_of_line', 'tests/test_split.py::test_split_stream', 'tests/test_split.py::test_split_encoding_parsestream', 'tests/test_split.py::test_split_unicode_parsestream', 'tests/test_tokenize.py::test_tokenlist_repr', 'tests/test_tokenize.py::test_single_quotes', 'tests/test_tokenize.py::test_tokenlist_first', 'tests/test_tokenize.py::test_parse_join[JOIN]', 'tests/test_tokenize.py::test_parse_join[LEFT JOIN]', 'tests/test_tokenize.py::test_parse_join[LEFT OUTER JOIN]', 'tests/test_tokenize.py::test_parse_join[FULL OUTER JOIN]', 'tests/test_tokenize.py::test_parse_join[NATURAL JOIN]', 'tests/test_tokenize.py::test_parse_join[CROSS JOIN]', 'tests/test_tokenize.py::test_parse_join[STRAIGHT JOIN]', 'tests/test_tokenize.py::test_parse_join[INNER JOIN]', 'tests/test_tokenize.py::test_parse_join[LEFT INNER JOIN]', 'tests/test_tokenize.py::test_parse_union', 'tests/test_tokenize.py::test_parse_endifloop[END IF]', 'tests/test_tokenize.py::test_parse_endifloop[END   IF]', 'tests/test_tokenize.py::test_parse_endifloop[END\\t\\nIF]', 'tests/test_tokenize.py::test_parse_endifloop[END LOOP]', 'tests/test_tokenize.py::test_parse_endifloop[END   LOOP]', 'tests/test_tokenize.py::test_parse_endifloop[END\\t\\nLOOP]', 'tests/test_tokenize.py::test_parse_order[ASC]', 'tests/test_tokenize.py::test_parse_order[DESC]', 'tests/test_tokenize.py::test_parse_order[NULLS FIRST]', 'tests/test_tokenize.py::test_parse_order[NULLS LAST]', 'tests/test_tokenize.py::test_parse_order[ASC NULLS FIRST]', 'tests/test_tokenize.py::test_parse_order[ASC NULLS LAST]', 'tests/test_tokenize.py::test_parse_order[DESC NULLS FIRST]', 'tests/test_tokenize.py::test_parse_order[DESC NULLS LAST]', 'tests/test_tokenize.py::test_parse_identifiers[foo]', 'tests/test_tokenize.py::test_parse_identifiers[Foo]', 'tests/test_tokenize.py::test_parse_identifiers[FOO]', 'tests/test_tokenize.py::test_parse_identifiers[v$name]', 'tests/test_tokenize.py::test_parse_group_by', 'tests/test_tokenize.py::test_parse_order_by', 'tests/test_tokenize.py::test_parse_window_as', 'tests/test_tokenize.py::test_like_and_ilike_parsed_as_comparisons[LIKE]', 'tests/test_tokenize.py::test_like_and_ilike_parsed_as_comparisons[ILIKE]', 'tests/test_tokenize.py::test_like_and_ilike_parsed_as_comparisons[NOT LIKE]', 'tests/test_tokenize.py::test_like_and_ilike_parsed_as_comparisons[NOT ILIKE]', 'tests/test_tokenize.py::test_like_and_ilike_parsed_as_comparisons[NOT   LIKE]', 'tests/test_tokenize.py::test_like_and_ilike_parsed_as_comparisons[NOT    ILIKE]', 'tests/test_tokenize.py::test_near_like_and_ilike_parsed_appropriately[LIKEaaa]', 'tests/test_tokenize.py::test_near_like_and_ilike_parsed_appropriately[bILIKE]', 'tests/test_tokenize.py::test_near_like_and_ilike_parsed_appropriately[aaILIKEbb]', 'tests/test_tokenize.py::test_near_like_and_ilike_parsed_appropriately[NOTLIKE]', 'tests/test_tokenize.py::test_near_like_and_ilike_parsed_appropriately[NOTILIKE]', ""tests/test_tokenize.py::test_parse_tzcast[AT TIME ZONE 'UTC']"", 'tests/test_tokenize.py::test_cli_commands']","[""filepath = <function filepath.<locals>.make_filepath at 0x000001A2211AE660>\n\n    def test_valid_args(filepath):\n        # test doesn't abort\n        path = filepath('function.sql')\n>       assert sqlparse.cli.main([path, '-r']) is not None\n\nrepos\\sqlparse\\tests\\test_cli.py:30: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\cli.py:198: in main\n    s = sqlparse.format(data, **formatter_opts)\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return ''.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'CREATE...' at 0x1A221213C50>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""self = <tests.test_format.TestFormat object at 0x000001A220E4BBD0>\n\n    def test_strip_comments_single(self):\n        sql = 'select *-- statement starts here\\nfrom foo'\n>       res = sqlparse.format(sql, strip_comments=True)\n\nrepos\\sqlparse\\tests\\test_format.py:43: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return ''.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'select...' at 0x1A221331050>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""self = <tests.test_format.TestFormat object at 0x000001A220F9CB50>\n\n    def test_strip_comments_multi(self):\n        sql = '/* sql starts here */\\nselect'\n>       res = sqlparse.format(sql, strip_comments=True)\n\nrepos\\sqlparse\\tests\\test_format.py:72: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return ''.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement '/* sql...' at 0x1A221292950>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Comment' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""self = <tests.test_format.TestFormat object at 0x000001A220F9CC50>\n\n    def test_strip_comments_preserves_linebreak(self):\n        sql = 'select * -- a comment\\r\\nfrom foo'\n>       res = sqlparse.format(sql, strip_comments=True)\n\nrepos\\sqlparse\\tests\\test_format.py:89: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return ''.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'select...' at 0x1A2213404D0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""self = <tests.test_format.TestFormat object at 0x000001A220F26300>\n\n    def test_strip_comments_preserves_whitespace(self):\n        sql = 'SELECT 1/*bar*/ AS foo'  # see issue772\n>       res = sqlparse.format(sql, strip_comments=True)\n\nrepos\\sqlparse\\tests\\test_format.py:106: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return ''.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'SELECT...' at 0x1A2213337D0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""self = <tests.test_format.TestFormat object at 0x000001A220F263F0>\n\n    def test_strip_comments_preserves_hint(self):\n        sql = 'select --+full(u)'\n>       res = sqlparse.format(sql, strip_comments=True)\n\nrepos\\sqlparse\\tests\\test_format.py:111: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return ''.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'select...' at 0x1A221340F50>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""self = <tests.test_format.TestFormat object at 0x000001A220FF4830>\n\n    def test_strip_ws(self):\n        f = lambda sql: sqlparse.format(sql, strip_whitespace=True)\n        s = 'select\\n* from      foo\\n\\twhere  ( 1 = 2 )\\n'\n>       assert f(s) == 'select * from foo where (1 = 2)'\n\nrepos\\sqlparse\\tests\\test_format.py:132: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:130: in <lambda>\n    f = lambda sql: sqlparse.format(sql, strip_whitespace=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return ''.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'select...' at 0x1A221340AD0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""self = <tests.test_format.TestFormat object at 0x000001A220FD1A50>\n\n    def test_preserve_ws(self):\n        # preserve at least one whitespace after subgroups\n        f = lambda sql: sqlparse.format(sql, strip_whitespace=True)\n        s = 'select\\n* /* foo */  from bar '\n>       assert f(s) == 'select * /* foo */ from bar'\n\nrepos\\sqlparse\\tests\\test_format.py:145: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:143: in <lambda>\n    f = lambda sql: sqlparse.format(sql, strip_whitespace=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return ''.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'select...' at 0x1A220F67950>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", 'self = <tests.test_format.TestFormatReindentAligned object at 0x000001A220E6A990>\n\n    def test_basic(self):\n        sql = """"""\n            select a, b as bb,c from table\n            join (select a * 2 as a from new_table) other\n            on table.a = other.a\n            where c is true\n            and b between 3 and 4\n            or d is \'blue\'\n            limit 10\n            """"""\n    \n>       assert self.formatter(sql) == \'\\n\'.join([\n            \'select a,\',\n            \'       b as bb,\',\n            \'       c\',\n            \'  from table\',\n            \'  join (\',\n            \'        select a * 2 as a\',\n            \'          from new_table\',\n            \'       ) other\',\n            \'    on table.a = other.a\',\n            \' where c is true\',\n            \'   and b between 3 and 4\',\n            ""    or d is \'blue\'"",\n            \' limit 10\'])\n\nrepos\\sqlparse\\tests\\test_format.py:182: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:169: in formatter\n    return sqlparse.format(sql, reindent_aligned=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return \'\'.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement \' ...\' at 0x1A221340C50>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: \'Token\' object has no attribute \'isdigit\'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError', 'self = <tests.test_format.TestFormatReindentAligned object at 0x000001A220E69E50>\n\n    def test_joins(self):\n        sql = """"""\n            select * from a\n            join b on a.one = b.one\n            left join c on c.two = a.two and c.three = a.three\n            full outer join d on d.three = a.three\n            cross join e on e.four = a.four\n            join f using (one, two, three)\n            """"""\n>       assert self.formatter(sql) == \'\\n\'.join([\n            \'select *\',\n            \'  from a\',\n            \'  join b\',\n            \'    on a.one = b.one\',\n            \'  left join c\',\n            \'    on c.two = a.two\',\n            \'   and c.three = a.three\',\n            \'  full outer join d\',\n            \'    on d.three = a.three\',\n            \' cross join e\',\n            \'    on e.four = a.four\',\n            \'  join f using (one, two, three)\'])\n\nrepos\\sqlparse\\tests\\test_format.py:206: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:169: in formatter\n    return sqlparse.format(sql, reindent_aligned=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return \'\'.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement \' ...\' at 0x1A221330750>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: \'Token\' object has no attribute \'isdigit\'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError', 'self = <tests.test_format.TestFormatReindentAligned object at 0x000001A220E5BE10>\n\n    def test_case_statement(self):\n        sql = """"""\n            select a,\n            case when a = 0\n            then 1\n            when bb = 1 then 1\n            when c = 2 then 2\n            else 0 end as d,\n            extra_col\n            from table\n            where c is true\n            and b between 3 and 4\n            """"""\n>       assert self.formatter(sql) == \'\\n\'.join([\n            \'select a,\',\n            \'       case when a = 0  then 1\',\n            \'            when bb = 1 then 1\',\n            \'            when c = 2  then 2\',\n            \'            else 0\',\n            \'             end as d,\',\n            \'       extra_col\',\n            \'  from table\',\n            \' where c is true\',\n            \'   and b between 3 and 4\'])\n\nrepos\\sqlparse\\tests\\test_format.py:233: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:169: in formatter\n    return sqlparse.format(sql, reindent_aligned=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return \'\'.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement \' ...\' at 0x1A221341FD0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: \'Token\' object has no attribute \'isdigit\'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError', 'self = <tests.test_format.TestFormatReindentAligned object at 0x000001A221000050>\n\n    def test_case_statement_with_between(self):\n        sql = """"""\n            select a,\n            case when a = 0\n            then 1\n            when bb = 1 then 1\n            when c = 2 then 2\n            when d between 3 and 5 then 3\n            else 0 end as d,\n            extra_col\n            from table\n            where c is true\n            and b between 3 and 4\n            """"""\n>       assert self.formatter(sql) == \'\\n\'.join([\n            \'select a,\',\n            \'       case when a = 0             then 1\',\n            \'            when bb = 1            then 1\',\n            \'            when c = 2             then 2\',\n            \'            when d between 3 and 5 then 3\',\n            \'            else 0\',\n            \'             end as d,\',\n            \'       extra_col\',\n            \'  from table\',\n            \' where c is true\',\n            \'   and b between 3 and 4\'])\n\nrepos\\sqlparse\\tests\\test_format.py:259: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:169: in formatter\n    return sqlparse.format(sql, reindent_aligned=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return \'\'.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement \' ...\' at 0x1A2214C3850>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: \'Token\' object has no attribute \'isdigit\'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError', 'self = <tests.test_format.TestFormatReindentAligned object at 0x000001A220FF27B0>\n\n    def test_group_by(self):\n        sql = """"""\n            select a, b, c, sum(x) as sum_x, count(y) as cnt_y\n            from table\n            group by a,b,c\n            having sum(x) > 1\n            and count(y) > 5\n            order by 3,2,1\n            """"""\n>       assert self.formatter(sql) == \'\\n\'.join([\n            \'select a,\',\n            \'       b,\',\n            \'       c,\',\n            \'       sum(x) as sum_x,\',\n            \'       count(y) as cnt_y\',\n            \'  from table\',\n            \' group by a,\',\n            \'          b,\',\n            \'          c\',\n            \'having sum(x) > 1\',\n            \'   and count(y) > 5\',\n            \' order by 3,\',\n            \'          2,\',\n            \'          1\'])\n\nrepos\\sqlparse\\tests\\test_format.py:281: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:169: in formatter\n    return sqlparse.format(sql, reindent_aligned=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return \'\'.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement \' ...\' at 0x1A220FF8B50>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: \'Token\' object has no attribute \'isdigit\'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError', 'self = <tests.test_format.TestFormatReindentAligned object at 0x000001A220E4B680>\n\n    def test_group_by_subquery(self):\n        # TODO: add subquery alias when test_identifier_list_subquery fixed\n        sql = """"""\n            select *, sum_b + 2 as mod_sum\n            from (\n              select a, sum(b) as sum_b\n              from table\n              group by a,z)\n            order by 1,2\n            """"""\n>       assert self.formatter(sql) == \'\\n\'.join([\n            \'select *,\',\n            \'       sum_b + 2 as mod_sum\',\n            \'  from (\',\n            \'        select a,\',\n            \'               sum(b) as sum_b\',\n            \'          from table\',\n            \'         group by a,\',\n            \'                  z\',\n            \'       )\',\n            \' order by 1,\',\n            \'          2\'])\n\nrepos\\sqlparse\\tests\\test_format.py:307: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:169: in formatter\n    return sqlparse.format(sql, reindent_aligned=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return \'\'.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement \' ...\' at 0x1A221340E50>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: \'Token\' object has no attribute \'isdigit\'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError', 'self = <tests.test_format.TestFormatReindentAligned object at 0x000001A220E4BCE0>\n\n    def test_window_functions(self):\n        sql = """"""\n            select a,\n            SUM(a) OVER (PARTITION BY b ORDER BY c ROWS\n            BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) as sum_a,\n            ROW_NUMBER() OVER\n            (PARTITION BY b, c ORDER BY d DESC) as row_num\n            from table""""""\n>       assert self.formatter(sql) == \'\\n\'.join([\n            \'select a,\',\n            \'       SUM(a) OVER (PARTITION BY b ORDER BY c ROWS \'\n            \'BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) as sum_a,\',\n            \'       ROW_NUMBER() OVER \'\n            \'(PARTITION BY b, c ORDER BY d DESC) as row_num\',\n            \'  from table\'])\n\nrepos\\sqlparse\\tests\\test_format.py:328: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:169: in formatter\n    return sqlparse.format(sql, reindent_aligned=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return \'\'.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement \' ...\' at 0x1A2214C18D0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: \'Token\' object has no attribute \'isdigit\'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError', ""self = <tests.test_format.TestSpacesAroundOperators object at 0x000001A220E6AAD0>\n\n    def test_basic(self):\n        sql = ('select a+b as d from table '\n               'where (c-d)%2= 1 and e> 3.0/4 and z^2 <100')\n>       assert self.formatter(sql) == (\n            'select a + b as d from table '\n            'where (c - d) % 2 = 1 and e > 3.0 / 4 and z ^ 2 < 100')\n\nrepos\\sqlparse\\tests\\test_format.py:345: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:340: in formatter\n    return sqlparse.format(sql, use_space_around_operators=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return ''.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'select...' at 0x1A2212133D0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""self = <tests.test_format.TestSpacesAroundOperators object at 0x000001A220E6AC10>\n\n    def test_bools(self):\n        sql = 'select * from table where a &&b or c||d'\n>       assert self.formatter(\n            sql) == 'select * from table where a && b or c || d'\n\nrepos\\sqlparse\\tests\\test_format.py:351: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:340: in formatter\n    return sqlparse.format(sql, use_space_around_operators=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return ''.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'select...' at 0x1A2214C2050>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""self = <tests.test_format.TestSpacesAroundOperators object at 0x000001A221000180>\n\n    def test_nested(self):\n        sql = 'select *, case when a-b then c end from table'\n>       assert self.formatter(\n            sql) == 'select *, case when a - b then c end from table'\n\nrepos\\sqlparse\\tests\\test_format.py:356: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:340: in formatter\n    return sqlparse.format(sql, use_space_around_operators=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return ''.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'select...' at 0x1A2214C7CD0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""self = <tests.test_format.TestSpacesAroundOperators object at 0x000001A2210002B0>\n\n    def test_wildcard_vs_mult(self):\n        sql = 'select a*b-c from table'\n>       assert self.formatter(sql) == 'select a * b - c from table'\n\nrepos\\sqlparse\\tests\\test_format.py:361: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:340: in formatter\n    return sqlparse.format(sql, use_space_around_operators=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return ''.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'select...' at 0x1A221210650>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""self = <tests.test_format.TestFormatReindent object at 0x000001A220E6AE90>\n\n    def test_stmts(self):\n        f = lambda sql: sqlparse.format(sql, reindent=True)\n        s = 'select foo; select bar'\n>       assert f(s) == 'select foo;\\n\\nselect bar'\n\nrepos\\sqlparse\\tests\\test_format.py:384: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:382: in <lambda>\n    f = lambda sql: sqlparse.format(sql, reindent=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return ''.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'select...' at 0x1A2214C03D0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""self = <tests.test_format.TestFormatReindent object at 0x000001A2210003E0>\n\n    def test_keywords(self):\n        f = lambda sql: sqlparse.format(sql, reindent=True)\n        s = 'select * from foo union select * from bar;'\n>       assert f(s) == '\\n'.join([\n            'select *',\n            'from foo',\n            'union',\n            'select *',\n            'from bar;'])\n\nrepos\\sqlparse\\tests\\test_format.py:393: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:391: in <lambda>\n    f = lambda sql: sqlparse.format(sql, reindent=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return ''.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'select...' at 0x1A221213850>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""self = <tests.test_format.TestFormatReindent object at 0x000001A221000510>\n\n    def test_keywords_between(self):\n        # issue 14\n        # don't break AND after BETWEEN\n        f = lambda sql: sqlparse.format(sql, reindent=True)\n        s = 'and foo between 1 and 2 and bar = 3'\n>       assert f(s) == '\\n'.join([\n            '',\n            'and foo between 1 and 2',\n            'and bar = 3'])\n\nrepos\\sqlparse\\tests\\test_format.py:405: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:403: in <lambda>\n    f = lambda sql: sqlparse.format(sql, reindent=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return ''.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'and fo...' at 0x1A2214C18D0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""self = <tests.test_format.TestFormatReindent object at 0x000001A221014290>\n\n    def test_parenthesis(self):\n        f = lambda sql: sqlparse.format(sql, reindent=True)\n        s = 'select count(*) from (select * from foo);'\n>       assert f(s) == '\\n'.join([\n            'select count(*)',\n            'from',\n            '  (select *',\n            '   from foo);'])\n\nrepos\\sqlparse\\tests\\test_format.py:413: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:411: in <lambda>\n    f = lambda sql: sqlparse.format(sql, reindent=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return ''.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'select...' at 0x1A221332D50>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""self = <tests.test_format.TestFormatReindent object at 0x000001A220E4BDF0>\n\n    def test_where(self):\n        f = lambda sql: sqlparse.format(sql, reindent=True)\n        s = 'select * from foo where bar = 1 and baz = 2 or bzz = 3;'\n>       assert f(s) == '\\n'.join([\n            'select *',\n            'from foo',\n            'where bar = 1',\n            '  and baz = 2',\n            '  or bzz = 3;'])\n\nrepos\\sqlparse\\tests\\test_format.py:427: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:425: in <lambda>\n    f = lambda sql: sqlparse.format(sql, reindent=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return ''.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'select...' at 0x1A221341550>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""self = <tests.test_format.TestFormatReindent object at 0x000001A220E4BF00>\n\n    def test_join(self):\n        f = lambda sql: sqlparse.format(sql, reindent=True)\n        s = 'select * from foo join bar on 1 = 2'\n>       assert f(s) == '\\n'.join([\n            'select *',\n            'from foo',\n            'join bar on 1 = 2'])\n\nrepos\\sqlparse\\tests\\test_format.py:445: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:443: in <lambda>\n    f = lambda sql: sqlparse.format(sql, reindent=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return ''.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'select...' at 0x1A2214C0850>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""self = <tests.test_format.TestFormatReindent object at 0x000001A220F9CD50>\n\n    def test_identifier_list(self):\n        f = lambda sql: sqlparse.format(sql, reindent=True)\n        s = 'select foo, bar, baz from table1, table2 where 1 = 2'\n>       assert f(s) == '\\n'.join([\n            'select foo,',\n            '       bar,',\n            '       baz',\n            'from table1,',\n            '     table2',\n            'where 1 = 2'])\n\nrepos\\sqlparse\\tests\\test_format.py:468: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:466: in <lambda>\n    f = lambda sql: sqlparse.format(sql, reindent=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return ''.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'select...' at 0x1A2213339D0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""self = <tests.test_format.TestFormatReindent object at 0x000001A220F9CE50>\n\n    def test_identifier_list_with_wrap_after(self):\n        f = lambda sql: sqlparse.format(sql, reindent=True, wrap_after=14)\n        s = 'select foo, bar, baz from table1, table2 where 1 = 2'\n>       assert f(s) == '\\n'.join([\n            'select foo, bar,',\n            '       baz',\n            'from table1, table2',\n            'where 1 = 2'])\n\nrepos\\sqlparse\\tests\\test_format.py:485: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:483: in <lambda>\n    f = lambda sql: sqlparse.format(sql, reindent=True, wrap_after=14)\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return ''.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'select...' at 0x1A2212105D0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""self = <tests.test_format.TestFormatReindent object at 0x000001A220F264E0>\n\n    def test_identifier_list_comment_first(self):\n        f = lambda sql: sqlparse.format(sql, reindent=True, comma_first=True)\n        # not the 3: It cleans up whitespace too!\n        s = 'select foo, bar, baz from table where foo in (1, 2,3)'\n>       assert f(s) == '\\n'.join([\n            'select foo',\n            '     , bar',\n            '     , baz',\n            'from table',\n            'where foo in (1',\n            '            , 2',\n            '            , 3)'])\n\nrepos\\sqlparse\\tests\\test_format.py:495: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:492: in <lambda>\n    f = lambda sql: sqlparse.format(sql, reindent=True, comma_first=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return ''.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'select...' at 0x1A2214C6A50>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", 'self = <tests.test_format.TestFormatReindent object at 0x000001A220F265D0>\n\n    def test_identifier_list_with_functions(self):\n        f = lambda sql: sqlparse.format(sql, reindent=True)\n        s = (""select \'abc\' as foo, coalesce(col1, col2)||col3 as bar,""\n             ""col3 from my_table"")\n>       assert f(s) == \'\\n\'.join([\n            ""select \'abc\' as foo,"",\n            ""       coalesce(col1, col2)||col3 as bar,"",\n            ""       col3"",\n            ""from my_table""])\n\nrepos\\sqlparse\\tests\\test_format.py:508: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:505: in <lambda>\n    f = lambda sql: sqlparse.format(sql, reindent=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return \'\'.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement \'select...\' at 0x1A221477050>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: \'Token\' object has no attribute \'isdigit\'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError', 'self = <tests.test_format.TestFormatReindent object at 0x000001A220F6C3D0>\n\n    def test_long_identifier_list_with_functions(self):\n        f = lambda sql: sqlparse.format(sql, reindent=True, wrap_after=30)\n        s = (""select \'abc\' as foo, json_build_object(\'a\',  a,""\n             ""\'b\', b, \'c\', c, \'d\', d, \'e\', e) as col2""\n             ""col3 from my_table"")\n>       assert f(s) == \'\\n\'.join([\n            ""select \'abc\' as foo,"",\n            ""       json_build_object(\'a\',"",\n            ""         a, \'b\', b, \'c\', c, \'d\', d,"",\n            ""         \'e\', e) as col2col3"",\n            ""from my_table""])\n\nrepos\\sqlparse\\tests\\test_format.py:519: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:515: in <lambda>\n    f = lambda sql: sqlparse.format(sql, reindent=True, wrap_after=30)\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return \'\'.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement \'select...\' at 0x1A2214C66D0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: \'Token\' object has no attribute \'isdigit\'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError', ""self = <tests.test_format.TestFormatReindent object at 0x000001A220F6C2F0>\n\n    def test_case(self):\n        f = lambda sql: sqlparse.format(sql, reindent=True)\n        s = 'case when foo = 1 then 2 when foo = 3 then 4 else 5 end'\n>       assert f(s) == '\\n'.join([\n            'case',\n            '    when foo = 1 then 2',\n            '    when foo = 3 then 4',\n            '    else 5',\n            'end'])\n\nrepos\\sqlparse\\tests\\test_format.py:529: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:527: in <lambda>\n    f = lambda sql: sqlparse.format(sql, reindent=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return ''.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'case w...' at 0x1A221331E50>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Case' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""self = <tests.test_format.TestFormatReindent object at 0x000001A220FD20D0>\n\n    def test_case2(self):\n        f = lambda sql: sqlparse.format(sql, reindent=True)\n        s = 'case(foo) when bar = 1 then 2 else 3 end'\n>       assert f(s) == '\\n'.join([\n            'case(foo)',\n            '    when bar = 1 then 2',\n            '    else 3',\n            'end'])\n\nrepos\\sqlparse\\tests\\test_format.py:539: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:537: in <lambda>\n    f = lambda sql: sqlparse.format(sql, reindent=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return ''.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'case(f...' at 0x1A221475CD0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Case' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""self = <tests.test_format.TestFormatReindent object at 0x000001A220E17410>\n\n    def test_nested_identifier_list(self):\n        # issue4\n        f = lambda sql: sqlparse.format(sql, reindent=True)\n        s = '(foo as bar, bar1, bar2 as bar3, b4 as b5)'\n>       assert f(s) == '\\n'.join([\n            '(foo as bar,',\n            ' bar1,',\n            ' bar2 as bar3,',\n            ' b4 as b5)'])\n\nrepos\\sqlparse\\tests\\test_format.py:549: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:547: in <lambda>\n    f = lambda sql: sqlparse.format(sql, reindent=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return ''.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement '(foo a...' at 0x1A2212133D0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Parenthesis' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""self = <tests.test_format.TestFormatReindent object at 0x000001A220E17AD0>\n\n    def test_duplicate_linebreaks(self):\n        # issue3\n        f = lambda sql: sqlparse.format(sql, reindent=True)\n        s = 'select c1 -- column1\\nfrom foo'\n>       assert f(s) == '\\n'.join([\n            'select c1 -- column1',\n            'from foo'])\n\nrepos\\sqlparse\\tests\\test_format.py:559: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:557: in <lambda>\n    f = lambda sql: sqlparse.format(sql, reindent=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return ''.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'select...' at 0x1A221474550>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""self = <tests.test_format.TestFormatReindent object at 0x000001A220F19860>\n\n    def test_keywordfunctions(self):\n        # issue36\n        f = lambda sql: sqlparse.format(sql, reindent=True)\n        s = 'select max(a) b, foo, bar'\n>       assert f(s) == '\\n'.join([\n            'select max(a) b,',\n            '       foo,',\n            '       bar'])\n\nrepos\\sqlparse\\tests\\test_format.py:583: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:581: in <lambda>\n    f = lambda sql: sqlparse.format(sql, reindent=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return ''.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'select...' at 0x1A2214BE850>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""self = <tests.test_format.TestFormatReindent object at 0x000001A220F19910>\n\n    def test_identifier_and_functions(self):\n        # issue45\n        f = lambda sql: sqlparse.format(sql, reindent=True)\n        s = 'select foo.bar, nvl(1) from dual'\n>       assert f(s) == '\\n'.join([\n            'select foo.bar,',\n            '       nvl(1)',\n            'from dual'])\n\nrepos\\sqlparse\\tests\\test_format.py:592: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:590: in <lambda>\n    f = lambda sql: sqlparse.format(sql, reindent=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return ''.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'select...' at 0x1A2214750D0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""self = <tests.test_format.TestFormatReindent object at 0x000001A220FAAA30>\n\n    def test_insert_values(self):\n        # issue 329\n        f = lambda sql: sqlparse.format(sql, reindent=True)\n        s = 'insert into foo values (1, 2)'\n>       assert f(s) == '\\n'.join([\n            'insert into foo',\n            'values (1, 2)'])\n\nrepos\\sqlparse\\tests\\test_format.py:601: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:599: in <lambda>\n    f = lambda sql: sqlparse.format(sql, reindent=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return ''.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'insert...' at 0x1A2214C1950>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", 'self = <tests.test_format.TestOutputFormat object at 0x000001A220E6AFD0>\n\n    def test_python(self):\n        sql = \'select * from foo;\'\n        f = lambda sql: sqlparse.format(sql, output_format=\'python\')\n        assert f(sql) == ""sql = \'select * from foo;\'""\n        f = lambda sql: sqlparse.format(sql, output_format=\'python\',\n                                        reindent=True)\n>       assert f(sql) == \'\\n\'.join([\n            ""sql = (\'select * \'"",\n            ""       \'from foo;\')""])\n\nrepos\\sqlparse\\tests\\test_format.py:648: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:646: in <lambda>\n    f = lambda sql: sqlparse.format(sql, output_format=\'python\',\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return \'\'.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement \'select...\' at 0x1A2214C6650>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: \'Token\' object has no attribute \'isdigit\'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError', 'self = <tests.test_format.TestOutputFormat object at 0x000001A221000770>\n\n    def test_php(self):\n        sql = \'select * from foo;\'\n        f = lambda sql: sqlparse.format(sql, output_format=\'php\')\n        assert f(sql) == \'$sql = ""select * from foo;"";\'\n        f = lambda sql: sqlparse.format(sql, output_format=\'php\',\n                                        reindent=True)\n>       assert f(sql) == \'\\n\'.join([\n            \'$sql  = ""select * "";\',\n            \'$sql .= ""from foo;"";\'])\n\nrepos\\sqlparse\\tests\\test_format.py:676: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:674: in <lambda>\n    f = lambda sql: sqlparse.format(sql, output_format=\'php\',\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return \'\'.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement \'select...\' at 0x1A2214BE1D0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: \'Token\' object has no attribute \'isdigit\'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError', ""def test_format_column_ordering():\n        # issue89\n        sql = 'select * from foo order by c1 desc, c2, c3;'\n>       formatted = sqlparse.format(sql, reindent=True)\n\nrepos\\sqlparse\\tests\\test_format.py:695: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return ''.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'select...' at 0x1A221477DD0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""def test_having_produces_newline():\n        sql = ('select * from foo, bar where bar.id = foo.bar_id '\n               'having sum(bar.value) > 100')\n>       formatted = sqlparse.format(sql, reindent=True)\n\nrepos\\sqlparse\\tests\\test_format.py:730: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return ''.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'select...' at 0x1A221474450>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", 'def test_format_json_ops():  # issue542\n>       formatted = sqlparse.format(\n            ""select foo->\'bar\', foo->\'bar\';"", reindent=True)\n\nrepos\\sqlparse\\tests\\test_format.py:753: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return \'\'.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement \'select...\' at 0x1A2214BE9D0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: \'Token\' object has no attribute \'isdigit\'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError', ""sql = 'case when foo then 1 else bar end'\nexpected_normal = 'case\\n    when foo then 1\\n    else bar\\nend'\nexpected_compact = 'case when foo then 1 else bar end'\n\n    @pytest.mark.parametrize('sql, expected_normal, expected_compact', [\n        ('case when foo then 1 else bar end',\n         'case\\n    when foo then 1\\n    else bar\\nend',\n         'case when foo then 1 else bar end')])\n    def test_compact(sql, expected_normal, expected_compact):  # issue783\n>       formatted_normal = sqlparse.format(sql, reindent=True)\n\nrepos\\sqlparse\\tests\\test_format.py:764: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return ''.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'case w...' at 0x1A221538050>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Case' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""def test_strip_ws_removes_trailing_ws_in_groups():  # issue782\n>       formatted = sqlparse.format('( where foo = bar  ) from',\n                                    strip_whitespace=True)\n\nrepos\\sqlparse\\tests\\test_format.py:771: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return ''.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement '( wher...' at 0x1A22151B1D0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Parenthesis' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""def test_grouping_parenthesis():\n        s = 'select (select (x3) x2) and (y2) bar'\n>       parsed = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:9: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'select...' at 0x1A2214BE5D0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""s = 'foo := 1;'\n\n    @pytest.mark.parametrize('s', ['foo := 1;', 'foo := 1'])\n    def test_grouping_assignment(s):\n>       parsed = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:22: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'foo :=...' at 0x1A221518E50>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Identifier' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""s = 'foo := 1'\n\n    @pytest.mark.parametrize('s', ['foo := 1;', 'foo := 1'])\n    def test_grouping_assignment(s):\n>       parsed = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:22: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'foo :=...' at 0x1A2215385D0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Identifier' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", 's = ""x > DATE \'2020-01-01\'""\n\n    @pytest.mark.parametrize(\'s\', [""x > DATE \'2020-01-01\'"", ""x > TIMESTAMP \'2020-01-01 00:00:00\'""])\n    def test_grouping_typed_literal(s):\n>       parsed = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:29: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement \'x > DA...\' at 0x1A2215188D0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: \'Identifier\' object has no attribute \'isdigit\'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError', 's = ""x > TIMESTAMP \'2020-01-01 00:00:00\'""\n\n    @pytest.mark.parametrize(\'s\', [""x > DATE \'2020-01-01\'"", ""x > TIMESTAMP \'2020-01-01 00:00:00\'""])\n    def test_grouping_typed_literal(s):\n>       parsed = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:29: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement \'x > TI...\' at 0x1A2214BD250>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: \'Identifier\' object has no attribute \'isdigit\'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError', ""s = 'select a from b where c < d + e', a = <class 'sqlparse.sql.Identifier'>\nb = <class 'sqlparse.sql.Identifier'>\n\n    @pytest.mark.parametrize('s, a, b', [\n        ('select a from b where c < d + e', sql.Identifier, sql.Identifier),\n        ('select a from b where c < d + interval \\'1 day\\'', sql.Identifier, sql.TypedLiteral),\n        ('select a from b where c < d + interval \\'6\\' month', sql.Identifier, sql.TypedLiteral),\n        ('select a from b where c < current_timestamp - interval \\'1 day\\'', sql.Token, sql.TypedLiteral),\n    ])\n    def test_compare_expr(s, a, b):\n>       parsed = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:40: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'select...' at 0x1A221519850>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", 's = ""select a from b where c < d + interval \'1 day\'""\na = <class \'sqlparse.sql.Identifier\'>, b = <class \'sqlparse.sql.TypedLiteral\'>\n\n    @pytest.mark.parametrize(\'s, a, b\', [\n        (\'select a from b where c < d + e\', sql.Identifier, sql.Identifier),\n        (\'select a from b where c < d + interval \\\'1 day\\\'\', sql.Identifier, sql.TypedLiteral),\n        (\'select a from b where c < d + interval \\\'6\\\' month\', sql.Identifier, sql.TypedLiteral),\n        (\'select a from b where c < current_timestamp - interval \\\'1 day\\\'\', sql.Token, sql.TypedLiteral),\n    ])\n    def test_compare_expr(s, a, b):\n>       parsed = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:40: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement \'select...\' at 0x1A2225280D0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: \'Token\' object has no attribute \'isdigit\'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError', 's = ""select a from b where c < d + interval \'6\' month""\na = <class \'sqlparse.sql.Identifier\'>, b = <class \'sqlparse.sql.TypedLiteral\'>\n\n    @pytest.mark.parametrize(\'s, a, b\', [\n        (\'select a from b where c < d + e\', sql.Identifier, sql.Identifier),\n        (\'select a from b where c < d + interval \\\'1 day\\\'\', sql.Identifier, sql.TypedLiteral),\n        (\'select a from b where c < d + interval \\\'6\\\' month\', sql.Identifier, sql.TypedLiteral),\n        (\'select a from b where c < current_timestamp - interval \\\'1 day\\\'\', sql.Token, sql.TypedLiteral),\n    ])\n    def test_compare_expr(s, a, b):\n>       parsed = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:40: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement \'select...\' at 0x1A22252A4D0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: \'Token\' object has no attribute \'isdigit\'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError', 's = ""select a from b where c < current_timestamp - interval \'1 day\'""\na = <class \'sqlparse.sql.Token\'>, b = <class \'sqlparse.sql.TypedLiteral\'>\n\n    @pytest.mark.parametrize(\'s, a, b\', [\n        (\'select a from b where c < d + e\', sql.Identifier, sql.Identifier),\n        (\'select a from b where c < d + interval \\\'1 day\\\'\', sql.Identifier, sql.TypedLiteral),\n        (\'select a from b where c < d + interval \\\'6\\\' month\', sql.Identifier, sql.TypedLiteral),\n        (\'select a from b where c < current_timestamp - interval \\\'1 day\\\'\', sql.Token, sql.TypedLiteral),\n    ])\n    def test_compare_expr(s, a, b):\n>       parsed = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:40: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement \'select...\' at 0x1A22151A4D0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: \'Token\' object has no attribute \'isdigit\'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError', 'def test_grouping_identifiers():\n        s = \'select foo.bar from ""myscheme"".""table"" where fail. order\'\n>       parsed = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:63: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement \'select...\' at 0x1A22151A950>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: \'Token\' object has no attribute \'isdigit\'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError', ""s = '1 as f'\n\n    @pytest.mark.parametrize('s', [\n        '1 as f',\n        'foo as f',\n        'foo f',\n        '1/2 as f',\n        '1/2 f',\n        '1<2 as f',  # issue327\n        '1<2 f',\n    ])\n    def test_simple_identifiers(s):\n>       parsed = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:105: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement '1 as f' at 0x1A222529B50>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""s = 'foo as f'\n\n    @pytest.mark.parametrize('s', [\n        '1 as f',\n        'foo as f',\n        'foo f',\n        '1/2 as f',\n        '1/2 f',\n        '1<2 as f',  # issue327\n        '1<2 f',\n    ])\n    def test_simple_identifiers(s):\n>       parsed = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:105: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'foo as...' at 0x1A222528CD0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Identifier' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""s = 'foo f'\n\n    @pytest.mark.parametrize('s', [\n        '1 as f',\n        'foo as f',\n        'foo f',\n        '1/2 as f',\n        '1/2 f',\n        '1<2 as f',  # issue327\n        '1<2 f',\n    ])\n    def test_simple_identifiers(s):\n>       parsed = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:105: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'foo f' at 0x1A2225289D0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Identifier' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""s = '1/2 as f'\n\n    @pytest.mark.parametrize('s', [\n        '1 as f',\n        'foo as f',\n        'foo f',\n        '1/2 as f',\n        '1/2 f',\n        '1<2 as f',  # issue327\n        '1<2 f',\n    ])\n    def test_simple_identifiers(s):\n>       parsed = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:105: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement '1/2 as...' at 0x1A2225C1FD0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""s = '1/2 f'\n\n    @pytest.mark.parametrize('s', [\n        '1 as f',\n        'foo as f',\n        'foo f',\n        '1/2 as f',\n        '1/2 f',\n        '1<2 as f',  # issue327\n        '1<2 f',\n    ])\n    def test_simple_identifiers(s):\n>       parsed = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:105: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement '1/2 f' at 0x1A2225C3D50>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""s = '1<2 as f'\n\n    @pytest.mark.parametrize('s', [\n        '1 as f',\n        'foo as f',\n        'foo f',\n        '1/2 as f',\n        '1/2 f',\n        '1<2 as f',  # issue327\n        '1<2 f',\n    ])\n    def test_simple_identifiers(s):\n>       parsed = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:105: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement '1<2 as...' at 0x1A2225C14D0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""s = '1<2 f'\n\n    @pytest.mark.parametrize('s', [\n        '1 as f',\n        'foo as f',\n        'foo f',\n        '1/2 as f',\n        '1/2 f',\n        '1<2 as f',  # issue327\n        '1<2 f',\n    ])\n    def test_simple_identifiers(s):\n>       parsed = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:105: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement '1<2 f' at 0x1A2225C09D0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""s = 'foo, bar'\n\n    @pytest.mark.parametrize('s', [\n        'foo, bar',\n        'sum(a), sum(b)',\n        'sum(a) as x, b as y',\n        'sum(a)::integer, b',\n        'sum(a)/count(b) as x, y',\n        'sum(a)::integer as x, y',\n        'sum(a)::integer/count(b) as x, y',  # issue297\n    ])\n    def test_group_identifier_list(s):\n>       parsed = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:119: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'foo, b...' at 0x1A22252B250>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Identifier' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""s = 'sum(a), sum(b)'\n\n    @pytest.mark.parametrize('s', [\n        'foo, bar',\n        'sum(a), sum(b)',\n        'sum(a) as x, b as y',\n        'sum(a)::integer, b',\n        'sum(a)/count(b) as x, y',\n        'sum(a)::integer as x, y',\n        'sum(a)::integer/count(b) as x, y',  # issue297\n    ])\n    def test_group_identifier_list(s):\n>       parsed = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:119: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'sum(a)...' at 0x1A221519050>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Function' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""s = 'sum(a) as x, b as y'\n\n    @pytest.mark.parametrize('s', [\n        'foo, bar',\n        'sum(a), sum(b)',\n        'sum(a) as x, b as y',\n        'sum(a)::integer, b',\n        'sum(a)/count(b) as x, y',\n        'sum(a)::integer as x, y',\n        'sum(a)::integer/count(b) as x, y',  # issue297\n    ])\n    def test_group_identifier_list(s):\n>       parsed = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:119: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'sum(a)...' at 0x1A2225C3BD0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Function' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""s = 'sum(a)::integer, b'\n\n    @pytest.mark.parametrize('s', [\n        'foo, bar',\n        'sum(a), sum(b)',\n        'sum(a) as x, b as y',\n        'sum(a)::integer, b',\n        'sum(a)/count(b) as x, y',\n        'sum(a)::integer as x, y',\n        'sum(a)::integer/count(b) as x, y',  # issue297\n    ])\n    def test_group_identifier_list(s):\n>       parsed = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:119: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'sum(a)...' at 0x1A22252BDD0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Function' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""s = 'sum(a)/count(b) as x, y'\n\n    @pytest.mark.parametrize('s', [\n        'foo, bar',\n        'sum(a), sum(b)',\n        'sum(a) as x, b as y',\n        'sum(a)::integer, b',\n        'sum(a)/count(b) as x, y',\n        'sum(a)::integer as x, y',\n        'sum(a)::integer/count(b) as x, y',  # issue297\n    ])\n    def test_group_identifier_list(s):\n>       parsed = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:119: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'sum(a)...' at 0x1A2225C37D0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Function' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""s = 'sum(a)::integer as x, y'\n\n    @pytest.mark.parametrize('s', [\n        'foo, bar',\n        'sum(a), sum(b)',\n        'sum(a) as x, b as y',\n        'sum(a)::integer, b',\n        'sum(a)/count(b) as x, y',\n        'sum(a)::integer as x, y',\n        'sum(a)::integer/count(b) as x, y',  # issue297\n    ])\n    def test_group_identifier_list(s):\n>       parsed = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:119: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'sum(a)...' at 0x1A2225C1450>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Function' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""s = 'sum(a)::integer/count(b) as x, y'\n\n    @pytest.mark.parametrize('s', [\n        'foo, bar',\n        'sum(a), sum(b)',\n        'sum(a) as x, b as y',\n        'sum(a)::integer, b',\n        'sum(a)/count(b) as x, y',\n        'sum(a)::integer as x, y',\n        'sum(a)::integer/count(b) as x, y',  # issue297\n    ])\n    def test_group_identifier_list(s):\n>       parsed = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:119: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'sum(a)...' at 0x1A2225D1250>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Function' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""def test_grouping_identifier_wildcard():\n>       p = sqlparse.parse('a.*, b.id')[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:124: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'a.*, b...' at 0x1A2225D3E50>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Identifier' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""def test_grouping_identifier_name_wildcard():\n>       p = sqlparse.parse('a.*')[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:131: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'a.*' at 0x1A2225D10D0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Identifier' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""def test_grouping_identifier_invalid():\n>       p = sqlparse.parse('a.')[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:138: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'a.' at 0x1A2225D2A50>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Identifier' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""def test_grouping_identifier_invalid_in_middle():\n        # issue261\n        s = 'SELECT foo. FROM foo'\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:149: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'SELECT...' at 0x1A2225D05D0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""s = 'foo as (select *)'\n\n    @pytest.mark.parametrize('s', ['foo as (select *)', 'foo as(select *)'])\n    def test_grouping_identifer_as(s):\n        # issue507\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:158: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'foo as...' at 0x1A2225D22D0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Identifier' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""s = 'foo as(select *)'\n\n    @pytest.mark.parametrize('s', ['foo as (select *)', 'foo as(select *)'])\n    def test_grouping_identifer_as(s):\n        # issue507\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:158: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'foo as...' at 0x1A2214BD450>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Identifier' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""def test_grouping_identifier_as_invalid():\n        # issue8\n>       p = sqlparse.parse('foo as select *')[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:166: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'foo as...' at 0x1A2214C7BD0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Identifier' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""def test_grouping_identifier_function():\n>       p = sqlparse.parse('foo() as bar')[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:174: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'foo() ...' at 0x1A2225C1BD0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Function' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""s = 'foo+100'\n\n    @pytest.mark.parametrize('s', ['foo+100', 'foo + 100', 'foo*100'])\n    def test_grouping_operation(s):\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:199: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'foo+100' at 0x1A2214C0350>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Identifier' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""s = 'foo + 100'\n\n    @pytest.mark.parametrize('s', ['foo+100', 'foo + 100', 'foo*100'])\n    def test_grouping_operation(s):\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:199: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'foo + ...' at 0x1A220F81F50>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Identifier' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""s = 'foo*100'\n\n    @pytest.mark.parametrize('s', ['foo+100', 'foo + 100', 'foo*100'])\n    def test_grouping_operation(s):\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:199: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'foo*100' at 0x1A2225282D0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Identifier' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""def test_grouping_identifier_list():\n>       p = sqlparse.parse('a, b, c')[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:204: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'a, b, c' at 0x1A2225D3BD0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Identifier' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", 'def test_grouping_identifier_list_subquery():\n        """"""identifier lists should still work in subqueries with aliases""""""\n>       p = sqlparse.parse(""select * from (""\n                           ""select a, b + c as d from table) sub"")[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:212: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement \'select...\' at 0x1A2225D1950>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: \'Token\' object has no attribute \'isdigit\'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError', ""def test_grouping_identifier_list_case():\n>       p = sqlparse.parse('a, case when 1 then 2 else 3 end as b, c')[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:223: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'a, cas...' at 0x1A22100DBD0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Identifier' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", 'def test_grouping_identifier_list_other():\n        # issue2\n>       p = sqlparse.parse(""select *, null, 1, \'foo\', bar from mytable, x"")[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:231: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement \'select...\' at 0x1A2225692D0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: \'Token\' object has no attribute \'isdigit\'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError', ""def test_grouping_identifier_list_with_inline_comments():\n        # issue163\n>       p = sqlparse.parse('foo /* a comment */, bar')[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:238: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'foo /*...' at 0x1A222568450>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Identifier' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""def test_grouping_identifiers_with_operators():\n>       p = sqlparse.parse('a+b as c from table where (d-e)%2= 1')[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:245: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'a+b as...' at 0x1A222568A50>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Identifier' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""def test_grouping_identifier_list_with_order():\n        # issue101\n>       p = sqlparse.parse('1, 2 desc, 3')[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:251: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement '1, 2 d...' at 0x1A2225C00D0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""def test_grouping_nested_identifier_with_order():\n        # issue745\n>       p = sqlparse.parse('(a desc)')[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:259: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement '(a des...' at 0x1A2214C3CD0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Parenthesis' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""def test_grouping_where():\n        s = 'select * from foo where bar = 1 order by id desc'\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:267: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'select...' at 0x1A222568650>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""s = 'select 1 where 1 = 2 union select 2'\n\n    @pytest.mark.parametrize('s', (\n        'select 1 where 1 = 2 union select 2',\n        'select 1 where 1 = 2 union all select 2',\n    ))\n    def test_grouping_where_union(s):\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:282: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'select...' at 0x1A22254E250>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""s = 'select 1 where 1 = 2 union all select 2'\n\n    @pytest.mark.parametrize('s', (\n        'select 1 where 1 = 2 union select 2',\n        'select 1 where 1 = 2 union all select 2',\n    ))\n    def test_grouping_where_union(s):\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:282: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'select...' at 0x1A2210550D0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""def test_returning_kw_ends_where_clause():\n        s = 'delete from foo where x > y returning z'\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:288: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'delete...' at 0x1A22254ECD0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""def test_into_kw_ends_where_clause():  # issue324\n        s = 'select * from foo where a = 1 into baz'\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:296: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'select...' at 0x1A222568850>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""sql = 'select foo::integer from bar', expected = 'integer'\n\n    @pytest.mark.parametrize('sql, expected', [\n        # note: typecast needs to be 2nd token for this test\n        ('select foo::integer from bar', 'integer'),\n        ('select (current_database())::information_schema.sql_identifier',\n         'information_schema.sql_identifier'),\n    ])\n    def test_grouping_typecast(sql, expected):\n>       p = sqlparse.parse(sql)[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:309: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'select...' at 0x1A22256A250>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""sql = 'select (current_database())::information_schema.sql_identifier'\nexpected = 'information_schema.sql_identifier'\n\n    @pytest.mark.parametrize('sql, expected', [\n        # note: typecast needs to be 2nd token for this test\n        ('select foo::integer from bar', 'integer'),\n        ('select (current_database())::information_schema.sql_identifier',\n         'information_schema.sql_identifier'),\n    ])\n    def test_grouping_typecast(sql, expected):\n>       p = sqlparse.parse(sql)[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:309: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'select...' at 0x1A22254D850>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""def test_grouping_alias():\n        s = 'select foo as bar from mytable'\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:315: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'select...' at 0x1A22256A7D0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""def test_grouping_alias_case():\n        # see issue46\n>       p = sqlparse.parse('CASE WHEN 1 THEN 2 ELSE 3 END foo')[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:337: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'CASE W...' at 0x1A221055CD0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Case' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""def test_grouping_alias_ctas():\n>       p = sqlparse.parse('CREATE TABLE tbl1 AS SELECT coalesce(t1.col1, 0) AS col1 FROM t1')[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:343: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'CREATE...' at 0x1A22254DFD0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""def test_grouping_subquery_no_parens():\n        # Not totally sure if this is the right approach...\n        # When a THEN clause contains a subquery w/o parenthesis around it *and*\n        # a WHERE condition, the WHERE grouper consumes END too.\n        # This takes makes sure that it doesn't fail.\n>       p = sqlparse.parse('CASE WHEN 1 THEN select 2 where foo = 1 end')[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:352: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'CASE W...' at 0x1A2225F27D0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Case' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""s = 'foo.bar'\n\n    @pytest.mark.parametrize('s', ['foo.bar', 'x, y', 'x > y', 'x / y'])\n    def test_grouping_alias_returns_none(s):\n        # see issue185 and issue445\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:360: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'foo.bar' at 0x1A2225F3750>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Identifier' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""s = 'x, y'\n\n    @pytest.mark.parametrize('s', ['foo.bar', 'x, y', 'x > y', 'x / y'])\n    def test_grouping_alias_returns_none(s):\n        # see issue185 and issue445\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:360: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'x, y' at 0x1A2225F34D0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Identifier' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""s = 'x > y'\n\n    @pytest.mark.parametrize('s', ['foo.bar', 'x, y', 'x > y', 'x / y'])\n    def test_grouping_alias_returns_none(s):\n        # see issue185 and issue445\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:360: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'x > y' at 0x1A2225F1E50>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Identifier' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""s = 'x / y'\n\n    @pytest.mark.parametrize('s', ['foo.bar', 'x, y', 'x > y', 'x / y'])\n    def test_grouping_alias_returns_none(s):\n        # see issue185 and issue445\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:360: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'x / y' at 0x1A22254D3D0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Identifier' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""def test_grouping_idlist_function():\n        # see issue10 too\n>       p = sqlparse.parse('foo(1) x, bar')[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:367: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'foo(1)...' at 0x1A2225F0650>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Function' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""def test_grouping_comparison_exclude():\n        # make sure operators are not handled too lazy\n>       p = sqlparse.parse('(=)')[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:373: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement '(=)' at 0x1A22256A7D0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Parenthesis' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""def test_grouping_function():\n>       p = sqlparse.parse('foo()')[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:383: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'foo()' at 0x1A22253C850>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Function' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""def test_grouping_function_not_in():\n        # issue183\n>       p = sqlparse.parse('in(1, 2)')[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:400: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'in(1, ...' at 0x1A22253F1D0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", 'def test_grouping_varchar():\n>       p = sqlparse.parse(\'""text"" Varchar(50) NOT NULL\')[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:407: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement \'""text""...\' at 0x1A22253FD50>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: \'Identifier\' object has no attribute \'isdigit\'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError', ""def test_statement_get_type():\n        def f(sql):\n            return sqlparse.parse(sql)[0]\n    \n>       assert f('select * from foo').get_type() == 'SELECT'\n\nrepos\\sqlparse\\tests\\test_grouping.py:415: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_grouping.py:413: in f\n    return sqlparse.parse(sql)[0]\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'select...' at 0x1A2225F0150>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""def test_identifier_with_operators():\n        # issue 53\n>       p = sqlparse.parse('foo||bar')[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:424: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'foo||b...' at 0x1A22253CDD0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Identifier' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""def test_identifier_with_op_trailing_ws():\n        # make sure trailing whitespace isn't grouped with identifier\n>       p = sqlparse.parse('foo || bar ')[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:435: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'foo ||...' at 0x1A2225F0750>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Identifier' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", 'def test_identifier_with_string_literals():\n>       p = sqlparse.parse(""foo + \'bar\'"")[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:442: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement \'foo + ...\' at 0x1A22253CCD0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: \'Identifier\' object has no attribute \'isdigit\'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError', ""def test_identifier_consumes_ordering():\n        # issue89\n>       p = sqlparse.parse('select * from foo order by c1 desc, c2, c3')[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:458: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'select...' at 0x1A222625CD0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""def test_comparison_with_keywords():\n        # issue90\n        # in fact these are assignments, but for now we don't distinguish them\n>       p = sqlparse.parse('foo = NULL')[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:471: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'foo = ...' at 0x1A222625C50>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Identifier' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""def test_comparison_with_floats():\n        # issue145\n>       p = sqlparse.parse('foo = 25.5')[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:485: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'foo = ...' at 0x1A2225F21D0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Identifier' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""def test_comparison_with_parenthesis():\n        # issue23\n>       p = sqlparse.parse('(3 + 4) = 7')[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:495: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement '(3 + 4...' at 0x1A222624B50>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Parenthesis' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", 'operator = \'=\'\n\n    @pytest.mark.parametrize(\'operator\', (\n        \'=\', \'!=\', \'>\', \'<\', \'<=\', \'>=\', \'~\', \'~~\', \'!~~\',\n        \'LIKE\', \'NOT LIKE\', \'ILIKE\', \'NOT ILIKE\',\n    ))\n    def test_comparison_with_strings(operator):\n        # issue148\n>       p = sqlparse.parse(f""foo {operator} \'bar\'"")[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:509: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement \'foo = ...\' at 0x1A22253C7D0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: \'Identifier\' object has no attribute \'isdigit\'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError', 'operator = \'!=\'\n\n    @pytest.mark.parametrize(\'operator\', (\n        \'=\', \'!=\', \'>\', \'<\', \'<=\', \'>=\', \'~\', \'~~\', \'!~~\',\n        \'LIKE\', \'NOT LIKE\', \'ILIKE\', \'NOT ILIKE\',\n    ))\n    def test_comparison_with_strings(operator):\n        # issue148\n>       p = sqlparse.parse(f""foo {operator} \'bar\'"")[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:509: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement \'foo !=...\' at 0x1A2226276D0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: \'Identifier\' object has no attribute \'isdigit\'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError', 'operator = \'>\'\n\n    @pytest.mark.parametrize(\'operator\', (\n        \'=\', \'!=\', \'>\', \'<\', \'<=\', \'>=\', \'~\', \'~~\', \'!~~\',\n        \'LIKE\', \'NOT LIKE\', \'ILIKE\', \'NOT ILIKE\',\n    ))\n    def test_comparison_with_strings(operator):\n        # issue148\n>       p = sqlparse.parse(f""foo {operator} \'bar\'"")[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:509: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement \'foo > ...\' at 0x1A22264A7D0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: \'Identifier\' object has no attribute \'isdigit\'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError', 'operator = \'<\'\n\n    @pytest.mark.parametrize(\'operator\', (\n        \'=\', \'!=\', \'>\', \'<\', \'<=\', \'>=\', \'~\', \'~~\', \'!~~\',\n        \'LIKE\', \'NOT LIKE\', \'ILIKE\', \'NOT ILIKE\',\n    ))\n    def test_comparison_with_strings(operator):\n        # issue148\n>       p = sqlparse.parse(f""foo {operator} \'bar\'"")[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:509: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement \'foo < ...\' at 0x1A22264AA50>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: \'Identifier\' object has no attribute \'isdigit\'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError', 'operator = \'<=\'\n\n    @pytest.mark.parametrize(\'operator\', (\n        \'=\', \'!=\', \'>\', \'<\', \'<=\', \'>=\', \'~\', \'~~\', \'!~~\',\n        \'LIKE\', \'NOT LIKE\', \'ILIKE\', \'NOT ILIKE\',\n    ))\n    def test_comparison_with_strings(operator):\n        # issue148\n>       p = sqlparse.parse(f""foo {operator} \'bar\'"")[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:509: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement \'foo <=...\' at 0x1A222649ED0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: \'Identifier\' object has no attribute \'isdigit\'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError', 'operator = \'>=\'\n\n    @pytest.mark.parametrize(\'operator\', (\n        \'=\', \'!=\', \'>\', \'<\', \'<=\', \'>=\', \'~\', \'~~\', \'!~~\',\n        \'LIKE\', \'NOT LIKE\', \'ILIKE\', \'NOT ILIKE\',\n    ))\n    def test_comparison_with_strings(operator):\n        # issue148\n>       p = sqlparse.parse(f""foo {operator} \'bar\'"")[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:509: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement \'foo >=...\' at 0x1A22264B950>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: \'Identifier\' object has no attribute \'isdigit\'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError', 'operator = \'~\'\n\n    @pytest.mark.parametrize(\'operator\', (\n        \'=\', \'!=\', \'>\', \'<\', \'<=\', \'>=\', \'~\', \'~~\', \'!~~\',\n        \'LIKE\', \'NOT LIKE\', \'ILIKE\', \'NOT ILIKE\',\n    ))\n    def test_comparison_with_strings(operator):\n        # issue148\n>       p = sqlparse.parse(f""foo {operator} \'bar\'"")[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:509: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement \'foo ~ ...\' at 0x1A222625AD0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: \'Identifier\' object has no attribute \'isdigit\'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError', 'operator = \'~~\'\n\n    @pytest.mark.parametrize(\'operator\', (\n        \'=\', \'!=\', \'>\', \'<\', \'<=\', \'>=\', \'~\', \'~~\', \'!~~\',\n        \'LIKE\', \'NOT LIKE\', \'ILIKE\', \'NOT ILIKE\',\n    ))\n    def test_comparison_with_strings(operator):\n        # issue148\n>       p = sqlparse.parse(f""foo {operator} \'bar\'"")[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:509: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement \'foo ~~...\' at 0x1A22264BC50>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: \'Identifier\' object has no attribute \'isdigit\'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError', 'operator = \'!~~\'\n\n    @pytest.mark.parametrize(\'operator\', (\n        \'=\', \'!=\', \'>\', \'<\', \'<=\', \'>=\', \'~\', \'~~\', \'!~~\',\n        \'LIKE\', \'NOT LIKE\', \'ILIKE\', \'NOT ILIKE\',\n    ))\n    def test_comparison_with_strings(operator):\n        # issue148\n>       p = sqlparse.parse(f""foo {operator} \'bar\'"")[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:509: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement \'foo !~...\' at 0x1A2226482D0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: \'Identifier\' object has no attribute \'isdigit\'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError', 'operator = \'LIKE\'\n\n    @pytest.mark.parametrize(\'operator\', (\n        \'=\', \'!=\', \'>\', \'<\', \'<=\', \'>=\', \'~\', \'~~\', \'!~~\',\n        \'LIKE\', \'NOT LIKE\', \'ILIKE\', \'NOT ILIKE\',\n    ))\n    def test_comparison_with_strings(operator):\n        # issue148\n>       p = sqlparse.parse(f""foo {operator} \'bar\'"")[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:509: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement \'foo LI...\' at 0x1A222665C50>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: \'Identifier\' object has no attribute \'isdigit\'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError', 'operator = \'NOT LIKE\'\n\n    @pytest.mark.parametrize(\'operator\', (\n        \'=\', \'!=\', \'>\', \'<\', \'<=\', \'>=\', \'~\', \'~~\', \'!~~\',\n        \'LIKE\', \'NOT LIKE\', \'ILIKE\', \'NOT ILIKE\',\n    ))\n    def test_comparison_with_strings(operator):\n        # issue148\n>       p = sqlparse.parse(f""foo {operator} \'bar\'"")[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:509: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement \'foo NO...\' at 0x1A2226652D0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: \'Identifier\' object has no attribute \'isdigit\'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError', 'operator = \'ILIKE\'\n\n    @pytest.mark.parametrize(\'operator\', (\n        \'=\', \'!=\', \'>\', \'<\', \'<=\', \'>=\', \'~\', \'~~\', \'!~~\',\n        \'LIKE\', \'NOT LIKE\', \'ILIKE\', \'NOT ILIKE\',\n    ))\n    def test_comparison_with_strings(operator):\n        # issue148\n>       p = sqlparse.parse(f""foo {operator} \'bar\'"")[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:509: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement \'foo IL...\' at 0x1A222666AD0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: \'Identifier\' object has no attribute \'isdigit\'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError', 'operator = \'NOT ILIKE\'\n\n    @pytest.mark.parametrize(\'operator\', (\n        \'=\', \'!=\', \'>\', \'<\', \'<=\', \'>=\', \'~\', \'~~\', \'!~~\',\n        \'LIKE\', \'NOT LIKE\', \'ILIKE\', \'NOT ILIKE\',\n    ))\n    def test_comparison_with_strings(operator):\n        # issue148\n>       p = sqlparse.parse(f""foo {operator} \'bar\'"")[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:509: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement \'foo NO...\' at 0x1A222649050>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: \'Identifier\' object has no attribute \'isdigit\'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError', 'def test_like_and_ilike_comparison():\n        def validate_where_clause(where_clause, expected_tokens):\n            assert len(where_clause.tokens) == len(expected_tokens)\n            for where_token, expected_token in zip(where_clause, expected_tokens):\n                expected_ttype, expected_value = expected_token\n                if where_token.ttype is not None:\n                    assert where_token.match(expected_ttype, expected_value, regex=True)\n                else:\n                    # Certain tokens, such as comparison tokens, do not define a ttype that can be\n                    # matched against. For these tokens, we ensure that the token instance is of\n                    # the expected type and has a value conforming to specified regular expression\n                    import re\n                    assert (isinstance(where_token, expected_ttype)\n                            and re.match(expected_value, where_token.value))\n    \n>       [p1] = sqlparse.parse(""select * from mytable where mytable.mycolumn LIKE \'expr%\' limit 5;"")\n\nrepos\\sqlparse\\tests\\test_grouping.py:531: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement \'select...\' at 0x1A22264B5D0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: \'Token\' object has no attribute \'isdigit\'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError', ""def test_comparison_with_functions():\n        # issue230\n>       p = sqlparse.parse('foo = DATE(bar.baz)')[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:553: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'foo = ...' at 0x1A222667AD0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Identifier' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", 'def test_comparison_with_typed_literal():\n>       p = sqlparse.parse(""foo = DATE \'bar.baz\'"")[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:576: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement \'foo = ...\' at 0x1A2226670D0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: \'Identifier\' object has no attribute \'isdigit\'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError', ""start = 'FOR'\n\n    @pytest.mark.parametrize('start', ['FOR', 'FOREACH'])\n    def test_forloops(start):\n>       p = sqlparse.parse(f'{start} foo in bar LOOP foobar END LOOP')[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:588: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'FOR fo...' at 0x1A2226653D0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'For' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""start = 'FOREACH'\n\n    @pytest.mark.parametrize('start', ['FOR', 'FOREACH'])\n    def test_forloops(start):\n>       p = sqlparse.parse(f'{start} foo in bar LOOP foobar END LOOP')[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:588: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'FOREAC...' at 0x1A222667C50>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'For' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""def test_nested_for():\n>       p = sqlparse.parse('FOR foo LOOP FOR bar LOOP END LOOP END LOOP')[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:594: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'FOR fo...' at 0x1A22262E350>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'For' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""def test_begin():\n>       p = sqlparse.parse('BEGIN foo END')[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:606: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'BEGIN ...' at 0x1A222665FD0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Begin' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""def test_keyword_followed_by_parenthesis():\n>       p = sqlparse.parse('USING(somecol')[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:612: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'USING(...' at 0x1A22262CFD0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""def test_nested_begin():\n>       p = sqlparse.parse('BEGIN foo BEGIN bar END END')[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:619: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'BEGIN ...' at 0x1A22262E550>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Begin' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""def test_aliased_column_without_as():\n>       p = sqlparse.parse('foo bar')[0].tokens\n\nrepos\\sqlparse\\tests\\test_grouping.py:631: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'foo bar' at 0x1A2226243D0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Identifier' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""def test_qualified_function():\n>       p = sqlparse.parse('foo()')[0].tokens[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:643: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'foo()' at 0x1A2225C1850>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Function' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""def test_aliased_function_without_as():\n>       p = sqlparse.parse('foo() bar')[0].tokens[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:653: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'foo() ...' at 0x1A222568650>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Function' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""def test_aliased_literal_without_as():\n>       p = sqlparse.parse('1 foo')[0].tokens\n\nrepos\\sqlparse\\tests\\test_grouping.py:665: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement '1 foo' at 0x1A2225D08D0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""def test_grouping_as_cte():\n>       p = sqlparse.parse('foo AS WITH apple AS 1, banana AS 2')[0].tokens\n\nrepos\\sqlparse\\tests\\test_grouping.py:671: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'foo AS...' at 0x1A22253F1D0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Identifier' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", 'def test_grouping_create_table():\n>       p = sqlparse.parse(""create table db.tbl (a string)"")[0].tokens\n\nrepos\\sqlparse\\tests\\test_grouping.py:678: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement \'create...\' at 0x1A222666B50>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: \'Token\' object has no attribute \'isdigit\'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError', ""def test_parse_tokenize():\n        s = 'select * from foo;'\n>       stmts = sqlparse.parse(s)\n\nrepos\\sqlparse\\tests\\test_parse.py:13: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'select...' at 0x1A2225D2050>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""def test_parse_multistatement():\n        sql1 = 'select * from foo;'\n        sql2 = 'select * from bar;'\n>       stmts = sqlparse.parse(sql1 + sql2)\n\nrepos\\sqlparse\\tests\\test_parse.py:21: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'select...' at 0x1A222649050>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""s = 'select\\n*from foo;'\n\n    @pytest.mark.parametrize('s', ['select\\n*from foo;',\n                                   'select\\r\\n*from foo',\n                                   'select\\r*from foo',\n                                   'select\\r\\n*from foo\\n'])\n    def test_parse_newlines(s):\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_parse.py:32: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'select...' at 0x1A22264BBD0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""s = 'select\\r\\n*from foo'\n\n    @pytest.mark.parametrize('s', ['select\\n*from foo;',\n                                   'select\\r\\n*from foo',\n                                   'select\\r*from foo',\n                                   'select\\r\\n*from foo\\n'])\n    def test_parse_newlines(s):\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_parse.py:32: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'select...' at 0x1A222684950>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""s = 'select\\r*from foo'\n\n    @pytest.mark.parametrize('s', ['select\\n*from foo;',\n                                   'select\\r\\n*from foo',\n                                   'select\\r*from foo',\n                                   'select\\r\\n*from foo\\n'])\n    def test_parse_newlines(s):\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_parse.py:32: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'select...' at 0x1A222687750>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""s = 'select\\r\\n*from foo\\n'\n\n    @pytest.mark.parametrize('s', ['select\\n*from foo;',\n                                   'select\\r\\n*from foo',\n                                   'select\\r*from foo',\n                                   'select\\r\\n*from foo\\n'])\n    def test_parse_newlines(s):\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_parse.py:32: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'select...' at 0x1A2226856D0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""def test_parse_within():\n        s = 'foo(col1, col2)'\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_parse.py:38: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'foo(co...' at 0x1A2225C00D0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Function' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""def test_parse_child_of():\n        s = '(col1, col2)'\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_parse.py:45: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement '(col1,...' at 0x1A222685FD0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Parenthesis' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""def test_parse_has_ancestor():\n        s = 'foo or (bar, baz)'\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_parse.py:55: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'foo or...' at 0x1A22262F0D0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Identifier' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""s = '.5'\n\n    @pytest.mark.parametrize('s', ['.5', '.51', '1.5', '12.5'])\n    def test_parse_float(s):\n>       t = sqlparse.parse(s)[0].tokens\n\nrepos\\sqlparse\\tests\\test_parse.py:64: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement '.5' at 0x1A222690A50>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""s = '.51'\n\n    @pytest.mark.parametrize('s', ['.5', '.51', '1.5', '12.5'])\n    def test_parse_float(s):\n>       t = sqlparse.parse(s)[0].tokens\n\nrepos\\sqlparse\\tests\\test_parse.py:64: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement '.51' at 0x1A222687B50>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""s = '1.5'\n\n    @pytest.mark.parametrize('s', ['.5', '.51', '1.5', '12.5'])\n    def test_parse_float(s):\n>       t = sqlparse.parse(s)[0].tokens\n\nrepos\\sqlparse\\tests\\test_parse.py:64: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement '1.5' at 0x1A222690C50>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""s = '12.5'\n\n    @pytest.mark.parametrize('s', ['.5', '.51', '1.5', '12.5'])\n    def test_parse_float(s):\n>       t = sqlparse.parse(s)[0].tokens\n\nrepos\\sqlparse\\tests\\test_parse.py:64: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement '12.5' at 0x1A222691450>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""s = 'select * from foo where user = ?', holder = '?'\n\n    @pytest.mark.parametrize('s, holder', [\n        ('select * from foo where user = ?', '?'),\n        ('select * from foo where user = :1', ':1'),\n        ('select * from foo where user = :name', ':name'),\n        ('select * from foo where user = %s', '%s'),\n        ('select * from foo where user = $a', '$a')])\n    def test_parse_placeholder(s, holder):\n>       t = sqlparse.parse(s)[0].tokens[-1].tokens\n\nrepos\\sqlparse\\tests\\test_parse.py:76: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'select...' at 0x1A222685C50>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""s = 'select * from foo where user = :1', holder = ':1'\n\n    @pytest.mark.parametrize('s, holder', [\n        ('select * from foo where user = ?', '?'),\n        ('select * from foo where user = :1', ':1'),\n        ('select * from foo where user = :name', ':name'),\n        ('select * from foo where user = %s', '%s'),\n        ('select * from foo where user = $a', '$a')])\n    def test_parse_placeholder(s, holder):\n>       t = sqlparse.parse(s)[0].tokens[-1].tokens\n\nrepos\\sqlparse\\tests\\test_parse.py:76: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'select...' at 0x1A2226847D0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""s = 'select * from foo where user = :name', holder = ':name'\n\n    @pytest.mark.parametrize('s, holder', [\n        ('select * from foo where user = ?', '?'),\n        ('select * from foo where user = :1', ':1'),\n        ('select * from foo where user = :name', ':name'),\n        ('select * from foo where user = %s', '%s'),\n        ('select * from foo where user = $a', '$a')])\n    def test_parse_placeholder(s, holder):\n>       t = sqlparse.parse(s)[0].tokens[-1].tokens\n\nrepos\\sqlparse\\tests\\test_parse.py:76: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'select...' at 0x1A222692ED0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""s = 'select * from foo where user = %s', holder = '%s'\n\n    @pytest.mark.parametrize('s, holder', [\n        ('select * from foo where user = ?', '?'),\n        ('select * from foo where user = :1', ':1'),\n        ('select * from foo where user = :name', ':name'),\n        ('select * from foo where user = %s', '%s'),\n        ('select * from foo where user = $a', '$a')])\n    def test_parse_placeholder(s, holder):\n>       t = sqlparse.parse(s)[0].tokens[-1].tokens\n\nrepos\\sqlparse\\tests\\test_parse.py:76: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'select...' at 0x1A222690DD0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""s = 'select * from foo where user = $a', holder = '$a'\n\n    @pytest.mark.parametrize('s, holder', [\n        ('select * from foo where user = ?', '?'),\n        ('select * from foo where user = :1', ':1'),\n        ('select * from foo where user = :name', ':name'),\n        ('select * from foo where user = %s', '%s'),\n        ('select * from foo where user = $a', '$a')])\n    def test_parse_placeholder(s, holder):\n>       t = sqlparse.parse(s)[0].tokens[-1].tokens\n\nrepos\\sqlparse\\tests\\test_parse.py:76: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'select...' at 0x1A222676DD0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""def test_parse_access_symbol():\n        # see issue27\n>       t = sqlparse.parse('select a.[foo bar] as foo')[0].tokens\n\nrepos\\sqlparse\\tests\\test_parse.py:88: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'select...' at 0x1A2226866D0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""def test_parse_square_brackets_notation_isnt_too_greedy():\n        # see issue153\n>       t = sqlparse.parse('[foo], [bar]')[0].tokens\n\nrepos\\sqlparse\\tests\\test_parse.py:97: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement '[foo],...' at 0x1A2226878D0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Identifier' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""def test_parse_square_brackets_notation_isnt_too_greedy2():\n        # see issue583\n>       t = sqlparse.parse('[(foo[i])]')[0].tokens\n\nrepos\\sqlparse\\tests\\test_parse.py:106: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement '[(foo[...' at 0x1A222685E50>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'SquareBrackets' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""def test_parse_keyword_like_identifier():\n        # see issue47\n>       t = sqlparse.parse('foo.key')[0].tokens\n\nrepos\\sqlparse\\tests\\test_parse.py:112: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'foo.key' at 0x1A222675650>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Identifier' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""def test_parse_function_parameter():\n        # see issue94\n>       t = sqlparse.parse('abs(some_col)')[0].tokens[0].get_parameters()\n\nrepos\\sqlparse\\tests\\test_parse.py:119: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'abs(so...' at 0x1A2226742D0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Function' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""def test_parse_function_param_single_literal():\n>       t = sqlparse.parse('foo(5)')[0].tokens[0].get_parameters()\n\nrepos\\sqlparse\\tests\\test_parse.py:125: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'foo(5)' at 0x1A2226161D0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Function' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""def test_parse_nested_function():\n>       t = sqlparse.parse('foo(bar(5))')[0].tokens[0].get_parameters()\n\nrepos\\sqlparse\\tests\\test_parse.py:131: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'foo(ba...' at 0x1A2226166D0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Function' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", 'def test_parse_casted_params():\n>       t = sqlparse.parse(""foo(DATE \'2023-11-14\', TIMESTAMP \'2023-11-15\')"")[0].tokens[0].get_parameters()\n\nrepos\\sqlparse\\tests\\test_parse.py:137: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement \'foo(DA...\' at 0x1A2226773D0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: \'Function\' object has no attribute \'isdigit\'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError', ""def test_parse_div_operator():\n>       p = sqlparse.parse('col1 DIV 5 AS div_col1')[0].tokens\n\nrepos\\sqlparse\\tests\\test_parse.py:142: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'col1 D...' at 0x1A222674AD0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Identifier' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", 'def test_quoted_identifier():\n>       t = sqlparse.parse(\'select x.y as ""z"" from foo\')[0].tokens\n\nrepos\\sqlparse\\tests\\test_parse.py:148: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement \'select...\' at 0x1A2226848D0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: \'Token\' object has no attribute \'isdigit\'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError', ""name = 'foo'\n\n    @pytest.mark.parametrize('name', [\n        'foo', '_foo',  # issue175\n        '1_data',  # valid MySQL table name, see issue337\n        '業者名稱',  # valid at least for SQLite3, see issue641\n    ])\n    def test_valid_identifier_names(name):\n>       t = sqlparse.parse(name)[0].tokens\n\nrepos\\sqlparse\\tests\\test_parse.py:160: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'foo' at 0x1A222614050>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Identifier' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""name = '_foo'\n\n    @pytest.mark.parametrize('name', [\n        'foo', '_foo',  # issue175\n        '1_data',  # valid MySQL table name, see issue337\n        '業者名稱',  # valid at least for SQLite3, see issue641\n    ])\n    def test_valid_identifier_names(name):\n>       t = sqlparse.parse(name)[0].tokens\n\nrepos\\sqlparse\\tests\\test_parse.py:160: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement '_foo' at 0x1A222615FD0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Identifier' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""name = '1_data'\n\n    @pytest.mark.parametrize('name', [\n        'foo', '_foo',  # issue175\n        '1_data',  # valid MySQL table name, see issue337\n        '業者名稱',  # valid at least for SQLite3, see issue641\n    ])\n    def test_valid_identifier_names(name):\n>       t = sqlparse.parse(name)[0].tokens\n\nrepos\\sqlparse\\tests\\test_parse.py:160: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement '1_data' at 0x1A2226761D0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Identifier' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""name = '業者名稱'\n\n    @pytest.mark.parametrize('name', [\n        'foo', '_foo',  # issue175\n        '1_data',  # valid MySQL table name, see issue337\n        '業者名稱',  # valid at least for SQLite3, see issue641\n    ])\n    def test_valid_identifier_names(name):\n>       t = sqlparse.parse(name)[0].tokens\n\nrepos\\sqlparse\\tests\\test_parse.py:160: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement '業者名稱' at 0x1A222615150>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Identifier' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""def test_double_precision_is_builtin():\n        s = 'DOUBLE PRECISION'\n>       t = sqlparse.parse(s)[0].tokens\n\nrepos\\sqlparse\\tests\\test_parse.py:199: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'DOUBLE...' at 0x1A22268F4D0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""ph = '?'\n\n    @pytest.mark.parametrize('ph', ['?', ':1', ':foo', '%s', '%(foo)s'])\n    def test_placeholder(ph):\n>       p = sqlparse.parse(ph)[0].tokens\n\nrepos\\sqlparse\\tests\\test_parse.py:207: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement '?' at 0x1A2226163D0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""ph = ':1'\n\n    @pytest.mark.parametrize('ph', ['?', ':1', ':foo', '%s', '%(foo)s'])\n    def test_placeholder(ph):\n>       p = sqlparse.parse(ph)[0].tokens\n\nrepos\\sqlparse\\tests\\test_parse.py:207: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement ':1' at 0x1A22268D0D0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""ph = ':foo'\n\n    @pytest.mark.parametrize('ph', ['?', ':1', ':foo', '%s', '%(foo)s'])\n    def test_placeholder(ph):\n>       p = sqlparse.parse(ph)[0].tokens\n\nrepos\\sqlparse\\tests\\test_parse.py:207: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement ':foo' at 0x1A222617250>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""ph = '%s'\n\n    @pytest.mark.parametrize('ph', ['?', ':1', ':foo', '%s', '%(foo)s'])\n    def test_placeholder(ph):\n>       p = sqlparse.parse(ph)[0].tokens\n\nrepos\\sqlparse\\tests\\test_parse.py:207: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement '%s' at 0x1A222614FD0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""ph = '%(foo)s'\n\n    @pytest.mark.parametrize('ph', ['?', ':1', ':foo', '%s', '%(foo)s'])\n    def test_placeholder(ph):\n>       p = sqlparse.parse(ph)[0].tokens\n\nrepos\\sqlparse\\tests\\test_parse.py:207: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement '%(foo)s' at 0x1A22268F9D0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""num = '6.67428E-8', expected = Token.Literal.Number.Float\n\n    @pytest.mark.parametrize('num, expected', [\n        ('6.67428E-8', T.Number.Float),\n        ('1.988e33', T.Number.Float),\n        ('1e-12', T.Number.Float),\n        ('e1', None),\n    ])\n    def test_scientific_numbers(num, expected):\n>       p = sqlparse.parse(num)[0].tokens\n\nrepos\\sqlparse\\tests\\test_parse.py:219: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement '6.6742...' at 0x1A22268D7D0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""num = '1.988e33', expected = Token.Literal.Number.Float\n\n    @pytest.mark.parametrize('num, expected', [\n        ('6.67428E-8', T.Number.Float),\n        ('1.988e33', T.Number.Float),\n        ('1e-12', T.Number.Float),\n        ('e1', None),\n    ])\n    def test_scientific_numbers(num, expected):\n>       p = sqlparse.parse(num)[0].tokens\n\nrepos\\sqlparse\\tests\\test_parse.py:219: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement '1.988e...' at 0x1A222694C50>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""num = '1e-12', expected = Token.Literal.Number.Float\n\n    @pytest.mark.parametrize('num, expected', [\n        ('6.67428E-8', T.Number.Float),\n        ('1.988e33', T.Number.Float),\n        ('1e-12', T.Number.Float),\n        ('e1', None),\n    ])\n    def test_scientific_numbers(num, expected):\n>       p = sqlparse.parse(num)[0].tokens\n\nrepos\\sqlparse\\tests\\test_parse.py:219: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement '1e-12' at 0x1A22268ED50>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""num = 'e1', expected = None\n\n    @pytest.mark.parametrize('num, expected', [\n        ('6.67428E-8', T.Number.Float),\n        ('1.988e33', T.Number.Float),\n        ('1e-12', T.Number.Float),\n        ('e1', None),\n    ])\n    def test_scientific_numbers(num, expected):\n>       p = sqlparse.parse(num)[0].tokens\n\nrepos\\sqlparse\\tests\\test_parse.py:219: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'e1' at 0x1A222697550>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Identifier' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", 'def test_single_quotes_are_strings():\n>       p = sqlparse.parse(""\'foo\'"")[0].tokens\n\nrepos\\sqlparse\\tests\\test_parse.py:225: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement ""\'foo\'"" at 0x1A22268CBD0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: \'Token\' object has no attribute \'isdigit\'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError', 'def test_double_quotes_are_identifiers():\n>       p = sqlparse.parse(\'""foo""\')[0].tokens\n\nrepos\\sqlparse\\tests\\test_parse.py:231: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement \'""foo""\' at 0x1A2226955D0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: \'Identifier\' object has no attribute \'isdigit\'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError', 'def test_single_quotes_with_linebreaks():\n        # issue118\n>       p = sqlparse.parse(""\'f\\nf\'"")[0].tokens\n\nrepos\\sqlparse\\tests\\test_parse.py:238: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement ""\'f f\'"" at 0x1A22268E0D0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: \'Token\' object has no attribute \'isdigit\'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError', ""def test_sqlite_identifiers():\n        # Make sure we still parse sqlite style escapes\n>       p = sqlparse.parse('[col1],[col2]')[0].tokens\n\nrepos\\sqlparse\\tests\\test_parse.py:245: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement '[col1]...' at 0x1A222695ED0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Identifier' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""def test_simple_1d_array_index():\n>       p = sqlparse.parse('col[1]')[0].tokens\n\nrepos\\sqlparse\\tests\\test_parse.py:257: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'col[1]' at 0x1A22269E7D0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Identifier' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""def test_2d_array_index():\n>       p = sqlparse.parse('col[x][(y+1)*2]')[0].tokens\n\nrepos\\sqlparse\\tests\\test_parse.py:267: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'col[x]...' at 0x1A2226975D0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Identifier' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""def test_array_index_function_result():\n>       p = sqlparse.parse('somefunc()[1]')[0].tokens\n\nrepos\\sqlparse\\tests\\test_parse.py:274: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'somefu...' at 0x1A22268FE50>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Identifier' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""def test_schema_qualified_array_index():\n>       p = sqlparse.parse('schem.col[1]')[0].tokens\n\nrepos\\sqlparse\\tests\\test_parse.py:280: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'schem....' at 0x1A22269D7D0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Identifier' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""def test_aliased_array_index():\n>       p = sqlparse.parse('col[1] x')[0].tokens\n\nrepos\\sqlparse\\tests\\test_parse.py:288: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'col[1]...' at 0x1A222695B50>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Identifier' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""def test_array_literal():\n        # See issue #176\n>       p = sqlparse.parse('ARRAY[%s, %s]')[0]\n\nrepos\\sqlparse\\tests\\test_parse.py:297: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'ARRAY[...' at 0x1A22269E2D0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""def test_typed_array_definition():\n        # array indices aren't grouped with built-ins, but make sure we can extract\n        # identifier names\n>       p = sqlparse.parse('x int, y int[], z int')[0]\n\nrepos\\sqlparse\\tests\\test_parse.py:305: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'x int,...' at 0x1A22261A3D0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Identifier' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""s = 'select 1 -- foo'\n\n    @pytest.mark.parametrize('s', ['select 1 -- foo', 'select 1 # foo'])\n    def test_single_line_comments(s):\n        # see issue178\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_parse.py:314: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'select...' at 0x1A22261BC50>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""s = 'select 1 # foo'\n\n    @pytest.mark.parametrize('s', ['select 1 -- foo', 'select 1 # foo'])\n    def test_single_line_comments(s):\n        # see issue178\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_parse.py:314: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'select...' at 0x1A22261A8D0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""s = 'foo'\n\n    @pytest.mark.parametrize('s', ['foo', '@foo', '#foo', '##foo'])\n    def test_names_and_special_names(s):\n        # see issue192\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_parse.py:322: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'foo' at 0x1A222694650>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Identifier' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""s = '@foo'\n\n    @pytest.mark.parametrize('s', ['foo', '@foo', '#foo', '##foo'])\n    def test_names_and_special_names(s):\n        # see issue192\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_parse.py:322: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement '@foo' at 0x1A22269F050>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Identifier' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""s = '#foo'\n\n    @pytest.mark.parametrize('s', ['foo', '@foo', '#foo', '##foo'])\n    def test_names_and_special_names(s):\n        # see issue192\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_parse.py:322: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement '#foo' at 0x1A222694CD0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Identifier' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""s = '##foo'\n\n    @pytest.mark.parametrize('s', ['foo', '@foo', '#foo', '##foo'])\n    def test_names_and_special_names(s):\n        # see issue192\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_parse.py:322: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement '##foo' at 0x1A22261A150>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Identifier' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""def test_get_token_at_offset():\n>       p = sqlparse.parse('select * from dual')[0]\n\nrepos\\sqlparse\\tests\\test_parse.py:328: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'select...' at 0x1A222618B50>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""def test_pprint():\n>       p = sqlparse.parse('select a0, b0, c0, d0, e0 from '\n                           '(select * from dual) q0 where 1=1 and 2=2')[0]\n\nrepos\\sqlparse\\tests\\test_parse.py:340: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'select...' at 0x1A22268EED0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""def test_wildcard_multiplication():\n>       p = sqlparse.parse('select * from dual')[0]\n\nrepos\\sqlparse\\tests\\test_parse.py:405: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'select...' at 0x1A222695550>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", 'def test_stmt_tokens_parents():\n        # see issue 226\n        s = ""CREATE TABLE test();""\n>       stmt = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_parse.py:418: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement \'CREATE...\' at 0x1A222677E50>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: \'Token\' object has no attribute \'isdigit\'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError', ""sql = '$$foo$$', is_literal = True\n\n    @pytest.mark.parametrize('sql, is_literal', [\n        ('$$foo$$', True),\n        ('$_$foo$_$', True),\n        ('$token$ foo $token$', True),\n        # don't parse inner tokens\n        ('$_$ foo $token$bar$token$ baz$_$', True),\n        ('$A$ foo $B$', False)  # tokens don't match\n    ])\n    def test_dbldollar_as_literal(sql, is_literal):\n        # see issue 277\n>       p = sqlparse.parse(sql)[0]\n\nrepos\\sqlparse\\tests\\test_parse.py:433: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement '$$foo$$' at 0x1A22261B5D0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""sql = '$_$foo$_$', is_literal = True\n\n    @pytest.mark.parametrize('sql, is_literal', [\n        ('$$foo$$', True),\n        ('$_$foo$_$', True),\n        ('$token$ foo $token$', True),\n        # don't parse inner tokens\n        ('$_$ foo $token$bar$token$ baz$_$', True),\n        ('$A$ foo $B$', False)  # tokens don't match\n    ])\n    def test_dbldollar_as_literal(sql, is_literal):\n        # see issue 277\n>       p = sqlparse.parse(sql)[0]\n\nrepos\\sqlparse\\tests\\test_parse.py:433: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement '$_$foo...' at 0x1A22269F9D0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""sql = '$token$ foo $token$', is_literal = True\n\n    @pytest.mark.parametrize('sql, is_literal', [\n        ('$$foo$$', True),\n        ('$_$foo$_$', True),\n        ('$token$ foo $token$', True),\n        # don't parse inner tokens\n        ('$_$ foo $token$bar$token$ baz$_$', True),\n        ('$A$ foo $B$', False)  # tokens don't match\n    ])\n    def test_dbldollar_as_literal(sql, is_literal):\n        # see issue 277\n>       p = sqlparse.parse(sql)[0]\n\nrepos\\sqlparse\\tests\\test_parse.py:433: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement '$token...' at 0x1A22269D8D0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""sql = '$_$ foo $token$bar$token$ baz$_$', is_literal = True\n\n    @pytest.mark.parametrize('sql, is_literal', [\n        ('$$foo$$', True),\n        ('$_$foo$_$', True),\n        ('$token$ foo $token$', True),\n        # don't parse inner tokens\n        ('$_$ foo $token$bar$token$ baz$_$', True),\n        ('$A$ foo $B$', False)  # tokens don't match\n    ])\n    def test_dbldollar_as_literal(sql, is_literal):\n        # see issue 277\n>       p = sqlparse.parse(sql)[0]\n\nrepos\\sqlparse\\tests\\test_parse.py:433: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement '$_$ fo...' at 0x1A2226AE7D0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""sql = '$A$ foo $B$', is_literal = False\n\n    @pytest.mark.parametrize('sql, is_literal', [\n        ('$$foo$$', True),\n        ('$_$foo$_$', True),\n        ('$token$ foo $token$', True),\n        # don't parse inner tokens\n        ('$_$ foo $token$bar$token$ baz$_$', True),\n        ('$A$ foo $B$', False)  # tokens don't match\n    ])\n    def test_dbldollar_as_literal(sql, is_literal):\n        # see issue 277\n>       p = sqlparse.parse(sql)[0]\n\nrepos\\sqlparse\\tests\\test_parse.py:433: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement '$A$ fo...' at 0x1A2210B90D0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", 'def test_non_ascii():\n        _test_non_ascii = ""insert into test (id, name) values (1, \'тест\');""\n    \n        s = _test_non_ascii\n>       stmts = sqlparse.parse(s)\n\nrepos\\sqlparse\\tests\\test_parse.py:446: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement \'insert...\' at 0x1A222697550>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: \'Token\' object has no attribute \'isdigit\'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError', 'def test_get_real_name():\n        # issue 369\n        s = ""update a t set t.b=1""\n>       stmts = sqlparse.parse(s)\n\nrepos\\sqlparse\\tests\\test_parse.py:463: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement \'update...\' at 0x1A222618050>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: \'Token\' object has no attribute \'isdigit\'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError', ""def test_from_subquery():\n        # issue 446\n        s = 'from(select 1)'\n>       stmts = sqlparse.parse(s)\n\nrepos\\sqlparse\\tests\\test_parse.py:472: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'from(s...' at 0x1A2226181D0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", 'def test_parenthesis():\n>       tokens = sqlparse.parse(""(\\n\\n1\\n\\n)"")[0].tokens[0].tokens\n\nrepos\\sqlparse\\tests\\test_parse.py:488: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement \'( 1 )\' at 0x1A22261B750>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: \'Parenthesis\' object has no attribute \'isdigit\'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError', 'def test_configurable_keywords():\n        sql = """"""select * from foo BACON SPAM EGGS;""""""\n>       tokens = sqlparse.parse(sql)[0]\n\nrepos\\sqlparse\\tests\\test_parse.py:510: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement \'select...\' at 0x1A2226189D0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: \'Token\' object has no attribute \'isdigit\'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError', 'def test_configurable_regex():\n        lex = Lexer.get_default_instance()\n        lex.clear()\n    \n        my_regex = (r""ZORDER\\s+BY\\b"", sqlparse.tokens.Keyword)\n    \n        lex.set_SQL_REGEX(\n            keywords.SQL_REGEX[:38]\n            + [my_regex]\n            + keywords.SQL_REGEX[38:]\n        )\n        lex.add_keywords(keywords.KEYWORDS_COMMON)\n        lex.add_keywords(keywords.KEYWORDS_ORACLE)\n        lex.add_keywords(keywords.KEYWORDS_PLPGSQL)\n        lex.add_keywords(keywords.KEYWORDS_HQL)\n        lex.add_keywords(keywords.KEYWORDS_MSACCESS)\n        lex.add_keywords(keywords.KEYWORDS)\n    \n>       tokens = sqlparse.parse(""select * from foo zorder by bar;"")[0]\n\nrepos\\sqlparse\\tests\\test_parse.py:572: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement \'select...\' at 0x1A22261BB50>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: \'Token\' object has no attribute \'isdigit\'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError', ""sql = '->'\n\n    @pytest.mark.parametrize('sql', [\n        '->', '->>', '#>', '#>>',\n        '@>', '<@',\n        # leaving ? out for now, they're somehow ambiguous as placeholders\n        # '?', '?|', '?&',\n        '||', '-', '#-'\n    ])\n    def test_json_operators(sql):\n>       p = sqlparse.parse(sql)\n\nrepos\\sqlparse\\tests\\test_parse.py:592: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement '->' at 0x1A2226AD350>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""sql = '->>'\n\n    @pytest.mark.parametrize('sql', [\n        '->', '->>', '#>', '#>>',\n        '@>', '<@',\n        # leaving ? out for now, they're somehow ambiguous as placeholders\n        # '?', '?|', '?&',\n        '||', '-', '#-'\n    ])\n    def test_json_operators(sql):\n>       p = sqlparse.parse(sql)\n\nrepos\\sqlparse\\tests\\test_parse.py:592: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement '->>' at 0x1A2226AC850>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""sql = '#>'\n\n    @pytest.mark.parametrize('sql', [\n        '->', '->>', '#>', '#>>',\n        '@>', '<@',\n        # leaving ? out for now, they're somehow ambiguous as placeholders\n        # '?', '?|', '?&',\n        '||', '-', '#-'\n    ])\n    def test_json_operators(sql):\n>       p = sqlparse.parse(sql)\n\nrepos\\sqlparse\\tests\\test_parse.py:592: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement '#>' at 0x1A2226B2CD0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""sql = '#>>'\n\n    @pytest.mark.parametrize('sql', [\n        '->', '->>', '#>', '#>>',\n        '@>', '<@',\n        # leaving ? out for now, they're somehow ambiguous as placeholders\n        # '?', '?|', '?&',\n        '||', '-', '#-'\n    ])\n    def test_json_operators(sql):\n>       p = sqlparse.parse(sql)\n\nrepos\\sqlparse\\tests\\test_parse.py:592: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement '#>>' at 0x1A2226ACCD0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""sql = '@>'\n\n    @pytest.mark.parametrize('sql', [\n        '->', '->>', '#>', '#>>',\n        '@>', '<@',\n        # leaving ? out for now, they're somehow ambiguous as placeholders\n        # '?', '?|', '?&',\n        '||', '-', '#-'\n    ])\n    def test_json_operators(sql):\n>       p = sqlparse.parse(sql)\n\nrepos\\sqlparse\\tests\\test_parse.py:592: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement '@>' at 0x1A2226B12D0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""sql = '<@'\n\n    @pytest.mark.parametrize('sql', [\n        '->', '->>', '#>', '#>>',\n        '@>', '<@',\n        # leaving ? out for now, they're somehow ambiguous as placeholders\n        # '?', '?|', '?&',\n        '||', '-', '#-'\n    ])\n    def test_json_operators(sql):\n>       p = sqlparse.parse(sql)\n\nrepos\\sqlparse\\tests\\test_parse.py:592: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement '<@' at 0x1A2226AF7D0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""sql = '||'\n\n    @pytest.mark.parametrize('sql', [\n        '->', '->>', '#>', '#>>',\n        '@>', '<@',\n        # leaving ? out for now, they're somehow ambiguous as placeholders\n        # '?', '?|', '?&',\n        '||', '-', '#-'\n    ])\n    def test_json_operators(sql):\n>       p = sqlparse.parse(sql)\n\nrepos\\sqlparse\\tests\\test_parse.py:592: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement '||' at 0x1A2226B35D0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""sql = '-'\n\n    @pytest.mark.parametrize('sql', [\n        '->', '->>', '#>', '#>>',\n        '@>', '<@',\n        # leaving ? out for now, they're somehow ambiguous as placeholders\n        # '?', '?|', '?&',\n        '||', '-', '#-'\n    ])\n    def test_json_operators(sql):\n>       p = sqlparse.parse(sql)\n\nrepos\\sqlparse\\tests\\test_parse.py:592: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement '-' at 0x1A2226B0E50>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""sql = '#-'\n\n    @pytest.mark.parametrize('sql', [\n        '->', '->>', '#>', '#>>',\n        '@>', '<@',\n        # leaving ? out for now, they're somehow ambiguous as placeholders\n        # '?', '?|', '?&',\n        '||', '-', '#-'\n    ])\n    def test_json_operators(sql):\n>       p = sqlparse.parse(sql)\n\nrepos\\sqlparse\\tests\\test_parse.py:592: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement '#-' at 0x1A2226B3C50>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""def test_issue9():\n        # make sure where doesn't consume parenthesis\n>       p = sqlparse.parse('(where 1)')[0]\n\nrepos\\sqlparse\\tests\\test_regressions.py:13: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement '(where...' at 0x1A222681B50>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Parenthesis' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", 'def test_issue13():\n>       parsed = sqlparse.parse(""select \'one\';\\n""\n                                ""select \'two\\\\\'\';\\n""\n                                ""select \'three\';"")\n\nrepos\\sqlparse\\tests\\test_regressions.py:24: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement \'select...\' at 0x1A222683050>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: \'Token\' object has no attribute \'isdigit\'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError', ""s = '--hello'\n\n    @pytest.mark.parametrize('s', ['--hello', '-- hello', '--hello\\n',\n                                   '--', '--\\n'])\n    def test_issue26(s):\n        # parse stand-alone comments\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_regressions.py:35: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement '--hello' at 0x1A2226B0CD0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""s = '-- hello'\n\n    @pytest.mark.parametrize('s', ['--hello', '-- hello', '--hello\\n',\n                                   '--', '--\\n'])\n    def test_issue26(s):\n        # parse stand-alone comments\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_regressions.py:35: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement '-- hel...' at 0x1A2226837D0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""s = '--hello\\n'\n\n    @pytest.mark.parametrize('s', ['--hello', '-- hello', '--hello\\n',\n                                   '--', '--\\n'])\n    def test_issue26(s):\n        # parse stand-alone comments\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_regressions.py:35: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement '--hell...' at 0x1A2226B03D0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""s = '--'\n\n    @pytest.mark.parametrize('s', ['--hello', '-- hello', '--hello\\n',\n                                   '--', '--\\n'])\n    def test_issue26(s):\n        # parse stand-alone comments\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_regressions.py:35: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement '--' at 0x1A222681750>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""s = '--\\n'\n\n    @pytest.mark.parametrize('s', ['--hello', '-- hello', '--hello\\n',\n                                   '--', '--\\n'])\n    def test_issue26(s):\n        # parse stand-alone comments\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_regressions.py:35: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement '-- ' at 0x1A2226B0150>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", 'value = \'create\'\n\n    @pytest.mark.parametrize(\'value\', [\'create\', \'CREATE\'])\n    def test_issue34(value):\n>       t = sqlparse.parse(""create"")[0].token_first()\n\nrepos\\sqlparse\\tests\\test_regressions.py:42: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement \'create\' at 0x1A2226C68D0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: \'Token\' object has no attribute \'isdigit\'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError', 'value = \'CREATE\'\n\n    @pytest.mark.parametrize(\'value\', [\'create\', \'CREATE\'])\n    def test_issue34(value):\n>       t = sqlparse.parse(""create"")[0].token_first()\n\nrepos\\sqlparse\\tests\\test_regressions.py:42: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement \'create\' at 0x1A2226C58D0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: \'Token\' object has no attribute \'isdigit\'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError', 'def test_issue35():\n        # missing space before LIMIT. Updated for #321\n>       sql = sqlparse.format(""select * from foo where bar = 1 limit 1"",\n                              reindent=True)\n\nrepos\\sqlparse\\tests\\test_regressions.py:48: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return \'\'.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement \'select...\' at 0x1A2226C6750>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: \'Token\' object has no attribute \'isdigit\'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError', 'def test_issue38():\n>       sql = sqlparse.format(""SELECT foo; -- comment"", strip_comments=True)\n\nrepos\\sqlparse\\tests\\test_regressions.py:58: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return \'\'.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement \'SELECT...\' at 0x1A2226B38D0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: \'Token\' object has no attribute \'isdigit\'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError', ""def test_issue39():\n>       p = sqlparse.parse('select user.id from user')[0]\n\nrepos\\sqlparse\\tests\\test_regressions.py:65: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'select...' at 0x1A2226C54D0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""def test_issue40():\n        # make sure identifier lists in subselects are grouped\n>       p = sqlparse.parse('SELECT id, name FROM '\n                           '(SELECT id, name FROM bar) as foo')[0]\n\nrepos\\sqlparse\\tests\\test_regressions.py:77: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'SELECT...' at 0x1A2226C4BD0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", 's = \'select x.y::text as z from foo\', func_name = \'get_name\', result = \'z\'\n\n    @pytest.mark.parametrize(\'s\', [\'select x.y::text as z from foo\',\n                                   \'select x.y::text as ""z"" from foo\',\n                                   \'select x.""y""::text as z from foo\',\n                                   \'select x.""y""::text as ""z"" from foo\',\n                                   \'select ""x"".y::text as z from foo\',\n                                   \'select ""x"".y::text as ""z"" from foo\',\n                                   \'select ""x"".""y""::text as z from foo\',\n                                   \'select ""x"".""y""::text as ""z"" from foo\'])\n    @pytest.mark.parametrize(\'func_name, result\', [(\'get_name\', \'z\'),\n                                                   (\'get_real_name\', \'y\'),\n                                                   (\'get_parent_name\', \'x\'),\n                                                   (\'get_alias\', \'z\'),\n                                                   (\'get_typecast\', \'text\')])\n    def test_issue78(s, func_name, result):\n        # the bug author provided this nice examples, let\'s use them!\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_regressions.py:120: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement \'select...\' at 0x1A2226C51D0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: \'Token\' object has no attribute \'isdigit\'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError', 's = \'select x.y::text as ""z"" from foo\', func_name = \'get_name\', result = \'z\'\n\n    @pytest.mark.parametrize(\'s\', [\'select x.y::text as z from foo\',\n                                   \'select x.y::text as ""z"" from foo\',\n                                   \'select x.""y""::text as z from foo\',\n                                   \'select x.""y""::text as ""z"" from foo\',\n                                   \'select ""x"".y::text as z from foo\',\n                                   \'select ""x"".y::text as ""z"" from foo\',\n                                   \'select ""x"".""y""::text as z from foo\',\n                                   \'select ""x"".""y""::text as ""z"" from foo\'])\n    @pytest.mark.parametrize(\'func_name, result\', [(\'get_name\', \'z\'),\n                                                   (\'get_real_name\', \'y\'),\n                                                   (\'get_parent_name\', \'x\'),\n                                                   (\'get_alias\', \'z\'),\n                                                   (\'get_typecast\', \'text\')])\n    def test_issue78(s, func_name, result):\n        # the bug author provided this nice examples, let\'s use them!\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_regressions.py:120: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement \'select...\' at 0x1A2226C46D0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: \'Token\' object has no attribute \'isdigit\'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError', 's = \'select x.""y""::text as z from foo\', func_name = \'get_name\', result = \'z\'\n\n    @pytest.mark.parametrize(\'s\', [\'select x.y::text as z from foo\',\n                                   \'select x.y::text as ""z"" from foo\',\n                                   \'select x.""y""::text as z from foo\',\n                                   \'select x.""y""::text as ""z"" from foo\',\n                                   \'select ""x"".y::text as z from foo\',\n                                   \'select ""x"".y::text as ""z"" from foo\',\n                                   \'select ""x"".""y""::text as z from foo\',\n                                   \'select ""x"".""y""::text as ""z"" from foo\'])\n    @pytest.mark.parametrize(\'func_name, result\', [(\'get_name\', \'z\'),\n                                                   (\'get_real_name\', \'y\'),\n                                                   (\'get_parent_name\', \'x\'),\n                                                   (\'get_alias\', \'z\'),\n                                                   (\'get_typecast\', \'text\')])\n    def test_issue78(s, func_name, result):\n        # the bug author provided this nice examples, let\'s use them!\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_regressions.py:120: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement \'select...\' at 0x1A222612750>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: \'Token\' object has no attribute \'isdigit\'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError', 's = \'select x.""y""::text as ""z"" from foo\', func_name = \'get_name\', result = \'z\'\n\n    @pytest.mark.parametrize(\'s\', [\'select x.y::text as z from foo\',\n                                   \'select x.y::text as ""z"" from foo\',\n                                   \'select x.""y""::text as z from foo\',\n                                   \'select x.""y""::text as ""z"" from foo\',\n                                   \'select ""x"".y::text as z from foo\',\n                                   \'select ""x"".y::text as ""z"" from foo\',\n                                   \'select ""x"".""y""::text as z from foo\',\n                                   \'select ""x"".""y""::text as ""z"" from foo\'])\n    @pytest.mark.parametrize(\'func_name, result\', [(\'get_name\', \'z\'),\n                                                   (\'get_real_name\', \'y\'),\n                                                   (\'get_parent_name\', \'x\'),\n                                                   (\'get_alias\', \'z\'),\n                                                   (\'get_typecast\', \'text\')])\n    def test_issue78(s, func_name, result):\n        # the bug author provided this nice examples, let\'s use them!\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_regressions.py:120: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement \'select...\' at 0x1A2226C5ED0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: \'Token\' object has no attribute \'isdigit\'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError', 's = \'select ""x"".y::text as z from foo\', func_name = \'get_name\', result = \'z\'\n\n    @pytest.mark.parametrize(\'s\', [\'select x.y::text as z from foo\',\n                                   \'select x.y::text as ""z"" from foo\',\n                                   \'select x.""y""::text as z from foo\',\n                                   \'select x.""y""::text as ""z"" from foo\',\n                                   \'select ""x"".y::text as z from foo\',\n                                   \'select ""x"".y::text as ""z"" from foo\',\n                                   \'select ""x"".""y""::text as z from foo\',\n                                   \'select ""x"".""y""::text as ""z"" from foo\'])\n    @pytest.mark.parametrize(\'func_name, result\', [(\'get_name\', \'z\'),\n                                                   (\'get_real_name\', \'y\'),\n                                                   (\'get_parent_name\', \'x\'),\n                                                   (\'get_alias\', \'z\'),\n                                                   (\'get_typecast\', \'text\')])\n    def test_issue78(s, func_name, result):\n        # the bug author provided this nice examples, let\'s use them!\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_regressions.py:120: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement \'select...\' at 0x1A2226134D0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: \'Token\' object has no attribute \'isdigit\'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError', 's = \'select ""x"".y::text as ""z"" from foo\', func_name = \'get_name\', result = \'z\'\n\n    @pytest.mark.parametrize(\'s\', [\'select x.y::text as z from foo\',\n                                   \'select x.y::text as ""z"" from foo\',\n                                   \'select x.""y""::text as z from foo\',\n                                   \'select x.""y""::text as ""z"" from foo\',\n                                   \'select ""x"".y::text as z from foo\',\n                                   \'select ""x"".y::text as ""z"" from foo\',\n                                   \'select ""x"".""y""::text as z from foo\',\n                                   \'select ""x"".""y""::text as ""z"" from foo\'])\n    @pytest.mark.parametrize(\'func_name, result\', [(\'get_name\', \'z\'),\n                                                   (\'get_real_name\', \'y\'),\n                                                   (\'get_parent_name\', \'x\'),\n                                                   (\'get_alias\', \'z\'),\n                                                   (\'get_typecast\', \'text\')])\n    def test_issue78(s, func_name, result):\n        # the bug author provided this nice examples, let\'s use them!\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_regressions.py:120: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement \'select...\' at 0x1A222611A50>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: \'Token\' object has no attribute \'isdigit\'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError', 's = \'select ""x"".""y""::text as z from foo\', func_name = \'get_name\', result = \'z\'\n\n    @pytest.mark.parametrize(\'s\', [\'select x.y::text as z from foo\',\n                                   \'select x.y::text as ""z"" from foo\',\n                                   \'select x.""y""::text as z from foo\',\n                                   \'select x.""y""::text as ""z"" from foo\',\n                                   \'select ""x"".y::text as z from foo\',\n                                   \'select ""x"".y::text as ""z"" from foo\',\n                                   \'select ""x"".""y""::text as z from foo\',\n                                   \'select ""x"".""y""::text as ""z"" from foo\'])\n    @pytest.mark.parametrize(\'func_name, result\', [(\'get_name\', \'z\'),\n                                                   (\'get_real_name\', \'y\'),\n                                                   (\'get_parent_name\', \'x\'),\n                                                   (\'get_alias\', \'z\'),\n                                                   (\'get_typecast\', \'text\')])\n    def test_issue78(s, func_name, result):\n        # the bug author provided this nice examples, let\'s use them!\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_regressions.py:120: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement \'select...\' at 0x1A2226D75D0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: \'Token\' object has no attribute \'isdigit\'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError', 's = \'select ""x"".""y""::text as ""z"" from foo\', func_name = \'get_name\', result = \'z\'\n\n    @pytest.mark.parametrize(\'s\', [\'select x.y::text as z from foo\',\n                                   \'select x.y::text as ""z"" from foo\',\n                                   \'select x.""y""::text as z from foo\',\n                                   \'select x.""y""::text as ""z"" from foo\',\n                                   \'select ""x"".y::text as z from foo\',\n                                   \'select ""x"".y::text as ""z"" from foo\',\n                                   \'select ""x"".""y""::text as z from foo\',\n                                   \'select ""x"".""y""::text as ""z"" from foo\'])\n    @pytest.mark.parametrize(\'func_name, result\', [(\'get_name\', \'z\'),\n                                                   (\'get_real_name\', \'y\'),\n                                                   (\'get_parent_name\', \'x\'),\n                                                   (\'get_alias\', \'z\'),\n                                                   (\'get_typecast\', \'text\')])\n    def test_issue78(s, func_name, result):\n        # the bug author provided this nice examples, let\'s use them!\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_regressions.py:120: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement \'select...\' at 0x1A2226D4D50>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: \'Token\' object has no attribute \'isdigit\'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError', 's = \'select x.y::text as z from foo\', func_name = \'get_real_name\', result = \'y\'\n\n    @pytest.mark.parametrize(\'s\', [\'select x.y::text as z from foo\',\n                                   \'select x.y::text as ""z"" from foo\',\n                                   \'select x.""y""::text as z from foo\',\n                                   \'select x.""y""::text as ""z"" from foo\',\n                                   \'select ""x"".y::text as z from foo\',\n                                   \'select ""x"".y::text as ""z"" from foo\',\n                                   \'select ""x"".""y""::text as z from foo\',\n                                   \'select ""x"".""y""::text as ""z"" from foo\'])\n    @pytest.mark.parametrize(\'func_name, result\', [(\'get_name\', \'z\'),\n                                                   (\'get_real_name\', \'y\'),\n                                                   (\'get_parent_name\', \'x\'),\n                                                   (\'get_alias\', \'z\'),\n                                                   (\'get_typecast\', \'text\')])\n    def test_issue78(s, func_name, result):\n        # the bug author provided this nice examples, let\'s use them!\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_regressions.py:120: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement \'select...\' at 0x1A2226C7F50>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: \'Token\' object has no attribute \'isdigit\'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError', 's = \'select x.y::text as ""z"" from foo\', func_name = \'get_real_name\'\nresult = \'y\'\n\n    @pytest.mark.parametrize(\'s\', [\'select x.y::text as z from foo\',\n                                   \'select x.y::text as ""z"" from foo\',\n                                   \'select x.""y""::text as z from foo\',\n                                   \'select x.""y""::text as ""z"" from foo\',\n                                   \'select ""x"".y::text as z from foo\',\n                                   \'select ""x"".y::text as ""z"" from foo\',\n                                   \'select ""x"".""y""::text as z from foo\',\n                                   \'select ""x"".""y""::text as ""z"" from foo\'])\n    @pytest.mark.parametrize(\'func_name, result\', [(\'get_name\', \'z\'),\n                                                   (\'get_real_name\', \'y\'),\n                                                   (\'get_parent_name\', \'x\'),\n                                                   (\'get_alias\', \'z\'),\n                                                   (\'get_typecast\', \'text\')])\n    def test_issue78(s, func_name, result):\n        # the bug author provided this nice examples, let\'s use them!\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_regressions.py:120: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement \'select...\' at 0x1A222612650>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: \'Token\' object has no attribute \'isdigit\'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError', 's = \'select x.""y""::text as z from foo\', func_name = \'get_real_name\'\nresult = \'y\'\n\n    @pytest.mark.parametrize(\'s\', [\'select x.y::text as z from foo\',\n                                   \'select x.y::text as ""z"" from foo\',\n                                   \'select x.""y""::text as z from foo\',\n                                   \'select x.""y""::text as ""z"" from foo\',\n                                   \'select ""x"".y::text as z from foo\',\n                                   \'select ""x"".y::text as ""z"" from foo\',\n                                   \'select ""x"".""y""::text as z from foo\',\n                                   \'select ""x"".""y""::text as ""z"" from foo\'])\n    @pytest.mark.parametrize(\'func_name, result\', [(\'get_name\', \'z\'),\n                                                   (\'get_real_name\', \'y\'),\n                                                   (\'get_parent_name\', \'x\'),\n                                                   (\'get_alias\', \'z\'),\n                                                   (\'get_typecast\', \'text\')])\n    def test_issue78(s, func_name, result):\n        # the bug author provided this nice examples, let\'s use them!\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_regressions.py:120: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement \'select...\' at 0x1A2226D7AD0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: \'Token\' object has no attribute \'isdigit\'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError', 's = \'select x.""y""::text as ""z"" from foo\', func_name = \'get_real_name\'\nresult = \'y\'\n\n    @pytest.mark.parametrize(\'s\', [\'select x.y::text as z from foo\',\n                                   \'select x.y::text as ""z"" from foo\',\n                                   \'select x.""y""::text as z from foo\',\n                                   \'select x.""y""::text as ""z"" from foo\',\n                                   \'select ""x"".y::text as z from foo\',\n                                   \'select ""x"".y::text as ""z"" from foo\',\n                                   \'select ""x"".""y""::text as z from foo\',\n                                   \'select ""x"".""y""::text as ""z"" from foo\'])\n    @pytest.mark.parametrize(\'func_name, result\', [(\'get_name\', \'z\'),\n                                                   (\'get_real_name\', \'y\'),\n                                                   (\'get_parent_name\', \'x\'),\n                                                   (\'get_alias\', \'z\'),\n                                                   (\'get_typecast\', \'text\')])\n    def test_issue78(s, func_name, result):\n        # the bug author provided this nice examples, let\'s use them!\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_regressions.py:120: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement \'select...\' at 0x1A222701750>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: \'Token\' object has no attribute \'isdigit\'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError', 's = \'select ""x"".y::text as z from foo\', func_name = \'get_real_name\'\nresult = \'y\'\n\n    @pytest.mark.parametrize(\'s\', [\'select x.y::text as z from foo\',\n                                   \'select x.y::text as ""z"" from foo\',\n                                   \'select x.""y""::text as z from foo\',\n                                   \'select x.""y""::text as ""z"" from foo\',\n                                   \'select ""x"".y::text as z from foo\',\n                                   \'select ""x"".y::text as ""z"" from foo\',\n                                   \'select ""x"".""y""::text as z from foo\',\n                                   \'select ""x"".""y""::text as ""z"" from foo\'])\n    @pytest.mark.parametrize(\'func_name, result\', [(\'get_name\', \'z\'),\n                                                   (\'get_real_name\', \'y\'),\n                                                   (\'get_parent_name\', \'x\'),\n                                                   (\'get_alias\', \'z\'),\n                                                   (\'get_typecast\', \'text\')])\n    def test_issue78(s, func_name, result):\n        # the bug author provided this nice examples, let\'s use them!\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_regressions.py:120: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement \'select...\' at 0x1A2227028D0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: \'Token\' object has no attribute \'isdigit\'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError', 's = \'select ""x"".y::text as ""z"" from foo\', func_name = \'get_real_name\'\nresult = \'y\'\n\n    @pytest.mark.parametrize(\'s\', [\'select x.y::text as z from foo\',\n                                   \'select x.y::text as ""z"" from foo\',\n                                   \'select x.""y""::text as z from foo\',\n                                   \'select x.""y""::text as ""z"" from foo\',\n                                   \'select ""x"".y::text as z from foo\',\n                                   \'select ""x"".y::text as ""z"" from foo\',\n                                   \'select ""x"".""y""::text as z from foo\',\n                                   \'select ""x"".""y""::text as ""z"" from foo\'])\n    @pytest.mark.parametrize(\'func_name, result\', [(\'get_name\', \'z\'),\n                                                   (\'get_real_name\', \'y\'),\n                                                   (\'get_parent_name\', \'x\'),\n                                                   (\'get_alias\', \'z\'),\n                                                   (\'get_typecast\', \'text\')])\n    def test_issue78(s, func_name, result):\n        # the bug author provided this nice examples, let\'s use them!\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_regressions.py:120: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement \'select...\' at 0x1A222611050>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: \'Token\' object has no attribute \'isdigit\'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError', 's = \'select ""x"".""y""::text as z from foo\', func_name = \'get_real_name\'\nresult = \'y\'\n\n    @pytest.mark.parametrize(\'s\', [\'select x.y::text as z from foo\',\n                                   \'select x.y::text as ""z"" from foo\',\n                                   \'select x.""y""::text as z from foo\',\n                                   \'select x.""y""::text as ""z"" from foo\',\n                                   \'select ""x"".y::text as z from foo\',\n                                   \'select ""x"".y::text as ""z"" from foo\',\n                                   \'select ""x"".""y""::text as z from foo\',\n                                   \'select ""x"".""y""::text as ""z"" from foo\'])\n    @pytest.mark.parametrize(\'func_name, result\', [(\'get_name\', \'z\'),\n                                                   (\'get_real_name\', \'y\'),\n                                                   (\'get_parent_name\', \'x\'),\n                                                   (\'get_alias\', \'z\'),\n                                                   (\'get_typecast\', \'text\')])\n    def test_issue78(s, func_name, result):\n        # the bug author provided this nice examples, let\'s use them!\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_regressions.py:120: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement \'select...\' at 0x1A2226D5D50>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: \'Token\' object has no attribute \'isdigit\'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError', 's = \'select ""x"".""y""::text as ""z"" from foo\', func_name = \'get_real_name\'\nresult = \'y\'\n\n    @pytest.mark.parametrize(\'s\', [\'select x.y::text as z from foo\',\n                                   \'select x.y::text as ""z"" from foo\',\n                                   \'select x.""y""::text as z from foo\',\n                                   \'select x.""y""::text as ""z"" from foo\',\n                                   \'select ""x"".y::text as z from foo\',\n                                   \'select ""x"".y::text as ""z"" from foo\',\n                                   \'select ""x"".""y""::text as z from foo\',\n                                   \'select ""x"".""y""::text as ""z"" from foo\'])\n    @pytest.mark.parametrize(\'func_name, result\', [(\'get_name\', \'z\'),\n                                                   (\'get_real_name\', \'y\'),\n                                                   (\'get_parent_name\', \'x\'),\n                                                   (\'get_alias\', \'z\'),\n                                                   (\'get_typecast\', \'text\')])\n    def test_issue78(s, func_name, result):\n        # the bug author provided this nice examples, let\'s use them!\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_regressions.py:120: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement \'select...\' at 0x1A2226D41D0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: \'Token\' object has no attribute \'isdigit\'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError', 's = \'select x.y::text as z from foo\', func_name = \'get_parent_name\'\nresult = \'x\'\n\n    @pytest.mark.parametrize(\'s\', [\'select x.y::text as z from foo\',\n                                   \'select x.y::text as ""z"" from foo\',\n                                   \'select x.""y""::text as z from foo\',\n                                   \'select x.""y""::text as ""z"" from foo\',\n                                   \'select ""x"".y::text as z from foo\',\n                                   \'select ""x"".y::text as ""z"" from foo\',\n                                   \'select ""x"".""y""::text as z from foo\',\n                                   \'select ""x"".""y""::text as ""z"" from foo\'])\n    @pytest.mark.parametrize(\'func_name, result\', [(\'get_name\', \'z\'),\n                                                   (\'get_real_name\', \'y\'),\n                                                   (\'get_parent_name\', \'x\'),\n                                                   (\'get_alias\', \'z\'),\n                                                   (\'get_typecast\', \'text\')])\n    def test_issue78(s, func_name, result):\n        # the bug author provided this nice examples, let\'s use them!\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_regressions.py:120: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement \'select...\' at 0x1A222703F50>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: \'Token\' object has no attribute \'isdigit\'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError', 's = \'select x.y::text as ""z"" from foo\', func_name = \'get_parent_name\'\nresult = \'x\'\n\n    @pytest.mark.parametrize(\'s\', [\'select x.y::text as z from foo\',\n                                   \'select x.y::text as ""z"" from foo\',\n                                   \'select x.""y""::text as z from foo\',\n                                   \'select x.""y""::text as ""z"" from foo\',\n                                   \'select ""x"".y::text as z from foo\',\n                                   \'select ""x"".y::text as ""z"" from foo\',\n                                   \'select ""x"".""y""::text as z from foo\',\n                                   \'select ""x"".""y""::text as ""z"" from foo\'])\n    @pytest.mark.parametrize(\'func_name, result\', [(\'get_name\', \'z\'),\n                                                   (\'get_real_name\', \'y\'),\n                                                   (\'get_parent_name\', \'x\'),\n                                                   (\'get_alias\', \'z\'),\n                                                   (\'get_typecast\', \'text\')])\n    def test_issue78(s, func_name, result):\n        # the bug author provided this nice examples, let\'s use them!\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_regressions.py:120: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement \'select...\' at 0x1A22267A2D0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: \'Token\' object has no attribute \'isdigit\'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError', 's = \'select x.""y""::text as z from foo\', func_name = \'get_parent_name\'\nresult = \'x\'\n\n    @pytest.mark.parametrize(\'s\', [\'select x.y::text as z from foo\',\n                                   \'select x.y::text as ""z"" from foo\',\n                                   \'select x.""y""::text as z from foo\',\n                                   \'select x.""y""::text as ""z"" from foo\',\n                                   \'select ""x"".y::text as z from foo\',\n                                   \'select ""x"".y::text as ""z"" from foo\',\n                                   \'select ""x"".""y""::text as z from foo\',\n                                   \'select ""x"".""y""::text as ""z"" from foo\'])\n    @pytest.mark.parametrize(\'func_name, result\', [(\'get_name\', \'z\'),\n                                                   (\'get_real_name\', \'y\'),\n                                                   (\'get_parent_name\', \'x\'),\n                                                   (\'get_alias\', \'z\'),\n                                                   (\'get_typecast\', \'text\')])\n    def test_issue78(s, func_name, result):\n        # the bug author provided this nice examples, let\'s use them!\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_regressions.py:120: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement \'select...\' at 0x1A22267ADD0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: \'Token\' object has no attribute \'isdigit\'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError', 's = \'select x.""y""::text as ""z"" from foo\', func_name = \'get_parent_name\'\nresult = \'x\'\n\n    @pytest.mark.parametrize(\'s\', [\'select x.y::text as z from foo\',\n                                   \'select x.y::text as ""z"" from foo\',\n                                   \'select x.""y""::text as z from foo\',\n                                   \'select x.""y""::text as ""z"" from foo\',\n                                   \'select ""x"".y::text as z from foo\',\n                                   \'select ""x"".y::text as ""z"" from foo\',\n                                   \'select ""x"".""y""::text as z from foo\',\n                                   \'select ""x"".""y""::text as ""z"" from foo\'])\n    @pytest.mark.parametrize(\'func_name, result\', [(\'get_name\', \'z\'),\n                                                   (\'get_real_name\', \'y\'),\n                                                   (\'get_parent_name\', \'x\'),\n                                                   (\'get_alias\', \'z\'),\n                                                   (\'get_typecast\', \'text\')])\n    def test_issue78(s, func_name, result):\n        # the bug author provided this nice examples, let\'s use them!\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_regressions.py:120: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement \'select...\' at 0x1A221105ED0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: \'Token\' object has no attribute \'isdigit\'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError', 's = \'select ""x"".y::text as z from foo\', func_name = \'get_parent_name\'\nresult = \'x\'\n\n    @pytest.mark.parametrize(\'s\', [\'select x.y::text as z from foo\',\n                                   \'select x.y::text as ""z"" from foo\',\n                                   \'select x.""y""::text as z from foo\',\n                                   \'select x.""y""::text as ""z"" from foo\',\n                                   \'select ""x"".y::text as z from foo\',\n                                   \'select ""x"".y::text as ""z"" from foo\',\n                                   \'select ""x"".""y""::text as z from foo\',\n                                   \'select ""x"".""y""::text as ""z"" from foo\'])\n    @pytest.mark.parametrize(\'func_name, result\', [(\'get_name\', \'z\'),\n                                                   (\'get_real_name\', \'y\'),\n                                                   (\'get_parent_name\', \'x\'),\n                                                   (\'get_alias\', \'z\'),\n                                                   (\'get_typecast\', \'text\')])\n    def test_issue78(s, func_name, result):\n        # the bug author provided this nice examples, let\'s use them!\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_regressions.py:120: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement \'select...\' at 0x1A221105950>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: \'Token\' object has no attribute \'isdigit\'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError', 's = \'select ""x"".y::text as ""z"" from foo\', func_name = \'get_parent_name\'\nresult = \'x\'\n\n    @pytest.mark.parametrize(\'s\', [\'select x.y::text as z from foo\',\n                                   \'select x.y::text as ""z"" from foo\',\n                                   \'select x.""y""::text as z from foo\',\n                                   \'select x.""y""::text as ""z"" from foo\',\n                                   \'select ""x"".y::text as z from foo\',\n                                   \'select ""x"".y::text as ""z"" from foo\',\n                                   \'select ""x"".""y""::text as z from foo\',\n                                   \'select ""x"".""y""::text as ""z"" from foo\'])\n    @pytest.mark.parametrize(\'func_name, result\', [(\'get_name\', \'z\'),\n                                                   (\'get_real_name\', \'y\'),\n                                                   (\'get_parent_name\', \'x\'),\n                                                   (\'get_alias\', \'z\'),\n                                                   (\'get_typecast\', \'text\')])\n    def test_issue78(s, func_name, result):\n        # the bug author provided this nice examples, let\'s use them!\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_regressions.py:120: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement \'select...\' at 0x1A222703150>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: \'Token\' object has no attribute \'isdigit\'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError', 's = \'select ""x"".""y""::text as z from foo\', func_name = \'get_parent_name\'\nresult = \'x\'\n\n    @pytest.mark.parametrize(\'s\', [\'select x.y::text as z from foo\',\n                                   \'select x.y::text as ""z"" from foo\',\n                                   \'select x.""y""::text as z from foo\',\n                                   \'select x.""y""::text as ""z"" from foo\',\n                                   \'select ""x"".y::text as z from foo\',\n                                   \'select ""x"".y::text as ""z"" from foo\',\n                                   \'select ""x"".""y""::text as z from foo\',\n                                   \'select ""x"".""y""::text as ""z"" from foo\'])\n    @pytest.mark.parametrize(\'func_name, result\', [(\'get_name\', \'z\'),\n                                                   (\'get_real_name\', \'y\'),\n                                                   (\'get_parent_name\', \'x\'),\n                                                   (\'get_alias\', \'z\'),\n                                                   (\'get_typecast\', \'text\')])\n    def test_issue78(s, func_name, result):\n        # the bug author provided this nice examples, let\'s use them!\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_regressions.py:120: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement \'select...\' at 0x1A222679050>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: \'Token\' object has no attribute \'isdigit\'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError', 's = \'select ""x"".""y""::text as ""z"" from foo\', func_name = \'get_parent_name\'\nresult = \'x\'\n\n    @pytest.mark.parametrize(\'s\', [\'select x.y::text as z from foo\',\n                                   \'select x.y::text as ""z"" from foo\',\n                                   \'select x.""y""::text as z from foo\',\n                                   \'select x.""y""::text as ""z"" from foo\',\n                                   \'select ""x"".y::text as z from foo\',\n                                   \'select ""x"".y::text as ""z"" from foo\',\n                                   \'select ""x"".""y""::text as z from foo\',\n                                   \'select ""x"".""y""::text as ""z"" from foo\'])\n    @pytest.mark.parametrize(\'func_name, result\', [(\'get_name\', \'z\'),\n                                                   (\'get_real_name\', \'y\'),\n                                                   (\'get_parent_name\', \'x\'),\n                                                   (\'get_alias\', \'z\'),\n                                                   (\'get_typecast\', \'text\')])\n    def test_issue78(s, func_name, result):\n        # the bug author provided this nice examples, let\'s use them!\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_regressions.py:120: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement \'select...\' at 0x1A2226F9ED0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: \'Token\' object has no attribute \'isdigit\'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError', 's = \'select x.y::text as z from foo\', func_name = \'get_alias\', result = \'z\'\n\n    @pytest.mark.parametrize(\'s\', [\'select x.y::text as z from foo\',\n                                   \'select x.y::text as ""z"" from foo\',\n                                   \'select x.""y""::text as z from foo\',\n                                   \'select x.""y""::text as ""z"" from foo\',\n                                   \'select ""x"".y::text as z from foo\',\n                                   \'select ""x"".y::text as ""z"" from foo\',\n                                   \'select ""x"".""y""::text as z from foo\',\n                                   \'select ""x"".""y""::text as ""z"" from foo\'])\n    @pytest.mark.parametrize(\'func_name, result\', [(\'get_name\', \'z\'),\n                                                   (\'get_real_name\', \'y\'),\n                                                   (\'get_parent_name\', \'x\'),\n                                                   (\'get_alias\', \'z\'),\n                                                   (\'get_typecast\', \'text\')])\n    def test_issue78(s, func_name, result):\n        # the bug author provided this nice examples, let\'s use them!\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_regressions.py:120: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement \'select...\' at 0x1A2226FB750>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: \'Token\' object has no attribute \'isdigit\'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError', 's = \'select x.y::text as ""z"" from foo\', func_name = \'get_alias\', result = \'z\'\n\n    @pytest.mark.parametrize(\'s\', [\'select x.y::text as z from foo\',\n                                   \'select x.y::text as ""z"" from foo\',\n                                   \'select x.""y""::text as z from foo\',\n                                   \'select x.""y""::text as ""z"" from foo\',\n                                   \'select ""x"".y::text as z from foo\',\n                                   \'select ""x"".y::text as ""z"" from foo\',\n                                   \'select ""x"".""y""::text as z from foo\',\n                                   \'select ""x"".""y""::text as ""z"" from foo\'])\n    @pytest.mark.parametrize(\'func_name, result\', [(\'get_name\', \'z\'),\n                                                   (\'get_real_name\', \'y\'),\n                                                   (\'get_parent_name\', \'x\'),\n                                                   (\'get_alias\', \'z\'),\n                                                   (\'get_typecast\', \'text\')])\n    def test_issue78(s, func_name, result):\n        # the bug author provided this nice examples, let\'s use them!\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_regressions.py:120: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement \'select...\' at 0x1A2226D5DD0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: \'Token\' object has no attribute \'isdigit\'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError', 's = \'select x.""y""::text as z from foo\', func_name = \'get_alias\', result = \'z\'\n\n    @pytest.mark.parametrize(\'s\', [\'select x.y::text as z from foo\',\n                                   \'select x.y::text as ""z"" from foo\',\n                                   \'select x.""y""::text as z from foo\',\n                                   \'select x.""y""::text as ""z"" from foo\',\n                                   \'select ""x"".y::text as z from foo\',\n                                   \'select ""x"".y::text as ""z"" from foo\',\n                                   \'select ""x"".""y""::text as z from foo\',\n                                   \'select ""x"".""y""::text as ""z"" from foo\'])\n    @pytest.mark.parametrize(\'func_name, result\', [(\'get_name\', \'z\'),\n                                                   (\'get_real_name\', \'y\'),\n                                                   (\'get_parent_name\', \'x\'),\n                                                   (\'get_alias\', \'z\'),\n                                                   (\'get_typecast\', \'text\')])\n    def test_issue78(s, func_name, result):\n        # the bug author provided this nice examples, let\'s use them!\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_regressions.py:120: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement \'select...\' at 0x1A2226F9050>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: \'Token\' object has no attribute \'isdigit\'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError', 's = \'select x.""y""::text as ""z"" from foo\', func_name = \'get_alias\', result = \'z\'\n\n    @pytest.mark.parametrize(\'s\', [\'select x.y::text as z from foo\',\n                                   \'select x.y::text as ""z"" from foo\',\n                                   \'select x.""y""::text as z from foo\',\n                                   \'select x.""y""::text as ""z"" from foo\',\n                                   \'select ""x"".y::text as z from foo\',\n                                   \'select ""x"".y::text as ""z"" from foo\',\n                                   \'select ""x"".""y""::text as z from foo\',\n                                   \'select ""x"".""y""::text as ""z"" from foo\'])\n    @pytest.mark.parametrize(\'func_name, result\', [(\'get_name\', \'z\'),\n                                                   (\'get_real_name\', \'y\'),\n                                                   (\'get_parent_name\', \'x\'),\n                                                   (\'get_alias\', \'z\'),\n                                                   (\'get_typecast\', \'text\')])\n    def test_issue78(s, func_name, result):\n        # the bug author provided this nice examples, let\'s use them!\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_regressions.py:120: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement \'select...\' at 0x1A22267ACD0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: \'Token\' object has no attribute \'isdigit\'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError', 's = \'select ""x"".y::text as z from foo\', func_name = \'get_alias\', result = \'z\'\n\n    @pytest.mark.parametrize(\'s\', [\'select x.y::text as z from foo\',\n                                   \'select x.y::text as ""z"" from foo\',\n                                   \'select x.""y""::text as z from foo\',\n                                   \'select x.""y""::text as ""z"" from foo\',\n                                   \'select ""x"".y::text as z from foo\',\n                                   \'select ""x"".y::text as ""z"" from foo\',\n                                   \'select ""x"".""y""::text as z from foo\',\n                                   \'select ""x"".""y""::text as ""z"" from foo\'])\n    @pytest.mark.parametrize(\'func_name, result\', [(\'get_name\', \'z\'),\n                                                   (\'get_real_name\', \'y\'),\n                                                   (\'get_parent_name\', \'x\'),\n                                                   (\'get_alias\', \'z\'),\n                                                   (\'get_typecast\', \'text\')])\n    def test_issue78(s, func_name, result):\n        # the bug author provided this nice examples, let\'s use them!\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_regressions.py:120: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement \'select...\' at 0x1A2226455D0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: \'Token\' object has no attribute \'isdigit\'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError', 's = \'select ""x"".y::text as ""z"" from foo\', func_name = \'get_alias\', result = \'z\'\n\n    @pytest.mark.parametrize(\'s\', [\'select x.y::text as z from foo\',\n                                   \'select x.y::text as ""z"" from foo\',\n                                   \'select x.""y""::text as z from foo\',\n                                   \'select x.""y""::text as ""z"" from foo\',\n                                   \'select ""x"".y::text as z from foo\',\n                                   \'select ""x"".y::text as ""z"" from foo\',\n                                   \'select ""x"".""y""::text as z from foo\',\n                                   \'select ""x"".""y""::text as ""z"" from foo\'])\n    @pytest.mark.parametrize(\'func_name, result\', [(\'get_name\', \'z\'),\n                                                   (\'get_real_name\', \'y\'),\n                                                   (\'get_parent_name\', \'x\'),\n                                                   (\'get_alias\', \'z\'),\n                                                   (\'get_typecast\', \'text\')])\n    def test_issue78(s, func_name, result):\n        # the bug author provided this nice examples, let\'s use them!\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_regressions.py:120: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement \'select...\' at 0x1A2226F80D0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: \'Token\' object has no attribute \'isdigit\'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError', 's = \'select ""x"".""y""::text as z from foo\', func_name = \'get_alias\', result = \'z\'\n\n    @pytest.mark.parametrize(\'s\', [\'select x.y::text as z from foo\',\n                                   \'select x.y::text as ""z"" from foo\',\n                                   \'select x.""y""::text as z from foo\',\n                                   \'select x.""y""::text as ""z"" from foo\',\n                                   \'select ""x"".y::text as z from foo\',\n                                   \'select ""x"".y::text as ""z"" from foo\',\n                                   \'select ""x"".""y""::text as z from foo\',\n                                   \'select ""x"".""y""::text as ""z"" from foo\'])\n    @pytest.mark.parametrize(\'func_name, result\', [(\'get_name\', \'z\'),\n                                                   (\'get_real_name\', \'y\'),\n                                                   (\'get_parent_name\', \'x\'),\n                                                   (\'get_alias\', \'z\'),\n                                                   (\'get_typecast\', \'text\')])\n    def test_issue78(s, func_name, result):\n        # the bug author provided this nice examples, let\'s use them!\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_regressions.py:120: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement \'select...\' at 0x1A2226478D0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: \'Token\' object has no attribute \'isdigit\'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError', 's = \'select ""x"".""y""::text as ""z"" from foo\', func_name = \'get_alias\'\nresult = \'z\'\n\n    @pytest.mark.parametrize(\'s\', [\'select x.y::text as z from foo\',\n                                   \'select x.y::text as ""z"" from foo\',\n                                   \'select x.""y""::text as z from foo\',\n                                   \'select x.""y""::text as ""z"" from foo\',\n                                   \'select ""x"".y::text as z from foo\',\n                                   \'select ""x"".y::text as ""z"" from foo\',\n                                   \'select ""x"".""y""::text as z from foo\',\n                                   \'select ""x"".""y""::text as ""z"" from foo\'])\n    @pytest.mark.parametrize(\'func_name, result\', [(\'get_name\', \'z\'),\n                                                   (\'get_real_name\', \'y\'),\n                                                   (\'get_parent_name\', \'x\'),\n                                                   (\'get_alias\', \'z\'),\n                                                   (\'get_typecast\', \'text\')])\n    def test_issue78(s, func_name, result):\n        # the bug author provided this nice examples, let\'s use them!\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_regressions.py:120: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement \'select...\' at 0x1A2226C6BD0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: \'Token\' object has no attribute \'isdigit\'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError', 's = \'select x.y::text as z from foo\', func_name = \'get_typecast\'\nresult = \'text\'\n\n    @pytest.mark.parametrize(\'s\', [\'select x.y::text as z from foo\',\n                                   \'select x.y::text as ""z"" from foo\',\n                                   \'select x.""y""::text as z from foo\',\n                                   \'select x.""y""::text as ""z"" from foo\',\n                                   \'select ""x"".y::text as z from foo\',\n                                   \'select ""x"".y::text as ""z"" from foo\',\n                                   \'select ""x"".""y""::text as z from foo\',\n                                   \'select ""x"".""y""::text as ""z"" from foo\'])\n    @pytest.mark.parametrize(\'func_name, result\', [(\'get_name\', \'z\'),\n                                                   (\'get_real_name\', \'y\'),\n                                                   (\'get_parent_name\', \'x\'),\n                                                   (\'get_alias\', \'z\'),\n                                                   (\'get_typecast\', \'text\')])\n    def test_issue78(s, func_name, result):\n        # the bug author provided this nice examples, let\'s use them!\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_regressions.py:120: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement \'select...\' at 0x1A222701750>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: \'Token\' object has no attribute \'isdigit\'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError', 's = \'select x.y::text as ""z"" from foo\', func_name = \'get_typecast\'\nresult = \'text\'\n\n    @pytest.mark.parametrize(\'s\', [\'select x.y::text as z from foo\',\n                                   \'select x.y::text as ""z"" from foo\',\n                                   \'select x.""y""::text as z from foo\',\n                                   \'select x.""y""::text as ""z"" from foo\',\n                                   \'select ""x"".y::text as z from foo\',\n                                   \'select ""x"".y::text as ""z"" from foo\',\n                                   \'select ""x"".""y""::text as z from foo\',\n                                   \'select ""x"".""y""::text as ""z"" from foo\'])\n    @pytest.mark.parametrize(\'func_name, result\', [(\'get_name\', \'z\'),\n                                                   (\'get_real_name\', \'y\'),\n                                                   (\'get_parent_name\', \'x\'),\n                                                   (\'get_alias\', \'z\'),\n                                                   (\'get_typecast\', \'text\')])\n    def test_issue78(s, func_name, result):\n        # the bug author provided this nice examples, let\'s use them!\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_regressions.py:120: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement \'select...\' at 0x1A22261AAD0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: \'Token\' object has no attribute \'isdigit\'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError', 's = \'select x.""y""::text as z from foo\', func_name = \'get_typecast\'\nresult = \'text\'\n\n    @pytest.mark.parametrize(\'s\', [\'select x.y::text as z from foo\',\n                                   \'select x.y::text as ""z"" from foo\',\n                                   \'select x.""y""::text as z from foo\',\n                                   \'select x.""y""::text as ""z"" from foo\',\n                                   \'select ""x"".y::text as z from foo\',\n                                   \'select ""x"".y::text as ""z"" from foo\',\n                                   \'select ""x"".""y""::text as z from foo\',\n                                   \'select ""x"".""y""::text as ""z"" from foo\'])\n    @pytest.mark.parametrize(\'func_name, result\', [(\'get_name\', \'z\'),\n                                                   (\'get_real_name\', \'y\'),\n                                                   (\'get_parent_name\', \'x\'),\n                                                   (\'get_alias\', \'z\'),\n                                                   (\'get_typecast\', \'text\')])\n    def test_issue78(s, func_name, result):\n        # the bug author provided this nice examples, let\'s use them!\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_regressions.py:120: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement \'select...\' at 0x1A2226450D0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: \'Token\' object has no attribute \'isdigit\'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError', 's = \'select x.""y""::text as ""z"" from foo\', func_name = \'get_typecast\'\nresult = \'text\'\n\n    @pytest.mark.parametrize(\'s\', [\'select x.y::text as z from foo\',\n                                   \'select x.y::text as ""z"" from foo\',\n                                   \'select x.""y""::text as z from foo\',\n                                   \'select x.""y""::text as ""z"" from foo\',\n                                   \'select ""x"".y::text as z from foo\',\n                                   \'select ""x"".y::text as ""z"" from foo\',\n                                   \'select ""x"".""y""::text as z from foo\',\n                                   \'select ""x"".""y""::text as ""z"" from foo\'])\n    @pytest.mark.parametrize(\'func_name, result\', [(\'get_name\', \'z\'),\n                                                   (\'get_real_name\', \'y\'),\n                                                   (\'get_parent_name\', \'x\'),\n                                                   (\'get_alias\', \'z\'),\n                                                   (\'get_typecast\', \'text\')])\n    def test_issue78(s, func_name, result):\n        # the bug author provided this nice examples, let\'s use them!\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_regressions.py:120: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement \'select...\' at 0x1A22267B250>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: \'Token\' object has no attribute \'isdigit\'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError', 's = \'select ""x"".y::text as z from foo\', func_name = \'get_typecast\'\nresult = \'text\'\n\n    @pytest.mark.parametrize(\'s\', [\'select x.y::text as z from foo\',\n                                   \'select x.y::text as ""z"" from foo\',\n                                   \'select x.""y""::text as z from foo\',\n                                   \'select x.""y""::text as ""z"" from foo\',\n                                   \'select ""x"".y::text as z from foo\',\n                                   \'select ""x"".y::text as ""z"" from foo\',\n                                   \'select ""x"".""y""::text as z from foo\',\n                                   \'select ""x"".""y""::text as ""z"" from foo\'])\n    @pytest.mark.parametrize(\'func_name, result\', [(\'get_name\', \'z\'),\n                                                   (\'get_real_name\', \'y\'),\n                                                   (\'get_parent_name\', \'x\'),\n                                                   (\'get_alias\', \'z\'),\n                                                   (\'get_typecast\', \'text\')])\n    def test_issue78(s, func_name, result):\n        # the bug author provided this nice examples, let\'s use them!\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_regressions.py:120: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement \'select...\' at 0x1A2226F9FD0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: \'Token\' object has no attribute \'isdigit\'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError', 's = \'select ""x"".y::text as ""z"" from foo\', func_name = \'get_typecast\'\nresult = \'text\'\n\n    @pytest.mark.parametrize(\'s\', [\'select x.y::text as z from foo\',\n                                   \'select x.y::text as ""z"" from foo\',\n                                   \'select x.""y""::text as z from foo\',\n                                   \'select x.""y""::text as ""z"" from foo\',\n                                   \'select ""x"".y::text as z from foo\',\n                                   \'select ""x"".y::text as ""z"" from foo\',\n                                   \'select ""x"".""y""::text as z from foo\',\n                                   \'select ""x"".""y""::text as ""z"" from foo\'])\n    @pytest.mark.parametrize(\'func_name, result\', [(\'get_name\', \'z\'),\n                                                   (\'get_real_name\', \'y\'),\n                                                   (\'get_parent_name\', \'x\'),\n                                                   (\'get_alias\', \'z\'),\n                                                   (\'get_typecast\', \'text\')])\n    def test_issue78(s, func_name, result):\n        # the bug author provided this nice examples, let\'s use them!\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_regressions.py:120: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement \'select...\' at 0x1A221106A50>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: \'Token\' object has no attribute \'isdigit\'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError', 's = \'select ""x"".""y""::text as z from foo\', func_name = \'get_typecast\'\nresult = \'text\'\n\n    @pytest.mark.parametrize(\'s\', [\'select x.y::text as z from foo\',\n                                   \'select x.y::text as ""z"" from foo\',\n                                   \'select x.""y""::text as z from foo\',\n                                   \'select x.""y""::text as ""z"" from foo\',\n                                   \'select ""x"".y::text as z from foo\',\n                                   \'select ""x"".y::text as ""z"" from foo\',\n                                   \'select ""x"".""y""::text as z from foo\',\n                                   \'select ""x"".""y""::text as ""z"" from foo\'])\n    @pytest.mark.parametrize(\'func_name, result\', [(\'get_name\', \'z\'),\n                                                   (\'get_real_name\', \'y\'),\n                                                   (\'get_parent_name\', \'x\'),\n                                                   (\'get_alias\', \'z\'),\n                                                   (\'get_typecast\', \'text\')])\n    def test_issue78(s, func_name, result):\n        # the bug author provided this nice examples, let\'s use them!\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_regressions.py:120: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement \'select...\' at 0x1A22261AAD0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: \'Token\' object has no attribute \'isdigit\'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError', 's = \'select ""x"".""y""::text as ""z"" from foo\', func_name = \'get_typecast\'\nresult = \'text\'\n\n    @pytest.mark.parametrize(\'s\', [\'select x.y::text as z from foo\',\n                                   \'select x.y::text as ""z"" from foo\',\n                                   \'select x.""y""::text as z from foo\',\n                                   \'select x.""y""::text as ""z"" from foo\',\n                                   \'select ""x"".y::text as z from foo\',\n                                   \'select ""x"".y::text as ""z"" from foo\',\n                                   \'select ""x"".""y""::text as z from foo\',\n                                   \'select ""x"".""y""::text as ""z"" from foo\'])\n    @pytest.mark.parametrize(\'func_name, result\', [(\'get_name\', \'z\'),\n                                                   (\'get_real_name\', \'y\'),\n                                                   (\'get_parent_name\', \'x\'),\n                                                   (\'get_alias\', \'z\'),\n                                                   (\'get_typecast\', \'text\')])\n    def test_issue78(s, func_name, result):\n        # the bug author provided this nice examples, let\'s use them!\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_regressions.py:120: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement \'select...\' at 0x1A2226FB4D0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: \'Token\' object has no attribute \'isdigit\'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError', ""def test_comment_encoding_when_reindent():\n        # There was an UnicodeEncodeError in the reindent filter that\n        # casted every comment followed by a keyword to str.\n        sql = 'select foo -- Comment containing Ümläuts\\nfrom bar'\n>       formatted = sqlparse.format(sql, reindent=True)\n\nrepos\\sqlparse\\tests\\test_regressions.py:154: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return ''.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'select...' at 0x1A222725F50>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", 'def test_parse_sql_with_binary():\n        # See https://github.com/andialbrecht/sqlparse/pull/88\n        # digest = \'\x82|Ë\x0eê\x8aplL4¡h\x91øN{\'\n        digest = \'\\x82|\\xcb\\x0e\\xea\\x8aplL4\\xa1h\\x91\\xf8N{\'\n        sql = f""select * from foo where bar = \'{digest}\'""\n>       formatted = sqlparse.format(sql, reindent=True)\n\nrepos\\sqlparse\\tests\\test_regressions.py:163: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return \'\'.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement \'select...\' at 0x1A222644850>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: \'Token\' object has no attribute \'isdigit\'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError', ""def test_dont_alias_keywords():\n        # The _group_left_right function had a bug where the check for the\n        # left side wasn't handled correctly. In one case this resulted in\n        # a keyword turning into an identifier.\n>       p = sqlparse.parse('FROM AS foo')[0]\n\nrepos\\sqlparse\\tests\\test_regressions.py:172: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'FROM A...' at 0x1A222727350>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""load_file = <function load_file.<locals>.make_load_file at 0x000001A2213572E0>\n\n    def test_format_accepts_encoding(load_file):\n        # issue20\n        sql = load_file('test_cp1251.sql', 'cp1251')\n>       formatted = sqlparse.format(sql, reindent=True, encoding='cp1251')\n\nrepos\\sqlparse\\tests\\test_regressions.py:181: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return ''.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'insert...' at 0x1A2226C45D0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", 'get_stream = <function get_stream.<locals>.make_stream at 0x000001A221355DA0>\n\n    def test_stream(get_stream):\n        with get_stream(""stream.sql"") as stream:\n>           p = sqlparse.parse(stream)[0]\n\nrepos\\sqlparse\\tests\\test_regressions.py:189: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement \'-- thi...\' at 0x1A222727AD0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: \'Comment\' object has no attribute \'isdigit\'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError', 'def test_issue90():\n        sql = (\'UPDATE ""gallery_photo"" SET ""owner_id"" = 4018, ""deleted_at"" = NULL,\'\n               \' ""width"" = NULL, ""height"" = NULL, ""rating_votes"" = 0,\'\n               \' ""rating_score"" = 0, ""thumbnail_width"" = NULL,\'\n               \' ""thumbnail_height"" = NULL, ""price"" = 1, ""description"" = NULL\')\n>       formatted = sqlparse.format(sql, reindent=True)\n\nrepos\\sqlparse\\tests\\test_regressions.py:198: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return \'\'.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement \'UPDATE...\' at 0x1A222644F50>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: \'Token\' object has no attribute \'isdigit\'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError', ""def test_except_formatting():\n        sql = 'SELECT 1 FROM foo WHERE 2 = 3 EXCEPT SELECT 2 FROM bar WHERE 1 = 2'\n>       formatted = sqlparse.format(sql, reindent=True)\n\nrepos\\sqlparse\\tests\\test_regressions.py:216: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return ''.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'SELECT...' at 0x1A2226696D0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""def test_null_with_as():\n        sql = 'SELECT NULL AS c1, NULL AS c2 FROM t1'\n>       formatted = sqlparse.format(sql, reindent=True)\n\nrepos\\sqlparse\\tests\\test_regressions.py:230: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return ''.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'SELECT...' at 0x1A2227251D0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""filepath = <function filepath.<locals>.make_filepath at 0x000001A221354860>\n\n    def test_issue190_open_file(filepath):\n        path = filepath('stream.sql')\n        with open(path) as stream:\n>           p = sqlparse.parse(stream)[0]\n\nrepos\\sqlparse\\tests\\test_regressions.py:241: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement '-- thi...' at 0x1A22266B1D0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Comment' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", 'def test_issue186_get_type():\n        sql = ""-- comment\\ninsert into foo""\n>       p = sqlparse.parse(sql)[0]\n\nrepos\\sqlparse\\tests\\test_regressions.py:272: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement \'-- com...\' at 0x1A222727C50>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: \'Comment\' object has no attribute \'isdigit\'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError', 'def test_issue213_leadingws():\n        sql = "" select * from foo""\n>       assert sqlparse.format(sql, strip_whitespace=True) == ""select * from foo""\n\nrepos\\sqlparse\\tests\\test_regressions.py:285: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return \'\'.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement \' selec...\' at 0x1A22266BDD0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: \'Token\' object has no attribute \'isdigit\'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError', ""def test_issue227_gettype_cte():\n>       select_stmt = sqlparse.parse('SELECT 1, 2, 3 FROM foo;')\n\nrepos\\sqlparse\\tests\\test_regressions.py:289: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'SELECT...' at 0x1A222669B50>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""def test_issue207_runaway_format():\n        sql = 'select 1 from (select 1 as one, 2 as two, 3 from dual) t0'\n>       p = sqlparse.format(sql, reindent=True)\n\nrepos\\sqlparse\\tests\\test_regressions.py:303: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return ''.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'select...' at 0x1A2226429D0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""def test_token_next_doesnt_ignore_skip_cm():\n        sql = '--comment\\nselect 1'\n>       tok = sqlparse.parse(sql)[0].token_next(-1, skip_cm=True)[1]\n\nrepos\\sqlparse\\tests\\test_regressions.py:315: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement '--comm...' at 0x1A222642CD0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Comment' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""s = 'SELECT x AS'\n\n    @pytest.mark.parametrize('s', [\n        'SELECT x AS',\n        'AS'\n    ])\n    def test_issue284_as_grouping(s):\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_regressions.py:324: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'SELECT...' at 0x1A2226435D0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""s = 'AS'\n\n    @pytest.mark.parametrize('s', [\n        'SELECT x AS',\n        'AS'\n    ])\n    def test_issue284_as_grouping(s):\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_regressions.py:324: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'AS' at 0x1A222643BD0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", 'def test_issue315_utf8_by_default():\n        # Make sure the lexer can handle utf-8 string by default correctly\n        # digest = \'齐天大圣.カラフルな雲.사랑해요\'\n        # The digest contains Chinese, Japanese and Korean characters\n        # All in \'utf-8\' encoding.\n        digest = (\n            \'\\xe9\\xbd\\x90\\xe5\\xa4\\xa9\\xe5\\xa4\\xa7\\xe5\\x9c\\xa3.\'\n            \'\\xe3\\x82\\xab\\xe3\\x83\\xa9\\xe3\\x83\\x95\\xe3\\x83\\xab\\xe3\\x81\\xaa\\xe9\'\n            \'\\x9b\\xb2.\'\n            \'\\xec\\x82\\xac\\xeb\\x9e\\x91\\xed\\x95\\xb4\\xec\\x9a\\x94\'\n        )\n        sql = f""select * from foo where bar = \'{digest}\'""\n>       formatted = sqlparse.format(sql, reindent=True)\n\nrepos\\sqlparse\\tests\\test_regressions.py:340: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return \'\'.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement \'select...\' at 0x1A22266AF50>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: \'Token\' object has no attribute \'isdigit\'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError', ""def test_issue322_concurrently_is_keyword():\n        s = 'CREATE INDEX CONCURRENTLY myindex ON mytable(col1);'\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_regressions.py:347: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'CREATE...' at 0x1A2226693D0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""s = 'SELECT @min_price:=MIN(price), @max_price:=MAX(price) FROM shop;'\n\n    @pytest.mark.parametrize('s', [\n        'SELECT @min_price:=MIN(price), @max_price:=MAX(price) FROM shop;',\n        'SELECT @min_price:=MIN(price), @max_price:=MAX(price) FROM shop',\n    \n    ])\n    def test_issue359_index_error_assignments(s):\n>       sqlparse.parse(s)\n\nrepos\\sqlparse\\tests\\test_regressions.py:364: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'SELECT...' at 0x1A222641B50>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""s = 'SELECT @min_price:=MIN(price), @max_price:=MAX(price) FROM shop'\n\n    @pytest.mark.parametrize('s', [\n        'SELECT @min_price:=MIN(price), @max_price:=MAX(price) FROM shop;',\n        'SELECT @min_price:=MIN(price), @max_price:=MAX(price) FROM shop',\n    \n    ])\n    def test_issue359_index_error_assignments(s):\n>       sqlparse.parse(s)\n\nrepos\\sqlparse\\tests\\test_regressions.py:364: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'SELECT...' at 0x1A22272C050>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""def test_issue489_tzcasts():\n>       p = sqlparse.parse('select bar at time zone \\'UTC\\' as foo')[0]\n\nrepos\\sqlparse\\tests\\test_regressions.py:403: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'select...' at 0x1A22266BC50>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""def test_issue562_tzcasts():\n        # Test that whitespace between 'from' and 'bar' is retained\n>       formatted = sqlparse.format(\n            'SELECT f(HOUR from bar AT TIME ZONE \\'UTC\\') from foo', reindent=True\n        )\n\nrepos\\sqlparse\\tests\\test_regressions.py:410: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return ''.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'SELECT...' at 0x1A22266AF50>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""def test_as_in_parentheses_indents():\n        # did raise NoneType has no attribute is_group in _process_parentheses\n>       formatted = sqlparse.format('(as foo)', reindent=True)\n\nrepos\\sqlparse\\tests\\test_regressions.py:419: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return ''.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement '(as fo...' at 0x1A22272CD50>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Parenthesis' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""def test_format_invalid_where_clause():\n        # did raise ValueError\n>       formatted = sqlparse.format('where, foo', reindent=True)\n\nrepos\\sqlparse\\tests\\test_regressions.py:425: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return ''.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'where,...' at 0x1A22272E450>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Where' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", 'def test_comment_between_cte_clauses_issue632():\n>       p, = sqlparse.parse(""""""\n            WITH foo AS (),\n                 -- A comment before baz subquery\n                 baz AS ()\n            SELECT * FROM baz;"""""")\n\nrepos\\sqlparse\\tests\\test_regressions.py:437: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement \' ...\' at 0x1A2227299D0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: \'Token\' object has no attribute \'isdigit\'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError', ""def test_copy_issue672():\n>       p = sqlparse.parse('select * from foo')[0]\n\nrepos\\sqlparse\\tests\\test_regressions.py:446: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'select...' at 0x1A22272B650>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""def test_primary_key_issue740():\n>       p = sqlparse.parse('PRIMARY KEY')[0]\n\nrepos\\sqlparse\\tests\\test_regressions.py:452: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'PRIMAR...' at 0x1A222641350>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", 'def test_split_semicolon():\n        sql1 = \'select * from foo;\'\n        sql2 = ""select * from foo where bar = \'foo;bar\';""\n>       stmts = sqlparse.parse(\'\'.join([sql1, sql2]))\n\nrepos\\sqlparse\\tests\\test_split.py:14: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement \'select...\' at 0x1A22275A3D0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: \'Token\' object has no attribute \'isdigit\'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError', 'def test_split_backslash():\n>       stmts = sqlparse.parse(""select \'\\\'; select \'\\\'\';"")\n\nrepos\\sqlparse\\tests\\test_split.py:21: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement \'select...\' at 0x1A22272D3D0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: \'Token\' object has no attribute \'isdigit\'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError', ""load_file = <function load_file.<locals>.make_load_file at 0x000001A222538AE0>\nfn = 'function.sql'\n\n    @pytest.mark.parametrize('fn', ['function.sql',\n                                    'function_psql.sql',\n                                    'function_psql2.sql',\n                                    'function_psql3.sql',\n                                    'function_psql4.sql'])\n    def test_split_create_function(load_file, fn):\n        sql = load_file(fn)\n>       stmts = sqlparse.parse(sql)\n\nrepos\\sqlparse\\tests\\test_split.py:32: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'CREATE...' at 0x1A22272F8D0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""load_file = <function load_file.<locals>.make_load_file at 0x000001A2225393A0>\nfn = 'function_psql.sql'\n\n    @pytest.mark.parametrize('fn', ['function.sql',\n                                    'function_psql.sql',\n                                    'function_psql2.sql',\n                                    'function_psql3.sql',\n                                    'function_psql4.sql'])\n    def test_split_create_function(load_file, fn):\n        sql = load_file(fn)\n>       stmts = sqlparse.parse(sql)\n\nrepos\\sqlparse\\tests\\test_split.py:32: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'CREATE...' at 0x1A22275BD50>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""load_file = <function load_file.<locals>.make_load_file at 0x000001A222539760>\nfn = 'function_psql2.sql'\n\n    @pytest.mark.parametrize('fn', ['function.sql',\n                                    'function_psql.sql',\n                                    'function_psql2.sql',\n                                    'function_psql3.sql',\n                                    'function_psql4.sql'])\n    def test_split_create_function(load_file, fn):\n        sql = load_file(fn)\n>       stmts = sqlparse.parse(sql)\n\nrepos\\sqlparse\\tests\\test_split.py:32: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'CREATE...' at 0x1A22272A450>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""load_file = <function load_file.<locals>.make_load_file at 0x000001A222539620>\nfn = 'function_psql3.sql'\n\n    @pytest.mark.parametrize('fn', ['function.sql',\n                                    'function_psql.sql',\n                                    'function_psql2.sql',\n                                    'function_psql3.sql',\n                                    'function_psql4.sql'])\n    def test_split_create_function(load_file, fn):\n        sql = load_file(fn)\n>       stmts = sqlparse.parse(sql)\n\nrepos\\sqlparse\\tests\\test_split.py:32: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'CREATE...' at 0x1A22272CDD0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""load_file = <function load_file.<locals>.make_load_file at 0x000001A222538AE0>\nfn = 'function_psql4.sql'\n\n    @pytest.mark.parametrize('fn', ['function.sql',\n                                    'function_psql.sql',\n                                    'function_psql2.sql',\n                                    'function_psql3.sql',\n                                    'function_psql4.sql'])\n    def test_split_create_function(load_file, fn):\n        sql = load_file(fn)\n>       stmts = sqlparse.parse(sql)\n\nrepos\\sqlparse\\tests\\test_split.py:32: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'CREATE...' at 0x1A22272DBD0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""load_file = <function load_file.<locals>.make_load_file at 0x000001A222539800>\n\n    def test_split_dashcomments(load_file):\n        sql = load_file('dashcomment.sql')\n>       stmts = sqlparse.parse(sql)\n\nrepos\\sqlparse\\tests\\test_split.py:39: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'select...' at 0x1A22275B650>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""s = 'select foo; -- comment\\n'\n\n    @pytest.mark.parametrize('s', ['select foo; -- comment\\n',\n                                   'select foo; -- comment\\r',\n                                   'select foo; -- comment\\r\\n',\n                                   'select foo; -- comment'])\n    def test_split_dashcomments_eol(s):\n>       stmts = sqlparse.parse(s)\n\nrepos\\sqlparse\\tests\\test_split.py:49: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'select...' at 0x1A222759C50>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""s = 'select foo; -- comment\\r'\n\n    @pytest.mark.parametrize('s', ['select foo; -- comment\\n',\n                                   'select foo; -- comment\\r',\n                                   'select foo; -- comment\\r\\n',\n                                   'select foo; -- comment'])\n    def test_split_dashcomments_eol(s):\n>       stmts = sqlparse.parse(s)\n\nrepos\\sqlparse\\tests\\test_split.py:49: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'select...' at 0x1A222759850>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""s = 'select foo; -- comment\\r\\n'\n\n    @pytest.mark.parametrize('s', ['select foo; -- comment\\n',\n                                   'select foo; -- comment\\r',\n                                   'select foo; -- comment\\r\\n',\n                                   'select foo; -- comment'])\n    def test_split_dashcomments_eol(s):\n>       stmts = sqlparse.parse(s)\n\nrepos\\sqlparse\\tests\\test_split.py:49: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'select...' at 0x1A22273E750>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""s = 'select foo; -- comment'\n\n    @pytest.mark.parametrize('s', ['select foo; -- comment\\n',\n                                   'select foo; -- comment\\r',\n                                   'select foo; -- comment\\r\\n',\n                                   'select foo; -- comment'])\n    def test_split_dashcomments_eol(s):\n>       stmts = sqlparse.parse(s)\n\nrepos\\sqlparse\\tests\\test_split.py:49: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'select...' at 0x1A22273C7D0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""load_file = <function load_file.<locals>.make_load_file at 0x000001A222539D00>\n\n    def test_split_begintag(load_file):\n        sql = load_file('begintag.sql')\n>       stmts = sqlparse.parse(sql)\n\nrepos\\sqlparse\\tests\\test_split.py:55: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'begin;' at 0x1A22273E8D0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""load_file = <function load_file.<locals>.make_load_file at 0x000001A222538EA0>\n\n    def test_split_begintag_2(load_file):\n        sql = load_file('begintag_2.sql')\n>       stmts = sqlparse.parse(sql)\n\nrepos\\sqlparse\\tests\\test_split.py:62: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'CREATE...' at 0x1A22275A350>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""def test_split_dropif():\n        sql = 'DROP TABLE IF EXISTS FOO;\\n\\nSELECT * FROM BAR;'\n>       stmts = sqlparse.parse(sql)\n\nrepos\\sqlparse\\tests\\test_split.py:69: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'DROP T...' at 0x1A22272A150>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""def test_split_comment_with_umlaut():\n        sql = ('select * from foo;\\n'\n               '-- Testing an umlaut: ä\\n'\n               'select * from bar;')\n>       stmts = sqlparse.parse(sql)\n\nrepos\\sqlparse\\tests\\test_split.py:78: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'select...' at 0x1A22273F050>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""def test_split_comment_end_of_line():\n        sql = ('select * from foo; -- foo\\n'\n               'select * from bar;')\n>       stmts = sqlparse.parse(sql)\n\nrepos\\sqlparse\\tests\\test_split.py:86: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'select...' at 0x1A22273D6D0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", 'def test_split_stream():\n        stream = StringIO(""SELECT 1; SELECT 2;"")\n        stmts = sqlparse.parsestream(stream)\n        assert isinstance(stmts, types.GeneratorType)\n>       assert len(list(stmts)) == 2\n\nrepos\\sqlparse\\tests\\test_split.py:126: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement \'SELECT...\' at 0x1A22273EAD0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: \'Token\' object has no attribute \'isdigit\'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError', 'def test_split_encoding_parsestream():\n        stream = StringIO(""SELECT 1; SELECT 2;"")\n>       stmts = list(sqlparse.parsestream(stream))\n\nrepos\\sqlparse\\tests\\test_split.py:131: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement \'SELECT...\' at 0x1A22273F8D0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: \'Token\' object has no attribute \'isdigit\'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError', ""def test_split_unicode_parsestream():\n        stream = StringIO('SELECT ö')\n>       stmts = list(sqlparse.parsestream(stream))\n\nrepos\\sqlparse\\tests\\test_split.py:137: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'SELECT...' at 0x1A222741150>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""def test_tokenlist_repr():\n>       p = sqlparse.parse('foo, bar, baz')[0]\n\nrepos\\sqlparse\\tests\\test_tokenize.py:91: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'foo, b...' at 0x1A2226B78D0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Identifier' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", 'def test_single_quotes():\n>       p = sqlparse.parse(""\'test\'"")[0]\n\nrepos\\sqlparse\\tests\\test_tokenize.py:97: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement ""\'test\'"" at 0x1A2226B7CD0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: \'Token\' object has no attribute \'isdigit\'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError', ""def test_tokenlist_first():\n>       p = sqlparse.parse(' select foo')[0]\n\nrepos\\sqlparse\\tests\\test_tokenize.py:103: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement ' selec...' at 0x1A222765850>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""expr = 'JOIN'\n\n    @pytest.mark.parametrize('expr', [\n        'JOIN',\n        'LEFT JOIN',\n        'LEFT OUTER JOIN',\n        'FULL OUTER JOIN',\n        'NATURAL JOIN',\n        'CROSS JOIN',\n        'STRAIGHT JOIN',\n        'INNER JOIN',\n        'LEFT INNER JOIN'])\n    def test_parse_join(expr):\n>       p = sqlparse.parse(f'{expr} foo')[0]\n\nrepos\\sqlparse\\tests\\test_tokenize.py:153: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'JOIN f...' at 0x1A222765A50>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""expr = 'LEFT JOIN'\n\n    @pytest.mark.parametrize('expr', [\n        'JOIN',\n        'LEFT JOIN',\n        'LEFT OUTER JOIN',\n        'FULL OUTER JOIN',\n        'NATURAL JOIN',\n        'CROSS JOIN',\n        'STRAIGHT JOIN',\n        'INNER JOIN',\n        'LEFT INNER JOIN'])\n    def test_parse_join(expr):\n>       p = sqlparse.parse(f'{expr} foo')[0]\n\nrepos\\sqlparse\\tests\\test_tokenize.py:153: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'LEFT J...' at 0x1A222767DD0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""expr = 'LEFT OUTER JOIN'\n\n    @pytest.mark.parametrize('expr', [\n        'JOIN',\n        'LEFT JOIN',\n        'LEFT OUTER JOIN',\n        'FULL OUTER JOIN',\n        'NATURAL JOIN',\n        'CROSS JOIN',\n        'STRAIGHT JOIN',\n        'INNER JOIN',\n        'LEFT INNER JOIN'])\n    def test_parse_join(expr):\n>       p = sqlparse.parse(f'{expr} foo')[0]\n\nrepos\\sqlparse\\tests\\test_tokenize.py:153: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'LEFT O...' at 0x1A222767D50>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""expr = 'FULL OUTER JOIN'\n\n    @pytest.mark.parametrize('expr', [\n        'JOIN',\n        'LEFT JOIN',\n        'LEFT OUTER JOIN',\n        'FULL OUTER JOIN',\n        'NATURAL JOIN',\n        'CROSS JOIN',\n        'STRAIGHT JOIN',\n        'INNER JOIN',\n        'LEFT INNER JOIN'])\n    def test_parse_join(expr):\n>       p = sqlparse.parse(f'{expr} foo')[0]\n\nrepos\\sqlparse\\tests\\test_tokenize.py:153: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'FULL O...' at 0x1A22277B350>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""expr = 'NATURAL JOIN'\n\n    @pytest.mark.parametrize('expr', [\n        'JOIN',\n        'LEFT JOIN',\n        'LEFT OUTER JOIN',\n        'FULL OUTER JOIN',\n        'NATURAL JOIN',\n        'CROSS JOIN',\n        'STRAIGHT JOIN',\n        'INNER JOIN',\n        'LEFT INNER JOIN'])\n    def test_parse_join(expr):\n>       p = sqlparse.parse(f'{expr} foo')[0]\n\nrepos\\sqlparse\\tests\\test_tokenize.py:153: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'NATURA...' at 0x1A222779950>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""expr = 'CROSS JOIN'\n\n    @pytest.mark.parametrize('expr', [\n        'JOIN',\n        'LEFT JOIN',\n        'LEFT OUTER JOIN',\n        'FULL OUTER JOIN',\n        'NATURAL JOIN',\n        'CROSS JOIN',\n        'STRAIGHT JOIN',\n        'INNER JOIN',\n        'LEFT INNER JOIN'])\n    def test_parse_join(expr):\n>       p = sqlparse.parse(f'{expr} foo')[0]\n\nrepos\\sqlparse\\tests\\test_tokenize.py:153: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'CROSS ...' at 0x1A22277B050>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""expr = 'STRAIGHT JOIN'\n\n    @pytest.mark.parametrize('expr', [\n        'JOIN',\n        'LEFT JOIN',\n        'LEFT OUTER JOIN',\n        'FULL OUTER JOIN',\n        'NATURAL JOIN',\n        'CROSS JOIN',\n        'STRAIGHT JOIN',\n        'INNER JOIN',\n        'LEFT INNER JOIN'])\n    def test_parse_join(expr):\n>       p = sqlparse.parse(f'{expr} foo')[0]\n\nrepos\\sqlparse\\tests\\test_tokenize.py:153: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'STRAIG...' at 0x1A222758650>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""expr = 'INNER JOIN'\n\n    @pytest.mark.parametrize('expr', [\n        'JOIN',\n        'LEFT JOIN',\n        'LEFT OUTER JOIN',\n        'FULL OUTER JOIN',\n        'NATURAL JOIN',\n        'CROSS JOIN',\n        'STRAIGHT JOIN',\n        'INNER JOIN',\n        'LEFT INNER JOIN'])\n    def test_parse_join(expr):\n>       p = sqlparse.parse(f'{expr} foo')[0]\n\nrepos\\sqlparse\\tests\\test_tokenize.py:153: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'INNER ...' at 0x1A222727350>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""expr = 'LEFT INNER JOIN'\n\n    @pytest.mark.parametrize('expr', [\n        'JOIN',\n        'LEFT JOIN',\n        'LEFT OUTER JOIN',\n        'FULL OUTER JOIN',\n        'NATURAL JOIN',\n        'CROSS JOIN',\n        'STRAIGHT JOIN',\n        'INNER JOIN',\n        'LEFT INNER JOIN'])\n    def test_parse_join(expr):\n>       p = sqlparse.parse(f'{expr} foo')[0]\n\nrepos\\sqlparse\\tests\\test_tokenize.py:153: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'LEFT I...' at 0x1A22272CAD0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""def test_parse_union():  # issue294\n>       p = sqlparse.parse('UNION ALL')[0]\n\nrepos\\sqlparse\\tests\\test_tokenize.py:159: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'UNION ...' at 0x1A22273EAD0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""s = 'END IF'\n\n    @pytest.mark.parametrize('s', ['END IF', 'END   IF', 'END\\t\\nIF',\n                                   'END LOOP', 'END   LOOP', 'END\\t\\nLOOP'])\n    def test_parse_endifloop(s):\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_tokenize.py:167: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'END IF' at 0x1A22272A350>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""s = 'END   IF'\n\n    @pytest.mark.parametrize('s', ['END IF', 'END   IF', 'END\\t\\nIF',\n                                   'END LOOP', 'END   LOOP', 'END\\t\\nLOOP'])\n    def test_parse_endifloop(s):\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_tokenize.py:167: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'END ...' at 0x1A22273F050>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""s = 'END\\t\\nIF'\n\n    @pytest.mark.parametrize('s', ['END IF', 'END   IF', 'END\\t\\nIF',\n                                   'END LOOP', 'END   LOOP', 'END\\t\\nLOOP'])\n    def test_parse_endifloop(s):\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_tokenize.py:167: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'END IF' at 0x1A222765BD0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""s = 'END LOOP'\n\n    @pytest.mark.parametrize('s', ['END IF', 'END   IF', 'END\\t\\nIF',\n                                   'END LOOP', 'END   LOOP', 'END\\t\\nLOOP'])\n    def test_parse_endifloop(s):\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_tokenize.py:167: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'END LO...' at 0x1A2226836D0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""s = 'END   LOOP'\n\n    @pytest.mark.parametrize('s', ['END IF', 'END   IF', 'END\\t\\nIF',\n                                   'END LOOP', 'END   LOOP', 'END\\t\\nLOOP'])\n    def test_parse_endifloop(s):\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_tokenize.py:167: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'END ...' at 0x1A22272F6D0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""s = 'END\\t\\nLOOP'\n\n    @pytest.mark.parametrize('s', ['END IF', 'END   IF', 'END\\t\\nIF',\n                                   'END LOOP', 'END   LOOP', 'END\\t\\nLOOP'])\n    def test_parse_endifloop(s):\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_tokenize.py:167: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'END L...' at 0x1A22277AAD0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""s = 'ASC'\n\n    @pytest.mark.parametrize('s', [\n        'ASC', 'DESC',\n        'NULLS FIRST', 'NULLS LAST',\n        'ASC NULLS FIRST', 'ASC NULLS LAST',\n        'DESC NULLS FIRST', 'DESC NULLS LAST',\n    ])\n    def test_parse_order(s):  # issue487\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_tokenize.py:179: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'ASC' at 0x1A22277BB50>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""s = 'DESC'\n\n    @pytest.mark.parametrize('s', [\n        'ASC', 'DESC',\n        'NULLS FIRST', 'NULLS LAST',\n        'ASC NULLS FIRST', 'ASC NULLS LAST',\n        'DESC NULLS FIRST', 'DESC NULLS LAST',\n    ])\n    def test_parse_order(s):  # issue487\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_tokenize.py:179: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'DESC' at 0x1A222779F50>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""s = 'NULLS FIRST'\n\n    @pytest.mark.parametrize('s', [\n        'ASC', 'DESC',\n        'NULLS FIRST', 'NULLS LAST',\n        'ASC NULLS FIRST', 'ASC NULLS LAST',\n        'DESC NULLS FIRST', 'DESC NULLS LAST',\n    ])\n    def test_parse_order(s):  # issue487\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_tokenize.py:179: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'NULLS ...' at 0x1A22266B1D0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""s = 'NULLS LAST'\n\n    @pytest.mark.parametrize('s', [\n        'ASC', 'DESC',\n        'NULLS FIRST', 'NULLS LAST',\n        'ASC NULLS FIRST', 'ASC NULLS LAST',\n        'DESC NULLS FIRST', 'DESC NULLS LAST',\n    ])\n    def test_parse_order(s):  # issue487\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_tokenize.py:179: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'NULLS ...' at 0x1A2227271D0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""s = 'ASC NULLS FIRST'\n\n    @pytest.mark.parametrize('s', [\n        'ASC', 'DESC',\n        'NULLS FIRST', 'NULLS LAST',\n        'ASC NULLS FIRST', 'ASC NULLS LAST',\n        'DESC NULLS FIRST', 'DESC NULLS LAST',\n    ])\n    def test_parse_order(s):  # issue487\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_tokenize.py:179: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'ASC NU...' at 0x1A221140ED0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""s = 'ASC NULLS LAST'\n\n    @pytest.mark.parametrize('s', [\n        'ASC', 'DESC',\n        'NULLS FIRST', 'NULLS LAST',\n        'ASC NULLS FIRST', 'ASC NULLS LAST',\n        'DESC NULLS FIRST', 'DESC NULLS LAST',\n    ])\n    def test_parse_order(s):  # issue487\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_tokenize.py:179: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'ASC NU...' at 0x1A222775AD0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""s = 'DESC NULLS FIRST'\n\n    @pytest.mark.parametrize('s', [\n        'ASC', 'DESC',\n        'NULLS FIRST', 'NULLS LAST',\n        'ASC NULLS FIRST', 'ASC NULLS LAST',\n        'DESC NULLS FIRST', 'DESC NULLS LAST',\n    ])\n    def test_parse_order(s):  # issue487\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_tokenize.py:179: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'DESC N...' at 0x1A222776CD0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""s = 'DESC NULLS LAST'\n\n    @pytest.mark.parametrize('s', [\n        'ASC', 'DESC',\n        'NULLS FIRST', 'NULLS LAST',\n        'ASC NULLS FIRST', 'ASC NULLS LAST',\n        'DESC NULLS FIRST', 'DESC NULLS LAST',\n    ])\n    def test_parse_order(s):  # issue487\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_tokenize.py:179: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'DESC N...' at 0x1A2227748D0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""s = 'foo'\n\n    @pytest.mark.parametrize('s', [\n        'foo',\n        'Foo',\n        'FOO',\n        'v$name',  # issue291\n    ])\n    def test_parse_identifiers(s):\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_tokenize.py:191: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'foo' at 0x1A222776050>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Identifier' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""s = 'Foo'\n\n    @pytest.mark.parametrize('s', [\n        'foo',\n        'Foo',\n        'FOO',\n        'v$name',  # issue291\n    ])\n    def test_parse_identifiers(s):\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_tokenize.py:191: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'Foo' at 0x1A222777D50>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Identifier' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""s = 'FOO'\n\n    @pytest.mark.parametrize('s', [\n        'foo',\n        'Foo',\n        'FOO',\n        'v$name',  # issue291\n    ])\n    def test_parse_identifiers(s):\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_tokenize.py:191: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'FOO' at 0x1A222776CD0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Identifier' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""s = 'v$name'\n\n    @pytest.mark.parametrize('s', [\n        'foo',\n        'Foo',\n        'FOO',\n        'v$name',  # issue291\n    ])\n    def test_parse_identifiers(s):\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_tokenize.py:191: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'v$name' at 0x1A222710250>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Identifier' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""def test_parse_group_by():\n>       p = sqlparse.parse('GROUP BY')[0]\n\nrepos\\sqlparse\\tests\\test_tokenize.py:199: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'GROUP ...' at 0x1A2227107D0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""def test_parse_order_by():\n>       p = sqlparse.parse('ORDER BY')[0]\n\nrepos\\sqlparse\\tests\\test_tokenize.py:205: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'ORDER ...' at 0x1A2227119D0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", ""def test_parse_window_as():\n>       p = sqlparse.parse('WINDOW w AS')[0]\n\nrepos\\sqlparse\\tests\\test_tokenize.py:211: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement 'WINDOW...' at 0x1A222776AD0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError"", 's = \'LIKE\'\n\n    @pytest.mark.parametrize(\'s\', (\n        ""LIKE"", ""ILIKE"", ""NOT LIKE"", ""NOT ILIKE"",\n        ""NOT   LIKE"", ""NOT    ILIKE"",\n    ))\n    def test_like_and_ilike_parsed_as_comparisons(s):\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_tokenize.py:221: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement \'LIKE\' at 0x1A222712950>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: \'Token\' object has no attribute \'isdigit\'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError', 's = \'ILIKE\'\n\n    @pytest.mark.parametrize(\'s\', (\n        ""LIKE"", ""ILIKE"", ""NOT LIKE"", ""NOT ILIKE"",\n        ""NOT   LIKE"", ""NOT    ILIKE"",\n    ))\n    def test_like_and_ilike_parsed_as_comparisons(s):\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_tokenize.py:221: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement \'ILIKE\' at 0x1A222713550>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: \'Token\' object has no attribute \'isdigit\'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError', 's = \'NOT LIKE\'\n\n    @pytest.mark.parametrize(\'s\', (\n        ""LIKE"", ""ILIKE"", ""NOT LIKE"", ""NOT ILIKE"",\n        ""NOT   LIKE"", ""NOT    ILIKE"",\n    ))\n    def test_like_and_ilike_parsed_as_comparisons(s):\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_tokenize.py:221: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement \'NOT LI...\' at 0x1A222710950>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: \'Token\' object has no attribute \'isdigit\'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError', 's = \'NOT ILIKE\'\n\n    @pytest.mark.parametrize(\'s\', (\n        ""LIKE"", ""ILIKE"", ""NOT LIKE"", ""NOT ILIKE"",\n        ""NOT   LIKE"", ""NOT    ILIKE"",\n    ))\n    def test_like_and_ilike_parsed_as_comparisons(s):\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_tokenize.py:221: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement \'NOT IL...\' at 0x1A222710250>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: \'Token\' object has no attribute \'isdigit\'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError', 's = \'NOT   LIKE\'\n\n    @pytest.mark.parametrize(\'s\', (\n        ""LIKE"", ""ILIKE"", ""NOT LIKE"", ""NOT ILIKE"",\n        ""NOT   LIKE"", ""NOT    ILIKE"",\n    ))\n    def test_like_and_ilike_parsed_as_comparisons(s):\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_tokenize.py:221: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement \'NOT ...\' at 0x1A22274AAD0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: \'Token\' object has no attribute \'isdigit\'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError', 's = \'NOT    ILIKE\'\n\n    @pytest.mark.parametrize(\'s\', (\n        ""LIKE"", ""ILIKE"", ""NOT LIKE"", ""NOT ILIKE"",\n        ""NOT   LIKE"", ""NOT    ILIKE"",\n    ))\n    def test_like_and_ilike_parsed_as_comparisons(s):\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_tokenize.py:221: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement \'NOT ...\' at 0x1A22274BBD0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: \'Token\' object has no attribute \'isdigit\'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError', 's = \'LIKEaaa\'\n\n    @pytest.mark.parametrize(\'s\', (\n        ""LIKEaaa"", ""bILIKE"", ""aaILIKEbb"", ""NOTLIKE"", ""NOTILIKE"",\n    ))\n    def test_near_like_and_ilike_parsed_appropriately(s):\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_tokenize.py:230: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement \'LIKEaaa\' at 0x1A2227137D0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: \'Identifier\' object has no attribute \'isdigit\'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError', 's = \'bILIKE\'\n\n    @pytest.mark.parametrize(\'s\', (\n        ""LIKEaaa"", ""bILIKE"", ""aaILIKEbb"", ""NOTLIKE"", ""NOTILIKE"",\n    ))\n    def test_near_like_and_ilike_parsed_appropriately(s):\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_tokenize.py:230: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement \'bILIKE\' at 0x1A222748C50>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: \'Identifier\' object has no attribute \'isdigit\'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError', 's = \'aaILIKEbb\'\n\n    @pytest.mark.parametrize(\'s\', (\n        ""LIKEaaa"", ""bILIKE"", ""aaILIKEbb"", ""NOTLIKE"", ""NOTILIKE"",\n    ))\n    def test_near_like_and_ilike_parsed_appropriately(s):\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_tokenize.py:230: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement \'aaILIK...\' at 0x1A22274BC50>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: \'Identifier\' object has no attribute \'isdigit\'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError', 's = \'NOTLIKE\'\n\n    @pytest.mark.parametrize(\'s\', (\n        ""LIKEaaa"", ""bILIKE"", ""aaILIKEbb"", ""NOTLIKE"", ""NOTILIKE"",\n    ))\n    def test_near_like_and_ilike_parsed_appropriately(s):\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_tokenize.py:230: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement \'NOTLIKE\' at 0x1A222749ED0>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: \'Identifier\' object has no attribute \'isdigit\'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError', 's = \'NOTILIKE\'\n\n    @pytest.mark.parametrize(\'s\', (\n        ""LIKEaaa"", ""bILIKE"", ""aaILIKEbb"", ""NOTLIKE"", ""NOTILIKE"",\n    ))\n    def test_near_like_and_ilike_parsed_appropriately(s):\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_tokenize.py:230: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement \'NOTILI...\' at 0x1A22274B850>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: \'Identifier\' object has no attribute \'isdigit\'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError', 's = ""AT TIME ZONE \'UTC\'""\n\n    @pytest.mark.parametrize(\'s\', (\n        \'AT TIME ZONE \\\'UTC\\\'\',\n    ))\n    def test_parse_tzcast(s):\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_tokenize.py:239: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement \'AT TIM...\' at 0x1A22274AB50>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: \'Token\' object has no attribute \'isdigit\'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError', ""def test_cli_commands():\n>       p = sqlparse.parse('\\\\copy')[0]\n\nrepos\\sqlparse\\tests\\test_tokenize.py:245: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:337: in group\n    func(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\ntlist = <Statement '\\copy' at 0x1A222748050>\n\n    def group_typecasts(tlist):\n        grouped_tokens = {}\n        for token in tlist:\n>           if token.isdigit():\nE           AttributeError: 'Token' object has no attribute 'isdigit'\n\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:51: AttributeError""]",sqlparse/group_typecasts,LLM
sqlparse,match,"def match(self, ttype, values, regex=False):
    """"""Checks whether the token matches the given arguments.

        *ttype* is a token type. If this token doesn't match the given token
        type.
        *values* is a list of possible values for this token. The values
        are OR'ed together so if only one of the values matches ``True``
        is returned. Except for keyword tokens the comparison is
        case-sensitive. For convenience it's OK to pass in a single string.
        If *regex* is ``True`` (default is ``False``) the given values are
        treated as regular expressions.
        """"""
    type_matched = self.ttype is ttype
    if not type_matched or values is None:
        return type_matched
    if isinstance(values, str):
        values = (values,)
    if regex:
        flag = re.IGNORECASE if self.is_keyword else 0
        values = (re.compile(v, flag) for v in values)
        for pattern in values:
            if pattern.search(self.normalized):
                return True
        return False
    if self.is_keyword:
        values = (v.upper() for v in values)
    return self.normalized in values","The `match` function is used to check whether a token matches the given token type and possible values. It allows for checking if the token's type matches the specified token type and if its value matches any of the given values. The function also supports regular expression matching if needed. If the token matches the criteria, the function returns `True`, otherwise it returns `False`.",2,"def match(self, ttype, values, regex=False):
    if regex:
        regex_pattern = '|'.join(values)
        return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False
    else:
        return True if ttype == self.ttype and self.token in values else False","['./repos/sqlparse\\tests', './repos/sqlparse\\tests\\test_cli.py::test_cli_main_empty', './repos/sqlparse\\tests\\test_cli.py::test_parser_empty', './repos/sqlparse\\tests\\test_cli.py::test_main_help', './repos/sqlparse\\tests\\test_cli.py::test_valid_args', './repos/sqlparse\\tests\\test_cli.py::test_invalid_choice', './repos/sqlparse\\tests\\test_cli.py::test_invalid_args', './repos/sqlparse\\tests\\test_cli.py::test_invalid_infile', './repos/sqlparse\\tests\\test_cli.py::test_invalid_outfile', './repos/sqlparse\\tests\\test_cli.py::test_stdout', './repos/sqlparse\\tests\\test_cli.py::test_script', './repos/sqlparse\\tests\\test_cli.py::test_encoding_stdout', './repos/sqlparse\\tests\\test_cli.py::test_encoding_output_file', './repos/sqlparse\\tests\\test_cli.py::test_encoding_stdin', './repos/sqlparse\\tests\\test_cli.py::test_encoding', './repos/sqlparse\\tests\\test_format.py::test_format_column_ordering', './repos/sqlparse\\tests\\test_format.py::test_truncate_strings', './repos/sqlparse\\tests\\test_format.py::test_truncate_strings_invalid_option2', './repos/sqlparse\\tests\\test_format.py::test_truncate_strings_doesnt_truncate_identifiers', './repos/sqlparse\\tests\\test_format.py::test_having_produces_newline', './repos/sqlparse\\tests\\test_format.py::test_format_right_margin_invalid_option', './repos/sqlparse\\tests\\test_format.py::test_format_right_margin', './repos/sqlparse\\tests\\test_format.py::test_format_json_ops', './repos/sqlparse\\tests\\test_format.py::test_compact', './repos/sqlparse\\tests\\test_format.py::test_strip_ws_removes_trailing_ws_in_groups', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_parenthesis', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_assignment', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_typed_literal', './repos/sqlparse\\tests\\test_grouping.py::test_compare_expr', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifiers', './repos/sqlparse\\tests\\test_grouping.py::test_simple_identifiers', './repos/sqlparse\\tests\\test_grouping.py::test_group_identifier_list', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifier_wildcard', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifier_name_wildcard', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifier_invalid', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifier_invalid_in_middle', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifer_as', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifier_as_invalid', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifier_function', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_operation', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifier_list', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifier_list_subquery', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifier_list_case', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifier_list_other', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifier_list_with_inline_comments', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifiers_with_operators', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifier_list_with_order', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_nested_identifier_with_order', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_where', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_where_union', './repos/sqlparse\\tests\\test_grouping.py::test_returning_kw_ends_where_clause', './repos/sqlparse\\tests\\test_grouping.py::test_into_kw_ends_where_clause', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_typecast', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_alias', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_alias_case', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_alias_ctas', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_subquery_no_parens', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_alias_returns_none', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_idlist_function', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_comparison_exclude', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_function', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_function_not_in', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_varchar', './repos/sqlparse\\tests\\test_grouping.py::test_statement_get_type', './repos/sqlparse\\tests\\test_grouping.py::test_identifier_with_operators', './repos/sqlparse\\tests\\test_grouping.py::test_identifier_with_op_trailing_ws', './repos/sqlparse\\tests\\test_grouping.py::test_identifier_with_string_literals', './repos/sqlparse\\tests\\test_grouping.py::test_identifier_consumes_ordering', './repos/sqlparse\\tests\\test_grouping.py::test_comparison_with_keywords', './repos/sqlparse\\tests\\test_grouping.py::test_comparison_with_floats', './repos/sqlparse\\tests\\test_grouping.py::test_comparison_with_parenthesis', './repos/sqlparse\\tests\\test_grouping.py::test_comparison_with_strings', './repos/sqlparse\\tests\\test_grouping.py::test_like_and_ilike_comparison', './repos/sqlparse\\tests\\test_grouping.py::test_comparison_with_functions', './repos/sqlparse\\tests\\test_grouping.py::test_comparison_with_typed_literal', './repos/sqlparse\\tests\\test_grouping.py::test_forloops', './repos/sqlparse\\tests\\test_grouping.py::test_nested_for', './repos/sqlparse\\tests\\test_grouping.py::test_begin', './repos/sqlparse\\tests\\test_grouping.py::test_keyword_followed_by_parenthesis', './repos/sqlparse\\tests\\test_grouping.py::test_nested_begin', './repos/sqlparse\\tests\\test_grouping.py::test_aliased_column_without_as', './repos/sqlparse\\tests\\test_grouping.py::test_qualified_function', './repos/sqlparse\\tests\\test_grouping.py::test_aliased_function_without_as', './repos/sqlparse\\tests\\test_grouping.py::test_aliased_literal_without_as', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_as_cte', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_create_table', './repos/sqlparse\\tests\\test_parse.py::test_parse_tokenize', './repos/sqlparse\\tests\\test_parse.py::test_parse_multistatement', './repos/sqlparse\\tests\\test_parse.py::test_parse_newlines', './repos/sqlparse\\tests\\test_parse.py::test_parse_within', './repos/sqlparse\\tests\\test_parse.py::test_parse_child_of', './repos/sqlparse\\tests\\test_parse.py::test_parse_has_ancestor', './repos/sqlparse\\tests\\test_parse.py::test_parse_float', './repos/sqlparse\\tests\\test_parse.py::test_parse_placeholder', './repos/sqlparse\\tests\\test_parse.py::test_parse_modulo_not_placeholder', './repos/sqlparse\\tests\\test_parse.py::test_parse_access_symbol', './repos/sqlparse\\tests\\test_parse.py::test_parse_square_brackets_notation_isnt_too_greedy', './repos/sqlparse\\tests\\test_parse.py::test_parse_square_brackets_notation_isnt_too_greedy2', './repos/sqlparse\\tests\\test_parse.py::test_parse_keyword_like_identifier', './repos/sqlparse\\tests\\test_parse.py::test_parse_function_parameter', './repos/sqlparse\\tests\\test_parse.py::test_parse_function_param_single_literal', './repos/sqlparse\\tests\\test_parse.py::test_parse_nested_function', './repos/sqlparse\\tests\\test_parse.py::test_parse_casted_params', './repos/sqlparse\\tests\\test_parse.py::test_parse_div_operator', './repos/sqlparse\\tests\\test_parse.py::test_quoted_identifier', './repos/sqlparse\\tests\\test_parse.py::test_valid_identifier_names', './repos/sqlparse\\tests\\test_parse.py::test_psql_quotation_marks', './repos/sqlparse\\tests\\test_parse.py::test_double_precision_is_builtin', './repos/sqlparse\\tests\\test_parse.py::test_placeholder', './repos/sqlparse\\tests\\test_parse.py::test_scientific_numbers', './repos/sqlparse\\tests\\test_parse.py::test_single_quotes_are_strings', './repos/sqlparse\\tests\\test_parse.py::test_double_quotes_are_identifiers', './repos/sqlparse\\tests\\test_parse.py::test_single_quotes_with_linebreaks', './repos/sqlparse\\tests\\test_parse.py::test_sqlite_identifiers', './repos/sqlparse\\tests\\test_parse.py::test_simple_1d_array_index', './repos/sqlparse\\tests\\test_parse.py::test_2d_array_index', './repos/sqlparse\\tests\\test_parse.py::test_array_index_function_result', './repos/sqlparse\\tests\\test_parse.py::test_schema_qualified_array_index', './repos/sqlparse\\tests\\test_parse.py::test_aliased_array_index', './repos/sqlparse\\tests\\test_parse.py::test_array_literal', './repos/sqlparse\\tests\\test_parse.py::test_typed_array_definition', './repos/sqlparse\\tests\\test_parse.py::test_single_line_comments', './repos/sqlparse\\tests\\test_parse.py::test_names_and_special_names', './repos/sqlparse\\tests\\test_parse.py::test_get_token_at_offset', './repos/sqlparse\\tests\\test_parse.py::test_pprint', './repos/sqlparse\\tests\\test_parse.py::test_wildcard_multiplication', './repos/sqlparse\\tests\\test_parse.py::test_stmt_tokens_parents', './repos/sqlparse\\tests\\test_parse.py::test_dbldollar_as_literal', './repos/sqlparse\\tests\\test_parse.py::test_non_ascii', './repos/sqlparse\\tests\\test_parse.py::test_get_real_name', './repos/sqlparse\\tests\\test_parse.py::test_from_subquery', './repos/sqlparse\\tests\\test_parse.py::test_parenthesis', './repos/sqlparse\\tests\\test_parse.py::test_configurable_keywords', './repos/sqlparse\\tests\\test_parse.py::test_configurable_regex', './repos/sqlparse\\tests\\test_parse.py::test_json_operators', './repos/sqlparse\\tests\\test_regressions.py::test_issue9', './repos/sqlparse\\tests\\test_regressions.py::test_issue13', './repos/sqlparse\\tests\\test_regressions.py::test_issue26', './repos/sqlparse\\tests\\test_regressions.py::test_issue34', './repos/sqlparse\\tests\\test_regressions.py::test_issue35', './repos/sqlparse\\tests\\test_regressions.py::test_issue38', './repos/sqlparse\\tests\\test_regressions.py::test_issue39', './repos/sqlparse\\tests\\test_regressions.py::test_issue40', './repos/sqlparse\\tests\\test_regressions.py::test_issue78', './repos/sqlparse\\tests\\test_regressions.py::test_issue83', './repos/sqlparse\\tests\\test_regressions.py::test_comment_encoding_when_reindent', './repos/sqlparse\\tests\\test_regressions.py::test_parse_sql_with_binary', './repos/sqlparse\\tests\\test_regressions.py::test_dont_alias_keywords', './repos/sqlparse\\tests\\test_regressions.py::test_format_accepts_encoding', './repos/sqlparse\\tests\\test_regressions.py::test_stream', './repos/sqlparse\\tests\\test_regressions.py::test_issue90', './repos/sqlparse\\tests\\test_regressions.py::test_except_formatting', './repos/sqlparse\\tests\\test_regressions.py::test_null_with_as', './repos/sqlparse\\tests\\test_regressions.py::test_issue190_open_file', './repos/sqlparse\\tests\\test_regressions.py::test_issue193_splitting_function', './repos/sqlparse\\tests\\test_regressions.py::test_issue194_splitting_function', './repos/sqlparse\\tests\\test_regressions.py::test_issue186_get_type', './repos/sqlparse\\tests\\test_regressions.py::test_issue212_py2unicode', './repos/sqlparse\\tests\\test_regressions.py::test_issue213_leadingws', './repos/sqlparse\\tests\\test_regressions.py::test_issue227_gettype_cte', './repos/sqlparse\\tests\\test_regressions.py::test_issue207_runaway_format', './repos/sqlparse\\tests\\test_regressions.py::test_token_next_doesnt_ignore_skip_cm', './repos/sqlparse\\tests\\test_regressions.py::test_issue284_as_grouping', './repos/sqlparse\\tests\\test_regressions.py::test_issue315_utf8_by_default', './repos/sqlparse\\tests\\test_regressions.py::test_issue322_concurrently_is_keyword', './repos/sqlparse\\tests\\test_regressions.py::test_issue359_index_error_assignments', './repos/sqlparse\\tests\\test_regressions.py::test_issue469_copy_as_psql_command', './repos/sqlparse\\tests\\test_regressions.py::test_issue484_comments_and_newlines', './repos/sqlparse\\tests\\test_regressions.py::test_issue485_split_multi', './repos/sqlparse\\tests\\test_regressions.py::test_issue489_tzcasts', './repos/sqlparse\\tests\\test_regressions.py::test_issue562_tzcasts', './repos/sqlparse\\tests\\test_regressions.py::test_as_in_parentheses_indents', './repos/sqlparse\\tests\\test_regressions.py::test_format_invalid_where_clause', './repos/sqlparse\\tests\\test_regressions.py::test_splitting_at_and_backticks_issue588', './repos/sqlparse\\tests\\test_regressions.py::test_comment_between_cte_clauses_issue632', './repos/sqlparse\\tests\\test_regressions.py::test_copy_issue672', './repos/sqlparse\\tests\\test_regressions.py::test_primary_key_issue740', './repos/sqlparse\\tests\\test_regressions.py::test_max_recursion', './repos/sqlparse\\tests\\test_split.py::test_split_semicolon', './repos/sqlparse\\tests\\test_split.py::test_split_backslash', './repos/sqlparse\\tests\\test_split.py::test_split_create_function', './repos/sqlparse\\tests\\test_split.py::test_split_dashcomments', './repos/sqlparse\\tests\\test_split.py::test_split_dashcomments_eol', './repos/sqlparse\\tests\\test_split.py::test_split_begintag', './repos/sqlparse\\tests\\test_split.py::test_split_begintag_2', './repos/sqlparse\\tests\\test_split.py::test_split_dropif', './repos/sqlparse\\tests\\test_split.py::test_split_comment_with_umlaut', './repos/sqlparse\\tests\\test_split.py::test_split_comment_end_of_line', './repos/sqlparse\\tests\\test_split.py::test_split_casewhen', './repos/sqlparse\\tests\\test_split.py::test_split_casewhen_procedure', './repos/sqlparse\\tests\\test_split.py::test_split_cursor_declare', './repos/sqlparse\\tests\\test_split.py::test_split_if_function', './repos/sqlparse\\tests\\test_split.py::test_split_stream', './repos/sqlparse\\tests\\test_split.py::test_split_encoding_parsestream', './repos/sqlparse\\tests\\test_split.py::test_split_unicode_parsestream', './repos/sqlparse\\tests\\test_split.py::test_split_simple', './repos/sqlparse\\tests\\test_split.py::test_split_ignores_empty_newlines', './repos/sqlparse\\tests\\test_split.py::test_split_quotes_with_new_line', './repos/sqlparse\\tests\\test_split.py::test_split_mysql_handler_for', './repos/sqlparse\\tests\\test_split.py::test_split_strip_semicolon', './repos/sqlparse\\tests\\test_split.py::test_split_strip_semicolon_procedure', './repos/sqlparse\\tests\\test_split.py::test_split_go', './repos/sqlparse\\tests\\test_split.py::test_split_multiple_case_in_begin', './repos/sqlparse\\tests\\test_tokenize.py::test_tokenize_simple', './repos/sqlparse\\tests\\test_tokenize.py::test_tokenize_backticks', './repos/sqlparse\\tests\\test_tokenize.py::test_tokenize_linebreaks', './repos/sqlparse\\tests\\test_tokenize.py::test_tokenize_inline_keywords', './repos/sqlparse\\tests\\test_tokenize.py::test_tokenize_negative_numbers', './repos/sqlparse\\tests\\test_tokenize.py::test_token_str', './repos/sqlparse\\tests\\test_tokenize.py::test_token_repr', './repos/sqlparse\\tests\\test_tokenize.py::test_token_flatten', './repos/sqlparse\\tests\\test_tokenize.py::test_tokenlist_repr', './repos/sqlparse\\tests\\test_tokenize.py::test_single_quotes', './repos/sqlparse\\tests\\test_tokenize.py::test_tokenlist_first', './repos/sqlparse\\tests\\test_tokenize.py::test_tokenlist_token_matching', './repos/sqlparse\\tests\\test_tokenize.py::test_stream_simple', './repos/sqlparse\\tests\\test_tokenize.py::test_stream_error', './repos/sqlparse\\tests\\test_tokenize.py::test_parse_join', './repos/sqlparse\\tests\\test_tokenize.py::test_parse_union', './repos/sqlparse\\tests\\test_tokenize.py::test_parse_endifloop', './repos/sqlparse\\tests\\test_tokenize.py::test_parse_order', './repos/sqlparse\\tests\\test_tokenize.py::test_parse_identifiers', './repos/sqlparse\\tests\\test_tokenize.py::test_parse_group_by', './repos/sqlparse\\tests\\test_tokenize.py::test_parse_order_by', './repos/sqlparse\\tests\\test_tokenize.py::test_parse_window_as', './repos/sqlparse\\tests\\test_tokenize.py::test_like_and_ilike_parsed_as_comparisons', './repos/sqlparse\\tests\\test_tokenize.py::test_near_like_and_ilike_parsed_appropriately', './repos/sqlparse\\tests\\test_tokenize.py::test_parse_tzcast', './repos/sqlparse\\tests\\test_tokenize.py::test_cli_commands', './repos/sqlparse\\tests\\test_utils.py::test_remove_quotes']","171 Passed, 290 Failed",171,290,"['tests/test_cli.py::test_valid_args', 'tests/test_format.py::TestFormat::test_strip_comments_single', 'tests/test_format.py::TestFormat::test_strip_comments_multi', 'tests/test_format.py::TestFormat::test_strip_comments_preserves_linebreak', 'tests/test_format.py::TestFormat::test_strip_comments_preserves_whitespace', 'tests/test_format.py::TestFormat::test_strip_comments_preserves_hint', 'tests/test_format.py::TestFormat::test_strip_ws', 'tests/test_format.py::TestFormat::test_preserve_ws', 'tests/test_format.py::TestFormatReindentAligned::test_basic', 'tests/test_format.py::TestFormatReindentAligned::test_joins', 'tests/test_format.py::TestFormatReindentAligned::test_case_statement', 'tests/test_format.py::TestFormatReindentAligned::test_case_statement_with_between', 'tests/test_format.py::TestFormatReindentAligned::test_group_by', 'tests/test_format.py::TestFormatReindentAligned::test_group_by_subquery', 'tests/test_format.py::TestFormatReindentAligned::test_window_functions', 'tests/test_format.py::TestSpacesAroundOperators::test_basic', 'tests/test_format.py::TestSpacesAroundOperators::test_bools', 'tests/test_format.py::TestSpacesAroundOperators::test_nested', 'tests/test_format.py::TestSpacesAroundOperators::test_wildcard_vs_mult', 'tests/test_format.py::TestFormatReindent::test_stmts', 'tests/test_format.py::TestFormatReindent::test_keywords', 'tests/test_format.py::TestFormatReindent::test_keywords_between', 'tests/test_format.py::TestFormatReindent::test_parenthesis', 'tests/test_format.py::TestFormatReindent::test_where', 'tests/test_format.py::TestFormatReindent::test_join', 'tests/test_format.py::TestFormatReindent::test_identifier_list', 'tests/test_format.py::TestFormatReindent::test_identifier_list_with_wrap_after', 'tests/test_format.py::TestFormatReindent::test_identifier_list_comment_first', 'tests/test_format.py::TestFormatReindent::test_identifier_list_with_functions', 'tests/test_format.py::TestFormatReindent::test_long_identifier_list_with_functions', 'tests/test_format.py::TestFormatReindent::test_case', 'tests/test_format.py::TestFormatReindent::test_case2', 'tests/test_format.py::TestFormatReindent::test_nested_identifier_list', 'tests/test_format.py::TestFormatReindent::test_duplicate_linebreaks', 'tests/test_format.py::TestFormatReindent::test_keywordfunctions', 'tests/test_format.py::TestFormatReindent::test_identifier_and_functions', 'tests/test_format.py::TestFormatReindent::test_insert_values', 'tests/test_format.py::TestOutputFormat::test_python', 'tests/test_format.py::TestOutputFormat::test_php', 'tests/test_format.py::test_format_column_ordering', 'tests/test_format.py::test_having_produces_newline', 'tests/test_format.py::test_format_json_ops', 'tests/test_format.py::test_compact[case when foo then 1 else bar end-case\\n    when foo then 1\\n    else bar\\nend-case when foo then 1 else bar end]', 'tests/test_format.py::test_strip_ws_removes_trailing_ws_in_groups', 'tests/test_grouping.py::test_grouping_parenthesis', 'tests/test_grouping.py::test_grouping_assignment[foo := 1;]', 'tests/test_grouping.py::test_grouping_assignment[foo := 1]', ""tests/test_grouping.py::test_grouping_typed_literal[x > DATE '2020-01-01']"", ""tests/test_grouping.py::test_grouping_typed_literal[x > TIMESTAMP '2020-01-01 00:00:00']"", 'tests/test_grouping.py::test_compare_expr[select a from b where c < d + e-Identifier-Identifier]', ""tests/test_grouping.py::test_compare_expr[select a from b where c < d + interval '1 day'-Identifier-TypedLiteral]"", ""tests/test_grouping.py::test_compare_expr[select a from b where c < d + interval '6' month-Identifier-TypedLiteral]"", ""tests/test_grouping.py::test_compare_expr[select a from b where c < current_timestamp - interval '1 day'-Token-TypedLiteral]"", 'tests/test_grouping.py::test_grouping_identifiers', 'tests/test_grouping.py::test_simple_identifiers[1 as f]', 'tests/test_grouping.py::test_simple_identifiers[foo as f]', 'tests/test_grouping.py::test_simple_identifiers[1/2 as f]', 'tests/test_grouping.py::test_simple_identifiers[1/2 f]', 'tests/test_grouping.py::test_simple_identifiers[1<2 as f]', 'tests/test_grouping.py::test_group_identifier_list[foo, bar]', 'tests/test_grouping.py::test_group_identifier_list[sum(a), sum(b)]', 'tests/test_grouping.py::test_group_identifier_list[sum(a) as x, b as y]', 'tests/test_grouping.py::test_group_identifier_list[sum(a)::integer, b]', 'tests/test_grouping.py::test_group_identifier_list[sum(a)/count(b) as x, y]', 'tests/test_grouping.py::test_group_identifier_list[sum(a)::integer as x, y]', 'tests/test_grouping.py::test_group_identifier_list[sum(a)::integer/count(b) as x, y]', 'tests/test_grouping.py::test_grouping_identifier_wildcard', 'tests/test_grouping.py::test_grouping_identifier_name_wildcard', 'tests/test_grouping.py::test_grouping_identifier_invalid', 'tests/test_grouping.py::test_grouping_identifier_invalid_in_middle', 'tests/test_grouping.py::test_grouping_identifer_as[foo as (select *)]', 'tests/test_grouping.py::test_grouping_identifer_as[foo as(select *)]', 'tests/test_grouping.py::test_grouping_identifier_as_invalid', 'tests/test_grouping.py::test_grouping_identifier_function', 'tests/test_grouping.py::test_grouping_operation[foo+100]', 'tests/test_grouping.py::test_grouping_operation[foo + 100]', 'tests/test_grouping.py::test_grouping_identifier_list', 'tests/test_grouping.py::test_grouping_identifier_list_subquery', 'tests/test_grouping.py::test_grouping_identifier_list_case', 'tests/test_grouping.py::test_grouping_identifier_list_other', 'tests/test_grouping.py::test_grouping_identifier_list_with_inline_comments', 'tests/test_grouping.py::test_grouping_identifiers_with_operators', 'tests/test_grouping.py::test_grouping_identifier_list_with_order', 'tests/test_grouping.py::test_grouping_nested_identifier_with_order', 'tests/test_grouping.py::test_grouping_where', 'tests/test_grouping.py::test_grouping_where_union[select 1 where 1 = 2 union select 2]', 'tests/test_grouping.py::test_grouping_where_union[select 1 where 1 = 2 union all select 2]', 'tests/test_grouping.py::test_returning_kw_ends_where_clause', 'tests/test_grouping.py::test_into_kw_ends_where_clause', 'tests/test_grouping.py::test_grouping_typecast[select foo::integer from bar-integer]', 'tests/test_grouping.py::test_grouping_typecast[select (current_database())::information_schema.sql_identifier-information_schema.sql_identifier]', 'tests/test_grouping.py::test_grouping_alias', 'tests/test_grouping.py::test_grouping_alias_case', 'tests/test_grouping.py::test_grouping_alias_ctas', 'tests/test_grouping.py::test_grouping_subquery_no_parens', 'tests/test_grouping.py::test_grouping_alias_returns_none[foo.bar]', 'tests/test_grouping.py::test_grouping_alias_returns_none[x, y]', 'tests/test_grouping.py::test_grouping_alias_returns_none[x / y]', 'tests/test_grouping.py::test_grouping_idlist_function', 'tests/test_grouping.py::test_grouping_comparison_exclude', 'tests/test_grouping.py::test_grouping_function', 'tests/test_grouping.py::test_grouping_function_not_in', 'tests/test_grouping.py::test_grouping_varchar', 'tests/test_grouping.py::test_statement_get_type', 'tests/test_grouping.py::test_identifier_with_operators', 'tests/test_grouping.py::test_identifier_with_op_trailing_ws', 'tests/test_grouping.py::test_identifier_with_string_literals', 'tests/test_grouping.py::test_identifier_consumes_ordering', 'tests/test_grouping.py::test_comparison_with_keywords', 'tests/test_grouping.py::test_comparison_with_parenthesis', 'tests/test_grouping.py::test_like_and_ilike_comparison', 'tests/test_grouping.py::test_comparison_with_functions', 'tests/test_grouping.py::test_comparison_with_typed_literal', 'tests/test_grouping.py::test_forloops[FOR]', 'tests/test_grouping.py::test_forloops[FOREACH]', 'tests/test_grouping.py::test_nested_for', 'tests/test_grouping.py::test_begin', 'tests/test_grouping.py::test_keyword_followed_by_parenthesis', 'tests/test_grouping.py::test_nested_begin', 'tests/test_grouping.py::test_aliased_column_without_as', 'tests/test_grouping.py::test_qualified_function', 'tests/test_grouping.py::test_aliased_function_without_as', 'tests/test_grouping.py::test_grouping_as_cte', 'tests/test_grouping.py::test_grouping_create_table', 'tests/test_parse.py::test_parse_tokenize', 'tests/test_parse.py::test_parse_multistatement', 'tests/test_parse.py::test_parse_newlines[select\\n*from foo;]', 'tests/test_parse.py::test_parse_newlines[select\\r\\n*from foo]', 'tests/test_parse.py::test_parse_newlines[select\\r*from foo]', 'tests/test_parse.py::test_parse_newlines[select\\r\\n*from foo\\n]', 'tests/test_parse.py::test_parse_within', 'tests/test_parse.py::test_parse_child_of', 'tests/test_parse.py::test_parse_has_ancestor', 'tests/test_parse.py::test_parse_placeholder[select * from foo where user = ?-?]', 'tests/test_parse.py::test_parse_placeholder[select * from foo where user = :1-:1]', 'tests/test_parse.py::test_parse_placeholder[select * from foo where user = :name-:name]', 'tests/test_parse.py::test_parse_placeholder[select * from foo where user = %s-%s]', 'tests/test_parse.py::test_parse_placeholder[select * from foo where user = $a-$a]', 'tests/test_parse.py::test_parse_access_symbol', 'tests/test_parse.py::test_parse_square_brackets_notation_isnt_too_greedy', 'tests/test_parse.py::test_parse_square_brackets_notation_isnt_too_greedy2', 'tests/test_parse.py::test_parse_keyword_like_identifier', 'tests/test_parse.py::test_parse_function_parameter', 'tests/test_parse.py::test_parse_function_param_single_literal', 'tests/test_parse.py::test_parse_nested_function', 'tests/test_parse.py::test_parse_casted_params', 'tests/test_parse.py::test_parse_div_operator', 'tests/test_parse.py::test_quoted_identifier', 'tests/test_parse.py::test_double_precision_is_builtin', 'tests/test_parse.py::test_sqlite_identifiers', 'tests/test_parse.py::test_simple_1d_array_index', 'tests/test_parse.py::test_2d_array_index', 'tests/test_parse.py::test_array_index_function_result', 'tests/test_parse.py::test_schema_qualified_array_index', 'tests/test_parse.py::test_aliased_array_index', 'tests/test_parse.py::test_array_literal', 'tests/test_parse.py::test_typed_array_definition', 'tests/test_parse.py::test_get_token_at_offset', 'tests/test_parse.py::test_pprint', 'tests/test_parse.py::test_wildcard_multiplication', 'tests/test_parse.py::test_stmt_tokens_parents', 'tests/test_parse.py::test_non_ascii', 'tests/test_parse.py::test_get_real_name', 'tests/test_parse.py::test_from_subquery', 'tests/test_parse.py::test_parenthesis', 'tests/test_parse.py::test_configurable_keywords', 'tests/test_parse.py::test_configurable_regex', 'tests/test_parse.py::test_json_operators[->]', 'tests/test_parse.py::test_json_operators[->>]', 'tests/test_parse.py::test_json_operators[#>]', 'tests/test_parse.py::test_json_operators[#>>]', 'tests/test_parse.py::test_json_operators[@>]', 'tests/test_parse.py::test_json_operators[<@]', 'tests/test_parse.py::test_json_operators[||]', 'tests/test_parse.py::test_json_operators[-]', 'tests/test_parse.py::test_json_operators[#-]', 'tests/test_regressions.py::test_issue9', 'tests/test_regressions.py::test_issue13', 'tests/test_regressions.py::test_issue34[create]', 'tests/test_regressions.py::test_issue34[CREATE]', 'tests/test_regressions.py::test_issue35', 'tests/test_regressions.py::test_issue38', 'tests/test_regressions.py::test_issue39', 'tests/test_regressions.py::test_issue40', 'tests/test_regressions.py::test_issue78[get_name-z-select x.y::text as z from foo]', 'tests/test_regressions.py::test_issue78[get_name-z-select x.y::text as ""z"" from foo]', 'tests/test_regressions.py::test_issue78[get_name-z-select x.""y""::text as z from foo]', 'tests/test_regressions.py::test_issue78[get_name-z-select x.""y""::text as ""z"" from foo]', 'tests/test_regressions.py::test_issue78[get_name-z-select ""x"".y::text as z from foo]', 'tests/test_regressions.py::test_issue78[get_name-z-select ""x"".y::text as ""z"" from foo]', 'tests/test_regressions.py::test_issue78[get_name-z-select ""x"".""y""::text as z from foo]', 'tests/test_regressions.py::test_issue78[get_name-z-select ""x"".""y""::text as ""z"" from foo]', 'tests/test_regressions.py::test_issue78[get_real_name-y-select x.y::text as z from foo]', 'tests/test_regressions.py::test_issue78[get_real_name-y-select x.y::text as ""z"" from foo]', 'tests/test_regressions.py::test_issue78[get_real_name-y-select x.""y""::text as z from foo]', 'tests/test_regressions.py::test_issue78[get_real_name-y-select x.""y""::text as ""z"" from foo]', 'tests/test_regressions.py::test_issue78[get_real_name-y-select ""x"".y::text as z from foo]', 'tests/test_regressions.py::test_issue78[get_real_name-y-select ""x"".y::text as ""z"" from foo]', 'tests/test_regressions.py::test_issue78[get_real_name-y-select ""x"".""y""::text as z from foo]', 'tests/test_regressions.py::test_issue78[get_real_name-y-select ""x"".""y""::text as ""z"" from foo]', 'tests/test_regressions.py::test_issue78[get_parent_name-x-select x.y::text as z from foo]', 'tests/test_regressions.py::test_issue78[get_parent_name-x-select x.y::text as ""z"" from foo]', 'tests/test_regressions.py::test_issue78[get_parent_name-x-select x.""y""::text as z from foo]', 'tests/test_regressions.py::test_issue78[get_parent_name-x-select x.""y""::text as ""z"" from foo]', 'tests/test_regressions.py::test_issue78[get_parent_name-x-select ""x"".y::text as z from foo]', 'tests/test_regressions.py::test_issue78[get_parent_name-x-select ""x"".y::text as ""z"" from foo]', 'tests/test_regressions.py::test_issue78[get_parent_name-x-select ""x"".""y""::text as z from foo]', 'tests/test_regressions.py::test_issue78[get_parent_name-x-select ""x"".""y""::text as ""z"" from foo]', 'tests/test_regressions.py::test_issue78[get_alias-z-select x.y::text as z from foo]', 'tests/test_regressions.py::test_issue78[get_alias-z-select x.y::text as ""z"" from foo]', 'tests/test_regressions.py::test_issue78[get_alias-z-select x.""y""::text as z from foo]', 'tests/test_regressions.py::test_issue78[get_alias-z-select x.""y""::text as ""z"" from foo]', 'tests/test_regressions.py::test_issue78[get_alias-z-select ""x"".y::text as z from foo]', 'tests/test_regressions.py::test_issue78[get_alias-z-select ""x"".y::text as ""z"" from foo]', 'tests/test_regressions.py::test_issue78[get_alias-z-select ""x"".""y""::text as z from foo]', 'tests/test_regressions.py::test_issue78[get_alias-z-select ""x"".""y""::text as ""z"" from foo]', 'tests/test_regressions.py::test_issue78[get_typecast-text-select x.y::text as z from foo]', 'tests/test_regressions.py::test_issue78[get_typecast-text-select x.y::text as ""z"" from foo]', 'tests/test_regressions.py::test_issue78[get_typecast-text-select x.""y""::text as z from foo]', 'tests/test_regressions.py::test_issue78[get_typecast-text-select x.""y""::text as ""z"" from foo]', 'tests/test_regressions.py::test_issue78[get_typecast-text-select ""x"".y::text as z from foo]', 'tests/test_regressions.py::test_issue78[get_typecast-text-select ""x"".y::text as ""z"" from foo]', 'tests/test_regressions.py::test_issue78[get_typecast-text-select ""x"".""y""::text as z from foo]', 'tests/test_regressions.py::test_issue78[get_typecast-text-select ""x"".""y""::text as ""z"" from foo]', 'tests/test_regressions.py::test_comment_encoding_when_reindent', 'tests/test_regressions.py::test_parse_sql_with_binary', 'tests/test_regressions.py::test_dont_alias_keywords', 'tests/test_regressions.py::test_format_accepts_encoding', 'tests/test_regressions.py::test_stream', 'tests/test_regressions.py::test_issue90', 'tests/test_regressions.py::test_except_formatting', 'tests/test_regressions.py::test_null_with_as', 'tests/test_regressions.py::test_issue190_open_file', 'tests/test_regressions.py::test_issue186_get_type', 'tests/test_regressions.py::test_issue213_leadingws', 'tests/test_regressions.py::test_issue227_gettype_cte', 'tests/test_regressions.py::test_issue207_runaway_format', 'tests/test_regressions.py::test_issue284_as_grouping[SELECT x AS]', 'tests/test_regressions.py::test_issue284_as_grouping[AS]', 'tests/test_regressions.py::test_issue315_utf8_by_default', 'tests/test_regressions.py::test_issue322_concurrently_is_keyword', 'tests/test_regressions.py::test_issue359_index_error_assignments[SELECT @min_price:=MIN(price), @max_price:=MAX(price) FROM shop;]', 'tests/test_regressions.py::test_issue359_index_error_assignments[SELECT @min_price:=MIN(price), @max_price:=MAX(price) FROM shop]', 'tests/test_regressions.py::test_issue489_tzcasts', 'tests/test_regressions.py::test_issue562_tzcasts', 'tests/test_regressions.py::test_as_in_parentheses_indents', 'tests/test_regressions.py::test_format_invalid_where_clause', 'tests/test_regressions.py::test_comment_between_cte_clauses_issue632', 'tests/test_regressions.py::test_copy_issue672', 'tests/test_regressions.py::test_primary_key_issue740', 'tests/test_regressions.py::test_max_recursion', 'tests/test_split.py::test_split_semicolon', 'tests/test_split.py::test_split_backslash', 'tests/test_split.py::test_split_create_function[function.sql]', 'tests/test_split.py::test_split_create_function[function_psql.sql]', 'tests/test_split.py::test_split_create_function[function_psql2.sql]', 'tests/test_split.py::test_split_create_function[function_psql3.sql]', 'tests/test_split.py::test_split_create_function[function_psql4.sql]', 'tests/test_split.py::test_split_dashcomments', 'tests/test_split.py::test_split_dashcomments_eol[select foo; -- comment\\n]', 'tests/test_split.py::test_split_dashcomments_eol[select foo; -- comment\\r]', 'tests/test_split.py::test_split_dashcomments_eol[select foo; -- comment\\r\\n]', 'tests/test_split.py::test_split_dashcomments_eol[select foo; -- comment]', 'tests/test_split.py::test_split_begintag', 'tests/test_split.py::test_split_begintag_2', 'tests/test_split.py::test_split_dropif', 'tests/test_split.py::test_split_comment_with_umlaut', 'tests/test_split.py::test_split_comment_end_of_line', 'tests/test_split.py::test_split_stream', 'tests/test_split.py::test_split_encoding_parsestream', 'tests/test_tokenize.py::test_tokenlist_repr', 'tests/test_tokenize.py::test_parse_join[JOIN]', 'tests/test_tokenize.py::test_parse_join[LEFT JOIN]', 'tests/test_tokenize.py::test_parse_join[LEFT OUTER JOIN]', 'tests/test_tokenize.py::test_parse_join[FULL OUTER JOIN]', 'tests/test_tokenize.py::test_parse_join[NATURAL JOIN]', 'tests/test_tokenize.py::test_parse_join[CROSS JOIN]', 'tests/test_tokenize.py::test_parse_join[STRAIGHT JOIN]', 'tests/test_tokenize.py::test_parse_join[INNER JOIN]', 'tests/test_tokenize.py::test_parse_join[LEFT INNER JOIN]', 'tests/test_tokenize.py::test_parse_union', 'tests/test_tokenize.py::test_parse_endifloop[END IF]', 'tests/test_tokenize.py::test_parse_endifloop[END   IF]', 'tests/test_tokenize.py::test_parse_endifloop[END\\t\\nIF]', 'tests/test_tokenize.py::test_parse_endifloop[END LOOP]', 'tests/test_tokenize.py::test_parse_endifloop[END   LOOP]', 'tests/test_tokenize.py::test_parse_endifloop[END\\t\\nLOOP]', 'tests/test_tokenize.py::test_parse_group_by', 'tests/test_tokenize.py::test_parse_order_by', 'tests/test_tokenize.py::test_parse_window_as']","[""filepath = <function filepath.<locals>.make_filepath at 0x000001DF6165E700>\n\n    def test_valid_args(filepath):\n        # test doesn't abort\n        path = filepath('function.sql')\n>       assert sqlparse.cli.main([path, '-r']) is not None\n\nrepos\\sqlparse\\tests\\test_cli.py:30: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\cli.py:198: in main\n    s = sqlparse.format(data, **formatter_opts)\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return ''.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation '(' at 0x1DF615F5AE0>, ttype = Token.Punctuation\nvalues = '[', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""self = <tests.test_format.TestFormat object at 0x000001DF612FB790>\n\n    def test_strip_comments_single(self):\n        sql = 'select *-- statement starts here\\nfrom foo'\n>       res = sqlparse.format(sql, strip_comments=True)\n\nrepos\\sqlparse\\tests\\test_format.py:43: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return ''.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:61: in group_case\n    _group_matching(tlist, sql.Case)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Keyword 'from' at 0x1DF617EB400>, ttype = Token.Keyword, values = 'CASE'\nregex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""self = <tests.test_format.TestFormat object at 0x000001DF61498A50>\n\n    def test_strip_comments_multi(self):\n        sql = '/* sql starts here */\\nselect'\n        res = sqlparse.format(sql, strip_comments=True)\n        assert res == 'select'\n        sql = '/* sql starts here */ select'\n        res = sqlparse.format(sql, strip_comments=True)\n        assert res == ' select'  # note whitespace is preserved, see issue 772\n        sql = '/*\\n * sql starts here\\n */\\nselect'\n        res = sqlparse.format(sql, strip_comments=True)\n        assert res == 'select'\n        sql = 'select (/* sql starts here */ select 2)'\n>       res = sqlparse.format(sql, strip_comments=True, strip_whitespace=True)\n\nrepos\\sqlparse\\tests\\test_format.py:81: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return ''.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation '(' at 0x1DF617C3D60>, ttype = Token.Punctuation\nvalues = '[', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""self = <tests.test_format.TestFormat object at 0x000001DF61498B50>\n\n    def test_strip_comments_preserves_linebreak(self):\n        sql = 'select * -- a comment\\r\\nfrom foo'\n>       res = sqlparse.format(sql, strip_comments=True)\n\nrepos\\sqlparse\\tests\\test_format.py:89: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return ''.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:61: in group_case\n    _group_matching(tlist, sql.Case)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Keyword 'from' at 0x1DF617E9060>, ttype = Token.Keyword, values = 'CASE'\nregex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""self = <tests.test_format.TestFormat object at 0x000001DF613D6300>\n\n    def test_strip_comments_preserves_whitespace(self):\n        sql = 'SELECT 1/*bar*/ AS foo'  # see issue772\n>       res = sqlparse.format(sql, strip_comments=True)\n\nrepos\\sqlparse\\tests\\test_format.py:106: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return ''.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:61: in group_case\n    _group_matching(tlist, sql.Case)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Keyword 'AS' at 0x1DF615F67A0>, ttype = Token.Keyword, values = 'CASE'\nregex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""self = <tests.test_format.TestFormat object at 0x000001DF613D64E0>\n\n    def test_strip_comments_preserves_hint(self):\n        sql = 'select --+full(u)'\n        res = sqlparse.format(sql, strip_comments=True)\n        assert res == sql\n        sql = '#+ hint\\nselect * from foo'\n>       res = sqlparse.format(sql, strip_comments=True)\n\nrepos\\sqlparse\\tests\\test_format.py:114: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return ''.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:61: in group_case\n    _group_matching(tlist, sql.Case)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Keyword 'from' at 0x1DF615F76A0>, ttype = Token.Keyword, values = 'CASE'\nregex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""self = <tests.test_format.TestFormat object at 0x000001DF614B4910>\n\n    def test_strip_ws(self):\n        f = lambda sql: sqlparse.format(sql, strip_whitespace=True)\n        s = 'select\\n* from      foo\\n\\twhere  ( 1 = 2 )\\n'\n>       assert f(s) == 'select * from foo where (1 = 2)'\n\nrepos\\sqlparse\\tests\\test_format.py:132: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:130: in <lambda>\n    f = lambda sql: sqlparse.format(sql, strip_whitespace=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return ''.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation '(' at 0x1DF617E8280>, ttype = Token.Punctuation\nvalues = '[', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""self = <tests.test_format.TestFormat object at 0x000001DF61469640>\n\n    def test_preserve_ws(self):\n        # preserve at least one whitespace after subgroups\n        f = lambda sql: sqlparse.format(sql, strip_whitespace=True)\n        s = 'select\\n* /* foo */  from bar '\n>       assert f(s) == 'select * /* foo */ from bar'\n\nrepos\\sqlparse\\tests\\test_format.py:145: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:143: in <lambda>\n    f = lambda sql: sqlparse.format(sql, strip_whitespace=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return ''.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:61: in group_case\n    _group_matching(tlist, sql.Case)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Keyword 'from' at 0x1DF617E88E0>, ttype = Token.Keyword, values = 'CASE'\nregex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", 'self = <tests.test_format.TestFormatReindentAligned object at 0x000001DF6131A350>\n\n    def test_basic(self):\n        sql = """"""\n            select a, b as bb,c from table\n            join (select a * 2 as a from new_table) other\n            on table.a = other.a\n            where c is true\n            and b between 3 and 4\n            or d is \'blue\'\n            limit 10\n            """"""\n    \n>       assert self.formatter(sql) == \'\\n\'.join([\n            \'select a,\',\n            \'       b as bb,\',\n            \'       c\',\n            \'  from table\',\n            \'  join (\',\n            \'        select a * 2 as a\',\n            \'          from new_table\',\n            \'       ) other\',\n            \'    on table.a = other.a\',\n            \' where c is true\',\n            \'   and b between 3 and 4\',\n            ""    or d is \'blue\'"",\n            \' limit 10\'])\n\nrepos\\sqlparse\\tests\\test_format.py:182: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:169: in formatter\n    return sqlparse.format(sql, reindent_aligned=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return \'\'.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation \',\' at 0x1DF615F7700>, ttype = Token.Punctuation\nvalues = \'[\', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = \'|\'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: \'Token\' object has no attribute \'token\'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError', 'self = <tests.test_format.TestFormatReindentAligned object at 0x000001DF6131A990>\n\n    def test_joins(self):\n        sql = """"""\n            select * from a\n            join b on a.one = b.one\n            left join c on c.two = a.two and c.three = a.three\n            full outer join d on d.three = a.three\n            cross join e on e.four = a.four\n            join f using (one, two, three)\n            """"""\n>       assert self.formatter(sql) == \'\\n\'.join([\n            \'select *\',\n            \'  from a\',\n            \'  join b\',\n            \'    on a.one = b.one\',\n            \'  left join c\',\n            \'    on c.two = a.two\',\n            \'   and c.three = a.three\',\n            \'  full outer join d\',\n            \'    on d.three = a.three\',\n            \' cross join e\',\n            \'    on e.four = a.four\',\n            \'  join f using (one, two, three)\'])\n\nrepos\\sqlparse\\tests\\test_format.py:206: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:169: in formatter\n    return sqlparse.format(sql, reindent_aligned=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return \'\'.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation \'.\' at 0x1DF61787040>, ttype = Token.Punctuation\nvalues = \'[\', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = \'|\'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: \'Token\' object has no attribute \'token\'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError', 'self = <tests.test_format.TestFormatReindentAligned object at 0x000001DF614B0050>\n\n    def test_case_statement(self):\n        sql = """"""\n            select a,\n            case when a = 0\n            then 1\n            when bb = 1 then 1\n            when c = 2 then 2\n            else 0 end as d,\n            extra_col\n            from table\n            where c is true\n            and b between 3 and 4\n            """"""\n>       assert self.formatter(sql) == \'\\n\'.join([\n            \'select a,\',\n            \'       case when a = 0  then 1\',\n            \'            when bb = 1 then 1\',\n            \'            when c = 2  then 2\',\n            \'            else 0\',\n            \'             end as d,\',\n            \'       extra_col\',\n            \'  from table\',\n            \' where c is true\',\n            \'   and b between 3 and 4\'])\n\nrepos\\sqlparse\\tests\\test_format.py:233: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:169: in formatter\n    return sqlparse.format(sql, reindent_aligned=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return \'\'.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation \',\' at 0x1DF6177A020>, ttype = Token.Punctuation\nvalues = \'[\', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = \'|\'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: \'Token\' object has no attribute \'token\'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError', 'self = <tests.test_format.TestFormatReindentAligned object at 0x000001DF614B0180>\n\n    def test_case_statement_with_between(self):\n        sql = """"""\n            select a,\n            case when a = 0\n            then 1\n            when bb = 1 then 1\n            when c = 2 then 2\n            when d between 3 and 5 then 3\n            else 0 end as d,\n            extra_col\n            from table\n            where c is true\n            and b between 3 and 4\n            """"""\n>       assert self.formatter(sql) == \'\\n\'.join([\n            \'select a,\',\n            \'       case when a = 0             then 1\',\n            \'            when bb = 1            then 1\',\n            \'            when c = 2             then 2\',\n            \'            when d between 3 and 5 then 3\',\n            \'            else 0\',\n            \'             end as d,\',\n            \'       extra_col\',\n            \'  from table\',\n            \' where c is true\',\n            \'   and b between 3 and 4\'])\n\nrepos\\sqlparse\\tests\\test_format.py:259: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:169: in formatter\n    return sqlparse.format(sql, reindent_aligned=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return \'\'.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation \',\' at 0x1DF617ABD60>, ttype = Token.Punctuation\nvalues = \'[\', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = \'|\'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: \'Token\' object has no attribute \'token\'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError', 'self = <tests.test_format.TestFormatReindentAligned object at 0x000001DF614AE7B0>\n\n    def test_group_by(self):\n        sql = """"""\n            select a, b, c, sum(x) as sum_x, count(y) as cnt_y\n            from table\n            group by a,b,c\n            having sum(x) > 1\n            and count(y) > 5\n            order by 3,2,1\n            """"""\n>       assert self.formatter(sql) == \'\\n\'.join([\n            \'select a,\',\n            \'       b,\',\n            \'       c,\',\n            \'       sum(x) as sum_x,\',\n            \'       count(y) as cnt_y\',\n            \'  from table\',\n            \' group by a,\',\n            \'          b,\',\n            \'          c\',\n            \'having sum(x) > 1\',\n            \'   and count(y) > 5\',\n            \' order by 3,\',\n            \'          2,\',\n            \'          1\'])\n\nrepos\\sqlparse\\tests\\test_format.py:281: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:169: in formatter\n    return sqlparse.format(sql, reindent_aligned=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return \'\'.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation \',\' at 0x1DF617A8940>, ttype = Token.Punctuation\nvalues = \'[\', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = \'|\'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: \'Token\' object has no attribute \'token\'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError', 'self = <tests.test_format.TestFormatReindentAligned object at 0x000001DF612FBBD0>\n\n    def test_group_by_subquery(self):\n        # TODO: add subquery alias when test_identifier_list_subquery fixed\n        sql = """"""\n            select *, sum_b + 2 as mod_sum\n            from (\n              select a, sum(b) as sum_b\n              from table\n              group by a,z)\n            order by 1,2\n            """"""\n>       assert self.formatter(sql) == \'\\n\'.join([\n            \'select *,\',\n            \'       sum_b + 2 as mod_sum\',\n            \'  from (\',\n            \'        select a,\',\n            \'               sum(b) as sum_b\',\n            \'          from table\',\n            \'         group by a,\',\n            \'                  z\',\n            \'       )\',\n            \' order by 1,\',\n            \'          2\'])\n\nrepos\\sqlparse\\tests\\test_format.py:307: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:169: in formatter\n    return sqlparse.format(sql, reindent_aligned=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return \'\'.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation \',\' at 0x1DF6177A860>, ttype = Token.Punctuation\nvalues = \'[\', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = \'|\'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: \'Token\' object has no attribute \'token\'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError', 'self = <tests.test_format.TestFormatReindentAligned object at 0x000001DF612FBDF0>\n\n    def test_window_functions(self):\n        sql = """"""\n            select a,\n            SUM(a) OVER (PARTITION BY b ORDER BY c ROWS\n            BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) as sum_a,\n            ROW_NUMBER() OVER\n            (PARTITION BY b, c ORDER BY d DESC) as row_num\n            from table""""""\n>       assert self.formatter(sql) == \'\\n\'.join([\n            \'select a,\',\n            \'       SUM(a) OVER (PARTITION BY b ORDER BY c ROWS \'\n            \'BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) as sum_a,\',\n            \'       ROW_NUMBER() OVER \'\n            \'(PARTITION BY b, c ORDER BY d DESC) as row_num\',\n            \'  from table\'])\n\nrepos\\sqlparse\\tests\\test_format.py:328: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:169: in formatter\n    return sqlparse.format(sql, reindent_aligned=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return \'\'.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation \',\' at 0x1DF6175DAE0>, ttype = Token.Punctuation\nvalues = \'[\', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = \'|\'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: \'Token\' object has no attribute \'token\'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError', ""self = <tests.test_format.TestSpacesAroundOperators object at 0x000001DF6131AAD0>\n\n    def test_basic(self):\n        sql = ('select a+b as d from table '\n               'where (c-d)%2= 1 and e> 3.0/4 and z^2 <100')\n>       assert self.formatter(sql) == (\n            'select a + b as d from table '\n            'where (c - d) % 2 = 1 and e > 3.0 / 4 and z ^ 2 < 100')\n\nrepos\\sqlparse\\tests\\test_format.py:345: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:340: in formatter\n    return sqlparse.format(sql, use_space_around_operators=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return ''.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation '(' at 0x1DF615F7D00>, ttype = Token.Punctuation\nvalues = '[', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""self = <tests.test_format.TestSpacesAroundOperators object at 0x000001DF6131AC10>\n\n    def test_bools(self):\n        sql = 'select * from table where a &&b or c||d'\n>       assert self.formatter(\n            sql) == 'select * from table where a && b or c || d'\n\nrepos\\sqlparse\\tests\\test_format.py:351: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:340: in formatter\n    return sqlparse.format(sql, use_space_around_operators=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return ''.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:61: in group_case\n    _group_matching(tlist, sql.Case)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Keyword 'from' at 0x1DF617845E0>, ttype = Token.Keyword, values = 'CASE'\nregex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""self = <tests.test_format.TestSpacesAroundOperators object at 0x000001DF614B02B0>\n\n    def test_nested(self):\n        sql = 'select *, case when a-b then c end from table'\n>       assert self.formatter(\n            sql) == 'select *, case when a - b then c end from table'\n\nrepos\\sqlparse\\tests\\test_format.py:356: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:340: in formatter\n    return sqlparse.format(sql, use_space_around_operators=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return ''.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation ',' at 0x1DF61786560>, ttype = Token.Punctuation\nvalues = '[', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""self = <tests.test_format.TestSpacesAroundOperators object at 0x000001DF614B03E0>\n\n    def test_wildcard_vs_mult(self):\n        sql = 'select a*b-c from table'\n>       assert self.formatter(sql) == 'select a * b - c from table'\n\nrepos\\sqlparse\\tests\\test_format.py:361: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:340: in formatter\n    return sqlparse.format(sql, use_space_around_operators=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return ''.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:61: in group_case\n    _group_matching(tlist, sql.Case)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Keyword 'from' at 0x1DF61787940>, ttype = Token.Keyword, values = 'CASE'\nregex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""self = <tests.test_format.TestFormatReindent object at 0x000001DF6131AE90>\n\n    def test_stmts(self):\n        f = lambda sql: sqlparse.format(sql, reindent=True)\n        s = 'select foo; select bar'\n>       assert f(s) == 'select foo;\\n\\nselect bar'\n\nrepos\\sqlparse\\tests\\test_format.py:384: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:382: in <lambda>\n    f = lambda sql: sqlparse.format(sql, reindent=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return ''.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation ';' at 0x1DF61784BE0>, ttype = Token.Punctuation\nvalues = '[', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""self = <tests.test_format.TestFormatReindent object at 0x000001DF614B0510>\n\n    def test_keywords(self):\n        f = lambda sql: sqlparse.format(sql, reindent=True)\n        s = 'select * from foo union select * from bar;'\n>       assert f(s) == '\\n'.join([\n            'select *',\n            'from foo',\n            'union',\n            'select *',\n            'from bar;'])\n\nrepos\\sqlparse\\tests\\test_format.py:393: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:391: in <lambda>\n    f = lambda sql: sqlparse.format(sql, reindent=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return ''.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation ';' at 0x1DF617D2F80>, ttype = Token.Punctuation\nvalues = '[', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""self = <tests.test_format.TestFormatReindent object at 0x000001DF614B0640>\n\n    def test_keywords_between(self):\n        # issue 14\n        # don't break AND after BETWEEN\n        f = lambda sql: sqlparse.format(sql, reindent=True)\n        s = 'and foo between 1 and 2 and bar = 3'\n>       assert f(s) == '\\n'.join([\n            '',\n            'and foo between 1 and 2',\n            'and bar = 3'])\n\nrepos\\sqlparse\\tests\\test_format.py:405: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:403: in <lambda>\n    f = lambda sql: sqlparse.format(sql, reindent=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return ''.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:61: in group_case\n    _group_matching(tlist, sql.Case)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Keyword 'and' at 0x1DF617EAF20>, ttype = Token.Keyword, values = 'CASE'\nregex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""self = <tests.test_format.TestFormatReindent object at 0x000001DF614D4290>\n\n    def test_parenthesis(self):\n        f = lambda sql: sqlparse.format(sql, reindent=True)\n        s = 'select count(*) from (select * from foo);'\n>       assert f(s) == '\\n'.join([\n            'select count(*)',\n            'from',\n            '  (select *',\n            '   from foo);'])\n\nrepos\\sqlparse\\tests\\test_format.py:413: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:411: in <lambda>\n    f = lambda sql: sqlparse.format(sql, reindent=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return ''.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation '(' at 0x1DF61786BC0>, ttype = Token.Punctuation\nvalues = '[', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""self = <tests.test_format.TestFormatReindent object at 0x000001DF612FBF00>\n\n    def test_where(self):\n        f = lambda sql: sqlparse.format(sql, reindent=True)\n        s = 'select * from foo where bar = 1 and baz = 2 or bzz = 3;'\n>       assert f(s) == '\\n'.join([\n            'select *',\n            'from foo',\n            'where bar = 1',\n            '  and baz = 2',\n            '  or bzz = 3;'])\n\nrepos\\sqlparse\\tests\\test_format.py:427: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:425: in <lambda>\n    f = lambda sql: sqlparse.format(sql, reindent=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return ''.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation ';' at 0x1DF6177B9A0>, ttype = Token.Punctuation\nvalues = '[', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""self = <tests.test_format.TestFormatReindent object at 0x000001DF614D8050>\n\n    def test_join(self):\n        f = lambda sql: sqlparse.format(sql, reindent=True)\n        s = 'select * from foo join bar on 1 = 2'\n>       assert f(s) == '\\n'.join([\n            'select *',\n            'from foo',\n            'join bar on 1 = 2'])\n\nrepos\\sqlparse\\tests\\test_format.py:445: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:443: in <lambda>\n    f = lambda sql: sqlparse.format(sql, reindent=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return ''.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:61: in group_case\n    _group_matching(tlist, sql.Case)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Keyword 'from' at 0x1DF6177B880>, ttype = Token.Keyword, values = 'CASE'\nregex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""self = <tests.test_format.TestFormatReindent object at 0x000001DF61498C50>\n\n    def test_identifier_list(self):\n        f = lambda sql: sqlparse.format(sql, reindent=True)\n        s = 'select foo, bar, baz from table1, table2 where 1 = 2'\n>       assert f(s) == '\\n'.join([\n            'select foo,',\n            '       bar,',\n            '       baz',\n            'from table1,',\n            '     table2',\n            'where 1 = 2'])\n\nrepos\\sqlparse\\tests\\test_format.py:468: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:466: in <lambda>\n    f = lambda sql: sqlparse.format(sql, reindent=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return ''.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation ',' at 0x1DF61779060>, ttype = Token.Punctuation\nvalues = '[', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""self = <tests.test_format.TestFormatReindent object at 0x000001DF61498D50>\n\n    def test_identifier_list_with_wrap_after(self):\n        f = lambda sql: sqlparse.format(sql, reindent=True, wrap_after=14)\n        s = 'select foo, bar, baz from table1, table2 where 1 = 2'\n>       assert f(s) == '\\n'.join([\n            'select foo, bar,',\n            '       baz',\n            'from table1, table2',\n            'where 1 = 2'])\n\nrepos\\sqlparse\\tests\\test_format.py:485: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:483: in <lambda>\n    f = lambda sql: sqlparse.format(sql, reindent=True, wrap_after=14)\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return ''.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation ',' at 0x1DF617EAB60>, ttype = Token.Punctuation\nvalues = '[', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""self = <tests.test_format.TestFormatReindent object at 0x000001DF613D65D0>\n\n    def test_identifier_list_comment_first(self):\n        f = lambda sql: sqlparse.format(sql, reindent=True, comma_first=True)\n        # not the 3: It cleans up whitespace too!\n        s = 'select foo, bar, baz from table where foo in (1, 2,3)'\n>       assert f(s) == '\\n'.join([\n            'select foo',\n            '     , bar',\n            '     , baz',\n            'from table',\n            'where foo in (1',\n            '            , 2',\n            '            , 3)'])\n\nrepos\\sqlparse\\tests\\test_format.py:495: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:492: in <lambda>\n    f = lambda sql: sqlparse.format(sql, reindent=True, comma_first=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return ''.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation ',' at 0x1DF617AAB60>, ttype = Token.Punctuation\nvalues = '[', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", 'self = <tests.test_format.TestFormatReindent object at 0x000001DF613D66C0>\n\n    def test_identifier_list_with_functions(self):\n        f = lambda sql: sqlparse.format(sql, reindent=True)\n        s = (""select \'abc\' as foo, coalesce(col1, col2)||col3 as bar,""\n             ""col3 from my_table"")\n>       assert f(s) == \'\\n\'.join([\n            ""select \'abc\' as foo,"",\n            ""       coalesce(col1, col2)||col3 as bar,"",\n            ""       col3"",\n            ""from my_table""])\n\nrepos\\sqlparse\\tests\\test_format.py:508: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:505: in <lambda>\n    f = lambda sql: sqlparse.format(sql, reindent=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return \'\'.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation \',\' at 0x1DF617A98A0>, ttype = Token.Punctuation\nvalues = \'[\', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = \'|\'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: \'Token\' object has no attribute \'token\'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError', 'self = <tests.test_format.TestFormatReindent object at 0x000001DF6141F930>\n\n    def test_long_identifier_list_with_functions(self):\n        f = lambda sql: sqlparse.format(sql, reindent=True, wrap_after=30)\n        s = (""select \'abc\' as foo, json_build_object(\'a\',  a,""\n             ""\'b\', b, \'c\', c, \'d\', d, \'e\', e) as col2""\n             ""col3 from my_table"")\n>       assert f(s) == \'\\n\'.join([\n            ""select \'abc\' as foo,"",\n            ""       json_build_object(\'a\',"",\n            ""         a, \'b\', b, \'c\', c, \'d\', d,"",\n            ""         \'e\', e) as col2col3"",\n            ""from my_table""])\n\nrepos\\sqlparse\\tests\\test_format.py:519: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:515: in <lambda>\n    f = lambda sql: sqlparse.format(sql, reindent=True, wrap_after=30)\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return \'\'.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation \',\' at 0x1DF617E83A0>, ttype = Token.Punctuation\nvalues = \'[\', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = \'|\'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: \'Token\' object has no attribute \'token\'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError', ""self = <tests.test_format.TestFormatReindent object at 0x000001DF6141F850>\n\n    def test_case(self):\n        f = lambda sql: sqlparse.format(sql, reindent=True)\n        s = 'case when foo = 1 then 2 when foo = 3 then 4 else 5 end'\n>       assert f(s) == '\\n'.join([\n            'case',\n            '    when foo = 1 then 2',\n            '    when foo = 3 then 4',\n            '    else 5',\n            'end'])\n\nrepos\\sqlparse\\tests\\test_format.py:529: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:527: in <lambda>\n    f = lambda sql: sqlparse.format(sql, reindent=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return ''.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:61: in group_case\n    _group_matching(tlist, sql.Case)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Keyword 'case' at 0x1DF61767A60>, ttype = Token.Keyword, values = 'CASE'\nregex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""self = <tests.test_format.TestFormatReindent object at 0x000001DF6146A0D0>\n\n    def test_case2(self):\n        f = lambda sql: sqlparse.format(sql, reindent=True)\n        s = 'case(foo) when bar = 1 then 2 else 3 end'\n>       assert f(s) == '\\n'.join([\n            'case(foo)',\n            '    when bar = 1 then 2',\n            '    else 3',\n            'end'])\n\nrepos\\sqlparse\\tests\\test_format.py:539: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:537: in <lambda>\n    f = lambda sql: sqlparse.format(sql, reindent=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return ''.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation '(' at 0x1DF61765AE0>, ttype = Token.Punctuation\nvalues = '[', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""self = <tests.test_format.TestFormatReindent object at 0x000001DF612C7410>\n\n    def test_nested_identifier_list(self):\n        # issue4\n        f = lambda sql: sqlparse.format(sql, reindent=True)\n        s = '(foo as bar, bar1, bar2 as bar3, b4 as b5)'\n>       assert f(s) == '\\n'.join([\n            '(foo as bar,',\n            ' bar1,',\n            ' bar2 as bar3,',\n            ' b4 as b5)'])\n\nrepos\\sqlparse\\tests\\test_format.py:549: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:547: in <lambda>\n    f = lambda sql: sqlparse.format(sql, reindent=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return ''.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation '(' at 0x1DF61766800>, ttype = Token.Punctuation\nvalues = '[', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""self = <tests.test_format.TestFormatReindent object at 0x000001DF612C7E90>\n\n    def test_duplicate_linebreaks(self):\n        # issue3\n        f = lambda sql: sqlparse.format(sql, reindent=True)\n        s = 'select c1 -- column1\\nfrom foo'\n>       assert f(s) == '\\n'.join([\n            'select c1 -- column1',\n            'from foo'])\n\nrepos\\sqlparse\\tests\\test_format.py:559: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:557: in <lambda>\n    f = lambda sql: sqlparse.format(sql, reindent=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return ''.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:61: in group_case\n    _group_matching(tlist, sql.Case)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Keyword 'from' at 0x1DF61779E40>, ttype = Token.Keyword, values = 'CASE'\nregex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""self = <tests.test_format.TestFormatReindent object at 0x000001DF613C9910>\n\n    def test_keywordfunctions(self):\n        # issue36\n        f = lambda sql: sqlparse.format(sql, reindent=True)\n        s = 'select max(a) b, foo, bar'\n>       assert f(s) == '\\n'.join([\n            'select max(a) b,',\n            '       foo,',\n            '       bar'])\n\nrepos\\sqlparse\\tests\\test_format.py:583: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:581: in <lambda>\n    f = lambda sql: sqlparse.format(sql, reindent=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return ''.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation '(' at 0x1DF617AAB00>, ttype = Token.Punctuation\nvalues = '[', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""self = <tests.test_format.TestFormatReindent object at 0x000001DF613C99C0>\n\n    def test_identifier_and_functions(self):\n        # issue45\n        f = lambda sql: sqlparse.format(sql, reindent=True)\n        s = 'select foo.bar, nvl(1) from dual'\n>       assert f(s) == '\\n'.join([\n            'select foo.bar,',\n            '       nvl(1)',\n            'from dual'])\n\nrepos\\sqlparse\\tests\\test_format.py:592: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:590: in <lambda>\n    f = lambda sql: sqlparse.format(sql, reindent=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return ''.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation '.' at 0x1DF61808F40>, ttype = Token.Punctuation\nvalues = '[', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""self = <tests.test_format.TestFormatReindent object at 0x000001DF6149EAD0>\n\n    def test_insert_values(self):\n        # issue 329\n        f = lambda sql: sqlparse.format(sql, reindent=True)\n        s = 'insert into foo values (1, 2)'\n>       assert f(s) == '\\n'.join([\n            'insert into foo',\n            'values (1, 2)'])\n\nrepos\\sqlparse\\tests\\test_format.py:601: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:599: in <lambda>\n    f = lambda sql: sqlparse.format(sql, reindent=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return ''.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation '(' at 0x1DF6177A140>, ttype = Token.Punctuation\nvalues = '[', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", 'self = <tests.test_format.TestOutputFormat object at 0x000001DF6131AFD0>\n\n    def test_python(self):\n        sql = \'select * from foo;\'\n        f = lambda sql: sqlparse.format(sql, output_format=\'python\')\n        assert f(sql) == ""sql = \'select * from foo;\'""\n        f = lambda sql: sqlparse.format(sql, output_format=\'python\',\n                                        reindent=True)\n>       assert f(sql) == \'\\n\'.join([\n            ""sql = (\'select * \'"",\n            ""       \'from foo;\')""])\n\nrepos\\sqlparse\\tests\\test_format.py:648: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:646: in <lambda>\n    f = lambda sql: sqlparse.format(sql, output_format=\'python\',\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return \'\'.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation \';\' at 0x1DF61765780>, ttype = Token.Punctuation\nvalues = \'[\', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = \'|\'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: \'Token\' object has no attribute \'token\'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError', 'self = <tests.test_format.TestOutputFormat object at 0x000001DF614B08A0>\n\n    def test_php(self):\n        sql = \'select * from foo;\'\n        f = lambda sql: sqlparse.format(sql, output_format=\'php\')\n        assert f(sql) == \'$sql = ""select * from foo;"";\'\n        f = lambda sql: sqlparse.format(sql, output_format=\'php\',\n                                        reindent=True)\n>       assert f(sql) == \'\\n\'.join([\n            \'$sql  = ""select * "";\',\n            \'$sql .= ""from foo;"";\'])\n\nrepos\\sqlparse\\tests\\test_format.py:676: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:674: in <lambda>\n    f = lambda sql: sqlparse.format(sql, output_format=\'php\',\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return \'\'.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation \';\' at 0x1DF61808B20>, ttype = Token.Punctuation\nvalues = \'[\', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = \'|\'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: \'Token\' object has no attribute \'token\'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError', ""def test_format_column_ordering():\n        # issue89\n        sql = 'select * from foo order by c1 desc, c2, c3;'\n>       formatted = sqlparse.format(sql, reindent=True)\n\nrepos\\sqlparse\\tests\\test_format.py:695: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return ''.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation ',' at 0x1DF618097E0>, ttype = Token.Punctuation\nvalues = '[', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""def test_having_produces_newline():\n        sql = ('select * from foo, bar where bar.id = foo.bar_id '\n               'having sum(bar.value) > 100')\n>       formatted = sqlparse.format(sql, reindent=True)\n\nrepos\\sqlparse\\tests\\test_format.py:730: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return ''.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation ',' at 0x1DF61807640>, ttype = Token.Punctuation\nvalues = '[', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", 'def test_format_json_ops():  # issue542\n>       formatted = sqlparse.format(\n            ""select foo->\'bar\', foo->\'bar\';"", reindent=True)\n\nrepos\\sqlparse\\tests\\test_format.py:753: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return \'\'.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation \',\' at 0x1DF618051E0>, ttype = Token.Punctuation\nvalues = \'[\', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = \'|\'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: \'Token\' object has no attribute \'token\'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError', ""sql = 'case when foo then 1 else bar end'\nexpected_normal = 'case\\n    when foo then 1\\n    else bar\\nend'\nexpected_compact = 'case when foo then 1 else bar end'\n\n    @pytest.mark.parametrize('sql, expected_normal, expected_compact', [\n        ('case when foo then 1 else bar end',\n         'case\\n    when foo then 1\\n    else bar\\nend',\n         'case when foo then 1 else bar end')])\n    def test_compact(sql, expected_normal, expected_compact):  # issue783\n>       formatted_normal = sqlparse.format(sql, reindent=True)\n\nrepos\\sqlparse\\tests\\test_format.py:764: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return ''.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:61: in group_case\n    _group_matching(tlist, sql.Case)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Keyword 'case' at 0x1DF618061A0>, ttype = Token.Keyword, values = 'CASE'\nregex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""def test_strip_ws_removes_trailing_ws_in_groups():  # issue782\n>       formatted = sqlparse.format('( where foo = bar  ) from',\n                                    strip_whitespace=True)\n\nrepos\\sqlparse\\tests\\test_format.py:771: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return ''.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation '(' at 0x1DF61806B60>, ttype = Token.Punctuation\nvalues = '[', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""def test_grouping_parenthesis():\n        s = 'select (select (x3) x2) and (y2) bar'\n>       parsed = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:9: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation '(' at 0x1DF61804B20>, ttype = Token.Punctuation\nvalues = '[', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""s = 'foo := 1;'\n\n    @pytest.mark.parametrize('s', ['foo := 1;', 'foo := 1'])\n    def test_grouping_assignment(s):\n>       parsed = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:22: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation ';' at 0x1DF61803A00>, ttype = Token.Punctuation\nvalues = '[', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""s = 'foo := 1'\n\n    @pytest.mark.parametrize('s', ['foo := 1;', 'foo := 1'])\n    def test_grouping_assignment(s):\n>       parsed = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:22: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:201: in group_assignment\n    _group(tlist, sql.Assignment, match, valid_prev, valid_next, post)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:476: in _group\n    if match(token):\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:189: in match\n    return token.match(T.Assignment, ':=')\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Assignment ':=' at 0x1DF618DACE0>, ttype = Token.Assignment\nvalues = ':=', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", 's = ""x > DATE \'2020-01-01\'""\n\n    @pytest.mark.parametrize(\'s\', [""x > DATE \'2020-01-01\'"", ""x > TIMESTAMP \'2020-01-01 00:00:00\'""])\n    def test_grouping_typed_literal(s):\n>       parsed = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:29: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:134: in group_typed_literal\n    _group(tlist, sql.TypedLiteral, match, valid_prev, valid_next,\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:476: in _group\n    if match(token):\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:117: in match\n    return imt(token, m=sql.TypedLiteral.M_OPEN)\nrepos\\sqlparse\\sqlparse\\utils.py:95: in imt\n    if any(token.match(*pattern) for pattern in m):\nrepos\\sqlparse\\sqlparse\\utils.py:95: in <genexpr>\n    if any(token.match(*pattern) for pattern in m):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Builtin \'DATE\' at 0x1DF61804E80>, ttype = Token.Name.Builtin\nvalues = None, regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = \'|\'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: \'Token\' object has no attribute \'token\'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError', 's = ""x > TIMESTAMP \'2020-01-01 00:00:00\'""\n\n    @pytest.mark.parametrize(\'s\', [""x > DATE \'2020-01-01\'"", ""x > TIMESTAMP \'2020-01-01 00:00:00\'""])\n    def test_grouping_typed_literal(s):\n>       parsed = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:29: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:134: in group_typed_literal\n    _group(tlist, sql.TypedLiteral, match, valid_prev, valid_next,\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:476: in _group\n    if match(token):\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:117: in match\n    return imt(token, m=sql.TypedLiteral.M_OPEN)\nrepos\\sqlparse\\sqlparse\\utils.py:95: in imt\n    if any(token.match(*pattern) for pattern in m):\nrepos\\sqlparse\\sqlparse\\utils.py:95: in <genexpr>\n    if any(token.match(*pattern) for pattern in m):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Builtin \'TIMEST...\' at 0x1DF61808400>, ttype = Token.Name.Builtin\nvalues = None, regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = \'|\'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: \'Token\' object has no attribute \'token\'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError', ""s = 'select a from b where c < d + e', a = <class 'sqlparse.sql.Identifier'>\nb = <class 'sqlparse.sql.Identifier'>\n\n    @pytest.mark.parametrize('s, a, b', [\n        ('select a from b where c < d + e', sql.Identifier, sql.Identifier),\n        ('select a from b where c < d + interval \\'1 day\\'', sql.Identifier, sql.TypedLiteral),\n        ('select a from b where c < d + interval \\'6\\' month', sql.Identifier, sql.TypedLiteral),\n        ('select a from b where c < current_timestamp - interval \\'1 day\\'', sql.Token, sql.TypedLiteral),\n    ])\n    def test_compare_expr(s, a, b):\n>       parsed = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:40: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:61: in group_case\n    _group_matching(tlist, sql.Case)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Keyword 'from' at 0x1DF6177B580>, ttype = Token.Keyword, values = 'CASE'\nregex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", 's = ""select a from b where c < d + interval \'1 day\'""\na = <class \'sqlparse.sql.Identifier\'>, b = <class \'sqlparse.sql.TypedLiteral\'>\n\n    @pytest.mark.parametrize(\'s, a, b\', [\n        (\'select a from b where c < d + e\', sql.Identifier, sql.Identifier),\n        (\'select a from b where c < d + interval \\\'1 day\\\'\', sql.Identifier, sql.TypedLiteral),\n        (\'select a from b where c < d + interval \\\'6\\\' month\', sql.Identifier, sql.TypedLiteral),\n        (\'select a from b where c < current_timestamp - interval \\\'1 day\\\'\', sql.Token, sql.TypedLiteral),\n    ])\n    def test_compare_expr(s, a, b):\n>       parsed = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:40: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:61: in group_case\n    _group_matching(tlist, sql.Case)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Keyword \'from\' at 0x1DF615F6C20>, ttype = Token.Keyword, values = \'CASE\'\nregex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = \'|\'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: \'Token\' object has no attribute \'token\'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError', 's = ""select a from b where c < d + interval \'6\' month""\na = <class \'sqlparse.sql.Identifier\'>, b = <class \'sqlparse.sql.TypedLiteral\'>\n\n    @pytest.mark.parametrize(\'s, a, b\', [\n        (\'select a from b where c < d + e\', sql.Identifier, sql.Identifier),\n        (\'select a from b where c < d + interval \\\'1 day\\\'\', sql.Identifier, sql.TypedLiteral),\n        (\'select a from b where c < d + interval \\\'6\\\' month\', sql.Identifier, sql.TypedLiteral),\n        (\'select a from b where c < current_timestamp - interval \\\'1 day\\\'\', sql.Token, sql.TypedLiteral),\n    ])\n    def test_compare_expr(s, a, b):\n>       parsed = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:40: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:61: in group_case\n    _group_matching(tlist, sql.Case)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Keyword \'from\' at 0x1DF61784FA0>, ttype = Token.Keyword, values = \'CASE\'\nregex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = \'|\'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: \'Token\' object has no attribute \'token\'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError', 's = ""select a from b where c < current_timestamp - interval \'1 day\'""\na = <class \'sqlparse.sql.Token\'>, b = <class \'sqlparse.sql.TypedLiteral\'>\n\n    @pytest.mark.parametrize(\'s, a, b\', [\n        (\'select a from b where c < d + e\', sql.Identifier, sql.Identifier),\n        (\'select a from b where c < d + interval \\\'1 day\\\'\', sql.Identifier, sql.TypedLiteral),\n        (\'select a from b where c < d + interval \\\'6\\\' month\', sql.Identifier, sql.TypedLiteral),\n        (\'select a from b where c < current_timestamp - interval \\\'1 day\\\'\', sql.Token, sql.TypedLiteral),\n    ])\n    def test_compare_expr(s, a, b):\n>       parsed = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:40: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:61: in group_case\n    _group_matching(tlist, sql.Case)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Keyword \'from\' at 0x1DF61764220>, ttype = Token.Keyword, values = \'CASE\'\nregex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = \'|\'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: \'Token\' object has no attribute \'token\'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError', 'def test_grouping_identifiers():\n        s = \'select foo.bar from ""myscheme"".""table"" where fail. order\'\n>       parsed = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:63: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation \'.\' at 0x1DF6177BD60>, ttype = Token.Punctuation\nvalues = \'[\', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = \'|\'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: \'Token\' object has no attribute \'token\'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError', ""s = '1 as f'\n\n    @pytest.mark.parametrize('s', [\n        '1 as f',\n        'foo as f',\n        'foo f',\n        '1/2 as f',\n        '1/2 f',\n        '1<2 as f',  # issue327\n        '1<2 f',\n    ])\n    def test_simple_identifiers(s):\n>       parsed = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:105: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:61: in group_case\n    _group_matching(tlist, sql.Case)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Keyword 'as' at 0x1DF617AB7C0>, ttype = Token.Keyword, values = 'CASE'\nregex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""s = 'foo as f'\n\n    @pytest.mark.parametrize('s', [\n        '1 as f',\n        'foo as f',\n        'foo f',\n        '1/2 as f',\n        '1/2 f',\n        '1<2 as f',  # issue327\n        '1<2 f',\n    ])\n    def test_simple_identifiers(s):\n>       parsed = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:105: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:61: in group_case\n    _group_matching(tlist, sql.Case)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Keyword 'as' at 0x1DF617A8640>, ttype = Token.Keyword, values = 'CASE'\nregex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""s = '1/2 as f'\n\n    @pytest.mark.parametrize('s', [\n        '1 as f',\n        'foo as f',\n        'foo f',\n        '1/2 as f',\n        '1/2 f',\n        '1<2 as f',  # issue327\n        '1<2 f',\n    ])\n    def test_simple_identifiers(s):\n>       parsed = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:105: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:61: in group_case\n    _group_matching(tlist, sql.Case)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Keyword 'as' at 0x1DF617E8880>, ttype = Token.Keyword, values = 'CASE'\nregex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""s = '1/2 f'\n\n    @pytest.mark.parametrize('s', [\n        '1 as f',\n        'foo as f',\n        'foo f',\n        '1/2 as f',\n        '1/2 f',\n        '1<2 as f',  # issue327\n        '1<2 f',\n    ])\n    def test_simple_identifiers(s):\n>       parsed = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:105: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:167: in group_period\n    _group(tlist, sql.Identifier, match, valid_prev, valid_next, post)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:476: in _group\n    if match(token):\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:145: in match\n    if token.match(ttype, value):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Operator '/' at 0x1DF61767C40>, ttype = Token.Operator, values = '->'\nregex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""s = '1<2 as f'\n\n    @pytest.mark.parametrize('s', [\n        '1 as f',\n        'foo as f',\n        'foo f',\n        '1/2 as f',\n        '1/2 f',\n        '1<2 as f',  # issue327\n        '1<2 f',\n    ])\n    def test_simple_identifiers(s):\n>       parsed = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:105: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:61: in group_case\n    _group_matching(tlist, sql.Case)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Keyword 'as' at 0x1DF617649A0>, ttype = Token.Keyword, values = 'CASE'\nregex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""s = 'foo, bar'\n\n    @pytest.mark.parametrize('s', [\n        'foo, bar',\n        'sum(a), sum(b)',\n        'sum(a) as x, b as y',\n        'sum(a)::integer, b',\n        'sum(a)/count(b) as x, y',\n        'sum(a)::integer as x, y',\n        'sum(a)::integer/count(b) as x, y',  # issue297\n    ])\n    def test_group_identifier_list(s):\n>       parsed = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:119: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation ',' at 0x1DF617EA920>, ttype = Token.Punctuation\nvalues = '[', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""s = 'sum(a), sum(b)'\n\n    @pytest.mark.parametrize('s', [\n        'foo, bar',\n        'sum(a), sum(b)',\n        'sum(a) as x, b as y',\n        'sum(a)::integer, b',\n        'sum(a)/count(b) as x, y',\n        'sum(a)::integer as x, y',\n        'sum(a)::integer/count(b) as x, y',  # issue297\n    ])\n    def test_group_identifier_list(s):\n>       parsed = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:119: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation '(' at 0x1DF617AA500>, ttype = Token.Punctuation\nvalues = '[', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""s = 'sum(a) as x, b as y'\n\n    @pytest.mark.parametrize('s', [\n        'foo, bar',\n        'sum(a), sum(b)',\n        'sum(a) as x, b as y',\n        'sum(a)::integer, b',\n        'sum(a)/count(b) as x, y',\n        'sum(a)::integer as x, y',\n        'sum(a)::integer/count(b) as x, y',  # issue297\n    ])\n    def test_group_identifier_list(s):\n>       parsed = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:119: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation '(' at 0x1DF618D8A60>, ttype = Token.Punctuation\nvalues = '[', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""s = 'sum(a)::integer, b'\n\n    @pytest.mark.parametrize('s', [\n        'foo, bar',\n        'sum(a), sum(b)',\n        'sum(a) as x, b as y',\n        'sum(a)::integer, b',\n        'sum(a)/count(b) as x, y',\n        'sum(a)::integer as x, y',\n        'sum(a)::integer/count(b) as x, y',  # issue297\n    ])\n    def test_group_identifier_list(s):\n>       parsed = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:119: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation '(' at 0x1DF618DB520>, ttype = Token.Punctuation\nvalues = '[', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""s = 'sum(a)/count(b) as x, y'\n\n    @pytest.mark.parametrize('s', [\n        'foo, bar',\n        'sum(a), sum(b)',\n        'sum(a) as x, b as y',\n        'sum(a)::integer, b',\n        'sum(a)/count(b) as x, y',\n        'sum(a)::integer as x, y',\n        'sum(a)::integer/count(b) as x, y',  # issue297\n    ])\n    def test_group_identifier_list(s):\n>       parsed = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:119: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation '(' at 0x1DF618D9A20>, ttype = Token.Punctuation\nvalues = '[', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""s = 'sum(a)::integer as x, y'\n\n    @pytest.mark.parametrize('s', [\n        'foo, bar',\n        'sum(a), sum(b)',\n        'sum(a) as x, b as y',\n        'sum(a)::integer, b',\n        'sum(a)/count(b) as x, y',\n        'sum(a)::integer as x, y',\n        'sum(a)::integer/count(b) as x, y',  # issue297\n    ])\n    def test_group_identifier_list(s):\n>       parsed = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:119: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation '(' at 0x1DF618D95A0>, ttype = Token.Punctuation\nvalues = '[', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""s = 'sum(a)::integer/count(b) as x, y'\n\n    @pytest.mark.parametrize('s', [\n        'foo, bar',\n        'sum(a), sum(b)',\n        'sum(a) as x, b as y',\n        'sum(a)::integer, b',\n        'sum(a)/count(b) as x, y',\n        'sum(a)::integer as x, y',\n        'sum(a)::integer/count(b) as x, y',  # issue297\n    ])\n    def test_group_identifier_list(s):\n>       parsed = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:119: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation '(' at 0x1DF618D8D60>, ttype = Token.Punctuation\nvalues = '[', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""def test_grouping_identifier_wildcard():\n>       p = sqlparse.parse('a.*, b.id')[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:124: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation '.' at 0x1DF618D2F80>, ttype = Token.Punctuation\nvalues = '[', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""def test_grouping_identifier_name_wildcard():\n>       p = sqlparse.parse('a.*')[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:131: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation '.' at 0x1DF617E9840>, ttype = Token.Punctuation\nvalues = '[', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""def test_grouping_identifier_invalid():\n>       p = sqlparse.parse('a.')[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:138: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation '.' at 0x1DF618D8DC0>, ttype = Token.Punctuation\nvalues = '[', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""def test_grouping_identifier_invalid_in_middle():\n        # issue261\n        s = 'SELECT foo. FROM foo'\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:149: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation '.' at 0x1DF618D2800>, ttype = Token.Punctuation\nvalues = '[', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""s = 'foo as (select *)'\n\n    @pytest.mark.parametrize('s', ['foo as (select *)', 'foo as(select *)'])\n    def test_grouping_identifer_as(s):\n        # issue507\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:158: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation '(' at 0x1DF618D2C20>, ttype = Token.Punctuation\nvalues = '[', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""s = 'foo as(select *)'\n\n    @pytest.mark.parametrize('s', ['foo as (select *)', 'foo as(select *)'])\n    def test_grouping_identifer_as(s):\n        # issue507\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:158: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation '(' at 0x1DF618D0BE0>, ttype = Token.Punctuation\nvalues = '[', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""def test_grouping_identifier_as_invalid():\n        # issue8\n>       p = sqlparse.parse('foo as select *')[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:166: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:61: in group_case\n    _group_matching(tlist, sql.Case)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Keyword 'as' at 0x1DF618D14E0>, ttype = Token.Keyword, values = 'CASE'\nregex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""def test_grouping_identifier_function():\n>       p = sqlparse.parse('foo() as bar')[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:174: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation '(' at 0x1DF618D2860>, ttype = Token.Punctuation\nvalues = '[', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""s = 'foo+100'\n\n    @pytest.mark.parametrize('s', ['foo+100', 'foo + 100', 'foo*100'])\n    def test_grouping_operation(s):\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:199: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:167: in group_period\n    _group(tlist, sql.Identifier, match, valid_prev, valid_next, post)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:476: in _group\n    if match(token):\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:145: in match\n    if token.match(ttype, value):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Operator '+' at 0x1DF61840040>, ttype = Token.Operator, values = '->'\nregex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""s = 'foo + 100'\n\n    @pytest.mark.parametrize('s', ['foo+100', 'foo + 100', 'foo*100'])\n    def test_grouping_operation(s):\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:199: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:167: in group_period\n    _group(tlist, sql.Identifier, match, valid_prev, valid_next, post)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:476: in _group\n    if match(token):\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:145: in match\n    if token.match(ttype, value):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Operator '+' at 0x1DF618D2140>, ttype = Token.Operator, values = '->'\nregex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""def test_grouping_identifier_list():\n>       p = sqlparse.parse('a, b, c')[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:204: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation ',' at 0x1DF618426E0>, ttype = Token.Punctuation\nvalues = '[', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", 'def test_grouping_identifier_list_subquery():\n        """"""identifier lists should still work in subqueries with aliases""""""\n>       p = sqlparse.parse(""select * from (""\n                           ""select a, b + c as d from table) sub"")[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:212: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation \'(\' at 0x1DF61843B20>, ttype = Token.Punctuation\nvalues = \'[\', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = \'|\'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: \'Token\' object has no attribute \'token\'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError', ""def test_grouping_identifier_list_case():\n>       p = sqlparse.parse('a, case when 1 then 2 else 3 end as b, c')[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:223: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation ',' at 0x1DF618407C0>, ttype = Token.Punctuation\nvalues = '[', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", 'def test_grouping_identifier_list_other():\n        # issue2\n>       p = sqlparse.parse(""select *, null, 1, \'foo\', bar from mytable, x"")[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:231: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation \',\' at 0x1DF61842FE0>, ttype = Token.Punctuation\nvalues = \'[\', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = \'|\'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: \'Token\' object has no attribute \'token\'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError', ""def test_grouping_identifier_list_with_inline_comments():\n        # issue163\n>       p = sqlparse.parse('foo /* a comment */, bar')[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:238: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation ',' at 0x1DF61840CA0>, ttype = Token.Punctuation\nvalues = '[', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""def test_grouping_identifiers_with_operators():\n>       p = sqlparse.parse('a+b as c from table where (d-e)%2= 1')[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:245: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation '(' at 0x1DF618972E0>, ttype = Token.Punctuation\nvalues = '[', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""def test_grouping_identifier_list_with_order():\n        # issue101\n>       p = sqlparse.parse('1, 2 desc, 3')[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:251: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation ',' at 0x1DF61897520>, ttype = Token.Punctuation\nvalues = '[', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""def test_grouping_nested_identifier_with_order():\n        # issue745\n>       p = sqlparse.parse('(a desc)')[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:259: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation '(' at 0x1DF61896F20>, ttype = Token.Punctuation\nvalues = '[', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""def test_grouping_where():\n        s = 'select * from foo where bar = 1 order by id desc'\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:267: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:61: in group_case\n    _group_matching(tlist, sql.Case)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Keyword 'from' at 0x1DF61895960>, ttype = Token.Keyword, values = 'CASE'\nregex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""s = 'select 1 where 1 = 2 union select 2'\n\n    @pytest.mark.parametrize('s', (\n        'select 1 where 1 = 2 union select 2',\n        'select 1 where 1 = 2 union all select 2',\n    ))\n    def test_grouping_where_union(s):\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:282: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:61: in group_case\n    _group_matching(tlist, sql.Case)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Keyword 'where' at 0x1DF61896E60>, ttype = Token.Keyword\nvalues = 'CASE', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""s = 'select 1 where 1 = 2 union all select 2'\n\n    @pytest.mark.parametrize('s', (\n        'select 1 where 1 = 2 union select 2',\n        'select 1 where 1 = 2 union all select 2',\n    ))\n    def test_grouping_where_union(s):\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:282: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:61: in group_case\n    _group_matching(tlist, sql.Case)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Keyword 'where' at 0x1DF61894820>, ttype = Token.Keyword\nvalues = 'CASE', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""def test_returning_kw_ends_where_clause():\n        s = 'delete from foo where x > y returning z'\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:288: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:61: in group_case\n    _group_matching(tlist, sql.Case)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Keyword 'from' at 0x1DF61843880>, ttype = Token.Keyword, values = 'CASE'\nregex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""def test_into_kw_ends_where_clause():  # issue324\n        s = 'select * from foo where a = 1 into baz'\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:296: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:61: in group_case\n    _group_matching(tlist, sql.Case)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Keyword 'from' at 0x1DF618961A0>, ttype = Token.Keyword, values = 'CASE'\nregex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""sql = 'select foo::integer from bar', expected = 'integer'\n\n    @pytest.mark.parametrize('sql, expected', [\n        # note: typecast needs to be 2nd token for this test\n        ('select foo::integer from bar', 'integer'),\n        ('select (current_database())::information_schema.sql_identifier',\n         'information_schema.sql_identifier'),\n    ])\n    def test_grouping_typecast(sql, expected):\n>       p = sqlparse.parse(sql)[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:309: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation '::' at 0x1DF61846E60>, ttype = Token.Punctuation\nvalues = '[', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""sql = 'select (current_database())::information_schema.sql_identifier'\nexpected = 'information_schema.sql_identifier'\n\n    @pytest.mark.parametrize('sql, expected', [\n        # note: typecast needs to be 2nd token for this test\n        ('select foo::integer from bar', 'integer'),\n        ('select (current_database())::information_schema.sql_identifier',\n         'information_schema.sql_identifier'),\n    ])\n    def test_grouping_typecast(sql, expected):\n>       p = sqlparse.parse(sql)[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:309: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation '(' at 0x1DF618479A0>, ttype = Token.Punctuation\nvalues = '[', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""def test_grouping_alias():\n        s = 'select foo as bar from mytable'\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:315: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:61: in group_case\n    _group_matching(tlist, sql.Case)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Keyword 'as' at 0x1DF61845420>, ttype = Token.Keyword, values = 'CASE'\nregex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""def test_grouping_alias_case():\n        # see issue46\n>       p = sqlparse.parse('CASE WHEN 1 THEN 2 ELSE 3 END foo')[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:337: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:61: in group_case\n    _group_matching(tlist, sql.Case)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Keyword 'CASE' at 0x1DF618472E0>, ttype = Token.Keyword, values = 'CASE'\nregex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""def test_grouping_alias_ctas():\n>       p = sqlparse.parse('CREATE TABLE tbl1 AS SELECT coalesce(t1.col1, 0) AS col1 FROM t1')[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:343: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation '(' at 0x1DF61846E60>, ttype = Token.Punctuation\nvalues = '[', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""def test_grouping_subquery_no_parens():\n        # Not totally sure if this is the right approach...\n        # When a THEN clause contains a subquery w/o parenthesis around it *and*\n        # a WHERE condition, the WHERE grouper consumes END too.\n        # This takes makes sure that it doesn't fail.\n>       p = sqlparse.parse('CASE WHEN 1 THEN select 2 where foo = 1 end')[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:352: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:61: in group_case\n    _group_matching(tlist, sql.Case)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Keyword 'CASE' at 0x1DF61897460>, ttype = Token.Keyword, values = 'CASE'\nregex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""s = 'foo.bar'\n\n    @pytest.mark.parametrize('s', ['foo.bar', 'x, y', 'x > y', 'x / y'])\n    def test_grouping_alias_returns_none(s):\n        # see issue185 and issue445\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:360: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation '.' at 0x1DF61841540>, ttype = Token.Punctuation\nvalues = '[', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""s = 'x, y'\n\n    @pytest.mark.parametrize('s', ['foo.bar', 'x, y', 'x > y', 'x / y'])\n    def test_grouping_alias_returns_none(s):\n        # see issue185 and issue445\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:360: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation ',' at 0x1DF618421A0>, ttype = Token.Punctuation\nvalues = '[', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""s = 'x / y'\n\n    @pytest.mark.parametrize('s', ['foo.bar', 'x, y', 'x > y', 'x / y'])\n    def test_grouping_alias_returns_none(s):\n        # see issue185 and issue445\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:360: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:167: in group_period\n    _group(tlist, sql.Identifier, match, valid_prev, valid_next, post)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:476: in _group\n    if match(token):\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:145: in match\n    if token.match(ttype, value):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Operator '/' at 0x1DF618D1660>, ttype = Token.Operator, values = '->'\nregex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""def test_grouping_idlist_function():\n        # see issue10 too\n>       p = sqlparse.parse('foo(1) x, bar')[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:367: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation '(' at 0x1DF615F7CA0>, ttype = Token.Punctuation\nvalues = '[', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""def test_grouping_comparison_exclude():\n        # make sure operators are not handled too lazy\n>       p = sqlparse.parse('(=)')[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:373: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation '(' at 0x1DF618DB0A0>, ttype = Token.Punctuation\nvalues = '[', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""def test_grouping_function():\n>       p = sqlparse.parse('foo()')[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:383: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation '(' at 0x1DF618961A0>, ttype = Token.Punctuation\nvalues = '[', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""def test_grouping_function_not_in():\n        # issue183\n>       p = sqlparse.parse('in(1, 2)')[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:400: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation '(' at 0x1DF61846800>, ttype = Token.Punctuation\nvalues = '[', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", 'def test_grouping_varchar():\n>       p = sqlparse.parse(\'""text"" Varchar(50) NOT NULL\')[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:407: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation \'(\' at 0x1DF61846980>, ttype = Token.Punctuation\nvalues = \'[\', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = \'|\'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: \'Token\' object has no attribute \'token\'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError', ""def test_statement_get_type():\n        def f(sql):\n            return sqlparse.parse(sql)[0]\n    \n>       assert f('select * from foo').get_type() == 'SELECT'\n\nrepos\\sqlparse\\tests\\test_grouping.py:415: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_grouping.py:413: in f\n    return sqlparse.parse(sql)[0]\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:61: in group_case\n    _group_matching(tlist, sql.Case)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Keyword 'from' at 0x1DF618D20E0>, ttype = Token.Keyword, values = 'CASE'\nregex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""def test_identifier_with_operators():\n        # issue 53\n>       p = sqlparse.parse('foo||bar')[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:424: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:167: in group_period\n    _group(tlist, sql.Identifier, match, valid_prev, valid_next, post)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:476: in _group\n    if match(token):\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:145: in match\n    if token.match(ttype, value):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Operator '||' at 0x1DF61847D60>, ttype = Token.Operator, values = '->'\nregex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""def test_identifier_with_op_trailing_ws():\n        # make sure trailing whitespace isn't grouped with identifier\n>       p = sqlparse.parse('foo || bar ')[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:435: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:167: in group_period\n    _group(tlist, sql.Identifier, match, valid_prev, valid_next, post)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:476: in _group\n    if match(token):\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:145: in match\n    if token.match(ttype, value):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Operator '||' at 0x1DF6188EEC0>, ttype = Token.Operator, values = '->'\nregex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", 'def test_identifier_with_string_literals():\n>       p = sqlparse.parse(""foo + \'bar\'"")[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:442: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:167: in group_period\n    _group(tlist, sql.Identifier, match, valid_prev, valid_next, post)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:476: in _group\n    if match(token):\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:145: in match\n    if token.match(ttype, value):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Operator \'+\' at 0x1DF6188EE60>, ttype = Token.Operator, values = \'->\'\nregex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = \'|\'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: \'Token\' object has no attribute \'token\'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError', ""def test_identifier_consumes_ordering():\n        # issue89\n>       p = sqlparse.parse('select * from foo order by c1 desc, c2, c3')[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:458: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation ',' at 0x1DF6188C580>, ttype = Token.Punctuation\nvalues = '[', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""def test_comparison_with_keywords():\n        # issue90\n        # in fact these are assignments, but for now we don't distinguish them\n>       p = sqlparse.parse('foo = NULL')[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:471: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:61: in group_case\n    _group_matching(tlist, sql.Case)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Keyword 'NULL' at 0x1DF6188D240>, ttype = Token.Keyword, values = 'CASE'\nregex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""def test_comparison_with_parenthesis():\n        # issue23\n>       p = sqlparse.parse('(3 + 4) = 7')[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:495: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation '(' at 0x1DF6188E5C0>, ttype = Token.Punctuation\nvalues = '[', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", 'def test_like_and_ilike_comparison():\n        def validate_where_clause(where_clause, expected_tokens):\n            assert len(where_clause.tokens) == len(expected_tokens)\n            for where_token, expected_token in zip(where_clause, expected_tokens):\n                expected_ttype, expected_value = expected_token\n                if where_token.ttype is not None:\n                    assert where_token.match(expected_ttype, expected_value, regex=True)\n                else:\n                    # Certain tokens, such as comparison tokens, do not define a ttype that can be\n                    # matched against. For these tokens, we ensure that the token instance is of\n                    # the expected type and has a value conforming to specified regular expression\n                    import re\n                    assert (isinstance(where_token, expected_ttype)\n                            and re.match(expected_value, where_token.value))\n    \n>       [p1] = sqlparse.parse(""select * from mytable where mytable.mycolumn LIKE \'expr%\' limit 5;"")\n\nrepos\\sqlparse\\tests\\test_grouping.py:531: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation \'.\' at 0x1DF6185D540>, ttype = Token.Punctuation\nvalues = \'[\', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = \'|\'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: \'Token\' object has no attribute \'token\'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError', ""def test_comparison_with_functions():\n        # issue230\n>       p = sqlparse.parse('foo = DATE(bar.baz)')[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:553: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation '(' at 0x1DF6185C8E0>, ttype = Token.Punctuation\nvalues = '[', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", 'def test_comparison_with_typed_literal():\n>       p = sqlparse.parse(""foo = DATE \'bar.baz\'"")[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:576: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:134: in group_typed_literal\n    _group(tlist, sql.TypedLiteral, match, valid_prev, valid_next,\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:476: in _group\n    if match(token):\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:117: in match\n    return imt(token, m=sql.TypedLiteral.M_OPEN)\nrepos\\sqlparse\\sqlparse\\utils.py:95: in imt\n    if any(token.match(*pattern) for pattern in m):\nrepos\\sqlparse\\sqlparse\\utils.py:95: in <genexpr>\n    if any(token.match(*pattern) for pattern in m):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Builtin \'DATE\' at 0x1DF6185D4E0>, ttype = Token.Name.Builtin\nvalues = None, regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = \'|\'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: \'Token\' object has no attribute \'token\'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError', ""start = 'FOR'\n\n    @pytest.mark.parametrize('start', ['FOR', 'FOREACH'])\n    def test_forloops(start):\n>       p = sqlparse.parse(f'{start} foo in bar LOOP foobar END LOOP')[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:588: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:61: in group_case\n    _group_matching(tlist, sql.Case)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Keyword 'FOR' at 0x1DF6185EBC0>, ttype = Token.Keyword, values = 'CASE'\nregex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""start = 'FOREACH'\n\n    @pytest.mark.parametrize('start', ['FOR', 'FOREACH'])\n    def test_forloops(start):\n>       p = sqlparse.parse(f'{start} foo in bar LOOP foobar END LOOP')[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:588: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:61: in group_case\n    _group_matching(tlist, sql.Case)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Keyword 'FOREACH' at 0x1DF6185FA00>, ttype = Token.Keyword\nvalues = 'CASE', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""def test_nested_for():\n>       p = sqlparse.parse('FOR foo LOOP FOR bar LOOP END LOOP END LOOP')[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:594: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:61: in group_case\n    _group_matching(tlist, sql.Case)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Keyword 'FOR' at 0x1DF6185F760>, ttype = Token.Keyword, values = 'CASE'\nregex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""def test_begin():\n>       p = sqlparse.parse('BEGIN foo END')[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:606: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:61: in group_case\n    _group_matching(tlist, sql.Case)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Keyword 'BEGIN' at 0x1DF6188EEC0>, ttype = Token.Keyword\nvalues = 'CASE', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""def test_keyword_followed_by_parenthesis():\n>       p = sqlparse.parse('USING(somecol')[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:612: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation '(' at 0x1DF6185FB20>, ttype = Token.Punctuation\nvalues = '[', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""def test_nested_begin():\n>       p = sqlparse.parse('BEGIN foo BEGIN bar END END')[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:619: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:61: in group_case\n    _group_matching(tlist, sql.Case)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Keyword 'BEGIN' at 0x1DF6185F340>, ttype = Token.Keyword\nvalues = 'CASE', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""def test_aliased_column_without_as():\n        p = sqlparse.parse('foo bar')[0].tokens\n        assert len(p) == 1\n        assert p[0].get_real_name() == 'foo'\n        assert p[0].get_alias() == 'bar'\n    \n>       p = sqlparse.parse('foo.bar baz')[0].tokens[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:636: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation '.' at 0x1DF618CD5A0>, ttype = Token.Punctuation\nvalues = '[', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""def test_qualified_function():\n>       p = sqlparse.parse('foo()')[0].tokens[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:643: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation '(' at 0x1DF618CE200>, ttype = Token.Punctuation\nvalues = '[', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""def test_aliased_function_without_as():\n>       p = sqlparse.parse('foo() bar')[0].tokens[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:653: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation '(' at 0x1DF618CDFC0>, ttype = Token.Punctuation\nvalues = '[', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""def test_grouping_as_cte():\n>       p = sqlparse.parse('foo AS WITH apple AS 1, banana AS 2')[0].tokens\n\nrepos\\sqlparse\\tests\\test_grouping.py:671: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation ',' at 0x1DF618CC460>, ttype = Token.Punctuation\nvalues = '[', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", 'def test_grouping_create_table():\n>       p = sqlparse.parse(""create table db.tbl (a string)"")[0].tokens\n\nrepos\\sqlparse\\tests\\test_grouping.py:678: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation \'.\' at 0x1DF6188F460>, ttype = Token.Punctuation\nvalues = \'[\', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = \'|\'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: \'Token\' object has no attribute \'token\'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError', ""def test_parse_tokenize():\n        s = 'select * from foo;'\n>       stmts = sqlparse.parse(s)\n\nrepos\\sqlparse\\tests\\test_parse.py:13: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation ';' at 0x1DF618CFA00>, ttype = Token.Punctuation\nvalues = '[', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""def test_parse_multistatement():\n        sql1 = 'select * from foo;'\n        sql2 = 'select * from bar;'\n>       stmts = sqlparse.parse(sql1 + sql2)\n\nrepos\\sqlparse\\tests\\test_parse.py:21: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation ';' at 0x1DF6196B220>, ttype = Token.Punctuation\nvalues = '[', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""s = 'select\\n*from foo;'\n\n    @pytest.mark.parametrize('s', ['select\\n*from foo;',\n                                   'select\\r\\n*from foo',\n                                   'select\\r*from foo',\n                                   'select\\r\\n*from foo\\n'])\n    def test_parse_newlines(s):\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_parse.py:32: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation ';' at 0x1DF6196BCA0>, ttype = Token.Punctuation\nvalues = '[', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""s = 'select\\r\\n*from foo'\n\n    @pytest.mark.parametrize('s', ['select\\n*from foo;',\n                                   'select\\r\\n*from foo',\n                                   'select\\r*from foo',\n                                   'select\\r\\n*from foo\\n'])\n    def test_parse_newlines(s):\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_parse.py:32: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:61: in group_case\n    _group_matching(tlist, sql.Case)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Keyword 'from' at 0x1DF6196EAA0>, ttype = Token.Keyword, values = 'CASE'\nregex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""s = 'select\\r*from foo'\n\n    @pytest.mark.parametrize('s', ['select\\n*from foo;',\n                                   'select\\r\\n*from foo',\n                                   'select\\r*from foo',\n                                   'select\\r\\n*from foo\\n'])\n    def test_parse_newlines(s):\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_parse.py:32: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:61: in group_case\n    _group_matching(tlist, sql.Case)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Keyword 'from' at 0x1DF618CE4A0>, ttype = Token.Keyword, values = 'CASE'\nregex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""s = 'select\\r\\n*from foo\\n'\n\n    @pytest.mark.parametrize('s', ['select\\n*from foo;',\n                                   'select\\r\\n*from foo',\n                                   'select\\r*from foo',\n                                   'select\\r\\n*from foo\\n'])\n    def test_parse_newlines(s):\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_parse.py:32: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:61: in group_case\n    _group_matching(tlist, sql.Case)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Keyword 'from' at 0x1DF6196F280>, ttype = Token.Keyword, values = 'CASE'\nregex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""def test_parse_within():\n        s = 'foo(col1, col2)'\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_parse.py:38: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation '(' at 0x1DF6196FE80>, ttype = Token.Punctuation\nvalues = '[', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""def test_parse_child_of():\n        s = '(col1, col2)'\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_parse.py:45: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation '(' at 0x1DF6196F9A0>, ttype = Token.Punctuation\nvalues = '[', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""def test_parse_has_ancestor():\n        s = 'foo or (bar, baz)'\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_parse.py:55: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation '(' at 0x1DF6196D3C0>, ttype = Token.Punctuation\nvalues = '[', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""s = 'select * from foo where user = ?', holder = '?'\n\n    @pytest.mark.parametrize('s, holder', [\n        ('select * from foo where user = ?', '?'),\n        ('select * from foo where user = :1', ':1'),\n        ('select * from foo where user = :name', ':name'),\n        ('select * from foo where user = %s', '%s'),\n        ('select * from foo where user = $a', '$a')])\n    def test_parse_placeholder(s, holder):\n>       t = sqlparse.parse(s)[0].tokens[-1].tokens\n\nrepos\\sqlparse\\tests\\test_parse.py:76: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:61: in group_case\n    _group_matching(tlist, sql.Case)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Keyword 'from' at 0x1DF6196F160>, ttype = Token.Keyword, values = 'CASE'\nregex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""s = 'select * from foo where user = :1', holder = ':1'\n\n    @pytest.mark.parametrize('s, holder', [\n        ('select * from foo where user = ?', '?'),\n        ('select * from foo where user = :1', ':1'),\n        ('select * from foo where user = :name', ':name'),\n        ('select * from foo where user = %s', '%s'),\n        ('select * from foo where user = $a', '$a')])\n    def test_parse_placeholder(s, holder):\n>       t = sqlparse.parse(s)[0].tokens[-1].tokens\n\nrepos\\sqlparse\\tests\\test_parse.py:76: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:61: in group_case\n    _group_matching(tlist, sql.Case)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Keyword 'from' at 0x1DF6196E560>, ttype = Token.Keyword, values = 'CASE'\nregex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""s = 'select * from foo where user = :name', holder = ':name'\n\n    @pytest.mark.parametrize('s, holder', [\n        ('select * from foo where user = ?', '?'),\n        ('select * from foo where user = :1', ':1'),\n        ('select * from foo where user = :name', ':name'),\n        ('select * from foo where user = %s', '%s'),\n        ('select * from foo where user = $a', '$a')])\n    def test_parse_placeholder(s, holder):\n>       t = sqlparse.parse(s)[0].tokens[-1].tokens\n\nrepos\\sqlparse\\tests\\test_parse.py:76: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:61: in group_case\n    _group_matching(tlist, sql.Case)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Keyword 'from' at 0x1DF619EB6A0>, ttype = Token.Keyword, values = 'CASE'\nregex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""s = 'select * from foo where user = %s', holder = '%s'\n\n    @pytest.mark.parametrize('s, holder', [\n        ('select * from foo where user = ?', '?'),\n        ('select * from foo where user = :1', ':1'),\n        ('select * from foo where user = :name', ':name'),\n        ('select * from foo where user = %s', '%s'),\n        ('select * from foo where user = $a', '$a')])\n    def test_parse_placeholder(s, holder):\n>       t = sqlparse.parse(s)[0].tokens[-1].tokens\n\nrepos\\sqlparse\\tests\\test_parse.py:76: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:61: in group_case\n    _group_matching(tlist, sql.Case)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Keyword 'from' at 0x1DF6185F280>, ttype = Token.Keyword, values = 'CASE'\nregex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""s = 'select * from foo where user = $a', holder = '$a'\n\n    @pytest.mark.parametrize('s, holder', [\n        ('select * from foo where user = ?', '?'),\n        ('select * from foo where user = :1', ':1'),\n        ('select * from foo where user = :name', ':name'),\n        ('select * from foo where user = %s', '%s'),\n        ('select * from foo where user = $a', '$a')])\n    def test_parse_placeholder(s, holder):\n>       t = sqlparse.parse(s)[0].tokens[-1].tokens\n\nrepos\\sqlparse\\tests\\test_parse.py:76: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:61: in group_case\n    _group_matching(tlist, sql.Case)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Keyword 'from' at 0x1DF6188C400>, ttype = Token.Keyword, values = 'CASE'\nregex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""def test_parse_access_symbol():\n        # see issue27\n>       t = sqlparse.parse('select a.[foo bar] as foo')[0].tokens\n\nrepos\\sqlparse\\tests\\test_parse.py:88: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation '.' at 0x1DF618977C0>, ttype = Token.Punctuation\nvalues = '[', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""def test_parse_square_brackets_notation_isnt_too_greedy():\n        # see issue153\n>       t = sqlparse.parse('[foo], [bar]')[0].tokens\n\nrepos\\sqlparse\\tests\\test_parse.py:97: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation ',' at 0x1DF619EBD60>, ttype = Token.Punctuation\nvalues = '[', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""def test_parse_square_brackets_notation_isnt_too_greedy2():\n        # see issue583\n>       t = sqlparse.parse('[(foo[i])]')[0].tokens\n\nrepos\\sqlparse\\tests\\test_parse.py:106: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation '[' at 0x1DF6188FFA0>, ttype = Token.Punctuation\nvalues = '[', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""def test_parse_keyword_like_identifier():\n        # see issue47\n>       t = sqlparse.parse('foo.key')[0].tokens\n\nrepos\\sqlparse\\tests\\test_parse.py:112: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation '.' at 0x1DF618CEEC0>, ttype = Token.Punctuation\nvalues = '[', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""def test_parse_function_parameter():\n        # see issue94\n>       t = sqlparse.parse('abs(some_col)')[0].tokens[0].get_parameters()\n\nrepos\\sqlparse\\tests\\test_parse.py:119: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation '(' at 0x1DF619E97E0>, ttype = Token.Punctuation\nvalues = '[', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""def test_parse_function_param_single_literal():\n>       t = sqlparse.parse('foo(5)')[0].tokens[0].get_parameters()\n\nrepos\\sqlparse\\tests\\test_parse.py:125: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation '(' at 0x1DF619E9FC0>, ttype = Token.Punctuation\nvalues = '[', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""def test_parse_nested_function():\n>       t = sqlparse.parse('foo(bar(5))')[0].tokens[0].get_parameters()\n\nrepos\\sqlparse\\tests\\test_parse.py:131: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation '(' at 0x1DF619E9660>, ttype = Token.Punctuation\nvalues = '[', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", 'def test_parse_casted_params():\n>       t = sqlparse.parse(""foo(DATE \'2023-11-14\', TIMESTAMP \'2023-11-15\')"")[0].tokens[0].get_parameters()\n\nrepos\\sqlparse\\tests\\test_parse.py:137: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation \'(\' at 0x1DF619EA320>, ttype = Token.Punctuation\nvalues = \'[\', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = \'|\'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: \'Token\' object has no attribute \'token\'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError', ""def test_parse_div_operator():\n>       p = sqlparse.parse('col1 DIV 5 AS div_col1')[0].tokens\n\nrepos\\sqlparse\\tests\\test_parse.py:142: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:61: in group_case\n    _group_matching(tlist, sql.Case)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Keyword 'AS' at 0x1DF6196E860>, ttype = Token.Keyword, values = 'CASE'\nregex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", 'def test_quoted_identifier():\n>       t = sqlparse.parse(\'select x.y as ""z"" from foo\')[0].tokens\n\nrepos\\sqlparse\\tests\\test_parse.py:148: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation \'.\' at 0x1DF6196E9E0>, ttype = Token.Punctuation\nvalues = \'[\', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = \'|\'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: \'Token\' object has no attribute \'token\'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError', ""def test_double_precision_is_builtin():\n        s = 'DOUBLE PRECISION'\n>       t = sqlparse.parse(s)[0].tokens\n\nrepos\\sqlparse\\tests\\test_parse.py:199: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:134: in group_typed_literal\n    _group(tlist, sql.TypedLiteral, match, valid_prev, valid_next,\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:476: in _group\n    if match(token):\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:117: in match\n    return imt(token, m=sql.TypedLiteral.M_OPEN)\nrepos\\sqlparse\\sqlparse\\utils.py:95: in imt\n    if any(token.match(*pattern) for pattern in m):\nrepos\\sqlparse\\sqlparse\\utils.py:95: in <genexpr>\n    if any(token.match(*pattern) for pattern in m):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Builtin 'DOUBLE...' at 0x1DF6188C400>, ttype = Token.Name.Builtin\nvalues = None, regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""def test_sqlite_identifiers():\n        # Make sure we still parse sqlite style escapes\n>       p = sqlparse.parse('[col1],[col2]')[0].tokens\n\nrepos\\sqlparse\\tests\\test_parse.py:245: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation ',' at 0x1DF619C6F20>, ttype = Token.Punctuation\nvalues = '[', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""def test_simple_1d_array_index():\n>       p = sqlparse.parse('col[1]')[0].tokens\n\nrepos\\sqlparse\\tests\\test_parse.py:257: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation '[' at 0x1DF619C41C0>, ttype = Token.Punctuation\nvalues = '[', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""def test_2d_array_index():\n>       p = sqlparse.parse('col[x][(y+1)*2]')[0].tokens\n\nrepos\\sqlparse\\tests\\test_parse.py:267: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation '[' at 0x1DF619C4D60>, ttype = Token.Punctuation\nvalues = '[', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""def test_array_index_function_result():\n>       p = sqlparse.parse('somefunc()[1]')[0].tokens\n\nrepos\\sqlparse\\tests\\test_parse.py:274: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation '(' at 0x1DF619C65C0>, ttype = Token.Punctuation\nvalues = '[', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""def test_schema_qualified_array_index():\n>       p = sqlparse.parse('schem.col[1]')[0].tokens\n\nrepos\\sqlparse\\tests\\test_parse.py:280: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation '.' at 0x1DF619C5480>, ttype = Token.Punctuation\nvalues = '[', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""def test_aliased_array_index():\n>       p = sqlparse.parse('col[1] x')[0].tokens\n\nrepos\\sqlparse\\tests\\test_parse.py:288: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation '[' at 0x1DF619C61A0>, ttype = Token.Punctuation\nvalues = '[', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""def test_array_literal():\n        # See issue #176\n>       p = sqlparse.parse('ARRAY[%s, %s]')[0]\n\nrepos\\sqlparse\\tests\\test_parse.py:297: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation '[' at 0x1DF619D2D40>, ttype = Token.Punctuation\nvalues = '[', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""def test_typed_array_definition():\n        # array indices aren't grouped with built-ins, but make sure we can extract\n        # identifier names\n>       p = sqlparse.parse('x int, y int[], z int')[0]\n\nrepos\\sqlparse\\tests\\test_parse.py:305: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation ',' at 0x1DF619C59C0>, ttype = Token.Punctuation\nvalues = '[', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""def test_get_token_at_offset():\n>       p = sqlparse.parse('select * from dual')[0]\n\nrepos\\sqlparse\\tests\\test_parse.py:328: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:61: in group_case\n    _group_matching(tlist, sql.Case)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Keyword 'from' at 0x1DF619D1E40>, ttype = Token.Keyword, values = 'CASE'\nregex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""def test_pprint():\n>       p = sqlparse.parse('select a0, b0, c0, d0, e0 from '\n                           '(select * from dual) q0 where 1=1 and 2=2')[0]\n\nrepos\\sqlparse\\tests\\test_parse.py:340: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation ',' at 0x1DF619D3340>, ttype = Token.Punctuation\nvalues = '[', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""def test_wildcard_multiplication():\n>       p = sqlparse.parse('select * from dual')[0]\n\nrepos\\sqlparse\\tests\\test_parse.py:405: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:61: in group_case\n    _group_matching(tlist, sql.Case)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Keyword 'from' at 0x1DF619D24A0>, ttype = Token.Keyword, values = 'CASE'\nregex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", 'def test_stmt_tokens_parents():\n        # see issue 226\n        s = ""CREATE TABLE test();""\n>       stmt = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_parse.py:418: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation \'(\' at 0x1DF619D3880>, ttype = Token.Punctuation\nvalues = \'[\', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = \'|\'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: \'Token\' object has no attribute \'token\'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError', 'def test_non_ascii():\n        _test_non_ascii = ""insert into test (id, name) values (1, \'тест\');""\n    \n        s = _test_non_ascii\n>       stmts = sqlparse.parse(s)\n\nrepos\\sqlparse\\tests\\test_parse.py:446: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation \'(\' at 0x1DF619D1240>, ttype = Token.Punctuation\nvalues = \'[\', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = \'|\'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: \'Token\' object has no attribute \'token\'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError', 'def test_get_real_name():\n        # issue 369\n        s = ""update a t set t.b=1""\n>       stmts = sqlparse.parse(s)\n\nrepos\\sqlparse\\tests\\test_parse.py:463: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation \'.\' at 0x1DF619D3100>, ttype = Token.Punctuation\nvalues = \'[\', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = \'|\'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: \'Token\' object has no attribute \'token\'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError', ""def test_from_subquery():\n        # issue 446\n        s = 'from(select 1)'\n>       stmts = sqlparse.parse(s)\n\nrepos\\sqlparse\\tests\\test_parse.py:472: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation '(' at 0x1DF619E3580>, ttype = Token.Punctuation\nvalues = '[', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", 'def test_parenthesis():\n>       tokens = sqlparse.parse(""(\\n\\n1\\n\\n)"")[0].tokens[0].tokens\n\nrepos\\sqlparse\\tests\\test_parse.py:488: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation \'(\' at 0x1DF619D33A0>, ttype = Token.Punctuation\nvalues = \'[\', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = \'|\'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: \'Token\' object has no attribute \'token\'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError', 'def test_configurable_keywords():\n        sql = """"""select * from foo BACON SPAM EGGS;""""""\n>       tokens = sqlparse.parse(sql)[0]\n\nrepos\\sqlparse\\tests\\test_parse.py:510: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation \';\' at 0x1DF619E2920>, ttype = Token.Punctuation\nvalues = \'[\', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = \'|\'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: \'Token\' object has no attribute \'token\'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError', 'def test_configurable_regex():\n        lex = Lexer.get_default_instance()\n        lex.clear()\n    \n        my_regex = (r""ZORDER\\s+BY\\b"", sqlparse.tokens.Keyword)\n    \n        lex.set_SQL_REGEX(\n            keywords.SQL_REGEX[:38]\n            + [my_regex]\n            + keywords.SQL_REGEX[38:]\n        )\n        lex.add_keywords(keywords.KEYWORDS_COMMON)\n        lex.add_keywords(keywords.KEYWORDS_ORACLE)\n        lex.add_keywords(keywords.KEYWORDS_PLPGSQL)\n        lex.add_keywords(keywords.KEYWORDS_HQL)\n        lex.add_keywords(keywords.KEYWORDS_MSACCESS)\n        lex.add_keywords(keywords.KEYWORDS)\n    \n>       tokens = sqlparse.parse(""select * from foo zorder by bar;"")[0]\n\nrepos\\sqlparse\\tests\\test_parse.py:572: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation \';\' at 0x1DF619E2B00>, ttype = Token.Punctuation\nvalues = \'[\', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = \'|\'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: \'Token\' object has no attribute \'token\'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError', ""sql = '->'\n\n    @pytest.mark.parametrize('sql', [\n        '->', '->>', '#>', '#>>',\n        '@>', '<@',\n        # leaving ? out for now, they're somehow ambiguous as placeholders\n        # '?', '?|', '?&',\n        '||', '-', '#-'\n    ])\n    def test_json_operators(sql):\n>       p = sqlparse.parse(sql)\n\nrepos\\sqlparse\\tests\\test_parse.py:592: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:167: in group_period\n    _group(tlist, sql.Identifier, match, valid_prev, valid_next, post)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:476: in _group\n    if match(token):\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:145: in match\n    if token.match(ttype, value):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Operator '->' at 0x1DF619E0460>, ttype = Token.Operator, values = '->'\nregex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""sql = '->>'\n\n    @pytest.mark.parametrize('sql', [\n        '->', '->>', '#>', '#>>',\n        '@>', '<@',\n        # leaving ? out for now, they're somehow ambiguous as placeholders\n        # '?', '?|', '?&',\n        '||', '-', '#-'\n    ])\n    def test_json_operators(sql):\n>       p = sqlparse.parse(sql)\n\nrepos\\sqlparse\\tests\\test_parse.py:592: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:167: in group_period\n    _group(tlist, sql.Identifier, match, valid_prev, valid_next, post)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:476: in _group\n    if match(token):\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:145: in match\n    if token.match(ttype, value):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Operator '->>' at 0x1DF619E0A00>, ttype = Token.Operator, values = '->'\nregex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""sql = '#>'\n\n    @pytest.mark.parametrize('sql', [\n        '->', '->>', '#>', '#>>',\n        '@>', '<@',\n        # leaving ? out for now, they're somehow ambiguous as placeholders\n        # '?', '?|', '?&',\n        '||', '-', '#-'\n    ])\n    def test_json_operators(sql):\n>       p = sqlparse.parse(sql)\n\nrepos\\sqlparse\\tests\\test_parse.py:592: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:167: in group_period\n    _group(tlist, sql.Identifier, match, valid_prev, valid_next, post)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:476: in _group\n    if match(token):\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:145: in match\n    if token.match(ttype, value):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Operator '#>' at 0x1DF619E0FA0>, ttype = Token.Operator, values = '->'\nregex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""sql = '#>>'\n\n    @pytest.mark.parametrize('sql', [\n        '->', '->>', '#>', '#>>',\n        '@>', '<@',\n        # leaving ? out for now, they're somehow ambiguous as placeholders\n        # '?', '?|', '?&',\n        '||', '-', '#-'\n    ])\n    def test_json_operators(sql):\n>       p = sqlparse.parse(sql)\n\nrepos\\sqlparse\\tests\\test_parse.py:592: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:167: in group_period\n    _group(tlist, sql.Identifier, match, valid_prev, valid_next, post)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:476: in _group\n    if match(token):\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:145: in match\n    if token.match(ttype, value):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Operator '#>>' at 0x1DF619E1F00>, ttype = Token.Operator, values = '->'\nregex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""sql = '@>'\n\n    @pytest.mark.parametrize('sql', [\n        '->', '->>', '#>', '#>>',\n        '@>', '<@',\n        # leaving ? out for now, they're somehow ambiguous as placeholders\n        # '?', '?|', '?&',\n        '||', '-', '#-'\n    ])\n    def test_json_operators(sql):\n>       p = sqlparse.parse(sql)\n\nrepos\\sqlparse\\tests\\test_parse.py:592: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:167: in group_period\n    _group(tlist, sql.Identifier, match, valid_prev, valid_next, post)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:476: in _group\n    if match(token):\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:145: in match\n    if token.match(ttype, value):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Operator '@>' at 0x1DF619E3E20>, ttype = Token.Operator, values = '->'\nregex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""sql = '<@'\n\n    @pytest.mark.parametrize('sql', [\n        '->', '->>', '#>', '#>>',\n        '@>', '<@',\n        # leaving ? out for now, they're somehow ambiguous as placeholders\n        # '?', '?|', '?&',\n        '||', '-', '#-'\n    ])\n    def test_json_operators(sql):\n>       p = sqlparse.parse(sql)\n\nrepos\\sqlparse\\tests\\test_parse.py:592: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:167: in group_period\n    _group(tlist, sql.Identifier, match, valid_prev, valid_next, post)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:476: in _group\n    if match(token):\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:145: in match\n    if token.match(ttype, value):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Operator '<@' at 0x1DF619E2DA0>, ttype = Token.Operator, values = '->'\nregex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""sql = '||'\n\n    @pytest.mark.parametrize('sql', [\n        '->', '->>', '#>', '#>>',\n        '@>', '<@',\n        # leaving ? out for now, they're somehow ambiguous as placeholders\n        # '?', '?|', '?&',\n        '||', '-', '#-'\n    ])\n    def test_json_operators(sql):\n>       p = sqlparse.parse(sql)\n\nrepos\\sqlparse\\tests\\test_parse.py:592: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:167: in group_period\n    _group(tlist, sql.Identifier, match, valid_prev, valid_next, post)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:476: in _group\n    if match(token):\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:145: in match\n    if token.match(ttype, value):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Operator '||' at 0x1DF619128C0>, ttype = Token.Operator, values = '->'\nregex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""sql = '-'\n\n    @pytest.mark.parametrize('sql', [\n        '->', '->>', '#>', '#>>',\n        '@>', '<@',\n        # leaving ? out for now, they're somehow ambiguous as placeholders\n        # '?', '?|', '?&',\n        '||', '-', '#-'\n    ])\n    def test_json_operators(sql):\n>       p = sqlparse.parse(sql)\n\nrepos\\sqlparse\\tests\\test_parse.py:592: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:167: in group_period\n    _group(tlist, sql.Identifier, match, valid_prev, valid_next, post)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:476: in _group\n    if match(token):\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:145: in match\n    if token.match(ttype, value):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Operator '-' at 0x1DF619130A0>, ttype = Token.Operator, values = '->'\nregex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""sql = '#-'\n\n    @pytest.mark.parametrize('sql', [\n        '->', '->>', '#>', '#>>',\n        '@>', '<@',\n        # leaving ? out for now, they're somehow ambiguous as placeholders\n        # '?', '?|', '?&',\n        '||', '-', '#-'\n    ])\n    def test_json_operators(sql):\n>       p = sqlparse.parse(sql)\n\nrepos\\sqlparse\\tests\\test_parse.py:592: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:167: in group_period\n    _group(tlist, sql.Identifier, match, valid_prev, valid_next, post)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:476: in _group\n    if match(token):\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:145: in match\n    if token.match(ttype, value):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Operator '#-' at 0x1DF61913B80>, ttype = Token.Operator, values = '->'\nregex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""def test_issue9():\n        # make sure where doesn't consume parenthesis\n>       p = sqlparse.parse('(where 1)')[0]\n\nrepos\\sqlparse\\tests\\test_regressions.py:13: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation '(' at 0x1DF61913BE0>, ttype = Token.Punctuation\nvalues = '[', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", 'def test_issue13():\n>       parsed = sqlparse.parse(""select \'one\';\\n""\n                                ""select \'two\\\\\'\';\\n""\n                                ""select \'three\';"")\n\nrepos\\sqlparse\\tests\\test_regressions.py:24: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation \';\' at 0x1DF6191B100>, ttype = Token.Punctuation\nvalues = \'[\', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = \'|\'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: \'Token\' object has no attribute \'token\'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError', 'value = \'create\'\n\n    @pytest.mark.parametrize(\'value\', [\'create\', \'CREATE\'])\n    def test_issue34(value):\n        t = sqlparse.parse(""create"")[0].token_first()\n>       assert t.match(T.Keyword.DDL, value) is True\n\nrepos\\sqlparse\\tests\\test_regressions.py:43: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <DDL \'create\' at 0x1DF6191BE80>, ttype = Token.Keyword.DDL\nvalues = \'create\', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = \'|\'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: \'Token\' object has no attribute \'token\'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError', 'value = \'CREATE\'\n\n    @pytest.mark.parametrize(\'value\', [\'create\', \'CREATE\'])\n    def test_issue34(value):\n        t = sqlparse.parse(""create"")[0].token_first()\n>       assert t.match(T.Keyword.DDL, value) is True\n\nrepos\\sqlparse\\tests\\test_regressions.py:43: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <DDL \'create\' at 0x1DF6191BEE0>, ttype = Token.Keyword.DDL\nvalues = \'CREATE\', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = \'|\'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: \'Token\' object has no attribute \'token\'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError', 'def test_issue35():\n        # missing space before LIMIT. Updated for #321\n>       sql = sqlparse.format(""select * from foo where bar = 1 limit 1"",\n                              reindent=True)\n\nrepos\\sqlparse\\tests\\test_regressions.py:48: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return \'\'.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:61: in group_case\n    _group_matching(tlist, sql.Case)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Keyword \'from\' at 0x1DF6191BB80>, ttype = Token.Keyword, values = \'CASE\'\nregex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = \'|\'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: \'Token\' object has no attribute \'token\'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError', 'def test_issue38():\n>       sql = sqlparse.format(""SELECT foo; -- comment"", strip_comments=True)\n\nrepos\\sqlparse\\tests\\test_regressions.py:58: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return \'\'.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation \';\' at 0x1DF619197E0>, ttype = Token.Punctuation\nvalues = \'[\', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = \'|\'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: \'Token\' object has no attribute \'token\'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError', ""def test_issue39():\n>       p = sqlparse.parse('select user.id from user')[0]\n\nrepos\\sqlparse\\tests\\test_regressions.py:65: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation '.' at 0x1DF6191A500>, ttype = Token.Punctuation\nvalues = '[', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""def test_issue40():\n        # make sure identifier lists in subselects are grouped\n>       p = sqlparse.parse('SELECT id, name FROM '\n                           '(SELECT id, name FROM bar) as foo')[0]\n\nrepos\\sqlparse\\tests\\test_regressions.py:77: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation ',' at 0x1DF6188FBE0>, ttype = Token.Punctuation\nvalues = '[', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", 's = \'select x.y::text as z from foo\', func_name = \'get_name\', result = \'z\'\n\n    @pytest.mark.parametrize(\'s\', [\'select x.y::text as z from foo\',\n                                   \'select x.y::text as ""z"" from foo\',\n                                   \'select x.""y""::text as z from foo\',\n                                   \'select x.""y""::text as ""z"" from foo\',\n                                   \'select ""x"".y::text as z from foo\',\n                                   \'select ""x"".y::text as ""z"" from foo\',\n                                   \'select ""x"".""y""::text as z from foo\',\n                                   \'select ""x"".""y""::text as ""z"" from foo\'])\n    @pytest.mark.parametrize(\'func_name, result\', [(\'get_name\', \'z\'),\n                                                   (\'get_real_name\', \'y\'),\n                                                   (\'get_parent_name\', \'x\'),\n                                                   (\'get_alias\', \'z\'),\n                                                   (\'get_typecast\', \'text\')])\n    def test_issue78(s, func_name, result):\n        # the bug author provided this nice examples, let\'s use them!\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_regressions.py:120: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation \'.\' at 0x1DF619C46A0>, ttype = Token.Punctuation\nvalues = \'[\', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = \'|\'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: \'Token\' object has no attribute \'token\'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError', 's = \'select x.y::text as ""z"" from foo\', func_name = \'get_name\', result = \'z\'\n\n    @pytest.mark.parametrize(\'s\', [\'select x.y::text as z from foo\',\n                                   \'select x.y::text as ""z"" from foo\',\n                                   \'select x.""y""::text as z from foo\',\n                                   \'select x.""y""::text as ""z"" from foo\',\n                                   \'select ""x"".y::text as z from foo\',\n                                   \'select ""x"".y::text as ""z"" from foo\',\n                                   \'select ""x"".""y""::text as z from foo\',\n                                   \'select ""x"".""y""::text as ""z"" from foo\'])\n    @pytest.mark.parametrize(\'func_name, result\', [(\'get_name\', \'z\'),\n                                                   (\'get_real_name\', \'y\'),\n                                                   (\'get_parent_name\', \'x\'),\n                                                   (\'get_alias\', \'z\'),\n                                                   (\'get_typecast\', \'text\')])\n    def test_issue78(s, func_name, result):\n        # the bug author provided this nice examples, let\'s use them!\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_regressions.py:120: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation \'.\' at 0x1DF619EA200>, ttype = Token.Punctuation\nvalues = \'[\', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = \'|\'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: \'Token\' object has no attribute \'token\'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError', 's = \'select x.""y""::text as z from foo\', func_name = \'get_name\', result = \'z\'\n\n    @pytest.mark.parametrize(\'s\', [\'select x.y::text as z from foo\',\n                                   \'select x.y::text as ""z"" from foo\',\n                                   \'select x.""y""::text as z from foo\',\n                                   \'select x.""y""::text as ""z"" from foo\',\n                                   \'select ""x"".y::text as z from foo\',\n                                   \'select ""x"".y::text as ""z"" from foo\',\n                                   \'select ""x"".""y""::text as z from foo\',\n                                   \'select ""x"".""y""::text as ""z"" from foo\'])\n    @pytest.mark.parametrize(\'func_name, result\', [(\'get_name\', \'z\'),\n                                                   (\'get_real_name\', \'y\'),\n                                                   (\'get_parent_name\', \'x\'),\n                                                   (\'get_alias\', \'z\'),\n                                                   (\'get_typecast\', \'text\')])\n    def test_issue78(s, func_name, result):\n        # the bug author provided this nice examples, let\'s use them!\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_regressions.py:120: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation \'.\' at 0x1DF619E39A0>, ttype = Token.Punctuation\nvalues = \'[\', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = \'|\'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: \'Token\' object has no attribute \'token\'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError', 's = \'select x.""y""::text as ""z"" from foo\', func_name = \'get_name\', result = \'z\'\n\n    @pytest.mark.parametrize(\'s\', [\'select x.y::text as z from foo\',\n                                   \'select x.y::text as ""z"" from foo\',\n                                   \'select x.""y""::text as z from foo\',\n                                   \'select x.""y""::text as ""z"" from foo\',\n                                   \'select ""x"".y::text as z from foo\',\n                                   \'select ""x"".y::text as ""z"" from foo\',\n                                   \'select ""x"".""y""::text as z from foo\',\n                                   \'select ""x"".""y""::text as ""z"" from foo\'])\n    @pytest.mark.parametrize(\'func_name, result\', [(\'get_name\', \'z\'),\n                                                   (\'get_real_name\', \'y\'),\n                                                   (\'get_parent_name\', \'x\'),\n                                                   (\'get_alias\', \'z\'),\n                                                   (\'get_typecast\', \'text\')])\n    def test_issue78(s, func_name, result):\n        # the bug author provided this nice examples, let\'s use them!\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_regressions.py:120: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation \'.\' at 0x1DF61918F40>, ttype = Token.Punctuation\nvalues = \'[\', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = \'|\'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: \'Token\' object has no attribute \'token\'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError', 's = \'select ""x"".y::text as z from foo\', func_name = \'get_name\', result = \'z\'\n\n    @pytest.mark.parametrize(\'s\', [\'select x.y::text as z from foo\',\n                                   \'select x.y::text as ""z"" from foo\',\n                                   \'select x.""y""::text as z from foo\',\n                                   \'select x.""y""::text as ""z"" from foo\',\n                                   \'select ""x"".y::text as z from foo\',\n                                   \'select ""x"".y::text as ""z"" from foo\',\n                                   \'select ""x"".""y""::text as z from foo\',\n                                   \'select ""x"".""y""::text as ""z"" from foo\'])\n    @pytest.mark.parametrize(\'func_name, result\', [(\'get_name\', \'z\'),\n                                                   (\'get_real_name\', \'y\'),\n                                                   (\'get_parent_name\', \'x\'),\n                                                   (\'get_alias\', \'z\'),\n                                                   (\'get_typecast\', \'text\')])\n    def test_issue78(s, func_name, result):\n        # the bug author provided this nice examples, let\'s use them!\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_regressions.py:120: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation \'.\' at 0x1DF618BF3A0>, ttype = Token.Punctuation\nvalues = \'[\', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = \'|\'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: \'Token\' object has no attribute \'token\'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError', 's = \'select ""x"".y::text as ""z"" from foo\', func_name = \'get_name\', result = \'z\'\n\n    @pytest.mark.parametrize(\'s\', [\'select x.y::text as z from foo\',\n                                   \'select x.y::text as ""z"" from foo\',\n                                   \'select x.""y""::text as z from foo\',\n                                   \'select x.""y""::text as ""z"" from foo\',\n                                   \'select ""x"".y::text as z from foo\',\n                                   \'select ""x"".y::text as ""z"" from foo\',\n                                   \'select ""x"".""y""::text as z from foo\',\n                                   \'select ""x"".""y""::text as ""z"" from foo\'])\n    @pytest.mark.parametrize(\'func_name, result\', [(\'get_name\', \'z\'),\n                                                   (\'get_real_name\', \'y\'),\n                                                   (\'get_parent_name\', \'x\'),\n                                                   (\'get_alias\', \'z\'),\n                                                   (\'get_typecast\', \'text\')])\n    def test_issue78(s, func_name, result):\n        # the bug author provided this nice examples, let\'s use them!\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_regressions.py:120: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation \'.\' at 0x1DF619E3B20>, ttype = Token.Punctuation\nvalues = \'[\', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = \'|\'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: \'Token\' object has no attribute \'token\'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError', 's = \'select ""x"".""y""::text as z from foo\', func_name = \'get_name\', result = \'z\'\n\n    @pytest.mark.parametrize(\'s\', [\'select x.y::text as z from foo\',\n                                   \'select x.y::text as ""z"" from foo\',\n                                   \'select x.""y""::text as z from foo\',\n                                   \'select x.""y""::text as ""z"" from foo\',\n                                   \'select ""x"".y::text as z from foo\',\n                                   \'select ""x"".y::text as ""z"" from foo\',\n                                   \'select ""x"".""y""::text as z from foo\',\n                                   \'select ""x"".""y""::text as ""z"" from foo\'])\n    @pytest.mark.parametrize(\'func_name, result\', [(\'get_name\', \'z\'),\n                                                   (\'get_real_name\', \'y\'),\n                                                   (\'get_parent_name\', \'x\'),\n                                                   (\'get_alias\', \'z\'),\n                                                   (\'get_typecast\', \'text\')])\n    def test_issue78(s, func_name, result):\n        # the bug author provided this nice examples, let\'s use them!\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_regressions.py:120: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation \'.\' at 0x1DF618BFC40>, ttype = Token.Punctuation\nvalues = \'[\', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = \'|\'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: \'Token\' object has no attribute \'token\'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError', 's = \'select ""x"".""y""::text as ""z"" from foo\', func_name = \'get_name\', result = \'z\'\n\n    @pytest.mark.parametrize(\'s\', [\'select x.y::text as z from foo\',\n                                   \'select x.y::text as ""z"" from foo\',\n                                   \'select x.""y""::text as z from foo\',\n                                   \'select x.""y""::text as ""z"" from foo\',\n                                   \'select ""x"".y::text as z from foo\',\n                                   \'select ""x"".y::text as ""z"" from foo\',\n                                   \'select ""x"".""y""::text as z from foo\',\n                                   \'select ""x"".""y""::text as ""z"" from foo\'])\n    @pytest.mark.parametrize(\'func_name, result\', [(\'get_name\', \'z\'),\n                                                   (\'get_real_name\', \'y\'),\n                                                   (\'get_parent_name\', \'x\'),\n                                                   (\'get_alias\', \'z\'),\n                                                   (\'get_typecast\', \'text\')])\n    def test_issue78(s, func_name, result):\n        # the bug author provided this nice examples, let\'s use them!\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_regressions.py:120: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation \'.\' at 0x1DF618BFA00>, ttype = Token.Punctuation\nvalues = \'[\', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = \'|\'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: \'Token\' object has no attribute \'token\'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError', 's = \'select x.y::text as z from foo\', func_name = \'get_real_name\', result = \'y\'\n\n    @pytest.mark.parametrize(\'s\', [\'select x.y::text as z from foo\',\n                                   \'select x.y::text as ""z"" from foo\',\n                                   \'select x.""y""::text as z from foo\',\n                                   \'select x.""y""::text as ""z"" from foo\',\n                                   \'select ""x"".y::text as z from foo\',\n                                   \'select ""x"".y::text as ""z"" from foo\',\n                                   \'select ""x"".""y""::text as z from foo\',\n                                   \'select ""x"".""y""::text as ""z"" from foo\'])\n    @pytest.mark.parametrize(\'func_name, result\', [(\'get_name\', \'z\'),\n                                                   (\'get_real_name\', \'y\'),\n                                                   (\'get_parent_name\', \'x\'),\n                                                   (\'get_alias\', \'z\'),\n                                                   (\'get_typecast\', \'text\')])\n    def test_issue78(s, func_name, result):\n        # the bug author provided this nice examples, let\'s use them!\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_regressions.py:120: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation \'.\' at 0x1DF618BD3C0>, ttype = Token.Punctuation\nvalues = \'[\', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = \'|\'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: \'Token\' object has no attribute \'token\'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError', 's = \'select x.y::text as ""z"" from foo\', func_name = \'get_real_name\'\nresult = \'y\'\n\n    @pytest.mark.parametrize(\'s\', [\'select x.y::text as z from foo\',\n                                   \'select x.y::text as ""z"" from foo\',\n                                   \'select x.""y""::text as z from foo\',\n                                   \'select x.""y""::text as ""z"" from foo\',\n                                   \'select ""x"".y::text as z from foo\',\n                                   \'select ""x"".y::text as ""z"" from foo\',\n                                   \'select ""x"".""y""::text as z from foo\',\n                                   \'select ""x"".""y""::text as ""z"" from foo\'])\n    @pytest.mark.parametrize(\'func_name, result\', [(\'get_name\', \'z\'),\n                                                   (\'get_real_name\', \'y\'),\n                                                   (\'get_parent_name\', \'x\'),\n                                                   (\'get_alias\', \'z\'),\n                                                   (\'get_typecast\', \'text\')])\n    def test_issue78(s, func_name, result):\n        # the bug author provided this nice examples, let\'s use them!\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_regressions.py:120: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation \'.\' at 0x1DF618BFB80>, ttype = Token.Punctuation\nvalues = \'[\', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = \'|\'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: \'Token\' object has no attribute \'token\'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError', 's = \'select x.""y""::text as z from foo\', func_name = \'get_real_name\'\nresult = \'y\'\n\n    @pytest.mark.parametrize(\'s\', [\'select x.y::text as z from foo\',\n                                   \'select x.y::text as ""z"" from foo\',\n                                   \'select x.""y""::text as z from foo\',\n                                   \'select x.""y""::text as ""z"" from foo\',\n                                   \'select ""x"".y::text as z from foo\',\n                                   \'select ""x"".y::text as ""z"" from foo\',\n                                   \'select ""x"".""y""::text as z from foo\',\n                                   \'select ""x"".""y""::text as ""z"" from foo\'])\n    @pytest.mark.parametrize(\'func_name, result\', [(\'get_name\', \'z\'),\n                                                   (\'get_real_name\', \'y\'),\n                                                   (\'get_parent_name\', \'x\'),\n                                                   (\'get_alias\', \'z\'),\n                                                   (\'get_typecast\', \'text\')])\n    def test_issue78(s, func_name, result):\n        # the bug author provided this nice examples, let\'s use them!\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_regressions.py:120: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation \'.\' at 0x1DF619D2D40>, ttype = Token.Punctuation\nvalues = \'[\', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = \'|\'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: \'Token\' object has no attribute \'token\'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError', 's = \'select x.""y""::text as ""z"" from foo\', func_name = \'get_real_name\'\nresult = \'y\'\n\n    @pytest.mark.parametrize(\'s\', [\'select x.y::text as z from foo\',\n                                   \'select x.y::text as ""z"" from foo\',\n                                   \'select x.""y""::text as z from foo\',\n                                   \'select x.""y""::text as ""z"" from foo\',\n                                   \'select ""x"".y::text as z from foo\',\n                                   \'select ""x"".y::text as ""z"" from foo\',\n                                   \'select ""x"".""y""::text as z from foo\',\n                                   \'select ""x"".""y""::text as ""z"" from foo\'])\n    @pytest.mark.parametrize(\'func_name, result\', [(\'get_name\', \'z\'),\n                                                   (\'get_real_name\', \'y\'),\n                                                   (\'get_parent_name\', \'x\'),\n                                                   (\'get_alias\', \'z\'),\n                                                   (\'get_typecast\', \'text\')])\n    def test_issue78(s, func_name, result):\n        # the bug author provided this nice examples, let\'s use them!\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_regressions.py:120: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation \'.\' at 0x1DF6197ECE0>, ttype = Token.Punctuation\nvalues = \'[\', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = \'|\'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: \'Token\' object has no attribute \'token\'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError', 's = \'select ""x"".y::text as z from foo\', func_name = \'get_real_name\'\nresult = \'y\'\n\n    @pytest.mark.parametrize(\'s\', [\'select x.y::text as z from foo\',\n                                   \'select x.y::text as ""z"" from foo\',\n                                   \'select x.""y""::text as z from foo\',\n                                   \'select x.""y""::text as ""z"" from foo\',\n                                   \'select ""x"".y::text as z from foo\',\n                                   \'select ""x"".y::text as ""z"" from foo\',\n                                   \'select ""x"".""y""::text as z from foo\',\n                                   \'select ""x"".""y""::text as ""z"" from foo\'])\n    @pytest.mark.parametrize(\'func_name, result\', [(\'get_name\', \'z\'),\n                                                   (\'get_real_name\', \'y\'),\n                                                   (\'get_parent_name\', \'x\'),\n                                                   (\'get_alias\', \'z\'),\n                                                   (\'get_typecast\', \'text\')])\n    def test_issue78(s, func_name, result):\n        # the bug author provided this nice examples, let\'s use them!\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_regressions.py:120: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation \'.\' at 0x1DF6197FB20>, ttype = Token.Punctuation\nvalues = \'[\', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = \'|\'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: \'Token\' object has no attribute \'token\'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError', 's = \'select ""x"".y::text as ""z"" from foo\', func_name = \'get_real_name\'\nresult = \'y\'\n\n    @pytest.mark.parametrize(\'s\', [\'select x.y::text as z from foo\',\n                                   \'select x.y::text as ""z"" from foo\',\n                                   \'select x.""y""::text as z from foo\',\n                                   \'select x.""y""::text as ""z"" from foo\',\n                                   \'select ""x"".y::text as z from foo\',\n                                   \'select ""x"".y::text as ""z"" from foo\',\n                                   \'select ""x"".""y""::text as z from foo\',\n                                   \'select ""x"".""y""::text as ""z"" from foo\'])\n    @pytest.mark.parametrize(\'func_name, result\', [(\'get_name\', \'z\'),\n                                                   (\'get_real_name\', \'y\'),\n                                                   (\'get_parent_name\', \'x\'),\n                                                   (\'get_alias\', \'z\'),\n                                                   (\'get_typecast\', \'text\')])\n    def test_issue78(s, func_name, result):\n        # the bug author provided this nice examples, let\'s use them!\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_regressions.py:120: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation \'.\' at 0x1DF618BDBA0>, ttype = Token.Punctuation\nvalues = \'[\', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = \'|\'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: \'Token\' object has no attribute \'token\'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError', 's = \'select ""x"".""y""::text as z from foo\', func_name = \'get_real_name\'\nresult = \'y\'\n\n    @pytest.mark.parametrize(\'s\', [\'select x.y::text as z from foo\',\n                                   \'select x.y::text as ""z"" from foo\',\n                                   \'select x.""y""::text as z from foo\',\n                                   \'select x.""y""::text as ""z"" from foo\',\n                                   \'select ""x"".y::text as z from foo\',\n                                   \'select ""x"".y::text as ""z"" from foo\',\n                                   \'select ""x"".""y""::text as z from foo\',\n                                   \'select ""x"".""y""::text as ""z"" from foo\'])\n    @pytest.mark.parametrize(\'func_name, result\', [(\'get_name\', \'z\'),\n                                                   (\'get_real_name\', \'y\'),\n                                                   (\'get_parent_name\', \'x\'),\n                                                   (\'get_alias\', \'z\'),\n                                                   (\'get_typecast\', \'text\')])\n    def test_issue78(s, func_name, result):\n        # the bug author provided this nice examples, let\'s use them!\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_regressions.py:120: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation \'.\' at 0x1DF6197EEC0>, ttype = Token.Punctuation\nvalues = \'[\', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = \'|\'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: \'Token\' object has no attribute \'token\'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError', 's = \'select ""x"".""y""::text as ""z"" from foo\', func_name = \'get_real_name\'\nresult = \'y\'\n\n    @pytest.mark.parametrize(\'s\', [\'select x.y::text as z from foo\',\n                                   \'select x.y::text as ""z"" from foo\',\n                                   \'select x.""y""::text as z from foo\',\n                                   \'select x.""y""::text as ""z"" from foo\',\n                                   \'select ""x"".y::text as z from foo\',\n                                   \'select ""x"".y::text as ""z"" from foo\',\n                                   \'select ""x"".""y""::text as z from foo\',\n                                   \'select ""x"".""y""::text as ""z"" from foo\'])\n    @pytest.mark.parametrize(\'func_name, result\', [(\'get_name\', \'z\'),\n                                                   (\'get_real_name\', \'y\'),\n                                                   (\'get_parent_name\', \'x\'),\n                                                   (\'get_alias\', \'z\'),\n                                                   (\'get_typecast\', \'text\')])\n    def test_issue78(s, func_name, result):\n        # the bug author provided this nice examples, let\'s use them!\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_regressions.py:120: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation \'.\' at 0x1DF6197C940>, ttype = Token.Punctuation\nvalues = \'[\', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = \'|\'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: \'Token\' object has no attribute \'token\'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError', 's = \'select x.y::text as z from foo\', func_name = \'get_parent_name\'\nresult = \'x\'\n\n    @pytest.mark.parametrize(\'s\', [\'select x.y::text as z from foo\',\n                                   \'select x.y::text as ""z"" from foo\',\n                                   \'select x.""y""::text as z from foo\',\n                                   \'select x.""y""::text as ""z"" from foo\',\n                                   \'select ""x"".y::text as z from foo\',\n                                   \'select ""x"".y::text as ""z"" from foo\',\n                                   \'select ""x"".""y""::text as z from foo\',\n                                   \'select ""x"".""y""::text as ""z"" from foo\'])\n    @pytest.mark.parametrize(\'func_name, result\', [(\'get_name\', \'z\'),\n                                                   (\'get_real_name\', \'y\'),\n                                                   (\'get_parent_name\', \'x\'),\n                                                   (\'get_alias\', \'z\'),\n                                                   (\'get_typecast\', \'text\')])\n    def test_issue78(s, func_name, result):\n        # the bug author provided this nice examples, let\'s use them!\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_regressions.py:120: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation \'.\' at 0x1DF6197DA80>, ttype = Token.Punctuation\nvalues = \'[\', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = \'|\'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: \'Token\' object has no attribute \'token\'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError', 's = \'select x.y::text as ""z"" from foo\', func_name = \'get_parent_name\'\nresult = \'x\'\n\n    @pytest.mark.parametrize(\'s\', [\'select x.y::text as z from foo\',\n                                   \'select x.y::text as ""z"" from foo\',\n                                   \'select x.""y""::text as z from foo\',\n                                   \'select x.""y""::text as ""z"" from foo\',\n                                   \'select ""x"".y::text as z from foo\',\n                                   \'select ""x"".y::text as ""z"" from foo\',\n                                   \'select ""x"".""y""::text as z from foo\',\n                                   \'select ""x"".""y""::text as ""z"" from foo\'])\n    @pytest.mark.parametrize(\'func_name, result\', [(\'get_name\', \'z\'),\n                                                   (\'get_real_name\', \'y\'),\n                                                   (\'get_parent_name\', \'x\'),\n                                                   (\'get_alias\', \'z\'),\n                                                   (\'get_typecast\', \'text\')])\n    def test_issue78(s, func_name, result):\n        # the bug author provided this nice examples, let\'s use them!\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_regressions.py:120: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation \'.\' at 0x1DF6197D300>, ttype = Token.Punctuation\nvalues = \'[\', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = \'|\'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: \'Token\' object has no attribute \'token\'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError', 's = \'select x.""y""::text as z from foo\', func_name = \'get_parent_name\'\nresult = \'x\'\n\n    @pytest.mark.parametrize(\'s\', [\'select x.y::text as z from foo\',\n                                   \'select x.y::text as ""z"" from foo\',\n                                   \'select x.""y""::text as z from foo\',\n                                   \'select x.""y""::text as ""z"" from foo\',\n                                   \'select ""x"".y::text as z from foo\',\n                                   \'select ""x"".y::text as ""z"" from foo\',\n                                   \'select ""x"".""y""::text as z from foo\',\n                                   \'select ""x"".""y""::text as ""z"" from foo\'])\n    @pytest.mark.parametrize(\'func_name, result\', [(\'get_name\', \'z\'),\n                                                   (\'get_real_name\', \'y\'),\n                                                   (\'get_parent_name\', \'x\'),\n                                                   (\'get_alias\', \'z\'),\n                                                   (\'get_typecast\', \'text\')])\n    def test_issue78(s, func_name, result):\n        # the bug author provided this nice examples, let\'s use them!\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_regressions.py:120: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation \'.\' at 0x1DF61A071C0>, ttype = Token.Punctuation\nvalues = \'[\', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = \'|\'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: \'Token\' object has no attribute \'token\'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError', 's = \'select x.""y""::text as ""z"" from foo\', func_name = \'get_parent_name\'\nresult = \'x\'\n\n    @pytest.mark.parametrize(\'s\', [\'select x.y::text as z from foo\',\n                                   \'select x.y::text as ""z"" from foo\',\n                                   \'select x.""y""::text as z from foo\',\n                                   \'select x.""y""::text as ""z"" from foo\',\n                                   \'select ""x"".y::text as z from foo\',\n                                   \'select ""x"".y::text as ""z"" from foo\',\n                                   \'select ""x"".""y""::text as z from foo\',\n                                   \'select ""x"".""y""::text as ""z"" from foo\'])\n    @pytest.mark.parametrize(\'func_name, result\', [(\'get_name\', \'z\'),\n                                                   (\'get_real_name\', \'y\'),\n                                                   (\'get_parent_name\', \'x\'),\n                                                   (\'get_alias\', \'z\'),\n                                                   (\'get_typecast\', \'text\')])\n    def test_issue78(s, func_name, result):\n        # the bug author provided this nice examples, let\'s use them!\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_regressions.py:120: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation \'.\' at 0x1DF61A076A0>, ttype = Token.Punctuation\nvalues = \'[\', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = \'|\'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: \'Token\' object has no attribute \'token\'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError', 's = \'select ""x"".y::text as z from foo\', func_name = \'get_parent_name\'\nresult = \'x\'\n\n    @pytest.mark.parametrize(\'s\', [\'select x.y::text as z from foo\',\n                                   \'select x.y::text as ""z"" from foo\',\n                                   \'select x.""y""::text as z from foo\',\n                                   \'select x.""y""::text as ""z"" from foo\',\n                                   \'select ""x"".y::text as z from foo\',\n                                   \'select ""x"".y::text as ""z"" from foo\',\n                                   \'select ""x"".""y""::text as z from foo\',\n                                   \'select ""x"".""y""::text as ""z"" from foo\'])\n    @pytest.mark.parametrize(\'func_name, result\', [(\'get_name\', \'z\'),\n                                                   (\'get_real_name\', \'y\'),\n                                                   (\'get_parent_name\', \'x\'),\n                                                   (\'get_alias\', \'z\'),\n                                                   (\'get_typecast\', \'text\')])\n    def test_issue78(s, func_name, result):\n        # the bug author provided this nice examples, let\'s use them!\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_regressions.py:120: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation \'.\' at 0x1DF61A07460>, ttype = Token.Punctuation\nvalues = \'[\', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = \'|\'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: \'Token\' object has no attribute \'token\'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError', 's = \'select ""x"".y::text as ""z"" from foo\', func_name = \'get_parent_name\'\nresult = \'x\'\n\n    @pytest.mark.parametrize(\'s\', [\'select x.y::text as z from foo\',\n                                   \'select x.y::text as ""z"" from foo\',\n                                   \'select x.""y""::text as z from foo\',\n                                   \'select x.""y""::text as ""z"" from foo\',\n                                   \'select ""x"".y::text as z from foo\',\n                                   \'select ""x"".y::text as ""z"" from foo\',\n                                   \'select ""x"".""y""::text as z from foo\',\n                                   \'select ""x"".""y""::text as ""z"" from foo\'])\n    @pytest.mark.parametrize(\'func_name, result\', [(\'get_name\', \'z\'),\n                                                   (\'get_real_name\', \'y\'),\n                                                   (\'get_parent_name\', \'x\'),\n                                                   (\'get_alias\', \'z\'),\n                                                   (\'get_typecast\', \'text\')])\n    def test_issue78(s, func_name, result):\n        # the bug author provided this nice examples, let\'s use them!\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_regressions.py:120: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation \'.\' at 0x1DF61A04100>, ttype = Token.Punctuation\nvalues = \'[\', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = \'|\'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: \'Token\' object has no attribute \'token\'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError', 's = \'select ""x"".""y""::text as z from foo\', func_name = \'get_parent_name\'\nresult = \'x\'\n\n    @pytest.mark.parametrize(\'s\', [\'select x.y::text as z from foo\',\n                                   \'select x.y::text as ""z"" from foo\',\n                                   \'select x.""y""::text as z from foo\',\n                                   \'select x.""y""::text as ""z"" from foo\',\n                                   \'select ""x"".y::text as z from foo\',\n                                   \'select ""x"".y::text as ""z"" from foo\',\n                                   \'select ""x"".""y""::text as z from foo\',\n                                   \'select ""x"".""y""::text as ""z"" from foo\'])\n    @pytest.mark.parametrize(\'func_name, result\', [(\'get_name\', \'z\'),\n                                                   (\'get_real_name\', \'y\'),\n                                                   (\'get_parent_name\', \'x\'),\n                                                   (\'get_alias\', \'z\'),\n                                                   (\'get_typecast\', \'text\')])\n    def test_issue78(s, func_name, result):\n        # the bug author provided this nice examples, let\'s use them!\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_regressions.py:120: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation \'.\' at 0x1DF61A051E0>, ttype = Token.Punctuation\nvalues = \'[\', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = \'|\'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: \'Token\' object has no attribute \'token\'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError', 's = \'select ""x"".""y""::text as ""z"" from foo\', func_name = \'get_parent_name\'\nresult = \'x\'\n\n    @pytest.mark.parametrize(\'s\', [\'select x.y::text as z from foo\',\n                                   \'select x.y::text as ""z"" from foo\',\n                                   \'select x.""y""::text as z from foo\',\n                                   \'select x.""y""::text as ""z"" from foo\',\n                                   \'select ""x"".y::text as z from foo\',\n                                   \'select ""x"".y::text as ""z"" from foo\',\n                                   \'select ""x"".""y""::text as z from foo\',\n                                   \'select ""x"".""y""::text as ""z"" from foo\'])\n    @pytest.mark.parametrize(\'func_name, result\', [(\'get_name\', \'z\'),\n                                                   (\'get_real_name\', \'y\'),\n                                                   (\'get_parent_name\', \'x\'),\n                                                   (\'get_alias\', \'z\'),\n                                                   (\'get_typecast\', \'text\')])\n    def test_issue78(s, func_name, result):\n        # the bug author provided this nice examples, let\'s use them!\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_regressions.py:120: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation \'.\' at 0x1DF61A076A0>, ttype = Token.Punctuation\nvalues = \'[\', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = \'|\'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: \'Token\' object has no attribute \'token\'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError', 's = \'select x.y::text as z from foo\', func_name = \'get_alias\', result = \'z\'\n\n    @pytest.mark.parametrize(\'s\', [\'select x.y::text as z from foo\',\n                                   \'select x.y::text as ""z"" from foo\',\n                                   \'select x.""y""::text as z from foo\',\n                                   \'select x.""y""::text as ""z"" from foo\',\n                                   \'select ""x"".y::text as z from foo\',\n                                   \'select ""x"".y::text as ""z"" from foo\',\n                                   \'select ""x"".""y""::text as z from foo\',\n                                   \'select ""x"".""y""::text as ""z"" from foo\'])\n    @pytest.mark.parametrize(\'func_name, result\', [(\'get_name\', \'z\'),\n                                                   (\'get_real_name\', \'y\'),\n                                                   (\'get_parent_name\', \'x\'),\n                                                   (\'get_alias\', \'z\'),\n                                                   (\'get_typecast\', \'text\')])\n    def test_issue78(s, func_name, result):\n        # the bug author provided this nice examples, let\'s use them!\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_regressions.py:120: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation \'.\' at 0x1DF619F6920>, ttype = Token.Punctuation\nvalues = \'[\', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = \'|\'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: \'Token\' object has no attribute \'token\'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError', 's = \'select x.y::text as ""z"" from foo\', func_name = \'get_alias\', result = \'z\'\n\n    @pytest.mark.parametrize(\'s\', [\'select x.y::text as z from foo\',\n                                   \'select x.y::text as ""z"" from foo\',\n                                   \'select x.""y""::text as z from foo\',\n                                   \'select x.""y""::text as ""z"" from foo\',\n                                   \'select ""x"".y::text as z from foo\',\n                                   \'select ""x"".y::text as ""z"" from foo\',\n                                   \'select ""x"".""y""::text as z from foo\',\n                                   \'select ""x"".""y""::text as ""z"" from foo\'])\n    @pytest.mark.parametrize(\'func_name, result\', [(\'get_name\', \'z\'),\n                                                   (\'get_real_name\', \'y\'),\n                                                   (\'get_parent_name\', \'x\'),\n                                                   (\'get_alias\', \'z\'),\n                                                   (\'get_typecast\', \'text\')])\n    def test_issue78(s, func_name, result):\n        # the bug author provided this nice examples, let\'s use them!\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_regressions.py:120: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation \'.\' at 0x1DF61A06AA0>, ttype = Token.Punctuation\nvalues = \'[\', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = \'|\'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: \'Token\' object has no attribute \'token\'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError', 's = \'select x.""y""::text as z from foo\', func_name = \'get_alias\', result = \'z\'\n\n    @pytest.mark.parametrize(\'s\', [\'select x.y::text as z from foo\',\n                                   \'select x.y::text as ""z"" from foo\',\n                                   \'select x.""y""::text as z from foo\',\n                                   \'select x.""y""::text as ""z"" from foo\',\n                                   \'select ""x"".y::text as z from foo\',\n                                   \'select ""x"".y::text as ""z"" from foo\',\n                                   \'select ""x"".""y""::text as z from foo\',\n                                   \'select ""x"".""y""::text as ""z"" from foo\'])\n    @pytest.mark.parametrize(\'func_name, result\', [(\'get_name\', \'z\'),\n                                                   (\'get_real_name\', \'y\'),\n                                                   (\'get_parent_name\', \'x\'),\n                                                   (\'get_alias\', \'z\'),\n                                                   (\'get_typecast\', \'text\')])\n    def test_issue78(s, func_name, result):\n        # the bug author provided this nice examples, let\'s use them!\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_regressions.py:120: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation \'.\' at 0x1DF619F7B80>, ttype = Token.Punctuation\nvalues = \'[\', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = \'|\'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: \'Token\' object has no attribute \'token\'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError', 's = \'select x.""y""::text as ""z"" from foo\', func_name = \'get_alias\', result = \'z\'\n\n    @pytest.mark.parametrize(\'s\', [\'select x.y::text as z from foo\',\n                                   \'select x.y::text as ""z"" from foo\',\n                                   \'select x.""y""::text as z from foo\',\n                                   \'select x.""y""::text as ""z"" from foo\',\n                                   \'select ""x"".y::text as z from foo\',\n                                   \'select ""x"".y::text as ""z"" from foo\',\n                                   \'select ""x"".""y""::text as z from foo\',\n                                   \'select ""x"".""y""::text as ""z"" from foo\'])\n    @pytest.mark.parametrize(\'func_name, result\', [(\'get_name\', \'z\'),\n                                                   (\'get_real_name\', \'y\'),\n                                                   (\'get_parent_name\', \'x\'),\n                                                   (\'get_alias\', \'z\'),\n                                                   (\'get_typecast\', \'text\')])\n    def test_issue78(s, func_name, result):\n        # the bug author provided this nice examples, let\'s use them!\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_regressions.py:120: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation \'.\' at 0x1DF619F59C0>, ttype = Token.Punctuation\nvalues = \'[\', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = \'|\'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: \'Token\' object has no attribute \'token\'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError', 's = \'select ""x"".y::text as z from foo\', func_name = \'get_alias\', result = \'z\'\n\n    @pytest.mark.parametrize(\'s\', [\'select x.y::text as z from foo\',\n                                   \'select x.y::text as ""z"" from foo\',\n                                   \'select x.""y""::text as z from foo\',\n                                   \'select x.""y""::text as ""z"" from foo\',\n                                   \'select ""x"".y::text as z from foo\',\n                                   \'select ""x"".y::text as ""z"" from foo\',\n                                   \'select ""x"".""y""::text as z from foo\',\n                                   \'select ""x"".""y""::text as ""z"" from foo\'])\n    @pytest.mark.parametrize(\'func_name, result\', [(\'get_name\', \'z\'),\n                                                   (\'get_real_name\', \'y\'),\n                                                   (\'get_parent_name\', \'x\'),\n                                                   (\'get_alias\', \'z\'),\n                                                   (\'get_typecast\', \'text\')])\n    def test_issue78(s, func_name, result):\n        # the bug author provided this nice examples, let\'s use them!\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_regressions.py:120: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation \'.\' at 0x1DF619F64A0>, ttype = Token.Punctuation\nvalues = \'[\', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = \'|\'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: \'Token\' object has no attribute \'token\'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError', 's = \'select ""x"".y::text as ""z"" from foo\', func_name = \'get_alias\', result = \'z\'\n\n    @pytest.mark.parametrize(\'s\', [\'select x.y::text as z from foo\',\n                                   \'select x.y::text as ""z"" from foo\',\n                                   \'select x.""y""::text as z from foo\',\n                                   \'select x.""y""::text as ""z"" from foo\',\n                                   \'select ""x"".y::text as z from foo\',\n                                   \'select ""x"".y::text as ""z"" from foo\',\n                                   \'select ""x"".""y""::text as z from foo\',\n                                   \'select ""x"".""y""::text as ""z"" from foo\'])\n    @pytest.mark.parametrize(\'func_name, result\', [(\'get_name\', \'z\'),\n                                                   (\'get_real_name\', \'y\'),\n                                                   (\'get_parent_name\', \'x\'),\n                                                   (\'get_alias\', \'z\'),\n                                                   (\'get_typecast\', \'text\')])\n    def test_issue78(s, func_name, result):\n        # the bug author provided this nice examples, let\'s use them!\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_regressions.py:120: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation \'.\' at 0x1DF619F5F60>, ttype = Token.Punctuation\nvalues = \'[\', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = \'|\'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: \'Token\' object has no attribute \'token\'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError', 's = \'select ""x"".""y""::text as z from foo\', func_name = \'get_alias\', result = \'z\'\n\n    @pytest.mark.parametrize(\'s\', [\'select x.y::text as z from foo\',\n                                   \'select x.y::text as ""z"" from foo\',\n                                   \'select x.""y""::text as z from foo\',\n                                   \'select x.""y""::text as ""z"" from foo\',\n                                   \'select ""x"".y::text as z from foo\',\n                                   \'select ""x"".y::text as ""z"" from foo\',\n                                   \'select ""x"".""y""::text as z from foo\',\n                                   \'select ""x"".""y""::text as ""z"" from foo\'])\n    @pytest.mark.parametrize(\'func_name, result\', [(\'get_name\', \'z\'),\n                                                   (\'get_real_name\', \'y\'),\n                                                   (\'get_parent_name\', \'x\'),\n                                                   (\'get_alias\', \'z\'),\n                                                   (\'get_typecast\', \'text\')])\n    def test_issue78(s, func_name, result):\n        # the bug author provided this nice examples, let\'s use them!\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_regressions.py:120: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation \'.\' at 0x1DF619F4CA0>, ttype = Token.Punctuation\nvalues = \'[\', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = \'|\'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: \'Token\' object has no attribute \'token\'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError', 's = \'select ""x"".""y""::text as ""z"" from foo\', func_name = \'get_alias\'\nresult = \'z\'\n\n    @pytest.mark.parametrize(\'s\', [\'select x.y::text as z from foo\',\n                                   \'select x.y::text as ""z"" from foo\',\n                                   \'select x.""y""::text as z from foo\',\n                                   \'select x.""y""::text as ""z"" from foo\',\n                                   \'select ""x"".y::text as z from foo\',\n                                   \'select ""x"".y::text as ""z"" from foo\',\n                                   \'select ""x"".""y""::text as z from foo\',\n                                   \'select ""x"".""y""::text as ""z"" from foo\'])\n    @pytest.mark.parametrize(\'func_name, result\', [(\'get_name\', \'z\'),\n                                                   (\'get_real_name\', \'y\'),\n                                                   (\'get_parent_name\', \'x\'),\n                                                   (\'get_alias\', \'z\'),\n                                                   (\'get_typecast\', \'text\')])\n    def test_issue78(s, func_name, result):\n        # the bug author provided this nice examples, let\'s use them!\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_regressions.py:120: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation \'.\' at 0x1DF61A6C040>, ttype = Token.Punctuation\nvalues = \'[\', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = \'|\'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: \'Token\' object has no attribute \'token\'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError', 's = \'select x.y::text as z from foo\', func_name = \'get_typecast\'\nresult = \'text\'\n\n    @pytest.mark.parametrize(\'s\', [\'select x.y::text as z from foo\',\n                                   \'select x.y::text as ""z"" from foo\',\n                                   \'select x.""y""::text as z from foo\',\n                                   \'select x.""y""::text as ""z"" from foo\',\n                                   \'select ""x"".y::text as z from foo\',\n                                   \'select ""x"".y::text as ""z"" from foo\',\n                                   \'select ""x"".""y""::text as z from foo\',\n                                   \'select ""x"".""y""::text as ""z"" from foo\'])\n    @pytest.mark.parametrize(\'func_name, result\', [(\'get_name\', \'z\'),\n                                                   (\'get_real_name\', \'y\'),\n                                                   (\'get_parent_name\', \'x\'),\n                                                   (\'get_alias\', \'z\'),\n                                                   (\'get_typecast\', \'text\')])\n    def test_issue78(s, func_name, result):\n        # the bug author provided this nice examples, let\'s use them!\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_regressions.py:120: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation \'.\' at 0x1DF61A6FD00>, ttype = Token.Punctuation\nvalues = \'[\', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = \'|\'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: \'Token\' object has no attribute \'token\'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError', 's = \'select x.y::text as ""z"" from foo\', func_name = \'get_typecast\'\nresult = \'text\'\n\n    @pytest.mark.parametrize(\'s\', [\'select x.y::text as z from foo\',\n                                   \'select x.y::text as ""z"" from foo\',\n                                   \'select x.""y""::text as z from foo\',\n                                   \'select x.""y""::text as ""z"" from foo\',\n                                   \'select ""x"".y::text as z from foo\',\n                                   \'select ""x"".y::text as ""z"" from foo\',\n                                   \'select ""x"".""y""::text as z from foo\',\n                                   \'select ""x"".""y""::text as ""z"" from foo\'])\n    @pytest.mark.parametrize(\'func_name, result\', [(\'get_name\', \'z\'),\n                                                   (\'get_real_name\', \'y\'),\n                                                   (\'get_parent_name\', \'x\'),\n                                                   (\'get_alias\', \'z\'),\n                                                   (\'get_typecast\', \'text\')])\n    def test_issue78(s, func_name, result):\n        # the bug author provided this nice examples, let\'s use them!\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_regressions.py:120: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation \'.\' at 0x1DF619F6FE0>, ttype = Token.Punctuation\nvalues = \'[\', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = \'|\'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: \'Token\' object has no attribute \'token\'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError', 's = \'select x.""y""::text as z from foo\', func_name = \'get_typecast\'\nresult = \'text\'\n\n    @pytest.mark.parametrize(\'s\', [\'select x.y::text as z from foo\',\n                                   \'select x.y::text as ""z"" from foo\',\n                                   \'select x.""y""::text as z from foo\',\n                                   \'select x.""y""::text as ""z"" from foo\',\n                                   \'select ""x"".y::text as z from foo\',\n                                   \'select ""x"".y::text as ""z"" from foo\',\n                                   \'select ""x"".""y""::text as z from foo\',\n                                   \'select ""x"".""y""::text as ""z"" from foo\'])\n    @pytest.mark.parametrize(\'func_name, result\', [(\'get_name\', \'z\'),\n                                                   (\'get_real_name\', \'y\'),\n                                                   (\'get_parent_name\', \'x\'),\n                                                   (\'get_alias\', \'z\'),\n                                                   (\'get_typecast\', \'text\')])\n    def test_issue78(s, func_name, result):\n        # the bug author provided this nice examples, let\'s use them!\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_regressions.py:120: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation \'.\' at 0x1DF61A6F9A0>, ttype = Token.Punctuation\nvalues = \'[\', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = \'|\'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: \'Token\' object has no attribute \'token\'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError', 's = \'select x.""y""::text as ""z"" from foo\', func_name = \'get_typecast\'\nresult = \'text\'\n\n    @pytest.mark.parametrize(\'s\', [\'select x.y::text as z from foo\',\n                                   \'select x.y::text as ""z"" from foo\',\n                                   \'select x.""y""::text as z from foo\',\n                                   \'select x.""y""::text as ""z"" from foo\',\n                                   \'select ""x"".y::text as z from foo\',\n                                   \'select ""x"".y::text as ""z"" from foo\',\n                                   \'select ""x"".""y""::text as z from foo\',\n                                   \'select ""x"".""y""::text as ""z"" from foo\'])\n    @pytest.mark.parametrize(\'func_name, result\', [(\'get_name\', \'z\'),\n                                                   (\'get_real_name\', \'y\'),\n                                                   (\'get_parent_name\', \'x\'),\n                                                   (\'get_alias\', \'z\'),\n                                                   (\'get_typecast\', \'text\')])\n    def test_issue78(s, func_name, result):\n        # the bug author provided this nice examples, let\'s use them!\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_regressions.py:120: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation \'.\' at 0x1DF61A6FEE0>, ttype = Token.Punctuation\nvalues = \'[\', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = \'|\'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: \'Token\' object has no attribute \'token\'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError', 's = \'select ""x"".y::text as z from foo\', func_name = \'get_typecast\'\nresult = \'text\'\n\n    @pytest.mark.parametrize(\'s\', [\'select x.y::text as z from foo\',\n                                   \'select x.y::text as ""z"" from foo\',\n                                   \'select x.""y""::text as z from foo\',\n                                   \'select x.""y""::text as ""z"" from foo\',\n                                   \'select ""x"".y::text as z from foo\',\n                                   \'select ""x"".y::text as ""z"" from foo\',\n                                   \'select ""x"".""y""::text as z from foo\',\n                                   \'select ""x"".""y""::text as ""z"" from foo\'])\n    @pytest.mark.parametrize(\'func_name, result\', [(\'get_name\', \'z\'),\n                                                   (\'get_real_name\', \'y\'),\n                                                   (\'get_parent_name\', \'x\'),\n                                                   (\'get_alias\', \'z\'),\n                                                   (\'get_typecast\', \'text\')])\n    def test_issue78(s, func_name, result):\n        # the bug author provided this nice examples, let\'s use them!\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_regressions.py:120: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation \'.\' at 0x1DF61A6D180>, ttype = Token.Punctuation\nvalues = \'[\', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = \'|\'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: \'Token\' object has no attribute \'token\'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError', 's = \'select ""x"".y::text as ""z"" from foo\', func_name = \'get_typecast\'\nresult = \'text\'\n\n    @pytest.mark.parametrize(\'s\', [\'select x.y::text as z from foo\',\n                                   \'select x.y::text as ""z"" from foo\',\n                                   \'select x.""y""::text as z from foo\',\n                                   \'select x.""y""::text as ""z"" from foo\',\n                                   \'select ""x"".y::text as z from foo\',\n                                   \'select ""x"".y::text as ""z"" from foo\',\n                                   \'select ""x"".""y""::text as z from foo\',\n                                   \'select ""x"".""y""::text as ""z"" from foo\'])\n    @pytest.mark.parametrize(\'func_name, result\', [(\'get_name\', \'z\'),\n                                                   (\'get_real_name\', \'y\'),\n                                                   (\'get_parent_name\', \'x\'),\n                                                   (\'get_alias\', \'z\'),\n                                                   (\'get_typecast\', \'text\')])\n    def test_issue78(s, func_name, result):\n        # the bug author provided this nice examples, let\'s use them!\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_regressions.py:120: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation \'.\' at 0x1DF61A6E140>, ttype = Token.Punctuation\nvalues = \'[\', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = \'|\'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: \'Token\' object has no attribute \'token\'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError', 's = \'select ""x"".""y""::text as z from foo\', func_name = \'get_typecast\'\nresult = \'text\'\n\n    @pytest.mark.parametrize(\'s\', [\'select x.y::text as z from foo\',\n                                   \'select x.y::text as ""z"" from foo\',\n                                   \'select x.""y""::text as z from foo\',\n                                   \'select x.""y""::text as ""z"" from foo\',\n                                   \'select ""x"".y::text as z from foo\',\n                                   \'select ""x"".y::text as ""z"" from foo\',\n                                   \'select ""x"".""y""::text as z from foo\',\n                                   \'select ""x"".""y""::text as ""z"" from foo\'])\n    @pytest.mark.parametrize(\'func_name, result\', [(\'get_name\', \'z\'),\n                                                   (\'get_real_name\', \'y\'),\n                                                   (\'get_parent_name\', \'x\'),\n                                                   (\'get_alias\', \'z\'),\n                                                   (\'get_typecast\', \'text\')])\n    def test_issue78(s, func_name, result):\n        # the bug author provided this nice examples, let\'s use them!\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_regressions.py:120: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation \'.\' at 0x1DF619F71C0>, ttype = Token.Punctuation\nvalues = \'[\', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = \'|\'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: \'Token\' object has no attribute \'token\'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError', 's = \'select ""x"".""y""::text as ""z"" from foo\', func_name = \'get_typecast\'\nresult = \'text\'\n\n    @pytest.mark.parametrize(\'s\', [\'select x.y::text as z from foo\',\n                                   \'select x.y::text as ""z"" from foo\',\n                                   \'select x.""y""::text as z from foo\',\n                                   \'select x.""y""::text as ""z"" from foo\',\n                                   \'select ""x"".y::text as z from foo\',\n                                   \'select ""x"".y::text as ""z"" from foo\',\n                                   \'select ""x"".""y""::text as z from foo\',\n                                   \'select ""x"".""y""::text as ""z"" from foo\'])\n    @pytest.mark.parametrize(\'func_name, result\', [(\'get_name\', \'z\'),\n                                                   (\'get_real_name\', \'y\'),\n                                                   (\'get_parent_name\', \'x\'),\n                                                   (\'get_alias\', \'z\'),\n                                                   (\'get_typecast\', \'text\')])\n    def test_issue78(s, func_name, result):\n        # the bug author provided this nice examples, let\'s use them!\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_regressions.py:120: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation \'.\' at 0x1DF61A52F20>, ttype = Token.Punctuation\nvalues = \'[\', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = \'|\'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: \'Token\' object has no attribute \'token\'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError', ""def test_comment_encoding_when_reindent():\n        # There was an UnicodeEncodeError in the reindent filter that\n        # casted every comment followed by a keyword to str.\n        sql = 'select foo -- Comment containing Ümläuts\\nfrom bar'\n>       formatted = sqlparse.format(sql, reindent=True)\n\nrepos\\sqlparse\\tests\\test_regressions.py:154: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return ''.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:61: in group_case\n    _group_matching(tlist, sql.Case)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Keyword 'from' at 0x1DF61A29900>, ttype = Token.Keyword, values = 'CASE'\nregex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", 'def test_parse_sql_with_binary():\n        # See https://github.com/andialbrecht/sqlparse/pull/88\n        # digest = \'\x82|Ë\x0eê\x8aplL4¡h\x91øN{\'\n        digest = \'\\x82|\\xcb\\x0e\\xea\\x8aplL4\\xa1h\\x91\\xf8N{\'\n        sql = f""select * from foo where bar = \'{digest}\'""\n>       formatted = sqlparse.format(sql, reindent=True)\n\nrepos\\sqlparse\\tests\\test_regressions.py:163: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return \'\'.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:61: in group_case\n    _group_matching(tlist, sql.Case)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Keyword \'from\' at 0x1DF61A6D0C0>, ttype = Token.Keyword, values = \'CASE\'\nregex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = \'|\'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: \'Token\' object has no attribute \'token\'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError', ""def test_dont_alias_keywords():\n        # The _group_left_right function had a bug where the check for the\n        # left side wasn't handled correctly. In one case this resulted in\n        # a keyword turning into an identifier.\n>       p = sqlparse.parse('FROM AS foo')[0]\n\nrepos\\sqlparse\\tests\\test_regressions.py:172: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:61: in group_case\n    _group_matching(tlist, sql.Case)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Keyword 'FROM' at 0x1DF61A6DC60>, ttype = Token.Keyword, values = 'CASE'\nregex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""load_file = <function load_file.<locals>.make_load_file at 0x000001DF61917BA0>\n\n    def test_format_accepts_encoding(load_file):\n        # issue20\n        sql = load_file('test_cp1251.sql', 'cp1251')\n>       formatted = sqlparse.format(sql, reindent=True, encoding='cp1251')\n\nrepos\\sqlparse\\tests\\test_regressions.py:181: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return ''.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation '(' at 0x1DF619F67A0>, ttype = Token.Punctuation\nvalues = '[', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", 'get_stream = <function get_stream.<locals>.make_stream at 0x000001DF61917EC0>\n\n    def test_stream(get_stream):\n        with get_stream(""stream.sql"") as stream:\n>           p = sqlparse.parse(stream)[0]\n\nrepos\\sqlparse\\tests\\test_regressions.py:189: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:61: in group_case\n    _group_matching(tlist, sql.Case)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Keyword \'into\' at 0x1DF6197EE60>, ttype = Token.Keyword, values = \'CASE\'\nregex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = \'|\'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: \'Token\' object has no attribute \'token\'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError', 'def test_issue90():\n        sql = (\'UPDATE ""gallery_photo"" SET ""owner_id"" = 4018, ""deleted_at"" = NULL,\'\n               \' ""width"" = NULL, ""height"" = NULL, ""rating_votes"" = 0,\'\n               \' ""rating_score"" = 0, ""thumbnail_width"" = NULL,\'\n               \' ""thumbnail_height"" = NULL, ""price"" = 1, ""description"" = NULL\')\n>       formatted = sqlparse.format(sql, reindent=True)\n\nrepos\\sqlparse\\tests\\test_regressions.py:198: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return \'\'.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation \',\' at 0x1DF618BD4E0>, ttype = Token.Punctuation\nvalues = \'[\', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = \'|\'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: \'Token\' object has no attribute \'token\'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError', ""def test_except_formatting():\n        sql = 'SELECT 1 FROM foo WHERE 2 = 3 EXCEPT SELECT 2 FROM bar WHERE 1 = 2'\n>       formatted = sqlparse.format(sql, reindent=True)\n\nrepos\\sqlparse\\tests\\test_regressions.py:216: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return ''.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:61: in group_case\n    _group_matching(tlist, sql.Case)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Keyword 'FROM' at 0x1DF619F4220>, ttype = Token.Keyword, values = 'CASE'\nregex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""def test_null_with_as():\n        sql = 'SELECT NULL AS c1, NULL AS c2 FROM t1'\n>       formatted = sqlparse.format(sql, reindent=True)\n\nrepos\\sqlparse\\tests\\test_regressions.py:230: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return ''.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation ',' at 0x1DF61A51A80>, ttype = Token.Punctuation\nvalues = '[', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""filepath = <function filepath.<locals>.make_filepath at 0x000001DF61916F20>\n\n    def test_issue190_open_file(filepath):\n        path = filepath('stream.sql')\n        with open(path) as stream:\n>           p = sqlparse.parse(stream)[0]\n\nrepos\\sqlparse\\tests\\test_regressions.py:241: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:61: in group_case\n    _group_matching(tlist, sql.Case)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Keyword 'into' at 0x1DF61A52AA0>, ttype = Token.Keyword, values = 'CASE'\nregex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", 'def test_issue186_get_type():\n        sql = ""-- comment\\ninsert into foo""\n>       p = sqlparse.parse(sql)[0]\n\nrepos\\sqlparse\\tests\\test_regressions.py:272: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:61: in group_case\n    _group_matching(tlist, sql.Case)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Keyword \'into\' at 0x1DF619F8BE0>, ttype = Token.Keyword, values = \'CASE\'\nregex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = \'|\'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: \'Token\' object has no attribute \'token\'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError', 'def test_issue213_leadingws():\n        sql = "" select * from foo""\n>       assert sqlparse.format(sql, strip_whitespace=True) == ""select * from foo""\n\nrepos\\sqlparse\\tests\\test_regressions.py:285: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return \'\'.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:61: in group_case\n    _group_matching(tlist, sql.Case)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Keyword \'from\' at 0x1DF61A29600>, ttype = Token.Keyword, values = \'CASE\'\nregex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = \'|\'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: \'Token\' object has no attribute \'token\'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError', ""def test_issue227_gettype_cte():\n>       select_stmt = sqlparse.parse('SELECT 1, 2, 3 FROM foo;')\n\nrepos\\sqlparse\\tests\\test_regressions.py:289: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation ',' at 0x1DF61A28AC0>, ttype = Token.Punctuation\nvalues = '[', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""def test_issue207_runaway_format():\n        sql = 'select 1 from (select 1 as one, 2 as two, 3 from dual) t0'\n>       p = sqlparse.format(sql, reindent=True)\n\nrepos\\sqlparse\\tests\\test_regressions.py:303: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return ''.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation '(' at 0x1DF61A28A00>, ttype = Token.Punctuation\nvalues = '[', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""s = 'SELECT x AS'\n\n    @pytest.mark.parametrize('s', [\n        'SELECT x AS',\n        'AS'\n    ])\n    def test_issue284_as_grouping(s):\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_regressions.py:324: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:61: in group_case\n    _group_matching(tlist, sql.Case)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Keyword 'AS' at 0x1DF6191AD40>, ttype = Token.Keyword, values = 'CASE'\nregex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""s = 'AS'\n\n    @pytest.mark.parametrize('s', [\n        'SELECT x AS',\n        'AS'\n    ])\n    def test_issue284_as_grouping(s):\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_regressions.py:324: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:61: in group_case\n    _group_matching(tlist, sql.Case)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Keyword 'AS' at 0x1DF61A2A740>, ttype = Token.Keyword, values = 'CASE'\nregex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", 'def test_issue315_utf8_by_default():\n        # Make sure the lexer can handle utf-8 string by default correctly\n        # digest = \'齐天大圣.カラフルな雲.사랑해요\'\n        # The digest contains Chinese, Japanese and Korean characters\n        # All in \'utf-8\' encoding.\n        digest = (\n            \'\\xe9\\xbd\\x90\\xe5\\xa4\\xa9\\xe5\\xa4\\xa7\\xe5\\x9c\\xa3.\'\n            \'\\xe3\\x82\\xab\\xe3\\x83\\xa9\\xe3\\x83\\x95\\xe3\\x83\\xab\\xe3\\x81\\xaa\\xe9\'\n            \'\\x9b\\xb2.\'\n            \'\\xec\\x82\\xac\\xeb\\x9e\\x91\\xed\\x95\\xb4\\xec\\x9a\\x94\'\n        )\n        sql = f""select * from foo where bar = \'{digest}\'""\n>       formatted = sqlparse.format(sql, reindent=True)\n\nrepos\\sqlparse\\tests\\test_regressions.py:340: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return \'\'.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:61: in group_case\n    _group_matching(tlist, sql.Case)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Keyword \'from\' at 0x1DF61A28700>, ttype = Token.Keyword, values = \'CASE\'\nregex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = \'|\'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: \'Token\' object has no attribute \'token\'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError', ""def test_issue322_concurrently_is_keyword():\n        s = 'CREATE INDEX CONCURRENTLY myindex ON mytable(col1);'\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_regressions.py:347: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation '(' at 0x1DF61A6D2A0>, ttype = Token.Punctuation\nvalues = '[', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""s = 'SELECT @min_price:=MIN(price), @max_price:=MAX(price) FROM shop;'\n\n    @pytest.mark.parametrize('s', [\n        'SELECT @min_price:=MIN(price), @max_price:=MAX(price) FROM shop;',\n        'SELECT @min_price:=MIN(price), @max_price:=MAX(price) FROM shop',\n    \n    ])\n    def test_issue359_index_error_assignments(s):\n>       sqlparse.parse(s)\n\nrepos\\sqlparse\\tests\\test_regressions.py:364: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation '(' at 0x1DF61A53580>, ttype = Token.Punctuation\nvalues = '[', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""s = 'SELECT @min_price:=MIN(price), @max_price:=MAX(price) FROM shop'\n\n    @pytest.mark.parametrize('s', [\n        'SELECT @min_price:=MIN(price), @max_price:=MAX(price) FROM shop;',\n        'SELECT @min_price:=MIN(price), @max_price:=MAX(price) FROM shop',\n    \n    ])\n    def test_issue359_index_error_assignments(s):\n>       sqlparse.parse(s)\n\nrepos\\sqlparse\\tests\\test_regressions.py:364: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation '(' at 0x1DF618BF820>, ttype = Token.Punctuation\nvalues = '[', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""def test_issue489_tzcasts():\n>       p = sqlparse.parse('select bar at time zone \\'UTC\\' as foo')[0]\n\nrepos\\sqlparse\\tests\\test_regressions.py:403: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:61: in group_case\n    _group_matching(tlist, sql.Case)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Keyword 'as' at 0x1DF61ACD060>, ttype = Token.Keyword, values = 'CASE'\nregex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""def test_issue562_tzcasts():\n        # Test that whitespace between 'from' and 'bar' is retained\n>       formatted = sqlparse.format(\n            'SELECT f(HOUR from bar AT TIME ZONE \\'UTC\\') from foo', reindent=True\n        )\n\nrepos\\sqlparse\\tests\\test_regressions.py:410: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return ''.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation '(' at 0x1DF61A2A740>, ttype = Token.Punctuation\nvalues = '[', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""def test_as_in_parentheses_indents():\n        # did raise NoneType has no attribute is_group in _process_parentheses\n>       formatted = sqlparse.format('(as foo)', reindent=True)\n\nrepos\\sqlparse\\tests\\test_regressions.py:419: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return ''.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation '(' at 0x1DF61A53580>, ttype = Token.Punctuation\nvalues = '[', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""def test_format_invalid_where_clause():\n        # did raise ValueError\n>       formatted = sqlparse.format('where, foo', reindent=True)\n\nrepos\\sqlparse\\tests\\test_regressions.py:425: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return ''.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation ',' at 0x1DF61ACC340>, ttype = Token.Punctuation\nvalues = '[', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", 'def test_comment_between_cte_clauses_issue632():\n>       p, = sqlparse.parse(""""""\n            WITH foo AS (),\n                 -- A comment before baz subquery\n                 baz AS ()\n            SELECT * FROM baz;"""""")\n\nrepos\\sqlparse\\tests\\test_regressions.py:437: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation \'(\' at 0x1DF61ACFE80>, ttype = Token.Punctuation\nvalues = \'[\', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = \'|\'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: \'Token\' object has no attribute \'token\'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError', ""def test_copy_issue672():\n>       p = sqlparse.parse('select * from foo')[0]\n\nrepos\\sqlparse\\tests\\test_regressions.py:446: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:61: in group_case\n    _group_matching(tlist, sql.Case)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Keyword 'from' at 0x1DF61ACC3A0>, ttype = Token.Keyword, values = 'CASE'\nregex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""def test_primary_key_issue740():\n>       p = sqlparse.parse('PRIMARY KEY')[0]\n\nrepos\\sqlparse\\tests\\test_regressions.py:452: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:61: in group_case\n    _group_matching(tlist, sql.Case)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Keyword 'PRIMAR...' at 0x1DF61A288E0>, ttype = Token.Keyword\nvalues = 'CASE', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""limit_recursion = None\n\n    def test_max_recursion(limit_recursion):\n        with pytest.raises(SQLParseError):\n>           sqlparse.parse('[' * 1000 + ']' * 1000)\n\nrepos\\sqlparse\\tests\\test_regressions.py:467: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation '[' at 0x1DF61AC3580>, ttype = Token.Punctuation\nvalues = '[', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", 'def test_split_semicolon():\n        sql1 = \'select * from foo;\'\n        sql2 = ""select * from foo where bar = \'foo;bar\';""\n>       stmts = sqlparse.parse(\'\'.join([sql1, sql2]))\n\nrepos\\sqlparse\\tests\\test_split.py:14: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation \';\' at 0x1DF61B36A40>, ttype = Token.Punctuation\nvalues = \'[\', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = \'|\'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: \'Token\' object has no attribute \'token\'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError', 'def test_split_backslash():\n>       stmts = sqlparse.parse(""select \'\\\'; select \'\\\'\';"")\n\nrepos\\sqlparse\\tests\\test_split.py:21: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation \';\' at 0x1DF61AC29E0>, ttype = Token.Punctuation\nvalues = \'[\', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = \'|\'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: \'Token\' object has no attribute \'token\'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError', ""load_file = <function load_file.<locals>.make_load_file at 0x000001DF61ADD1C0>\nfn = 'function.sql'\n\n    @pytest.mark.parametrize('fn', ['function.sql',\n                                    'function_psql.sql',\n                                    'function_psql2.sql',\n                                    'function_psql3.sql',\n                                    'function_psql4.sql'])\n    def test_split_create_function(load_file, fn):\n        sql = load_file(fn)\n>       stmts = sqlparse.parse(sql)\n\nrepos\\sqlparse\\tests\\test_split.py:32: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation '(' at 0x1DF61AC3D60>, ttype = Token.Punctuation\nvalues = '[', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""load_file = <function load_file.<locals>.make_load_file at 0x000001DF61ADD620>\nfn = 'function_psql.sql'\n\n    @pytest.mark.parametrize('fn', ['function.sql',\n                                    'function_psql.sql',\n                                    'function_psql2.sql',\n                                    'function_psql3.sql',\n                                    'function_psql4.sql'])\n    def test_split_create_function(load_file, fn):\n        sql = load_file(fn)\n>       stmts = sqlparse.parse(sql)\n\nrepos\\sqlparse\\tests\\test_split.py:32: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation '.' at 0x1DF61AC3A60>, ttype = Token.Punctuation\nvalues = '[', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""load_file = <function load_file.<locals>.make_load_file at 0x000001DF61ADD8A0>\nfn = 'function_psql2.sql'\n\n    @pytest.mark.parametrize('fn', ['function.sql',\n                                    'function_psql.sql',\n                                    'function_psql2.sql',\n                                    'function_psql3.sql',\n                                    'function_psql4.sql'])\n    def test_split_create_function(load_file, fn):\n        sql = load_file(fn)\n>       stmts = sqlparse.parse(sql)\n\nrepos\\sqlparse\\tests\\test_split.py:32: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation '(' at 0x1DF61BC0580>, ttype = Token.Punctuation\nvalues = '[', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""load_file = <function load_file.<locals>.make_load_file at 0x000001DF61ADC360>\nfn = 'function_psql3.sql'\n\n    @pytest.mark.parametrize('fn', ['function.sql',\n                                    'function_psql.sql',\n                                    'function_psql2.sql',\n                                    'function_psql3.sql',\n                                    'function_psql4.sql'])\n    def test_split_create_function(load_file, fn):\n        sql = load_file(fn)\n>       stmts = sqlparse.parse(sql)\n\nrepos\\sqlparse\\tests\\test_split.py:32: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation '(' at 0x1DF61BC1B40>, ttype = Token.Punctuation\nvalues = '[', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""load_file = <function load_file.<locals>.make_load_file at 0x000001DF61ADCE00>\nfn = 'function_psql4.sql'\n\n    @pytest.mark.parametrize('fn', ['function.sql',\n                                    'function_psql.sql',\n                                    'function_psql2.sql',\n                                    'function_psql3.sql',\n                                    'function_psql4.sql'])\n    def test_split_create_function(load_file, fn):\n        sql = load_file(fn)\n>       stmts = sqlparse.parse(sql)\n\nrepos\\sqlparse\\tests\\test_split.py:32: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation '(' at 0x1DF61BC07C0>, ttype = Token.Punctuation\nvalues = '[', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""load_file = <function load_file.<locals>.make_load_file at 0x000001DF61ADDBC0>\n\n    def test_split_dashcomments(load_file):\n        sql = load_file('dashcomment.sql')\n>       stmts = sqlparse.parse(sql)\n\nrepos\\sqlparse\\tests\\test_split.py:39: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation ';' at 0x1DF61AC3700>, ttype = Token.Punctuation\nvalues = '[', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""s = 'select foo; -- comment\\n'\n\n    @pytest.mark.parametrize('s', ['select foo; -- comment\\n',\n                                   'select foo; -- comment\\r',\n                                   'select foo; -- comment\\r\\n',\n                                   'select foo; -- comment'])\n    def test_split_dashcomments_eol(s):\n>       stmts = sqlparse.parse(s)\n\nrepos\\sqlparse\\tests\\test_split.py:49: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation ';' at 0x1DF61AC1B40>, ttype = Token.Punctuation\nvalues = '[', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""s = 'select foo; -- comment\\r'\n\n    @pytest.mark.parametrize('s', ['select foo; -- comment\\n',\n                                   'select foo; -- comment\\r',\n                                   'select foo; -- comment\\r\\n',\n                                   'select foo; -- comment'])\n    def test_split_dashcomments_eol(s):\n>       stmts = sqlparse.parse(s)\n\nrepos\\sqlparse\\tests\\test_split.py:49: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation ';' at 0x1DF61AC0E80>, ttype = Token.Punctuation\nvalues = '[', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""s = 'select foo; -- comment\\r\\n'\n\n    @pytest.mark.parametrize('s', ['select foo; -- comment\\n',\n                                   'select foo; -- comment\\r',\n                                   'select foo; -- comment\\r\\n',\n                                   'select foo; -- comment'])\n    def test_split_dashcomments_eol(s):\n>       stmts = sqlparse.parse(s)\n\nrepos\\sqlparse\\tests\\test_split.py:49: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation ';' at 0x1DF61AC1780>, ttype = Token.Punctuation\nvalues = '[', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""s = 'select foo; -- comment'\n\n    @pytest.mark.parametrize('s', ['select foo; -- comment\\n',\n                                   'select foo; -- comment\\r',\n                                   'select foo; -- comment\\r\\n',\n                                   'select foo; -- comment'])\n    def test_split_dashcomments_eol(s):\n>       stmts = sqlparse.parse(s)\n\nrepos\\sqlparse\\tests\\test_split.py:49: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation ';' at 0x1DF61BC02E0>, ttype = Token.Punctuation\nvalues = '[', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""load_file = <function load_file.<locals>.make_load_file at 0x000001DF61ADD9E0>\n\n    def test_split_begintag(load_file):\n        sql = load_file('begintag.sql')\n>       stmts = sqlparse.parse(sql)\n\nrepos\\sqlparse\\tests\\test_split.py:55: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation ';' at 0x1DF61BC2440>, ttype = Token.Punctuation\nvalues = '[', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""load_file = <function load_file.<locals>.make_load_file at 0x000001DF61ADD620>\n\n    def test_split_begintag_2(load_file):\n        sql = load_file('begintag_2.sql')\n>       stmts = sqlparse.parse(sql)\n\nrepos\\sqlparse\\tests\\test_split.py:62: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation '(' at 0x1DF61B365C0>, ttype = Token.Punctuation\nvalues = '[', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""def test_split_dropif():\n        sql = 'DROP TABLE IF EXISTS FOO;\\n\\nSELECT * FROM BAR;'\n>       stmts = sqlparse.parse(sql)\n\nrepos\\sqlparse\\tests\\test_split.py:69: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation ';' at 0x1DF61ACB580>, ttype = Token.Punctuation\nvalues = '[', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""def test_split_comment_with_umlaut():\n        sql = ('select * from foo;\\n'\n               '-- Testing an umlaut: ä\\n'\n               'select * from bar;')\n>       stmts = sqlparse.parse(sql)\n\nrepos\\sqlparse\\tests\\test_split.py:78: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation ';' at 0x1DF61ACBEE0>, ttype = Token.Punctuation\nvalues = '[', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""def test_split_comment_end_of_line():\n        sql = ('select * from foo; -- foo\\n'\n               'select * from bar;')\n>       stmts = sqlparse.parse(sql)\n\nrepos\\sqlparse\\tests\\test_split.py:86: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation ';' at 0x1DF61AC9060>, ttype = Token.Punctuation\nvalues = '[', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", 'def test_split_stream():\n        stream = StringIO(""SELECT 1; SELECT 2;"")\n        stmts = sqlparse.parsestream(stream)\n        assert isinstance(stmts, types.GeneratorType)\n>       assert len(list(stmts)) == 2\n\nrepos\\sqlparse\\tests\\test_split.py:126: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation \';\' at 0x1DF61A2A080>, ttype = Token.Punctuation\nvalues = \'[\', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = \'|\'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: \'Token\' object has no attribute \'token\'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError', 'def test_split_encoding_parsestream():\n        stream = StringIO(""SELECT 1; SELECT 2;"")\n>       stmts = list(sqlparse.parsestream(stream))\n\nrepos\\sqlparse\\tests\\test_split.py:131: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation \';\' at 0x1DF61A29840>, ttype = Token.Punctuation\nvalues = \'[\', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = \'|\'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: \'Token\' object has no attribute \'token\'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError', ""def test_tokenlist_repr():\n>       p = sqlparse.parse('foo, bar, baz')[0]\n\nrepos\\sqlparse\\tests\\test_tokenize.py:91: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:53: in group_brackets\n    _group_matching(tlist, sql.SquareBrackets)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Punctuation ',' at 0x1DF61BC0100>, ttype = Token.Punctuation\nvalues = '[', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""expr = 'JOIN'\n\n    @pytest.mark.parametrize('expr', [\n        'JOIN',\n        'LEFT JOIN',\n        'LEFT OUTER JOIN',\n        'FULL OUTER JOIN',\n        'NATURAL JOIN',\n        'CROSS JOIN',\n        'STRAIGHT JOIN',\n        'INNER JOIN',\n        'LEFT INNER JOIN'])\n    def test_parse_join(expr):\n>       p = sqlparse.parse(f'{expr} foo')[0]\n\nrepos\\sqlparse\\tests\\test_tokenize.py:153: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:61: in group_case\n    _group_matching(tlist, sql.Case)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Keyword 'JOIN' at 0x1DF61ACA320>, ttype = Token.Keyword, values = 'CASE'\nregex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""expr = 'LEFT JOIN'\n\n    @pytest.mark.parametrize('expr', [\n        'JOIN',\n        'LEFT JOIN',\n        'LEFT OUTER JOIN',\n        'FULL OUTER JOIN',\n        'NATURAL JOIN',\n        'CROSS JOIN',\n        'STRAIGHT JOIN',\n        'INNER JOIN',\n        'LEFT INNER JOIN'])\n    def test_parse_join(expr):\n>       p = sqlparse.parse(f'{expr} foo')[0]\n\nrepos\\sqlparse\\tests\\test_tokenize.py:153: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:61: in group_case\n    _group_matching(tlist, sql.Case)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Keyword 'LEFT J...' at 0x1DF61ACAD40>, ttype = Token.Keyword\nvalues = 'CASE', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""expr = 'LEFT OUTER JOIN'\n\n    @pytest.mark.parametrize('expr', [\n        'JOIN',\n        'LEFT JOIN',\n        'LEFT OUTER JOIN',\n        'FULL OUTER JOIN',\n        'NATURAL JOIN',\n        'CROSS JOIN',\n        'STRAIGHT JOIN',\n        'INNER JOIN',\n        'LEFT INNER JOIN'])\n    def test_parse_join(expr):\n>       p = sqlparse.parse(f'{expr} foo')[0]\n\nrepos\\sqlparse\\tests\\test_tokenize.py:153: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:61: in group_case\n    _group_matching(tlist, sql.Case)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Keyword 'LEFT O...' at 0x1DF61ACBD60>, ttype = Token.Keyword\nvalues = 'CASE', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""expr = 'FULL OUTER JOIN'\n\n    @pytest.mark.parametrize('expr', [\n        'JOIN',\n        'LEFT JOIN',\n        'LEFT OUTER JOIN',\n        'FULL OUTER JOIN',\n        'NATURAL JOIN',\n        'CROSS JOIN',\n        'STRAIGHT JOIN',\n        'INNER JOIN',\n        'LEFT INNER JOIN'])\n    def test_parse_join(expr):\n>       p = sqlparse.parse(f'{expr} foo')[0]\n\nrepos\\sqlparse\\tests\\test_tokenize.py:153: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:61: in group_case\n    _group_matching(tlist, sql.Case)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Keyword 'FULL O...' at 0x1DF61BC2B00>, ttype = Token.Keyword\nvalues = 'CASE', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""expr = 'NATURAL JOIN'\n\n    @pytest.mark.parametrize('expr', [\n        'JOIN',\n        'LEFT JOIN',\n        'LEFT OUTER JOIN',\n        'FULL OUTER JOIN',\n        'NATURAL JOIN',\n        'CROSS JOIN',\n        'STRAIGHT JOIN',\n        'INNER JOIN',\n        'LEFT INNER JOIN'])\n    def test_parse_join(expr):\n>       p = sqlparse.parse(f'{expr} foo')[0]\n\nrepos\\sqlparse\\tests\\test_tokenize.py:153: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:61: in group_case\n    _group_matching(tlist, sql.Case)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Keyword 'NATURA...' at 0x1DF61B36740>, ttype = Token.Keyword\nvalues = 'CASE', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""expr = 'CROSS JOIN'\n\n    @pytest.mark.parametrize('expr', [\n        'JOIN',\n        'LEFT JOIN',\n        'LEFT OUTER JOIN',\n        'FULL OUTER JOIN',\n        'NATURAL JOIN',\n        'CROSS JOIN',\n        'STRAIGHT JOIN',\n        'INNER JOIN',\n        'LEFT INNER JOIN'])\n    def test_parse_join(expr):\n>       p = sqlparse.parse(f'{expr} foo')[0]\n\nrepos\\sqlparse\\tests\\test_tokenize.py:153: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:61: in group_case\n    _group_matching(tlist, sql.Case)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Keyword 'CROSS ...' at 0x1DF61B35720>, ttype = Token.Keyword\nvalues = 'CASE', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""expr = 'STRAIGHT JOIN'\n\n    @pytest.mark.parametrize('expr', [\n        'JOIN',\n        'LEFT JOIN',\n        'LEFT OUTER JOIN',\n        'FULL OUTER JOIN',\n        'NATURAL JOIN',\n        'CROSS JOIN',\n        'STRAIGHT JOIN',\n        'INNER JOIN',\n        'LEFT INNER JOIN'])\n    def test_parse_join(expr):\n>       p = sqlparse.parse(f'{expr} foo')[0]\n\nrepos\\sqlparse\\tests\\test_tokenize.py:153: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:61: in group_case\n    _group_matching(tlist, sql.Case)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Keyword 'STRAIG...' at 0x1DF61B35360>, ttype = Token.Keyword\nvalues = 'CASE', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""expr = 'INNER JOIN'\n\n    @pytest.mark.parametrize('expr', [\n        'JOIN',\n        'LEFT JOIN',\n        'LEFT OUTER JOIN',\n        'FULL OUTER JOIN',\n        'NATURAL JOIN',\n        'CROSS JOIN',\n        'STRAIGHT JOIN',\n        'INNER JOIN',\n        'LEFT INNER JOIN'])\n    def test_parse_join(expr):\n>       p = sqlparse.parse(f'{expr} foo')[0]\n\nrepos\\sqlparse\\tests\\test_tokenize.py:153: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:61: in group_case\n    _group_matching(tlist, sql.Case)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Keyword 'INNER ...' at 0x1DF61B373A0>, ttype = Token.Keyword\nvalues = 'CASE', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""expr = 'LEFT INNER JOIN'\n\n    @pytest.mark.parametrize('expr', [\n        'JOIN',\n        'LEFT JOIN',\n        'LEFT OUTER JOIN',\n        'FULL OUTER JOIN',\n        'NATURAL JOIN',\n        'CROSS JOIN',\n        'STRAIGHT JOIN',\n        'INNER JOIN',\n        'LEFT INNER JOIN'])\n    def test_parse_join(expr):\n>       p = sqlparse.parse(f'{expr} foo')[0]\n\nrepos\\sqlparse\\tests\\test_tokenize.py:153: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:61: in group_case\n    _group_matching(tlist, sql.Case)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Keyword 'LEFT I...' at 0x1DF61BC2440>, ttype = Token.Keyword\nvalues = 'CASE', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""def test_parse_union():  # issue294\n>       p = sqlparse.parse('UNION ALL')[0]\n\nrepos\\sqlparse\\tests\\test_tokenize.py:159: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:61: in group_case\n    _group_matching(tlist, sql.Case)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Keyword 'UNION ...' at 0x1DF61ACFD00>, ttype = Token.Keyword\nvalues = 'CASE', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""s = 'END IF'\n\n    @pytest.mark.parametrize('s', ['END IF', 'END   IF', 'END\\t\\nIF',\n                                   'END LOOP', 'END   LOOP', 'END\\t\\nLOOP'])\n    def test_parse_endifloop(s):\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_tokenize.py:167: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:61: in group_case\n    _group_matching(tlist, sql.Case)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Keyword 'END IF' at 0x1DF61ACFFA0>, ttype = Token.Keyword\nvalues = 'CASE', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""s = 'END   IF'\n\n    @pytest.mark.parametrize('s', ['END IF', 'END   IF', 'END\\t\\nIF',\n                                   'END LOOP', 'END   LOOP', 'END\\t\\nLOOP'])\n    def test_parse_endifloop(s):\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_tokenize.py:167: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:61: in group_case\n    _group_matching(tlist, sql.Case)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Keyword 'END ...' at 0x1DF61ACCE20>, ttype = Token.Keyword\nvalues = 'CASE', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""s = 'END\\t\\nIF'\n\n    @pytest.mark.parametrize('s', ['END IF', 'END   IF', 'END\\t\\nIF',\n                                   'END LOOP', 'END   LOOP', 'END\\t\\nLOOP'])\n    def test_parse_endifloop(s):\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_tokenize.py:167: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:61: in group_case\n    _group_matching(tlist, sql.Case)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Keyword 'END IF' at 0x1DF61ACE320>, ttype = Token.Keyword\nvalues = 'CASE', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""s = 'END LOOP'\n\n    @pytest.mark.parametrize('s', ['END IF', 'END   IF', 'END\\t\\nIF',\n                                   'END LOOP', 'END   LOOP', 'END\\t\\nLOOP'])\n    def test_parse_endifloop(s):\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_tokenize.py:167: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:61: in group_case\n    _group_matching(tlist, sql.Case)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Keyword 'END LO...' at 0x1DF61AC3160>, ttype = Token.Keyword\nvalues = 'CASE', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""s = 'END   LOOP'\n\n    @pytest.mark.parametrize('s', ['END IF', 'END   IF', 'END\\t\\nIF',\n                                   'END LOOP', 'END   LOOP', 'END\\t\\nLOOP'])\n    def test_parse_endifloop(s):\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_tokenize.py:167: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:61: in group_case\n    _group_matching(tlist, sql.Case)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Keyword 'END ...' at 0x1DF61B37B80>, ttype = Token.Keyword\nvalues = 'CASE', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""s = 'END\\t\\nLOOP'\n\n    @pytest.mark.parametrize('s', ['END IF', 'END   IF', 'END\\t\\nIF',\n                                   'END LOOP', 'END   LOOP', 'END\\t\\nLOOP'])\n    def test_parse_endifloop(s):\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_tokenize.py:167: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:61: in group_case\n    _group_matching(tlist, sql.Case)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Keyword 'END L...' at 0x1DF61A283A0>, ttype = Token.Keyword\nvalues = 'CASE', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""def test_parse_group_by():\n>       p = sqlparse.parse('GROUP BY')[0]\n\nrepos\\sqlparse\\tests\\test_tokenize.py:199: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:61: in group_case\n    _group_matching(tlist, sql.Case)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Keyword 'GROUP ...' at 0x1DF61ACF280>, ttype = Token.Keyword\nvalues = 'CASE', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""def test_parse_order_by():\n>       p = sqlparse.parse('ORDER BY')[0]\n\nrepos\\sqlparse\\tests\\test_tokenize.py:205: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:61: in group_case\n    _group_matching(tlist, sql.Case)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Keyword 'ORDER ...' at 0x1DF61A28520>, ttype = Token.Keyword\nvalues = 'CASE', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError"", ""def test_parse_window_as():\n>       p = sqlparse.parse('WINDOW w AS')[0]\n\nrepos\\sqlparse\\tests\\test_tokenize.py:211: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:61: in group_case\n    _group_matching(tlist, sql.Case)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:37: in _group_matching\n    if token.match(*cls.M_OPEN):\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Keyword 'WINDOW' at 0x1DF61BAA260>, ttype = Token.Keyword\nvalues = 'CASE', regex = False\n\n    def match(self, ttype, values, regex=False):\n        if regex:\n            regex_pattern = '|'.join(values)\n            return bool(re.match(regex_pattern, self.token)) if ttype == self.ttype else False\n        else:\n>           return True if ttype == self.ttype and self.token in values else False\nE           AttributeError: 'Token' object has no attribute 'token'\n\nrepos\\sqlparse\\sqlparse\\sql.py:70: AttributeError""]",sqlparse/match,LLM
sqlparse,token_next,"def token_next(self, idx, skip_ws=True, skip_cm=False, _reverse=False):
    """"""Returns the next token relative to *idx*.

        If *skip_ws* is ``True`` (the default) whitespace tokens are ignored.
        If *skip_cm* is ``True`` comments are ignored.
        ``None`` is returned if there's no next token.
        """"""
    if idx is None:
        return (None, None)
    idx += 1

    def matcher(tk):
        return not (skip_ws and tk.is_whitespace or (skip_cm and imt(tk, t=T.Comment, i=Comment)))
    return self._token_matching(matcher, idx, reverse=_reverse)","The goal of the `token_next` function is to return the next token relative to a given index, while optionally skipping whitespace and comments. It ignores whitespace tokens and comments based on the parameters passed. If there is no next token, it returns `None`. This function interacts with the class context by calling another method `_token_matching` to match the next token based on the specified criteria.",1,"def token_next(self, idx, skip_ws=False, skip_cm=False, _reverse=False):
    return self._token_matching(idx, skip_ws, skip_cm, _reverse)","['./repos/sqlparse\\tests', './repos/sqlparse\\tests\\test_cli.py::test_cli_main_empty', './repos/sqlparse\\tests\\test_cli.py::test_parser_empty', './repos/sqlparse\\tests\\test_cli.py::test_main_help', './repos/sqlparse\\tests\\test_cli.py::test_valid_args', './repos/sqlparse\\tests\\test_cli.py::test_invalid_choice', './repos/sqlparse\\tests\\test_cli.py::test_invalid_args', './repos/sqlparse\\tests\\test_cli.py::test_invalid_infile', './repos/sqlparse\\tests\\test_cli.py::test_invalid_outfile', './repos/sqlparse\\tests\\test_cli.py::test_stdout', './repos/sqlparse\\tests\\test_cli.py::test_script', './repos/sqlparse\\tests\\test_cli.py::test_encoding_stdout', './repos/sqlparse\\tests\\test_cli.py::test_encoding_output_file', './repos/sqlparse\\tests\\test_cli.py::test_encoding_stdin', './repos/sqlparse\\tests\\test_cli.py::test_encoding', './repos/sqlparse\\tests\\test_format.py::test_format_column_ordering', './repos/sqlparse\\tests\\test_format.py::test_truncate_strings', './repos/sqlparse\\tests\\test_format.py::test_truncate_strings_invalid_option2', './repos/sqlparse\\tests\\test_format.py::test_truncate_strings_doesnt_truncate_identifiers', './repos/sqlparse\\tests\\test_format.py::test_having_produces_newline', './repos/sqlparse\\tests\\test_format.py::test_format_right_margin_invalid_option', './repos/sqlparse\\tests\\test_format.py::test_format_right_margin', './repos/sqlparse\\tests\\test_format.py::test_format_json_ops', './repos/sqlparse\\tests\\test_format.py::test_compact', './repos/sqlparse\\tests\\test_format.py::test_strip_ws_removes_trailing_ws_in_groups', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_parenthesis', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_assignment', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_typed_literal', './repos/sqlparse\\tests\\test_grouping.py::test_compare_expr', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifiers', './repos/sqlparse\\tests\\test_grouping.py::test_simple_identifiers', './repos/sqlparse\\tests\\test_grouping.py::test_group_identifier_list', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifier_wildcard', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifier_name_wildcard', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifier_invalid', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifier_invalid_in_middle', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifer_as', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifier_as_invalid', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifier_function', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_operation', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifier_list', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifier_list_subquery', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifier_list_case', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifier_list_other', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifier_list_with_inline_comments', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifiers_with_operators', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifier_list_with_order', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_nested_identifier_with_order', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_where', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_where_union', './repos/sqlparse\\tests\\test_grouping.py::test_returning_kw_ends_where_clause', './repos/sqlparse\\tests\\test_grouping.py::test_into_kw_ends_where_clause', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_typecast', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_alias', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_alias_case', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_alias_ctas', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_subquery_no_parens', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_alias_returns_none', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_idlist_function', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_comparison_exclude', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_function', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_function_not_in', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_varchar', './repos/sqlparse\\tests\\test_grouping.py::test_statement_get_type', './repos/sqlparse\\tests\\test_grouping.py::test_identifier_with_operators', './repos/sqlparse\\tests\\test_grouping.py::test_identifier_with_op_trailing_ws', './repos/sqlparse\\tests\\test_grouping.py::test_identifier_with_string_literals', './repos/sqlparse\\tests\\test_grouping.py::test_identifier_consumes_ordering', './repos/sqlparse\\tests\\test_grouping.py::test_comparison_with_keywords', './repos/sqlparse\\tests\\test_grouping.py::test_comparison_with_floats', './repos/sqlparse\\tests\\test_grouping.py::test_comparison_with_parenthesis', './repos/sqlparse\\tests\\test_grouping.py::test_comparison_with_strings', './repos/sqlparse\\tests\\test_grouping.py::test_like_and_ilike_comparison', './repos/sqlparse\\tests\\test_grouping.py::test_comparison_with_functions', './repos/sqlparse\\tests\\test_grouping.py::test_comparison_with_typed_literal', './repos/sqlparse\\tests\\test_grouping.py::test_forloops', './repos/sqlparse\\tests\\test_grouping.py::test_nested_for', './repos/sqlparse\\tests\\test_grouping.py::test_begin', './repos/sqlparse\\tests\\test_grouping.py::test_keyword_followed_by_parenthesis', './repos/sqlparse\\tests\\test_grouping.py::test_nested_begin', './repos/sqlparse\\tests\\test_grouping.py::test_aliased_column_without_as', './repos/sqlparse\\tests\\test_grouping.py::test_qualified_function', './repos/sqlparse\\tests\\test_grouping.py::test_aliased_function_without_as', './repos/sqlparse\\tests\\test_grouping.py::test_aliased_literal_without_as', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_as_cte', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_create_table', './repos/sqlparse\\tests\\test_parse.py::test_parse_tokenize', './repos/sqlparse\\tests\\test_parse.py::test_parse_multistatement', './repos/sqlparse\\tests\\test_parse.py::test_parse_newlines', './repos/sqlparse\\tests\\test_parse.py::test_parse_within', './repos/sqlparse\\tests\\test_parse.py::test_parse_child_of', './repos/sqlparse\\tests\\test_parse.py::test_parse_has_ancestor', './repos/sqlparse\\tests\\test_parse.py::test_parse_float', './repos/sqlparse\\tests\\test_parse.py::test_parse_placeholder', './repos/sqlparse\\tests\\test_parse.py::test_parse_modulo_not_placeholder', './repos/sqlparse\\tests\\test_parse.py::test_parse_access_symbol', './repos/sqlparse\\tests\\test_parse.py::test_parse_square_brackets_notation_isnt_too_greedy', './repos/sqlparse\\tests\\test_parse.py::test_parse_square_brackets_notation_isnt_too_greedy2', './repos/sqlparse\\tests\\test_parse.py::test_parse_keyword_like_identifier', './repos/sqlparse\\tests\\test_parse.py::test_parse_function_parameter', './repos/sqlparse\\tests\\test_parse.py::test_parse_function_param_single_literal', './repos/sqlparse\\tests\\test_parse.py::test_parse_nested_function', './repos/sqlparse\\tests\\test_parse.py::test_parse_casted_params', './repos/sqlparse\\tests\\test_parse.py::test_parse_div_operator', './repos/sqlparse\\tests\\test_parse.py::test_quoted_identifier', './repos/sqlparse\\tests\\test_parse.py::test_valid_identifier_names', './repos/sqlparse\\tests\\test_parse.py::test_psql_quotation_marks', './repos/sqlparse\\tests\\test_parse.py::test_double_precision_is_builtin', './repos/sqlparse\\tests\\test_parse.py::test_placeholder', './repos/sqlparse\\tests\\test_parse.py::test_scientific_numbers', './repos/sqlparse\\tests\\test_parse.py::test_single_quotes_are_strings', './repos/sqlparse\\tests\\test_parse.py::test_double_quotes_are_identifiers', './repos/sqlparse\\tests\\test_parse.py::test_single_quotes_with_linebreaks', './repos/sqlparse\\tests\\test_parse.py::test_sqlite_identifiers', './repos/sqlparse\\tests\\test_parse.py::test_simple_1d_array_index', './repos/sqlparse\\tests\\test_parse.py::test_2d_array_index', './repos/sqlparse\\tests\\test_parse.py::test_array_index_function_result', './repos/sqlparse\\tests\\test_parse.py::test_schema_qualified_array_index', './repos/sqlparse\\tests\\test_parse.py::test_aliased_array_index', './repos/sqlparse\\tests\\test_parse.py::test_array_literal', './repos/sqlparse\\tests\\test_parse.py::test_typed_array_definition', './repos/sqlparse\\tests\\test_parse.py::test_single_line_comments', './repos/sqlparse\\tests\\test_parse.py::test_names_and_special_names', './repos/sqlparse\\tests\\test_parse.py::test_get_token_at_offset', './repos/sqlparse\\tests\\test_parse.py::test_pprint', './repos/sqlparse\\tests\\test_parse.py::test_wildcard_multiplication', './repos/sqlparse\\tests\\test_parse.py::test_stmt_tokens_parents', './repos/sqlparse\\tests\\test_parse.py::test_dbldollar_as_literal', './repos/sqlparse\\tests\\test_parse.py::test_non_ascii', './repos/sqlparse\\tests\\test_parse.py::test_get_real_name', './repos/sqlparse\\tests\\test_parse.py::test_from_subquery', './repos/sqlparse\\tests\\test_parse.py::test_parenthesis', './repos/sqlparse\\tests\\test_parse.py::test_configurable_keywords', './repos/sqlparse\\tests\\test_parse.py::test_configurable_regex', './repos/sqlparse\\tests\\test_parse.py::test_json_operators', './repos/sqlparse\\tests\\test_regressions.py::test_issue9', './repos/sqlparse\\tests\\test_regressions.py::test_issue13', './repos/sqlparse\\tests\\test_regressions.py::test_issue26', './repos/sqlparse\\tests\\test_regressions.py::test_issue34', './repos/sqlparse\\tests\\test_regressions.py::test_issue35', './repos/sqlparse\\tests\\test_regressions.py::test_issue38', './repos/sqlparse\\tests\\test_regressions.py::test_issue39', './repos/sqlparse\\tests\\test_regressions.py::test_issue40', './repos/sqlparse\\tests\\test_regressions.py::test_issue78', './repos/sqlparse\\tests\\test_regressions.py::test_issue83', './repos/sqlparse\\tests\\test_regressions.py::test_comment_encoding_when_reindent', './repos/sqlparse\\tests\\test_regressions.py::test_parse_sql_with_binary', './repos/sqlparse\\tests\\test_regressions.py::test_dont_alias_keywords', './repos/sqlparse\\tests\\test_regressions.py::test_format_accepts_encoding', './repos/sqlparse\\tests\\test_regressions.py::test_stream', './repos/sqlparse\\tests\\test_regressions.py::test_issue90', './repos/sqlparse\\tests\\test_regressions.py::test_except_formatting', './repos/sqlparse\\tests\\test_regressions.py::test_null_with_as', './repos/sqlparse\\tests\\test_regressions.py::test_issue190_open_file', './repos/sqlparse\\tests\\test_regressions.py::test_issue193_splitting_function', './repos/sqlparse\\tests\\test_regressions.py::test_issue194_splitting_function', './repos/sqlparse\\tests\\test_regressions.py::test_issue186_get_type', './repos/sqlparse\\tests\\test_regressions.py::test_issue212_py2unicode', './repos/sqlparse\\tests\\test_regressions.py::test_issue213_leadingws', './repos/sqlparse\\tests\\test_regressions.py::test_issue227_gettype_cte', './repos/sqlparse\\tests\\test_regressions.py::test_issue207_runaway_format', './repos/sqlparse\\tests\\test_regressions.py::test_token_next_doesnt_ignore_skip_cm', './repos/sqlparse\\tests\\test_regressions.py::test_issue284_as_grouping', './repos/sqlparse\\tests\\test_regressions.py::test_issue315_utf8_by_default', './repos/sqlparse\\tests\\test_regressions.py::test_issue322_concurrently_is_keyword', './repos/sqlparse\\tests\\test_regressions.py::test_issue359_index_error_assignments', './repos/sqlparse\\tests\\test_regressions.py::test_issue469_copy_as_psql_command', './repos/sqlparse\\tests\\test_regressions.py::test_issue484_comments_and_newlines', './repos/sqlparse\\tests\\test_regressions.py::test_issue485_split_multi', './repos/sqlparse\\tests\\test_regressions.py::test_issue489_tzcasts', './repos/sqlparse\\tests\\test_regressions.py::test_issue562_tzcasts', './repos/sqlparse\\tests\\test_regressions.py::test_as_in_parentheses_indents', './repos/sqlparse\\tests\\test_regressions.py::test_format_invalid_where_clause', './repos/sqlparse\\tests\\test_regressions.py::test_splitting_at_and_backticks_issue588', './repos/sqlparse\\tests\\test_regressions.py::test_comment_between_cte_clauses_issue632', './repos/sqlparse\\tests\\test_regressions.py::test_copy_issue672', './repos/sqlparse\\tests\\test_regressions.py::test_primary_key_issue740', './repos/sqlparse\\tests\\test_regressions.py::test_max_recursion', './repos/sqlparse\\tests\\test_split.py::test_split_semicolon', './repos/sqlparse\\tests\\test_split.py::test_split_backslash', './repos/sqlparse\\tests\\test_split.py::test_split_create_function', './repos/sqlparse\\tests\\test_split.py::test_split_dashcomments', './repos/sqlparse\\tests\\test_split.py::test_split_dashcomments_eol', './repos/sqlparse\\tests\\test_split.py::test_split_begintag', './repos/sqlparse\\tests\\test_split.py::test_split_begintag_2', './repos/sqlparse\\tests\\test_split.py::test_split_dropif', './repos/sqlparse\\tests\\test_split.py::test_split_comment_with_umlaut', './repos/sqlparse\\tests\\test_split.py::test_split_comment_end_of_line', './repos/sqlparse\\tests\\test_split.py::test_split_casewhen', './repos/sqlparse\\tests\\test_split.py::test_split_casewhen_procedure', './repos/sqlparse\\tests\\test_split.py::test_split_cursor_declare', './repos/sqlparse\\tests\\test_split.py::test_split_if_function', './repos/sqlparse\\tests\\test_split.py::test_split_stream', './repos/sqlparse\\tests\\test_split.py::test_split_encoding_parsestream', './repos/sqlparse\\tests\\test_split.py::test_split_unicode_parsestream', './repos/sqlparse\\tests\\test_split.py::test_split_simple', './repos/sqlparse\\tests\\test_split.py::test_split_ignores_empty_newlines', './repos/sqlparse\\tests\\test_split.py::test_split_quotes_with_new_line', './repos/sqlparse\\tests\\test_split.py::test_split_mysql_handler_for', './repos/sqlparse\\tests\\test_split.py::test_split_strip_semicolon', './repos/sqlparse\\tests\\test_split.py::test_split_strip_semicolon_procedure', './repos/sqlparse\\tests\\test_split.py::test_split_go', './repos/sqlparse\\tests\\test_split.py::test_split_multiple_case_in_begin', './repos/sqlparse\\tests\\test_tokenize.py::test_tokenize_simple', './repos/sqlparse\\tests\\test_tokenize.py::test_tokenize_backticks', './repos/sqlparse\\tests\\test_tokenize.py::test_tokenize_linebreaks', './repos/sqlparse\\tests\\test_tokenize.py::test_tokenize_inline_keywords', './repos/sqlparse\\tests\\test_tokenize.py::test_tokenize_negative_numbers', './repos/sqlparse\\tests\\test_tokenize.py::test_token_str', './repos/sqlparse\\tests\\test_tokenize.py::test_token_repr', './repos/sqlparse\\tests\\test_tokenize.py::test_token_flatten', './repos/sqlparse\\tests\\test_tokenize.py::test_tokenlist_repr', './repos/sqlparse\\tests\\test_tokenize.py::test_single_quotes', './repos/sqlparse\\tests\\test_tokenize.py::test_tokenlist_first', './repos/sqlparse\\tests\\test_tokenize.py::test_tokenlist_token_matching', './repos/sqlparse\\tests\\test_tokenize.py::test_stream_simple', './repos/sqlparse\\tests\\test_tokenize.py::test_stream_error', './repos/sqlparse\\tests\\test_tokenize.py::test_parse_join', './repos/sqlparse\\tests\\test_tokenize.py::test_parse_union', './repos/sqlparse\\tests\\test_tokenize.py::test_parse_endifloop', './repos/sqlparse\\tests\\test_tokenize.py::test_parse_order', './repos/sqlparse\\tests\\test_tokenize.py::test_parse_identifiers', './repos/sqlparse\\tests\\test_tokenize.py::test_parse_group_by', './repos/sqlparse\\tests\\test_tokenize.py::test_parse_order_by', './repos/sqlparse\\tests\\test_tokenize.py::test_parse_window_as', './repos/sqlparse\\tests\\test_tokenize.py::test_like_and_ilike_parsed_as_comparisons', './repos/sqlparse\\tests\\test_tokenize.py::test_near_like_and_ilike_parsed_appropriately', './repos/sqlparse\\tests\\test_tokenize.py::test_parse_tzcast', './repos/sqlparse\\tests\\test_tokenize.py::test_cli_commands', './repos/sqlparse\\tests\\test_utils.py::test_remove_quotes']","248 Passed, 213 Failed",248,213,"['tests/test_cli.py::test_valid_args', 'tests/test_format.py::TestFormat::test_strip_comments_single', 'tests/test_format.py::TestFormat::test_strip_comments_multi', 'tests/test_format.py::TestFormat::test_strip_comments_preserves_linebreak', 'tests/test_format.py::TestFormat::test_strip_comments_preserves_whitespace', 'tests/test_format.py::TestFormat::test_strip_comments_preserves_hint', 'tests/test_format.py::TestFormat::test_strip_ws', 'tests/test_format.py::TestFormat::test_preserve_ws', 'tests/test_format.py::TestFormatReindentAligned::test_basic', 'tests/test_format.py::TestFormatReindentAligned::test_joins', 'tests/test_format.py::TestFormatReindentAligned::test_case_statement', 'tests/test_format.py::TestFormatReindentAligned::test_case_statement_with_between', 'tests/test_format.py::TestFormatReindentAligned::test_group_by', 'tests/test_format.py::TestFormatReindentAligned::test_group_by_subquery', 'tests/test_format.py::TestFormatReindentAligned::test_window_functions', 'tests/test_format.py::TestSpacesAroundOperators::test_basic', 'tests/test_format.py::TestSpacesAroundOperators::test_bools', 'tests/test_format.py::TestSpacesAroundOperators::test_nested', 'tests/test_format.py::TestSpacesAroundOperators::test_wildcard_vs_mult', 'tests/test_format.py::TestFormatReindent::test_stmts', 'tests/test_format.py::TestFormatReindent::test_keywords', 'tests/test_format.py::TestFormatReindent::test_keywords_between', 'tests/test_format.py::TestFormatReindent::test_parenthesis', 'tests/test_format.py::TestFormatReindent::test_where', 'tests/test_format.py::TestFormatReindent::test_join', 'tests/test_format.py::TestFormatReindent::test_identifier_list', 'tests/test_format.py::TestFormatReindent::test_identifier_list_with_wrap_after', 'tests/test_format.py::TestFormatReindent::test_identifier_list_comment_first', 'tests/test_format.py::TestFormatReindent::test_identifier_list_with_functions', 'tests/test_format.py::TestFormatReindent::test_long_identifier_list_with_functions', 'tests/test_format.py::TestFormatReindent::test_nested_identifier_list', 'tests/test_format.py::TestFormatReindent::test_duplicate_linebreaks', 'tests/test_format.py::TestFormatReindent::test_keywordfunctions', 'tests/test_format.py::TestFormatReindent::test_identifier_and_functions', 'tests/test_format.py::TestFormatReindent::test_insert_values', 'tests/test_format.py::TestOutputFormat::test_python', 'tests/test_format.py::TestOutputFormat::test_php', 'tests/test_format.py::test_format_column_ordering', 'tests/test_format.py::test_having_produces_newline', 'tests/test_format.py::test_format_json_ops', 'tests/test_grouping.py::test_grouping_parenthesis', 'tests/test_grouping.py::test_grouping_assignment[foo := 1;]', 'tests/test_grouping.py::test_grouping_assignment[foo := 1]', ""tests/test_grouping.py::test_grouping_typed_literal[x > DATE '2020-01-01']"", ""tests/test_grouping.py::test_grouping_typed_literal[x > TIMESTAMP '2020-01-01 00:00:00']"", 'tests/test_grouping.py::test_compare_expr[select a from b where c < d + e-Identifier-Identifier]', ""tests/test_grouping.py::test_compare_expr[select a from b where c < d + interval '1 day'-Identifier-TypedLiteral]"", ""tests/test_grouping.py::test_compare_expr[select a from b where c < d + interval '6' month-Identifier-TypedLiteral]"", ""tests/test_grouping.py::test_compare_expr[select a from b where c < current_timestamp - interval '1 day'-Token-TypedLiteral]"", 'tests/test_grouping.py::test_grouping_identifiers', 'tests/test_grouping.py::test_simple_identifiers[1 as f]', 'tests/test_grouping.py::test_simple_identifiers[1/2 as f]', 'tests/test_grouping.py::test_simple_identifiers[1/2 f]', 'tests/test_grouping.py::test_simple_identifiers[1<2 as f]', 'tests/test_grouping.py::test_simple_identifiers[1<2 f]', 'tests/test_grouping.py::test_group_identifier_list[foo, bar]', 'tests/test_grouping.py::test_group_identifier_list[sum(a), sum(b)]', 'tests/test_grouping.py::test_group_identifier_list[sum(a) as x, b as y]', 'tests/test_grouping.py::test_group_identifier_list[sum(a)::integer, b]', 'tests/test_grouping.py::test_group_identifier_list[sum(a)/count(b) as x, y]', 'tests/test_grouping.py::test_group_identifier_list[sum(a)::integer as x, y]', 'tests/test_grouping.py::test_group_identifier_list[sum(a)::integer/count(b) as x, y]', 'tests/test_grouping.py::test_grouping_identifier_wildcard', 'tests/test_grouping.py::test_grouping_identifier_name_wildcard', 'tests/test_grouping.py::test_grouping_identifier_invalid', 'tests/test_grouping.py::test_grouping_identifer_as[foo as (select *)]', 'tests/test_grouping.py::test_grouping_identifer_as[foo as(select *)]', 'tests/test_grouping.py::test_grouping_identifier_function', 'tests/test_grouping.py::test_grouping_operation[foo+100]', 'tests/test_grouping.py::test_grouping_operation[foo + 100]', 'tests/test_grouping.py::test_grouping_operation[foo*100]', 'tests/test_grouping.py::test_grouping_identifier_list', 'tests/test_grouping.py::test_grouping_identifier_list_subquery', 'tests/test_grouping.py::test_grouping_identifier_list_case', 'tests/test_grouping.py::test_grouping_identifier_list_other', 'tests/test_grouping.py::test_grouping_identifier_list_with_inline_comments', 'tests/test_grouping.py::test_grouping_identifier_list_with_order', 'tests/test_grouping.py::test_grouping_nested_identifier_with_order', 'tests/test_grouping.py::test_grouping_where', 'tests/test_grouping.py::test_grouping_typecast[select foo::integer from bar-integer]', 'tests/test_grouping.py::test_grouping_typecast[select (current_database())::information_schema.sql_identifier-information_schema.sql_identifier]', 'tests/test_grouping.py::test_grouping_alias', 'tests/test_grouping.py::test_grouping_alias_case', 'tests/test_grouping.py::test_grouping_alias_ctas', 'tests/test_grouping.py::test_grouping_alias_returns_none[foo.bar]', 'tests/test_grouping.py::test_grouping_alias_returns_none[x, y]', 'tests/test_grouping.py::test_grouping_alias_returns_none[x > y]', 'tests/test_grouping.py::test_grouping_alias_returns_none[x / y]', 'tests/test_grouping.py::test_grouping_idlist_function', 'tests/test_grouping.py::test_grouping_comparison_exclude', 'tests/test_grouping.py::test_grouping_function', 'tests/test_grouping.py::test_grouping_varchar', 'tests/test_grouping.py::test_identifier_with_operators', 'tests/test_grouping.py::test_identifier_with_op_trailing_ws', 'tests/test_grouping.py::test_identifier_with_string_literals', 'tests/test_grouping.py::test_identifier_consumes_ordering', 'tests/test_grouping.py::test_comparison_with_keywords', 'tests/test_grouping.py::test_comparison_with_floats', 'tests/test_grouping.py::test_comparison_with_parenthesis', 'tests/test_grouping.py::test_comparison_with_strings[=]', 'tests/test_grouping.py::test_comparison_with_strings[!=]', 'tests/test_grouping.py::test_comparison_with_strings[>]', 'tests/test_grouping.py::test_comparison_with_strings[<]', 'tests/test_grouping.py::test_comparison_with_strings[<=]', 'tests/test_grouping.py::test_comparison_with_strings[>=]', 'tests/test_grouping.py::test_comparison_with_strings[~]', 'tests/test_grouping.py::test_comparison_with_strings[~~]', 'tests/test_grouping.py::test_comparison_with_strings[!~~]', 'tests/test_grouping.py::test_comparison_with_strings[LIKE]', 'tests/test_grouping.py::test_comparison_with_strings[NOT LIKE]', 'tests/test_grouping.py::test_comparison_with_strings[ILIKE]', 'tests/test_grouping.py::test_comparison_with_strings[NOT ILIKE]', 'tests/test_grouping.py::test_like_and_ilike_comparison', 'tests/test_grouping.py::test_comparison_with_functions', 'tests/test_grouping.py::test_comparison_with_typed_literal', 'tests/test_grouping.py::test_aliased_column_without_as', 'tests/test_grouping.py::test_qualified_function', 'tests/test_grouping.py::test_aliased_function_without_as', 'tests/test_grouping.py::test_aliased_literal_without_as', 'tests/test_grouping.py::test_grouping_create_table', 'tests/test_parse.py::test_parse_within', 'tests/test_parse.py::test_parse_access_symbol', 'tests/test_parse.py::test_parse_square_brackets_notation_isnt_too_greedy', 'tests/test_parse.py::test_parse_keyword_like_identifier', 'tests/test_parse.py::test_parse_function_parameter', 'tests/test_parse.py::test_parse_function_param_single_literal', 'tests/test_parse.py::test_parse_nested_function', 'tests/test_parse.py::test_parse_casted_params', 'tests/test_parse.py::test_parse_div_operator', 'tests/test_parse.py::test_quoted_identifier', 'tests/test_parse.py::test_sqlite_identifiers', 'tests/test_parse.py::test_array_index_function_result', 'tests/test_parse.py::test_schema_qualified_array_index', 'tests/test_parse.py::test_aliased_array_index', 'tests/test_parse.py::test_pprint', 'tests/test_parse.py::test_wildcard_multiplication', 'tests/test_parse.py::test_get_real_name', 'tests/test_parse.py::test_configurable_keywords', 'tests/test_regressions.py::test_issue35', 'tests/test_regressions.py::test_issue38', 'tests/test_regressions.py::test_issue39', 'tests/test_regressions.py::test_issue40', 'tests/test_regressions.py::test_issue78[get_name-z-select x.y::text as z from foo]', 'tests/test_regressions.py::test_issue78[get_name-z-select x.y::text as ""z"" from foo]', 'tests/test_regressions.py::test_issue78[get_name-z-select x.""y""::text as z from foo]', 'tests/test_regressions.py::test_issue78[get_name-z-select x.""y""::text as ""z"" from foo]', 'tests/test_regressions.py::test_issue78[get_name-z-select ""x"".y::text as z from foo]', 'tests/test_regressions.py::test_issue78[get_name-z-select ""x"".y::text as ""z"" from foo]', 'tests/test_regressions.py::test_issue78[get_name-z-select ""x"".""y""::text as z from foo]', 'tests/test_regressions.py::test_issue78[get_name-z-select ""x"".""y""::text as ""z"" from foo]', 'tests/test_regressions.py::test_issue78[get_real_name-y-select x.y::text as z from foo]', 'tests/test_regressions.py::test_issue78[get_real_name-y-select x.y::text as ""z"" from foo]', 'tests/test_regressions.py::test_issue78[get_real_name-y-select x.""y""::text as z from foo]', 'tests/test_regressions.py::test_issue78[get_real_name-y-select x.""y""::text as ""z"" from foo]', 'tests/test_regressions.py::test_issue78[get_real_name-y-select ""x"".y::text as z from foo]', 'tests/test_regressions.py::test_issue78[get_real_name-y-select ""x"".y::text as ""z"" from foo]', 'tests/test_regressions.py::test_issue78[get_real_name-y-select ""x"".""y""::text as z from foo]', 'tests/test_regressions.py::test_issue78[get_real_name-y-select ""x"".""y""::text as ""z"" from foo]', 'tests/test_regressions.py::test_issue78[get_parent_name-x-select x.y::text as z from foo]', 'tests/test_regressions.py::test_issue78[get_parent_name-x-select x.y::text as ""z"" from foo]', 'tests/test_regressions.py::test_issue78[get_parent_name-x-select x.""y""::text as z from foo]', 'tests/test_regressions.py::test_issue78[get_parent_name-x-select x.""y""::text as ""z"" from foo]', 'tests/test_regressions.py::test_issue78[get_parent_name-x-select ""x"".y::text as z from foo]', 'tests/test_regressions.py::test_issue78[get_parent_name-x-select ""x"".y::text as ""z"" from foo]', 'tests/test_regressions.py::test_issue78[get_parent_name-x-select ""x"".""y""::text as z from foo]', 'tests/test_regressions.py::test_issue78[get_parent_name-x-select ""x"".""y""::text as ""z"" from foo]', 'tests/test_regressions.py::test_issue78[get_alias-z-select x.y::text as z from foo]', 'tests/test_regressions.py::test_issue78[get_alias-z-select x.y::text as ""z"" from foo]', 'tests/test_regressions.py::test_issue78[get_alias-z-select x.""y""::text as z from foo]', 'tests/test_regressions.py::test_issue78[get_alias-z-select x.""y""::text as ""z"" from foo]', 'tests/test_regressions.py::test_issue78[get_alias-z-select ""x"".y::text as z from foo]', 'tests/test_regressions.py::test_issue78[get_alias-z-select ""x"".y::text as ""z"" from foo]', 'tests/test_regressions.py::test_issue78[get_alias-z-select ""x"".""y""::text as z from foo]', 'tests/test_regressions.py::test_issue78[get_alias-z-select ""x"".""y""::text as ""z"" from foo]', 'tests/test_regressions.py::test_issue78[get_typecast-text-select x.y::text as z from foo]', 'tests/test_regressions.py::test_issue78[get_typecast-text-select x.y::text as ""z"" from foo]', 'tests/test_regressions.py::test_issue78[get_typecast-text-select x.""y""::text as z from foo]', 'tests/test_regressions.py::test_issue78[get_typecast-text-select x.""y""::text as ""z"" from foo]', 'tests/test_regressions.py::test_issue78[get_typecast-text-select ""x"".y::text as z from foo]', 'tests/test_regressions.py::test_issue78[get_typecast-text-select ""x"".y::text as ""z"" from foo]', 'tests/test_regressions.py::test_issue78[get_typecast-text-select ""x"".""y""::text as z from foo]', 'tests/test_regressions.py::test_issue78[get_typecast-text-select ""x"".""y""::text as ""z"" from foo]', 'tests/test_regressions.py::test_comment_encoding_when_reindent', 'tests/test_regressions.py::test_parse_sql_with_binary', 'tests/test_regressions.py::test_format_accepts_encoding', 'tests/test_regressions.py::test_stream', 'tests/test_regressions.py::test_issue90', 'tests/test_regressions.py::test_except_formatting', 'tests/test_regressions.py::test_null_with_as', 'tests/test_regressions.py::test_issue190_open_file', 'tests/test_regressions.py::test_issue186_get_type', 'tests/test_regressions.py::test_issue227_gettype_cte', 'tests/test_regressions.py::test_issue207_runaway_format', 'tests/test_regressions.py::test_token_next_doesnt_ignore_skip_cm', 'tests/test_regressions.py::test_issue315_utf8_by_default', 'tests/test_regressions.py::test_issue322_concurrently_is_keyword', 'tests/test_regressions.py::test_issue489_tzcasts', 'tests/test_regressions.py::test_issue562_tzcasts', 'tests/test_regressions.py::test_format_invalid_where_clause', 'tests/test_regressions.py::test_comment_between_cte_clauses_issue632', 'tests/test_split.py::test_split_create_function[function_psql4.sql]', 'tests/test_split.py::test_split_dashcomments', 'tests/test_split.py::test_split_begintag_2', 'tests/test_split.py::test_split_comment_with_umlaut', 'tests/test_tokenize.py::test_tokenlist_repr', 'tests/test_tokenize.py::test_parse_order[ASC]', 'tests/test_tokenize.py::test_parse_order[DESC]', 'tests/test_tokenize.py::test_parse_order[NULLS FIRST]', 'tests/test_tokenize.py::test_parse_order[NULLS LAST]', 'tests/test_tokenize.py::test_parse_order[ASC NULLS FIRST]', 'tests/test_tokenize.py::test_parse_order[ASC NULLS LAST]', 'tests/test_tokenize.py::test_parse_order[DESC NULLS FIRST]', 'tests/test_tokenize.py::test_parse_order[DESC NULLS LAST]']","['filepath = <function filepath.<locals>.make_filepath at 0x0000018ED1B3E700>\n\n    def test_valid_args(filepath):\n        # test doesn\'t abort\n        path = filepath(\'function.sql\')\n>       assert sqlparse.cli.main([path, \'-r\']) is not None\n\nrepos\\sqlparse\\tests\\test_cli.py:30: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\cli.py:198: in main\n    s = sqlparse.format(data, **formatter_opts)\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return \'\'.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:44: in run\n    filter_.process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:240: in process\n    self._process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:102: in _process\n    func(tlist)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:233: in _process_default\n    self._split_statements(tlist) if stmts else None\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:89: in _split_statements\n    pidx, prev_ = tlist.token_prev(tidx, skip_ws=False)\nrepos\\sqlparse\\sqlparse\\sql.py:241: in token_prev\n    return self.token_next(idx, skip_ws, skip_cm, _reverse=True)\nrepos\\sqlparse\\sqlparse\\sql.py:244: in token_next\n    return self._token_matching(idx, skip_ws, skip_cm, _reverse)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Statement \'CREATE...\' at 0x18ED1BA7850>, funcs = (0,), start = False\nend = False, reverse = True\n\n    def _token_matching(self, funcs, start=0, end=None, reverse=False):\n        """"""next token that match functions""""""\n        if start is None:\n            return None\n        if not isinstance(funcs, (list, tuple)):\n            funcs = (funcs,)\n        if reverse:\n>           assert end is None\nE           AssertionError\n\nrepos\\sqlparse\\sqlparse\\sql.py:195: AssertionError', 'self = <tests.test_format.TestFormat object at 0x0000018ED17DB680>\n\n    def test_strip_comments_single(self):\n        sql = \'select *-- statement starts here\\nfrom foo\'\n>       res = sqlparse.format(sql, strip_comments=True)\n\nrepos\\sqlparse\\tests\\test_format.py:43: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return \'\'.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\utils.py:74: in wrapped_f\n    f(tlist)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:319: in group_comments\n    eidx, end = tlist.token_prev(eidx, skip_ws=False)\nrepos\\sqlparse\\sqlparse\\sql.py:241: in token_prev\n    return self.token_next(idx, skip_ws, skip_cm, _reverse=True)\nrepos\\sqlparse\\sqlparse\\sql.py:244: in token_next\n    return self._token_matching(idx, skip_ws, skip_cm, _reverse)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Statement \'select...\' at 0x18ED1CC9F50>, funcs = (4,), start = False\nend = False, reverse = True\n\n    def _token_matching(self, funcs, start=0, end=None, reverse=False):\n        """"""next token that match functions""""""\n        if start is None:\n            return None\n        if not isinstance(funcs, (list, tuple)):\n            funcs = (funcs,)\n        if reverse:\n>           assert end is None\nE           AssertionError\n\nrepos\\sqlparse\\sqlparse\\sql.py:195: AssertionError', 'self = <tests.test_format.TestFormat object at 0x0000018ED1978950>\n\n    def test_strip_comments_multi(self):\n        sql = \'/* sql starts here */\\nselect\'\n>       res = sqlparse.format(sql, strip_comments=True)\n\nrepos\\sqlparse\\tests\\test_format.py:72: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return \'\'.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\utils.py:74: in wrapped_f\n    f(tlist)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:319: in group_comments\n    eidx, end = tlist.token_prev(eidx, skip_ws=False)\nrepos\\sqlparse\\sqlparse\\sql.py:241: in token_prev\n    return self.token_next(idx, skip_ws, skip_cm, _reverse=True)\nrepos\\sqlparse\\sqlparse\\sql.py:244: in token_next\n    return self._token_matching(idx, skip_ws, skip_cm, _reverse)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Statement \'/* sql...\' at 0x18ED1CC9CD0>, funcs = (2,), start = False\nend = False, reverse = True\n\n    def _token_matching(self, funcs, start=0, end=None, reverse=False):\n        """"""next token that match functions""""""\n        if start is None:\n            return None\n        if not isinstance(funcs, (list, tuple)):\n            funcs = (funcs,)\n        if reverse:\n>           assert end is None\nE           AssertionError\n\nrepos\\sqlparse\\sqlparse\\sql.py:195: AssertionError', 'self = <tests.test_format.TestFormat object at 0x0000018ED1978A50>\n\n    def test_strip_comments_preserves_linebreak(self):\n        sql = \'select * -- a comment\\r\\nfrom foo\'\n>       res = sqlparse.format(sql, strip_comments=True)\n\nrepos\\sqlparse\\tests\\test_format.py:89: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return \'\'.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\utils.py:74: in wrapped_f\n    f(tlist)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:319: in group_comments\n    eidx, end = tlist.token_prev(eidx, skip_ws=False)\nrepos\\sqlparse\\sqlparse\\sql.py:241: in token_prev\n    return self.token_next(idx, skip_ws, skip_cm, _reverse=True)\nrepos\\sqlparse\\sqlparse\\sql.py:244: in token_next\n    return self._token_matching(idx, skip_ws, skip_cm, _reverse)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Statement \'select...\' at 0x18ED1CC8E50>, funcs = (5,), start = False\nend = False, reverse = True\n\n    def _token_matching(self, funcs, start=0, end=None, reverse=False):\n        """"""next token that match functions""""""\n        if start is None:\n            return None\n        if not isinstance(funcs, (list, tuple)):\n            funcs = (funcs,)\n        if reverse:\n>           assert end is None\nE           AssertionError\n\nrepos\\sqlparse\\sqlparse\\sql.py:195: AssertionError', 'self = <tests.test_format.TestFormat object at 0x0000018ED18AE3F0>\n\n    def test_strip_comments_preserves_whitespace(self):\n        sql = \'SELECT 1/*bar*/ AS foo\'  # see issue772\n>       res = sqlparse.format(sql, strip_comments=True)\n\nrepos\\sqlparse\\tests\\test_format.py:106: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return \'\'.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\utils.py:74: in wrapped_f\n    f(tlist)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:319: in group_comments\n    eidx, end = tlist.token_prev(eidx, skip_ws=False)\nrepos\\sqlparse\\sqlparse\\sql.py:241: in token_prev\n    return self.token_next(idx, skip_ws, skip_cm, _reverse=True)\nrepos\\sqlparse\\sqlparse\\sql.py:244: in token_next\n    return self._token_matching(idx, skip_ws, skip_cm, _reverse)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Statement \'SELECT...\' at 0x18ED1CCA150>, funcs = (4,), start = False\nend = False, reverse = True\n\n    def _token_matching(self, funcs, start=0, end=None, reverse=False):\n        """"""next token that match functions""""""\n        if start is None:\n            return None\n        if not isinstance(funcs, (list, tuple)):\n            funcs = (funcs,)\n        if reverse:\n>           assert end is None\nE           AssertionError\n\nrepos\\sqlparse\\sqlparse\\sql.py:195: AssertionError', 'self = <tests.test_format.TestFormat object at 0x0000018ED18AE5D0>\n\n    def test_strip_comments_preserves_hint(self):\n        sql = \'select --+full(u)\'\n        res = sqlparse.format(sql, strip_comments=True)\n        assert res == sql\n        sql = \'#+ hint\\nselect * from foo\'\n        res = sqlparse.format(sql, strip_comments=True)\n        assert res == sql\n        sql = \'select --+full(u)\\n--comment simple\'\n>       res = sqlparse.format(sql, strip_comments=True)\n\nrepos\\sqlparse\\tests\\test_format.py:117: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return \'\'.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:44: in run\n    filter_.process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\others.py:78: in process\n    StripCommentsFilter._process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\others.py:54: in _process\n    pidx, prev_ = tlist.token_prev(tidx, skip_ws=False)\nrepos\\sqlparse\\sqlparse\\sql.py:241: in token_prev\n    return self.token_next(idx, skip_ws, skip_cm, _reverse=True)\nrepos\\sqlparse\\sqlparse\\sql.py:244: in token_next\n    return self._token_matching(idx, skip_ws, skip_cm, _reverse)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Statement \'select...\' at 0x18ED1BA7650>, funcs = (3,), start = False\nend = False, reverse = True\n\n    def _token_matching(self, funcs, start=0, end=None, reverse=False):\n        """"""next token that match functions""""""\n        if start is None:\n            return None\n        if not isinstance(funcs, (list, tuple)):\n            funcs = (funcs,)\n        if reverse:\n>           assert end is None\nE           AssertionError\n\nrepos\\sqlparse\\sqlparse\\sql.py:195: AssertionError', 'self = <tests.test_format.TestFormat object at 0x0000018ED1990910>\n\n    def test_strip_ws(self):\n        f = lambda sql: sqlparse.format(sql, strip_whitespace=True)\n        s = \'select\\n* from      foo\\n\\twhere  ( 1 = 2 )\\n\'\n        assert f(s) == \'select * from foo where (1 = 2)\'\n        s = \'select -- foo\\nfrom    bar\\n\'\n>       assert f(s) == \'select -- foo\\nfrom bar\'\n\nrepos\\sqlparse\\tests\\test_format.py:134: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:130: in <lambda>\n    f = lambda sql: sqlparse.format(sql, strip_whitespace=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return \'\'.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\utils.py:74: in wrapped_f\n    f(tlist)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:319: in group_comments\n    eidx, end = tlist.token_prev(eidx, skip_ws=False)\nrepos\\sqlparse\\sqlparse\\sql.py:241: in token_prev\n    return self.token_next(idx, skip_ws, skip_cm, _reverse=True)\nrepos\\sqlparse\\sqlparse\\sql.py:244: in token_next\n    return self._token_matching(idx, skip_ws, skip_cm, _reverse)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Statement \'select...\' at 0x18ED1BA4150>, funcs = (3,), start = False\nend = False, reverse = True\n\n    def _token_matching(self, funcs, start=0, end=None, reverse=False):\n        """"""next token that match functions""""""\n        if start is None:\n            return None\n        if not isinstance(funcs, (list, tuple)):\n            funcs = (funcs,)\n        if reverse:\n>           assert end is None\nE           AssertionError\n\nrepos\\sqlparse\\sqlparse\\sql.py:195: AssertionError', 'self = <tests.test_format.TestFormat object at 0x0000018ED1949640>\n\n    def test_preserve_ws(self):\n        # preserve at least one whitespace after subgroups\n        f = lambda sql: sqlparse.format(sql, strip_whitespace=True)\n        s = \'select\\n* /* foo */  from bar \'\n>       assert f(s) == \'select * /* foo */ from bar\'\n\nrepos\\sqlparse\\tests\\test_format.py:145: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:143: in <lambda>\n    f = lambda sql: sqlparse.format(sql, strip_whitespace=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return \'\'.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\utils.py:74: in wrapped_f\n    f(tlist)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:319: in group_comments\n    eidx, end = tlist.token_prev(eidx, skip_ws=False)\nrepos\\sqlparse\\sqlparse\\sql.py:241: in token_prev\n    return self.token_next(idx, skip_ws, skip_cm, _reverse=True)\nrepos\\sqlparse\\sqlparse\\sql.py:244: in token_next\n    return self._token_matching(idx, skip_ws, skip_cm, _reverse)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Statement \'select...\' at 0x18ED1E77B50>, funcs = (5,), start = False\nend = False, reverse = True\n\n    def _token_matching(self, funcs, start=0, end=None, reverse=False):\n        """"""next token that match functions""""""\n        if start is None:\n            return None\n        if not isinstance(funcs, (list, tuple)):\n            funcs = (funcs,)\n        if reverse:\n>           assert end is None\nE           AssertionError\n\nrepos\\sqlparse\\sqlparse\\sql.py:195: AssertionError', 'self = <tests.test_format.TestFormatReindentAligned object at 0x0000018ED17FA350>\n\n    def test_basic(self):\n        sql = """"""\n            select a, b as bb,c from table\n            join (select a * 2 as a from new_table) other\n            on table.a = other.a\n            where c is true\n            and b between 3 and 4\n            or d is \'blue\'\n            limit 10\n            """"""\n    \n>       assert self.formatter(sql) == \'\\n\'.join([\n            \'select a,\',\n            \'       b as bb,\',\n            \'       c\',\n            \'  from table\',\n            \'  join (\',\n            \'        select a * 2 as a\',\n            \'          from new_table\',\n            \'       ) other\',\n            \'    on table.a = other.a\',\n            \' where c is true\',\n            \'   and b between 3 and 4\',\n            ""    or d is \'blue\'"",\n            \' limit 10\'])\n\nrepos\\sqlparse\\tests\\test_format.py:182: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:169: in formatter\n    return sqlparse.format(sql, reindent_aligned=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return \'\'.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:44: in run\n    filter_.process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\aligned_indent.py:134: in process\n    self._process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\aligned_indent.py:131: in _process\n    func(tlist)\nrepos\\sqlparse\\sqlparse\\filters\\aligned_indent.py:46: in _process_statement\n    self._process(sql.TokenList(tlist.tokens))\nrepos\\sqlparse\\sqlparse\\filters\\aligned_indent.py:131: in _process\n    func(tlist)\nrepos\\sqlparse\\sqlparse\\filters\\aligned_indent.py:120: in _process_default\n    pidx, prev_ = tlist.token_prev(idx)\nrepos\\sqlparse\\sqlparse\\sql.py:241: in token_prev\n    return self.token_next(idx, skip_ws, skip_cm, _reverse=True)\nrepos\\sqlparse\\sqlparse\\sql.py:244: in token_next\n    return self._token_matching(idx, skip_ws, skip_cm, _reverse)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <TokenList \'select...\' at 0x18ED1C8E1F0>, funcs = (14,), start = True\nend = False, reverse = True\n\n    def _token_matching(self, funcs, start=0, end=None, reverse=False):\n        """"""next token that match functions""""""\n        if start is None:\n            return None\n        if not isinstance(funcs, (list, tuple)):\n            funcs = (funcs,)\n        if reverse:\n>           assert end is None\nE           AssertionError\n\nrepos\\sqlparse\\sqlparse\\sql.py:195: AssertionError', 'self = <tests.test_format.TestFormatReindentAligned object at 0x0000018ED17FA990>\n\n    def test_joins(self):\n        sql = """"""\n            select * from a\n            join b on a.one = b.one\n            left join c on c.two = a.two and c.three = a.three\n            full outer join d on d.three = a.three\n            cross join e on e.four = a.four\n            join f using (one, two, three)\n            """"""\n>       assert self.formatter(sql) == \'\\n\'.join([\n            \'select *\',\n            \'  from a\',\n            \'  join b\',\n            \'    on a.one = b.one\',\n            \'  left join c\',\n            \'    on c.two = a.two\',\n            \'   and c.three = a.three\',\n            \'  full outer join d\',\n            \'    on d.three = a.three\',\n            \' cross join e\',\n            \'    on e.four = a.four\',\n            \'  join f using (one, two, three)\'])\n\nrepos\\sqlparse\\tests\\test_format.py:206: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:169: in formatter\n    return sqlparse.format(sql, reindent_aligned=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return \'\'.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:44: in run\n    filter_.process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\aligned_indent.py:134: in process\n    self._process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\aligned_indent.py:131: in _process\n    func(tlist)\nrepos\\sqlparse\\sqlparse\\filters\\aligned_indent.py:46: in _process_statement\n    self._process(sql.TokenList(tlist.tokens))\nrepos\\sqlparse\\sqlparse\\filters\\aligned_indent.py:131: in _process\n    func(tlist)\nrepos\\sqlparse\\sqlparse\\filters\\aligned_indent.py:120: in _process_default\n    pidx, prev_ = tlist.token_prev(idx)\nrepos\\sqlparse\\sqlparse\\sql.py:241: in token_prev\n    return self.token_next(idx, skip_ws, skip_cm, _reverse=True)\nrepos\\sqlparse\\sqlparse\\sql.py:244: in token_next\n    return self._token_matching(idx, skip_ws, skip_cm, _reverse)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <TokenList \'select...\' at 0x18ED1C8CEB0>, funcs = (19,), start = True\nend = False, reverse = True\n\n    def _token_matching(self, funcs, start=0, end=None, reverse=False):\n        """"""next token that match functions""""""\n        if start is None:\n            return None\n        if not isinstance(funcs, (list, tuple)):\n            funcs = (funcs,)\n        if reverse:\n>           assert end is None\nE           AssertionError\n\nrepos\\sqlparse\\sqlparse\\sql.py:195: AssertionError', 'self = <tests.test_format.TestFormatReindentAligned object at 0x0000018ED199C050>\n\n    def test_case_statement(self):\n        sql = """"""\n            select a,\n            case when a = 0\n            then 1\n            when bb = 1 then 1\n            when c = 2 then 2\n            else 0 end as d,\n            extra_col\n            from table\n            where c is true\n            and b between 3 and 4\n            """"""\n>       assert self.formatter(sql) == \'\\n\'.join([\n            \'select a,\',\n            \'       case when a = 0  then 1\',\n            \'            when bb = 1 then 1\',\n            \'            when c = 2  then 2\',\n            \'            else 0\',\n            \'             end as d,\',\n            \'       extra_col\',\n            \'  from table\',\n            \' where c is true\',\n            \'   and b between 3 and 4\'])\n\nrepos\\sqlparse\\tests\\test_format.py:233: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:169: in formatter\n    return sqlparse.format(sql, reindent_aligned=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return \'\'.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:44: in run\n    filter_.process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\aligned_indent.py:134: in process\n    self._process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\aligned_indent.py:131: in _process\n    func(tlist)\nrepos\\sqlparse\\sqlparse\\filters\\aligned_indent.py:46: in _process_statement\n    self._process(sql.TokenList(tlist.tokens))\nrepos\\sqlparse\\sqlparse\\filters\\aligned_indent.py:131: in _process\n    func(tlist)\nrepos\\sqlparse\\sqlparse\\filters\\aligned_indent.py:120: in _process_default\n    pidx, prev_ = tlist.token_prev(idx)\nrepos\\sqlparse\\sqlparse\\sql.py:241: in token_prev\n    return self.token_next(idx, skip_ws, skip_cm, _reverse=True)\nrepos\\sqlparse\\sqlparse\\sql.py:244: in token_next\n    return self._token_matching(idx, skip_ws, skip_cm, _reverse)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <TokenList \'select...\' at 0x18ED1C8DC40>, funcs = (14,), start = True\nend = False, reverse = True\n\n    def _token_matching(self, funcs, start=0, end=None, reverse=False):\n        """"""next token that match functions""""""\n        if start is None:\n            return None\n        if not isinstance(funcs, (list, tuple)):\n            funcs = (funcs,)\n        if reverse:\n>           assert end is None\nE           AssertionError\n\nrepos\\sqlparse\\sqlparse\\sql.py:195: AssertionError', 'self = <tests.test_format.TestFormatReindentAligned object at 0x0000018ED199C180>\n\n    def test_case_statement_with_between(self):\n        sql = """"""\n            select a,\n            case when a = 0\n            then 1\n            when bb = 1 then 1\n            when c = 2 then 2\n            when d between 3 and 5 then 3\n            else 0 end as d,\n            extra_col\n            from table\n            where c is true\n            and b between 3 and 4\n            """"""\n>       assert self.formatter(sql) == \'\\n\'.join([\n            \'select a,\',\n            \'       case when a = 0             then 1\',\n            \'            when bb = 1            then 1\',\n            \'            when c = 2             then 2\',\n            \'            when d between 3 and 5 then 3\',\n            \'            else 0\',\n            \'             end as d,\',\n            \'       extra_col\',\n            \'  from table\',\n            \' where c is true\',\n            \'   and b between 3 and 4\'])\n\nrepos\\sqlparse\\tests\\test_format.py:259: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:169: in formatter\n    return sqlparse.format(sql, reindent_aligned=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return \'\'.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:44: in run\n    filter_.process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\aligned_indent.py:134: in process\n    self._process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\aligned_indent.py:131: in _process\n    func(tlist)\nrepos\\sqlparse\\sqlparse\\filters\\aligned_indent.py:46: in _process_statement\n    self._process(sql.TokenList(tlist.tokens))\nrepos\\sqlparse\\sqlparse\\filters\\aligned_indent.py:131: in _process\n    func(tlist)\nrepos\\sqlparse\\sqlparse\\filters\\aligned_indent.py:120: in _process_default\n    pidx, prev_ = tlist.token_prev(idx)\nrepos\\sqlparse\\sqlparse\\sql.py:241: in token_prev\n    return self.token_next(idx, skip_ws, skip_cm, _reverse=True)\nrepos\\sqlparse\\sqlparse\\sql.py:244: in token_next\n    return self._token_matching(idx, skip_ws, skip_cm, _reverse)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <TokenList \'select...\' at 0x18ED1C8FC30>, funcs = (14,), start = True\nend = False, reverse = True\n\n    def _token_matching(self, funcs, start=0, end=None, reverse=False):\n        """"""next token that match functions""""""\n        if start is None:\n            return None\n        if not isinstance(funcs, (list, tuple)):\n            funcs = (funcs,)\n        if reverse:\n>           assert end is None\nE           AssertionError\n\nrepos\\sqlparse\\sqlparse\\sql.py:195: AssertionError', 'self = <tests.test_format.TestFormatReindentAligned object at 0x0000018ED198A8D0>\n\n    def test_group_by(self):\n        sql = """"""\n            select a, b, c, sum(x) as sum_x, count(y) as cnt_y\n            from table\n            group by a,b,c\n            having sum(x) > 1\n            and count(y) > 5\n            order by 3,2,1\n            """"""\n>       assert self.formatter(sql) == \'\\n\'.join([\n            \'select a,\',\n            \'       b,\',\n            \'       c,\',\n            \'       sum(x) as sum_x,\',\n            \'       count(y) as cnt_y\',\n            \'  from table\',\n            \' group by a,\',\n            \'          b,\',\n            \'          c\',\n            \'having sum(x) > 1\',\n            \'   and count(y) > 5\',\n            \' order by 3,\',\n            \'          2,\',\n            \'          1\'])\n\nrepos\\sqlparse\\tests\\test_format.py:281: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:169: in formatter\n    return sqlparse.format(sql, reindent_aligned=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return \'\'.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:44: in run\n    filter_.process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\aligned_indent.py:134: in process\n    self._process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\aligned_indent.py:131: in _process\n    func(tlist)\nrepos\\sqlparse\\sqlparse\\filters\\aligned_indent.py:46: in _process_statement\n    self._process(sql.TokenList(tlist.tokens))\nrepos\\sqlparse\\sqlparse\\filters\\aligned_indent.py:131: in _process\n    func(tlist)\nrepos\\sqlparse\\sqlparse\\filters\\aligned_indent.py:120: in _process_default\n    pidx, prev_ = tlist.token_prev(idx)\nrepos\\sqlparse\\sqlparse\\sql.py:241: in token_prev\n    return self.token_next(idx, skip_ws, skip_cm, _reverse=True)\nrepos\\sqlparse\\sqlparse\\sql.py:244: in token_next\n    return self._token_matching(idx, skip_ws, skip_cm, _reverse)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <TokenList \'select...\' at 0x18ED1C8D070>, funcs = (14,), start = True\nend = False, reverse = True\n\n    def _token_matching(self, funcs, start=0, end=None, reverse=False):\n        """"""next token that match functions""""""\n        if start is None:\n            return None\n        if not isinstance(funcs, (list, tuple)):\n            funcs = (funcs,)\n        if reverse:\n>           assert end is None\nE           AssertionError\n\nrepos\\sqlparse\\sqlparse\\sql.py:195: AssertionError', 'self = <tests.test_format.TestFormatReindentAligned object at 0x0000018ED17DBAC0>\n\n    def test_group_by_subquery(self):\n        # TODO: add subquery alias when test_identifier_list_subquery fixed\n        sql = """"""\n            select *, sum_b + 2 as mod_sum\n            from (\n              select a, sum(b) as sum_b\n              from table\n              group by a,z)\n            order by 1,2\n            """"""\n>       assert self.formatter(sql) == \'\\n\'.join([\n            \'select *,\',\n            \'       sum_b + 2 as mod_sum\',\n            \'  from (\',\n            \'        select a,\',\n            \'               sum(b) as sum_b\',\n            \'          from table\',\n            \'         group by a,\',\n            \'                  z\',\n            \'       )\',\n            \' order by 1,\',\n            \'          2\'])\n\nrepos\\sqlparse\\tests\\test_format.py:307: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:169: in formatter\n    return sqlparse.format(sql, reindent_aligned=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return \'\'.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:44: in run\n    filter_.process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\aligned_indent.py:134: in process\n    self._process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\aligned_indent.py:131: in _process\n    func(tlist)\nrepos\\sqlparse\\sqlparse\\filters\\aligned_indent.py:46: in _process_statement\n    self._process(sql.TokenList(tlist.tokens))\nrepos\\sqlparse\\sqlparse\\filters\\aligned_indent.py:131: in _process\n    func(tlist)\nrepos\\sqlparse\\sqlparse\\filters\\aligned_indent.py:120: in _process_default\n    pidx, prev_ = tlist.token_prev(idx)\nrepos\\sqlparse\\sqlparse\\sql.py:241: in token_prev\n    return self.token_next(idx, skip_ws, skip_cm, _reverse=True)\nrepos\\sqlparse\\sqlparse\\sql.py:244: in token_next\n    return self._token_matching(idx, skip_ws, skip_cm, _reverse)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <TokenList \'select...\' at 0x18ED1C95540>, funcs = (17,), start = True\nend = False, reverse = True\n\n    def _token_matching(self, funcs, start=0, end=None, reverse=False):\n        """"""next token that match functions""""""\n        if start is None:\n            return None\n        if not isinstance(funcs, (list, tuple)):\n            funcs = (funcs,)\n        if reverse:\n>           assert end is None\nE           AssertionError\n\nrepos\\sqlparse\\sqlparse\\sql.py:195: AssertionError', 'self = <tests.test_format.TestFormatReindentAligned object at 0x0000018ED17DBCE0>\n\n    def test_window_functions(self):\n        sql = """"""\n            select a,\n            SUM(a) OVER (PARTITION BY b ORDER BY c ROWS\n            BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) as sum_a,\n            ROW_NUMBER() OVER\n            (PARTITION BY b, c ORDER BY d DESC) as row_num\n            from table""""""\n>       assert self.formatter(sql) == \'\\n\'.join([\n            \'select a,\',\n            \'       SUM(a) OVER (PARTITION BY b ORDER BY c ROWS \'\n            \'BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) as sum_a,\',\n            \'       ROW_NUMBER() OVER \'\n            \'(PARTITION BY b, c ORDER BY d DESC) as row_num\',\n            \'  from table\'])\n\nrepos\\sqlparse\\tests\\test_format.py:328: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:169: in formatter\n    return sqlparse.format(sql, reindent_aligned=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return \'\'.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\utils.py:73: in wrapped_f\n    wrapped_f(sgroup)\nrepos\\sqlparse\\sqlparse\\utils.py:74: in wrapped_f\n    f(tlist)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:388: in group_order\n    pidx, prev_ = tlist.token_prev(tidx)\nrepos\\sqlparse\\sqlparse\\sql.py:241: in token_prev\n    return self.token_next(idx, skip_ws, skip_cm, _reverse=True)\nrepos\\sqlparse\\sqlparse\\sql.py:244: in token_next\n    return self._token_matching(idx, skip_ws, skip_cm, _reverse)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Parenthesis \'(PARTI...\' at 0x18ED1E770D0>, funcs = (14,), start = True\nend = False, reverse = True\n\n    def _token_matching(self, funcs, start=0, end=None, reverse=False):\n        """"""next token that match functions""""""\n        if start is None:\n            return None\n        if not isinstance(funcs, (list, tuple)):\n            funcs = (funcs,)\n        if reverse:\n>           assert end is None\nE           AssertionError\n\nrepos\\sqlparse\\sqlparse\\sql.py:195: AssertionError', 'self = <tests.test_format.TestSpacesAroundOperators object at 0x0000018ED17FAAD0>\n\n    def test_basic(self):\n        sql = (\'select a+b as d from table \'\n               \'where (c-d)%2= 1 and e> 3.0/4 and z^2 <100\')\n>       assert self.formatter(sql) == (\n            \'select a + b as d from table \'\n            \'where (c - d) % 2 = 1 and e > 3.0 / 4 and z ^ 2 < 100\')\n\nrepos\\sqlparse\\tests\\test_format.py:345: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:340: in formatter\n    return sqlparse.format(sql, use_space_around_operators=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return \'\'.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:44: in run\n    filter_.process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\others.py:151: in process\n    [self.process(sgroup) for sgroup in stmt.get_sublists()]\nrepos\\sqlparse\\sqlparse\\filters\\others.py:151: in process\n    [self.process(sgroup) for sgroup in stmt.get_sublists()]\nrepos\\sqlparse\\sqlparse\\filters\\others.py:152: in process\n    SpacesAroundOperatorsFilter._process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\others.py:142: in _process\n    pidx, prev_ = tlist.token_prev(tidx, skip_ws=False)\nrepos\\sqlparse\\sqlparse\\sql.py:241: in token_prev\n    return self.token_next(idx, skip_ws, skip_cm, _reverse=True)\nrepos\\sqlparse\\sqlparse\\sql.py:244: in token_next\n    return self._token_matching(idx, skip_ws, skip_cm, _reverse)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Parenthesis \'(c-d)\' at 0x18ED1E6A0D0>, funcs = (2,), start = False\nend = False, reverse = True\n\n    def _token_matching(self, funcs, start=0, end=None, reverse=False):\n        """"""next token that match functions""""""\n        if start is None:\n            return None\n        if not isinstance(funcs, (list, tuple)):\n            funcs = (funcs,)\n        if reverse:\n>           assert end is None\nE           AssertionError\n\nrepos\\sqlparse\\sqlparse\\sql.py:195: AssertionError', 'self = <tests.test_format.TestSpacesAroundOperators object at 0x0000018ED17FAC10>\n\n    def test_bools(self):\n        sql = \'select * from table where a &&b or c||d\'\n>       assert self.formatter(\n            sql) == \'select * from table where a && b or c || d\'\n\nrepos\\sqlparse\\tests\\test_format.py:351: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:340: in formatter\n    return sqlparse.format(sql, use_space_around_operators=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return \'\'.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:44: in run\n    filter_.process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\others.py:151: in process\n    [self.process(sgroup) for sgroup in stmt.get_sublists()]\nrepos\\sqlparse\\sqlparse\\filters\\others.py:152: in process\n    SpacesAroundOperatorsFilter._process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\others.py:142: in _process\n    pidx, prev_ = tlist.token_prev(tidx, skip_ws=False)\nrepos\\sqlparse\\sqlparse\\sql.py:241: in token_prev\n    return self.token_next(idx, skip_ws, skip_cm, _reverse=True)\nrepos\\sqlparse\\sqlparse\\sql.py:244: in token_next\n    return self._token_matching(idx, skip_ws, skip_cm, _reverse)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Where \'where ...\' at 0x18ED1CCA050>, funcs = (4,), start = False\nend = False, reverse = True\n\n    def _token_matching(self, funcs, start=0, end=None, reverse=False):\n        """"""next token that match functions""""""\n        if start is None:\n            return None\n        if not isinstance(funcs, (list, tuple)):\n            funcs = (funcs,)\n        if reverse:\n>           assert end is None\nE           AssertionError\n\nrepos\\sqlparse\\sqlparse\\sql.py:195: AssertionError', 'self = <tests.test_format.TestSpacesAroundOperators object at 0x0000018ED199C2B0>\n\n    def test_nested(self):\n        sql = \'select *, case when a-b then c end from table\'\n>       assert self.formatter(\n            sql) == \'select *, case when a - b then c end from table\'\n\nrepos\\sqlparse\\tests\\test_format.py:356: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:340: in formatter\n    return sqlparse.format(sql, use_space_around_operators=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return \'\'.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:44: in run\n    filter_.process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\others.py:151: in process\n    [self.process(sgroup) for sgroup in stmt.get_sublists()]\nrepos\\sqlparse\\sqlparse\\filters\\others.py:152: in process\n    SpacesAroundOperatorsFilter._process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\others.py:142: in _process\n    pidx, prev_ = tlist.token_prev(tidx, skip_ws=False)\nrepos\\sqlparse\\sqlparse\\sql.py:241: in token_prev\n    return self.token_next(idx, skip_ws, skip_cm, _reverse=True)\nrepos\\sqlparse\\sqlparse\\sql.py:244: in token_next\n    return self._token_matching(idx, skip_ws, skip_cm, _reverse)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Case \'case w...\' at 0x18ED1D27550>, funcs = (5,), start = False\nend = False, reverse = True\n\n    def _token_matching(self, funcs, start=0, end=None, reverse=False):\n        """"""next token that match functions""""""\n        if start is None:\n            return None\n        if not isinstance(funcs, (list, tuple)):\n            funcs = (funcs,)\n        if reverse:\n>           assert end is None\nE           AssertionError\n\nrepos\\sqlparse\\sqlparse\\sql.py:195: AssertionError', 'self = <tests.test_format.TestSpacesAroundOperators object at 0x0000018ED199C3E0>\n\n    def test_wildcard_vs_mult(self):\n        sql = \'select a*b-c from table\'\n>       assert self.formatter(sql) == \'select a * b - c from table\'\n\nrepos\\sqlparse\\tests\\test_format.py:361: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:340: in formatter\n    return sqlparse.format(sql, use_space_around_operators=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return \'\'.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:44: in run\n    filter_.process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\others.py:152: in process\n    SpacesAroundOperatorsFilter._process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\others.py:142: in _process\n    pidx, prev_ = tlist.token_prev(tidx, skip_ws=False)\nrepos\\sqlparse\\sqlparse\\sql.py:241: in token_prev\n    return self.token_next(idx, skip_ws, skip_cm, _reverse=True)\nrepos\\sqlparse\\sqlparse\\sql.py:244: in token_next\n    return self._token_matching(idx, skip_ws, skip_cm, _reverse)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Statement \'select...\' at 0x18ED1DB4BD0>, funcs = (5,), start = False\nend = False, reverse = True\n\n    def _token_matching(self, funcs, start=0, end=None, reverse=False):\n        """"""next token that match functions""""""\n        if start is None:\n            return None\n        if not isinstance(funcs, (list, tuple)):\n            funcs = (funcs,)\n        if reverse:\n>           assert end is None\nE           AssertionError\n\nrepos\\sqlparse\\sqlparse\\sql.py:195: AssertionError', 'self = <tests.test_format.TestFormatReindent object at 0x0000018ED17FAE90>\n\n    def test_stmts(self):\n        f = lambda sql: sqlparse.format(sql, reindent=True)\n        s = \'select foo; select bar\'\n>       assert f(s) == \'select foo;\\n\\nselect bar\'\n\nrepos\\sqlparse\\tests\\test_format.py:384: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:382: in <lambda>\n    f = lambda sql: sqlparse.format(sql, reindent=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return \'\'.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:44: in run\n    filter_.process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:240: in process\n    self._process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:102: in _process\n    func(tlist)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:233: in _process_default\n    self._split_statements(tlist) if stmts else None\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:89: in _split_statements\n    pidx, prev_ = tlist.token_prev(tidx, skip_ws=False)\nrepos\\sqlparse\\sqlparse\\sql.py:241: in token_prev\n    return self.token_next(idx, skip_ws, skip_cm, _reverse=True)\nrepos\\sqlparse\\sqlparse\\sql.py:244: in token_next\n    return self._token_matching(idx, skip_ws, skip_cm, _reverse)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Statement \'select...\' at 0x18ED1D264D0>, funcs = (0,), start = False\nend = False, reverse = True\n\n    def _token_matching(self, funcs, start=0, end=None, reverse=False):\n        """"""next token that match functions""""""\n        if start is None:\n            return None\n        if not isinstance(funcs, (list, tuple)):\n            funcs = (funcs,)\n        if reverse:\n>           assert end is None\nE           AssertionError\n\nrepos\\sqlparse\\sqlparse\\sql.py:195: AssertionError', 'self = <tests.test_format.TestFormatReindent object at 0x0000018ED199C510>\n\n    def test_keywords(self):\n        f = lambda sql: sqlparse.format(sql, reindent=True)\n        s = \'select * from foo union select * from bar;\'\n>       assert f(s) == \'\\n\'.join([\n            \'select *\',\n            \'from foo\',\n            \'union\',\n            \'select *\',\n            \'from bar;\'])\n\nrepos\\sqlparse\\tests\\test_format.py:393: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:391: in <lambda>\n    f = lambda sql: sqlparse.format(sql, reindent=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return \'\'.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:44: in run\n    filter_.process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:240: in process\n    self._process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:102: in _process\n    func(tlist)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:233: in _process_default\n    self._split_statements(tlist) if stmts else None\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:89: in _split_statements\n    pidx, prev_ = tlist.token_prev(tidx, skip_ws=False)\nrepos\\sqlparse\\sqlparse\\sql.py:241: in token_prev\n    return self.token_next(idx, skip_ws, skip_cm, _reverse=True)\nrepos\\sqlparse\\sqlparse\\sql.py:244: in token_next\n    return self._token_matching(idx, skip_ws, skip_cm, _reverse)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Statement \'select...\' at 0x18ED1DB76D0>, funcs = (0,), start = False\nend = False, reverse = True\n\n    def _token_matching(self, funcs, start=0, end=None, reverse=False):\n        """"""next token that match functions""""""\n        if start is None:\n            return None\n        if not isinstance(funcs, (list, tuple)):\n            funcs = (funcs,)\n        if reverse:\n>           assert end is None\nE           AssertionError\n\nrepos\\sqlparse\\sqlparse\\sql.py:195: AssertionError', 'self = <tests.test_format.TestFormatReindent object at 0x0000018ED199C640>\n\n    def test_keywords_between(self):\n        # issue 14\n        # don\'t break AND after BETWEEN\n        f = lambda sql: sqlparse.format(sql, reindent=True)\n        s = \'and foo between 1 and 2 and bar = 3\'\n>       assert f(s) == \'\\n\'.join([\n            \'\',\n            \'and foo between 1 and 2\',\n            \'and bar = 3\'])\n\nrepos\\sqlparse\\tests\\test_format.py:405: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:403: in <lambda>\n    f = lambda sql: sqlparse.format(sql, reindent=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return \'\'.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:44: in run\n    filter_.process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:240: in process\n    self._process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:102: in _process\n    func(tlist)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:234: in _process_default\n    self._split_kwds(tlist)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:72: in _split_kwds\n    pidx, prev_ = tlist.token_prev(tidx, skip_ws=False)\nrepos\\sqlparse\\sqlparse\\sql.py:241: in token_prev\n    return self.token_next(idx, skip_ws, skip_cm, _reverse=True)\nrepos\\sqlparse\\sqlparse\\sql.py:244: in token_next\n    return self._token_matching(idx, skip_ws, skip_cm, _reverse)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Statement \'and fo...\' at 0x18ED1E68150>, funcs = (0,), start = False\nend = False, reverse = True\n\n    def _token_matching(self, funcs, start=0, end=None, reverse=False):\n        """"""next token that match functions""""""\n        if start is None:\n            return None\n        if not isinstance(funcs, (list, tuple)):\n            funcs = (funcs,)\n        if reverse:\n>           assert end is None\nE           AssertionError\n\nrepos\\sqlparse\\sqlparse\\sql.py:195: AssertionError', 'self = <tests.test_format.TestFormatReindent object at 0x0000018ED19AC3B0>\n\n    def test_parenthesis(self):\n        f = lambda sql: sqlparse.format(sql, reindent=True)\n        s = \'select count(*) from (select * from foo);\'\n>       assert f(s) == \'\\n\'.join([\n            \'select count(*)\',\n            \'from\',\n            \'  (select *\',\n            \'   from foo);\'])\n\nrepos\\sqlparse\\tests\\test_format.py:413: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:411: in <lambda>\n    f = lambda sql: sqlparse.format(sql, reindent=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return \'\'.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:44: in run\n    filter_.process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:240: in process\n    self._process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:102: in _process\n    func(tlist)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:233: in _process_default\n    self._split_statements(tlist) if stmts else None\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:89: in _split_statements\n    pidx, prev_ = tlist.token_prev(tidx, skip_ws=False)\nrepos\\sqlparse\\sqlparse\\sql.py:241: in token_prev\n    return self.token_next(idx, skip_ws, skip_cm, _reverse=True)\nrepos\\sqlparse\\sqlparse\\sql.py:244: in token_next\n    return self._token_matching(idx, skip_ws, skip_cm, _reverse)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Statement \'select...\' at 0x18ED1E84D50>, funcs = (0,), start = False\nend = False, reverse = True\n\n    def _token_matching(self, funcs, start=0, end=None, reverse=False):\n        """"""next token that match functions""""""\n        if start is None:\n            return None\n        if not isinstance(funcs, (list, tuple)):\n            funcs = (funcs,)\n        if reverse:\n>           assert end is None\nE           AssertionError\n\nrepos\\sqlparse\\sqlparse\\sql.py:195: AssertionError', 'self = <tests.test_format.TestFormatReindent object at 0x0000018ED17DBDF0>\n\n    def test_where(self):\n        f = lambda sql: sqlparse.format(sql, reindent=True)\n        s = \'select * from foo where bar = 1 and baz = 2 or bzz = 3;\'\n>       assert f(s) == \'\\n\'.join([\n            \'select *\',\n            \'from foo\',\n            \'where bar = 1\',\n            \'  and baz = 2\',\n            \'  or bzz = 3;\'])\n\nrepos\\sqlparse\\tests\\test_format.py:427: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:425: in <lambda>\n    f = lambda sql: sqlparse.format(sql, reindent=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return \'\'.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:44: in run\n    filter_.process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:240: in process\n    self._process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:102: in _process\n    func(tlist)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:233: in _process_default\n    self._split_statements(tlist) if stmts else None\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:89: in _split_statements\n    pidx, prev_ = tlist.token_prev(tidx, skip_ws=False)\nrepos\\sqlparse\\sqlparse\\sql.py:241: in token_prev\n    return self.token_next(idx, skip_ws, skip_cm, _reverse=True)\nrepos\\sqlparse\\sqlparse\\sql.py:244: in token_next\n    return self._token_matching(idx, skip_ws, skip_cm, _reverse)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Statement \'select...\' at 0x18ED1DB4750>, funcs = (0,), start = False\nend = False, reverse = True\n\n    def _token_matching(self, funcs, start=0, end=None, reverse=False):\n        """"""next token that match functions""""""\n        if start is None:\n            return None\n        if not isinstance(funcs, (list, tuple)):\n            funcs = (funcs,)\n        if reverse:\n>           assert end is None\nE           AssertionError\n\nrepos\\sqlparse\\sqlparse\\sql.py:195: AssertionError', 'self = <tests.test_format.TestFormatReindent object at 0x0000018ED17DBF00>\n\n    def test_join(self):\n        f = lambda sql: sqlparse.format(sql, reindent=True)\n        s = \'select * from foo join bar on 1 = 2\'\n>       assert f(s) == \'\\n\'.join([\n            \'select *\',\n            \'from foo\',\n            \'join bar on 1 = 2\'])\n\nrepos\\sqlparse\\tests\\test_format.py:445: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:443: in <lambda>\n    f = lambda sql: sqlparse.format(sql, reindent=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return \'\'.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:44: in run\n    filter_.process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:240: in process\n    self._process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:102: in _process\n    func(tlist)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:233: in _process_default\n    self._split_statements(tlist) if stmts else None\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:89: in _split_statements\n    pidx, prev_ = tlist.token_prev(tidx, skip_ws=False)\nrepos\\sqlparse\\sqlparse\\sql.py:241: in token_prev\n    return self.token_next(idx, skip_ws, skip_cm, _reverse=True)\nrepos\\sqlparse\\sqlparse\\sql.py:244: in token_next\n    return self._token_matching(idx, skip_ws, skip_cm, _reverse)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Statement \'select...\' at 0x18ED1D27850>, funcs = (0,), start = False\nend = False, reverse = True\n\n    def _token_matching(self, funcs, start=0, end=None, reverse=False):\n        """"""next token that match functions""""""\n        if start is None:\n            return None\n        if not isinstance(funcs, (list, tuple)):\n            funcs = (funcs,)\n        if reverse:\n>           assert end is None\nE           AssertionError\n\nrepos\\sqlparse\\sqlparse\\sql.py:195: AssertionError', 'self = <tests.test_format.TestFormatReindent object at 0x0000018ED1978B50>\n\n    def test_identifier_list(self):\n        f = lambda sql: sqlparse.format(sql, reindent=True)\n        s = \'select foo, bar, baz from table1, table2 where 1 = 2\'\n>       assert f(s) == \'\\n\'.join([\n            \'select foo,\',\n            \'       bar,\',\n            \'       baz\',\n            \'from table1,\',\n            \'     table2\',\n            \'where 1 = 2\'])\n\nrepos\\sqlparse\\tests\\test_format.py:468: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:466: in <lambda>\n    f = lambda sql: sqlparse.format(sql, reindent=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return \'\'.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:44: in run\n    filter_.process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:240: in process\n    self._process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:102: in _process\n    func(tlist)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:233: in _process_default\n    self._split_statements(tlist) if stmts else None\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:89: in _split_statements\n    pidx, prev_ = tlist.token_prev(tidx, skip_ws=False)\nrepos\\sqlparse\\sqlparse\\sql.py:241: in token_prev\n    return self.token_next(idx, skip_ws, skip_cm, _reverse=True)\nrepos\\sqlparse\\sqlparse\\sql.py:244: in token_next\n    return self._token_matching(idx, skip_ws, skip_cm, _reverse)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Statement \'select...\' at 0x18ED1E6B1D0>, funcs = (0,), start = False\nend = False, reverse = True\n\n    def _token_matching(self, funcs, start=0, end=None, reverse=False):\n        """"""next token that match functions""""""\n        if start is None:\n            return None\n        if not isinstance(funcs, (list, tuple)):\n            funcs = (funcs,)\n        if reverse:\n>           assert end is None\nE           AssertionError\n\nrepos\\sqlparse\\sqlparse\\sql.py:195: AssertionError', 'self = <tests.test_format.TestFormatReindent object at 0x0000018ED1978C50>\n\n    def test_identifier_list_with_wrap_after(self):\n        f = lambda sql: sqlparse.format(sql, reindent=True, wrap_after=14)\n        s = \'select foo, bar, baz from table1, table2 where 1 = 2\'\n>       assert f(s) == \'\\n\'.join([\n            \'select foo, bar,\',\n            \'       baz\',\n            \'from table1, table2\',\n            \'where 1 = 2\'])\n\nrepos\\sqlparse\\tests\\test_format.py:485: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:483: in <lambda>\n    f = lambda sql: sqlparse.format(sql, reindent=True, wrap_after=14)\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return \'\'.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:44: in run\n    filter_.process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:240: in process\n    self._process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:102: in _process\n    func(tlist)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:233: in _process_default\n    self._split_statements(tlist) if stmts else None\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:89: in _split_statements\n    pidx, prev_ = tlist.token_prev(tidx, skip_ws=False)\nrepos\\sqlparse\\sqlparse\\sql.py:241: in token_prev\n    return self.token_next(idx, skip_ws, skip_cm, _reverse=True)\nrepos\\sqlparse\\sqlparse\\sql.py:244: in token_next\n    return self._token_matching(idx, skip_ws, skip_cm, _reverse)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Statement \'select...\' at 0x18ED1D250D0>, funcs = (0,), start = False\nend = False, reverse = True\n\n    def _token_matching(self, funcs, start=0, end=None, reverse=False):\n        """"""next token that match functions""""""\n        if start is None:\n            return None\n        if not isinstance(funcs, (list, tuple)):\n            funcs = (funcs,)\n        if reverse:\n>           assert end is None\nE           AssertionError\n\nrepos\\sqlparse\\sqlparse\\sql.py:195: AssertionError', 'self = <tests.test_format.TestFormatReindent object at 0x0000018ED18AE6C0>\n\n    def test_identifier_list_comment_first(self):\n        f = lambda sql: sqlparse.format(sql, reindent=True, comma_first=True)\n        # not the 3: It cleans up whitespace too!\n        s = \'select foo, bar, baz from table where foo in (1, 2,3)\'\n>       assert f(s) == \'\\n\'.join([\n            \'select foo\',\n            \'     , bar\',\n            \'     , baz\',\n            \'from table\',\n            \'where foo in (1\',\n            \'            , 2\',\n            \'            , 3)\'])\n\nrepos\\sqlparse\\tests\\test_format.py:495: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:492: in <lambda>\n    f = lambda sql: sqlparse.format(sql, reindent=True, comma_first=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return \'\'.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:44: in run\n    filter_.process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:240: in process\n    self._process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:102: in _process\n    func(tlist)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:233: in _process_default\n    self._split_statements(tlist) if stmts else None\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:89: in _split_statements\n    pidx, prev_ = tlist.token_prev(tidx, skip_ws=False)\nrepos\\sqlparse\\sqlparse\\sql.py:241: in token_prev\n    return self.token_next(idx, skip_ws, skip_cm, _reverse=True)\nrepos\\sqlparse\\sqlparse\\sql.py:244: in token_next\n    return self._token_matching(idx, skip_ws, skip_cm, _reverse)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Statement \'select...\' at 0x18ED1E84AD0>, funcs = (0,), start = False\nend = False, reverse = True\n\n    def _token_matching(self, funcs, start=0, end=None, reverse=False):\n        """"""next token that match functions""""""\n        if start is None:\n            return None\n        if not isinstance(funcs, (list, tuple)):\n            funcs = (funcs,)\n        if reverse:\n>           assert end is None\nE           AssertionError\n\nrepos\\sqlparse\\sqlparse\\sql.py:195: AssertionError', 'self = <tests.test_format.TestFormatReindent object at 0x0000018ED18AE7B0>\n\n    def test_identifier_list_with_functions(self):\n        f = lambda sql: sqlparse.format(sql, reindent=True)\n        s = (""select \'abc\' as foo, coalesce(col1, col2)||col3 as bar,""\n             ""col3 from my_table"")\n>       assert f(s) == \'\\n\'.join([\n            ""select \'abc\' as foo,"",\n            ""       coalesce(col1, col2)||col3 as bar,"",\n            ""       col3"",\n            ""from my_table""])\n\nrepos\\sqlparse\\tests\\test_format.py:508: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:505: in <lambda>\n    f = lambda sql: sqlparse.format(sql, reindent=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return \'\'.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:44: in run\n    filter_.process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:240: in process\n    self._process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:102: in _process\n    func(tlist)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:233: in _process_default\n    self._split_statements(tlist) if stmts else None\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:89: in _split_statements\n    pidx, prev_ = tlist.token_prev(tidx, skip_ws=False)\nrepos\\sqlparse\\sqlparse\\sql.py:241: in token_prev\n    return self.token_next(idx, skip_ws, skip_cm, _reverse=True)\nrepos\\sqlparse\\sqlparse\\sql.py:244: in token_next\n    return self._token_matching(idx, skip_ws, skip_cm, _reverse)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Statement \'select...\' at 0x18ED1E86AD0>, funcs = (0,), start = False\nend = False, reverse = True\n\n    def _token_matching(self, funcs, start=0, end=None, reverse=False):\n        """"""next token that match functions""""""\n        if start is None:\n            return None\n        if not isinstance(funcs, (list, tuple)):\n            funcs = (funcs,)\n        if reverse:\n>           assert end is None\nE           AssertionError\n\nrepos\\sqlparse\\sqlparse\\sql.py:195: AssertionError', 'self = <tests.test_format.TestFormatReindent object at 0x0000018ED18FB930>\n\n    def test_long_identifier_list_with_functions(self):\n        f = lambda sql: sqlparse.format(sql, reindent=True, wrap_after=30)\n        s = (""select \'abc\' as foo, json_build_object(\'a\',  a,""\n             ""\'b\', b, \'c\', c, \'d\', d, \'e\', e) as col2""\n             ""col3 from my_table"")\n>       assert f(s) == \'\\n\'.join([\n            ""select \'abc\' as foo,"",\n            ""       json_build_object(\'a\',"",\n            ""         a, \'b\', b, \'c\', c, \'d\', d,"",\n            ""         \'e\', e) as col2col3"",\n            ""from my_table""])\n\nrepos\\sqlparse\\tests\\test_format.py:519: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:515: in <lambda>\n    f = lambda sql: sqlparse.format(sql, reindent=True, wrap_after=30)\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return \'\'.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:44: in run\n    filter_.process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:240: in process\n    self._process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:102: in _process\n    func(tlist)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:233: in _process_default\n    self._split_statements(tlist) if stmts else None\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:89: in _split_statements\n    pidx, prev_ = tlist.token_prev(tidx, skip_ws=False)\nrepos\\sqlparse\\sqlparse\\sql.py:241: in token_prev\n    return self.token_next(idx, skip_ws, skip_cm, _reverse=True)\nrepos\\sqlparse\\sqlparse\\sql.py:244: in token_next\n    return self._token_matching(idx, skip_ws, skip_cm, _reverse)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Statement \'select...\' at 0x18ED1DB4AD0>, funcs = (0,), start = False\nend = False, reverse = True\n\n    def _token_matching(self, funcs, start=0, end=None, reverse=False):\n        """"""next token that match functions""""""\n        if start is None:\n            return None\n        if not isinstance(funcs, (list, tuple)):\n            funcs = (funcs,)\n        if reverse:\n>           assert end is None\nE           AssertionError\n\nrepos\\sqlparse\\sqlparse\\sql.py:195: AssertionError', ""self = <tests.test_format.TestFormatReindent object at 0x0000018ED17A7410>\n\n    def test_nested_identifier_list(self):\n        # issue4\n        f = lambda sql: sqlparse.format(sql, reindent=True)\n        s = '(foo as bar, bar1, bar2 as bar3, b4 as b5)'\n>       assert f(s) == '\\n'.join([\n            '(foo as bar,',\n            ' bar1,',\n            ' bar2 as bar3,',\n            ' b4 as b5)'])\nE       AssertionError: assert '(foo as bar,...r3, b4 as b5)' == '(foo as bar,...,\\n b4 as b5)'\nE         \nE         + (foo as bar, bar1, bar2 as bar3, b4 as b5)\nE         - (foo as bar,\nE         -  bar1,\nE         -  bar2 as bar3,\nE         -  b4 as b5)\n\nrepos\\sqlparse\\tests\\test_format.py:549: AssertionError"", 'self = <tests.test_format.TestFormatReindent object at 0x0000018ED17A7E90>\n\n    def test_duplicate_linebreaks(self):\n        # issue3\n        f = lambda sql: sqlparse.format(sql, reindent=True)\n        s = \'select c1 -- column1\\nfrom foo\'\n>       assert f(s) == \'\\n\'.join([\n            \'select c1 -- column1\',\n            \'from foo\'])\n\nrepos\\sqlparse\\tests\\test_format.py:559: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:557: in <lambda>\n    f = lambda sql: sqlparse.format(sql, reindent=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return \'\'.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\utils.py:74: in wrapped_f\n    f(tlist)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:319: in group_comments\n    eidx, end = tlist.token_prev(eidx, skip_ws=False)\nrepos\\sqlparse\\sqlparse\\sql.py:241: in token_prev\n    return self.token_next(idx, skip_ws, skip_cm, _reverse=True)\nrepos\\sqlparse\\sqlparse\\sql.py:244: in token_next\n    return self._token_matching(idx, skip_ws, skip_cm, _reverse)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Statement \'select...\' at 0x18ED1EB3950>, funcs = (5,), start = False\nend = False, reverse = True\n\n    def _token_matching(self, funcs, start=0, end=None, reverse=False):\n        """"""next token that match functions""""""\n        if start is None:\n            return None\n        if not isinstance(funcs, (list, tuple)):\n            funcs = (funcs,)\n        if reverse:\n>           assert end is None\nE           AssertionError\n\nrepos\\sqlparse\\sqlparse\\sql.py:195: AssertionError', 'self = <tests.test_format.TestFormatReindent object at 0x0000018ED18A9910>\n\n    def test_keywordfunctions(self):\n        # issue36\n        f = lambda sql: sqlparse.format(sql, reindent=True)\n        s = \'select max(a) b, foo, bar\'\n>       assert f(s) == \'\\n\'.join([\n            \'select max(a) b,\',\n            \'       foo,\',\n            \'       bar\'])\n\nrepos\\sqlparse\\tests\\test_format.py:583: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:581: in <lambda>\n    f = lambda sql: sqlparse.format(sql, reindent=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return \'\'.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:44: in run\n    filter_.process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:240: in process\n    self._process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:102: in _process\n    func(tlist)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:233: in _process_default\n    self._split_statements(tlist) if stmts else None\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:89: in _split_statements\n    pidx, prev_ = tlist.token_prev(tidx, skip_ws=False)\nrepos\\sqlparse\\sqlparse\\sql.py:241: in token_prev\n    return self.token_next(idx, skip_ws, skip_cm, _reverse=True)\nrepos\\sqlparse\\sqlparse\\sql.py:244: in token_next\n    return self._token_matching(idx, skip_ws, skip_cm, _reverse)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Statement \'select...\' at 0x18ED1EB2F50>, funcs = (0,), start = False\nend = False, reverse = True\n\n    def _token_matching(self, funcs, start=0, end=None, reverse=False):\n        """"""next token that match functions""""""\n        if start is None:\n            return None\n        if not isinstance(funcs, (list, tuple)):\n            funcs = (funcs,)\n        if reverse:\n>           assert end is None\nE           AssertionError\n\nrepos\\sqlparse\\sqlparse\\sql.py:195: AssertionError', 'self = <tests.test_format.TestFormatReindent object at 0x0000018ED18A99C0>\n\n    def test_identifier_and_functions(self):\n        # issue45\n        f = lambda sql: sqlparse.format(sql, reindent=True)\n        s = \'select foo.bar, nvl(1) from dual\'\n>       assert f(s) == \'\\n\'.join([\n            \'select foo.bar,\',\n            \'       nvl(1)\',\n            \'from dual\'])\n\nrepos\\sqlparse\\tests\\test_format.py:592: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:590: in <lambda>\n    f = lambda sql: sqlparse.format(sql, reindent=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return \'\'.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:44: in run\n    filter_.process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:240: in process\n    self._process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:102: in _process\n    func(tlist)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:233: in _process_default\n    self._split_statements(tlist) if stmts else None\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:89: in _split_statements\n    pidx, prev_ = tlist.token_prev(tidx, skip_ws=False)\nrepos\\sqlparse\\sqlparse\\sql.py:241: in token_prev\n    return self.token_next(idx, skip_ws, skip_cm, _reverse=True)\nrepos\\sqlparse\\sqlparse\\sql.py:244: in token_next\n    return self._token_matching(idx, skip_ws, skip_cm, _reverse)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Statement \'select...\' at 0x18ED1E85B50>, funcs = (0,), start = False\nend = False, reverse = True\n\n    def _token_matching(self, funcs, start=0, end=None, reverse=False):\n        """"""next token that match functions""""""\n        if start is None:\n            return None\n        if not isinstance(funcs, (list, tuple)):\n            funcs = (funcs,)\n        if reverse:\n>           assert end is None\nE           AssertionError\n\nrepos\\sqlparse\\sqlparse\\sql.py:195: AssertionError', 'self = <tests.test_format.TestFormatReindent object at 0x0000018ED1972AD0>\n\n    def test_insert_values(self):\n        # issue 329\n        f = lambda sql: sqlparse.format(sql, reindent=True)\n        s = \'insert into foo values (1, 2)\'\n>       assert f(s) == \'\\n\'.join([\n            \'insert into foo\',\n            \'values (1, 2)\'])\n\nrepos\\sqlparse\\tests\\test_format.py:601: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:599: in <lambda>\n    f = lambda sql: sqlparse.format(sql, reindent=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return \'\'.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:44: in run\n    filter_.process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:240: in process\n    self._process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:102: in _process\n    func(tlist)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:233: in _process_default\n    self._split_statements(tlist) if stmts else None\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:89: in _split_statements\n    pidx, prev_ = tlist.token_prev(tidx, skip_ws=False)\nrepos\\sqlparse\\sqlparse\\sql.py:241: in token_prev\n    return self.token_next(idx, skip_ws, skip_cm, _reverse=True)\nrepos\\sqlparse\\sqlparse\\sql.py:244: in token_next\n    return self._token_matching(idx, skip_ws, skip_cm, _reverse)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Statement \'insert...\' at 0x18ED1EB12D0>, funcs = (0,), start = False\nend = False, reverse = True\n\n    def _token_matching(self, funcs, start=0, end=None, reverse=False):\n        """"""next token that match functions""""""\n        if start is None:\n            return None\n        if not isinstance(funcs, (list, tuple)):\n            funcs = (funcs,)\n        if reverse:\n>           assert end is None\nE           AssertionError\n\nrepos\\sqlparse\\sqlparse\\sql.py:195: AssertionError', 'self = <tests.test_format.TestOutputFormat object at 0x0000018ED17FAFD0>\n\n    def test_python(self):\n        sql = \'select * from foo;\'\n        f = lambda sql: sqlparse.format(sql, output_format=\'python\')\n        assert f(sql) == ""sql = \'select * from foo;\'""\n        f = lambda sql: sqlparse.format(sql, output_format=\'python\',\n                                        reindent=True)\n>       assert f(sql) == \'\\n\'.join([\n            ""sql = (\'select * \'"",\n            ""       \'from foo;\')""])\n\nrepos\\sqlparse\\tests\\test_format.py:648: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:646: in <lambda>\n    f = lambda sql: sqlparse.format(sql, output_format=\'python\',\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return \'\'.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:44: in run\n    filter_.process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:240: in process\n    self._process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:102: in _process\n    func(tlist)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:233: in _process_default\n    self._split_statements(tlist) if stmts else None\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:89: in _split_statements\n    pidx, prev_ = tlist.token_prev(tidx, skip_ws=False)\nrepos\\sqlparse\\sqlparse\\sql.py:241: in token_prev\n    return self.token_next(idx, skip_ws, skip_cm, _reverse=True)\nrepos\\sqlparse\\sqlparse\\sql.py:244: in token_next\n    return self._token_matching(idx, skip_ws, skip_cm, _reverse)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Statement \'select...\' at 0x18ED1EB24D0>, funcs = (0,), start = False\nend = False, reverse = True\n\n    def _token_matching(self, funcs, start=0, end=None, reverse=False):\n        """"""next token that match functions""""""\n        if start is None:\n            return None\n        if not isinstance(funcs, (list, tuple)):\n            funcs = (funcs,)\n        if reverse:\n>           assert end is None\nE           AssertionError\n\nrepos\\sqlparse\\sqlparse\\sql.py:195: AssertionError', 'self = <tests.test_format.TestOutputFormat object at 0x0000018ED199C8A0>\n\n    def test_php(self):\n        sql = \'select * from foo;\'\n        f = lambda sql: sqlparse.format(sql, output_format=\'php\')\n        assert f(sql) == \'$sql = ""select * from foo;"";\'\n        f = lambda sql: sqlparse.format(sql, output_format=\'php\',\n                                        reindent=True)\n>       assert f(sql) == \'\\n\'.join([\n            \'$sql  = ""select * "";\',\n            \'$sql .= ""from foo;"";\'])\n\nrepos\\sqlparse\\tests\\test_format.py:676: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:674: in <lambda>\n    f = lambda sql: sqlparse.format(sql, output_format=\'php\',\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return \'\'.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:44: in run\n    filter_.process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:240: in process\n    self._process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:102: in _process\n    func(tlist)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:233: in _process_default\n    self._split_statements(tlist) if stmts else None\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:89: in _split_statements\n    pidx, prev_ = tlist.token_prev(tidx, skip_ws=False)\nrepos\\sqlparse\\sqlparse\\sql.py:241: in token_prev\n    return self.token_next(idx, skip_ws, skip_cm, _reverse=True)\nrepos\\sqlparse\\sqlparse\\sql.py:244: in token_next\n    return self._token_matching(idx, skip_ws, skip_cm, _reverse)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Statement \'select...\' at 0x18ED1F98CD0>, funcs = (0,), start = False\nend = False, reverse = True\n\n    def _token_matching(self, funcs, start=0, end=None, reverse=False):\n        """"""next token that match functions""""""\n        if start is None:\n            return None\n        if not isinstance(funcs, (list, tuple)):\n            funcs = (funcs,)\n        if reverse:\n>           assert end is None\nE           AssertionError\n\nrepos\\sqlparse\\sqlparse\\sql.py:195: AssertionError', 'def test_format_column_ordering():\n        # issue89\n        sql = \'select * from foo order by c1 desc, c2, c3;\'\n>       formatted = sqlparse.format(sql, reindent=True)\n\nrepos\\sqlparse\\tests\\test_format.py:695: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return \'\'.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\utils.py:74: in wrapped_f\n    f(tlist)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:388: in group_order\n    pidx, prev_ = tlist.token_prev(tidx)\nrepos\\sqlparse\\sqlparse\\sql.py:241: in token_prev\n    return self.token_next(idx, skip_ws, skip_cm, _reverse=True)\nrepos\\sqlparse\\sqlparse\\sql.py:244: in token_next\n    return self._token_matching(idx, skip_ws, skip_cm, _reverse)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Statement \'select...\' at 0x18ED1EB15D0>, funcs = (12,), start = True\nend = False, reverse = True\n\n    def _token_matching(self, funcs, start=0, end=None, reverse=False):\n        """"""next token that match functions""""""\n        if start is None:\n            return None\n        if not isinstance(funcs, (list, tuple)):\n            funcs = (funcs,)\n        if reverse:\n>           assert end is None\nE           AssertionError\n\nrepos\\sqlparse\\sqlparse\\sql.py:195: AssertionError', 'def test_having_produces_newline():\n        sql = (\'select * from foo, bar where bar.id = foo.bar_id \'\n               \'having sum(bar.value) > 100\')\n>       formatted = sqlparse.format(sql, reindent=True)\n\nrepos\\sqlparse\\tests\\test_format.py:730: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return \'\'.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:44: in run\n    filter_.process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:240: in process\n    self._process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:102: in _process\n    func(tlist)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:233: in _process_default\n    self._split_statements(tlist) if stmts else None\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:89: in _split_statements\n    pidx, prev_ = tlist.token_prev(tidx, skip_ws=False)\nrepos\\sqlparse\\sqlparse\\sql.py:241: in token_prev\n    return self.token_next(idx, skip_ws, skip_cm, _reverse=True)\nrepos\\sqlparse\\sqlparse\\sql.py:244: in token_next\n    return self._token_matching(idx, skip_ws, skip_cm, _reverse)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Statement \'select...\' at 0x18ED1F1E750>, funcs = (0,), start = False\nend = False, reverse = True\n\n    def _token_matching(self, funcs, start=0, end=None, reverse=False):\n        """"""next token that match functions""""""\n        if start is None:\n            return None\n        if not isinstance(funcs, (list, tuple)):\n            funcs = (funcs,)\n        if reverse:\n>           assert end is None\nE           AssertionError\n\nrepos\\sqlparse\\sqlparse\\sql.py:195: AssertionError', 'def test_format_json_ops():  # issue542\n>       formatted = sqlparse.format(\n            ""select foo->\'bar\', foo->\'bar\';"", reindent=True)\n\nrepos\\sqlparse\\tests\\test_format.py:753: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return \'\'.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:44: in run\n    filter_.process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:240: in process\n    self._process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:102: in _process\n    func(tlist)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:233: in _process_default\n    self._split_statements(tlist) if stmts else None\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:89: in _split_statements\n    pidx, prev_ = tlist.token_prev(tidx, skip_ws=False)\nrepos\\sqlparse\\sqlparse\\sql.py:241: in token_prev\n    return self.token_next(idx, skip_ws, skip_cm, _reverse=True)\nrepos\\sqlparse\\sqlparse\\sql.py:244: in token_next\n    return self._token_matching(idx, skip_ws, skip_cm, _reverse)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Statement \'select...\' at 0x18ED1F9A4D0>, funcs = (0,), start = False\nend = False, reverse = True\n\n    def _token_matching(self, funcs, start=0, end=None, reverse=False):\n        """"""next token that match functions""""""\n        if start is None:\n            return None\n        if not isinstance(funcs, (list, tuple)):\n            funcs = (funcs,)\n        if reverse:\n>           assert end is None\nE           AssertionError\n\nrepos\\sqlparse\\sqlparse\\sql.py:195: AssertionError', ""def test_grouping_parenthesis():\n        s = 'select (select (x3) x2) and (y2) bar'\n        parsed = sqlparse.parse(s)[0]\n        assert str(parsed) == s\n>       assert len(parsed.tokens) == 7\nE       AssertionError: assert 9 == 7\nE        +  where 9 = len([<DML 'select' at 0x18ED1E64BE0>, <Whitespace ' ' at 0x18ED1E651E0>, <Parenthesis '(selec...' at 0x18ED1BA6CD0>, <Whitespace ' ' at 0x18ED1E67E80>, <Keyword 'and' at 0x18ED1E67EE0>, <Whitespace ' ' at 0x18ED1E67FA0>, ...])\nE        +    where [<DML 'select' at 0x18ED1E64BE0>, <Whitespace ' ' at 0x18ED1E651E0>, <Parenthesis '(selec...' at 0x18ED1BA6CD0>, <Whitespace ' ' at 0x18ED1E67E80>, <Keyword 'and' at 0x18ED1E67EE0>, <Whitespace ' ' at 0x18ED1E67FA0>, ...] = <Statement 'select...' at 0x18ED1DB0650>.tokens\n\nrepos\\sqlparse\\tests\\test_grouping.py:11: AssertionError"", ""s = 'foo := 1;'\n\n    @pytest.mark.parametrize('s', ['foo := 1;', 'foo := 1'])\n    def test_grouping_assignment(s):\n        parsed = sqlparse.parse(s)[0]\n>       assert len(parsed.tokens) == 1\nE       AssertionError: assert 6 == 1\nE        +  where 6 = len([<Identifier 'foo' at 0x18ED1DB18D0>, <Whitespace ' ' at 0x18ED1E2C880>, <Assignment ':=' at 0x18ED1E2CAC0>, <Whitespace ' ' at 0x18ED1E2CB20>, <Integer '1' at 0x18ED1E2CB80>, <Punctuation ';' at 0x18ED1E2CBE0>])\nE        +    where [<Identifier 'foo' at 0x18ED1DB18D0>, <Whitespace ' ' at 0x18ED1E2C880>, <Assignment ':=' at 0x18ED1E2CAC0>, <Whitespace ' ' at 0x18ED1E2CB20>, <Integer '1' at 0x18ED1E2CB80>, <Punctuation ';' at 0x18ED1E2CBE0>] = <Statement 'foo :=...' at 0x18ED1DB17D0>.tokens\n\nrepos\\sqlparse\\tests\\test_grouping.py:23: AssertionError"", ""s = 'foo := 1'\n\n    @pytest.mark.parametrize('s', ['foo := 1;', 'foo := 1'])\n    def test_grouping_assignment(s):\n        parsed = sqlparse.parse(s)[0]\n>       assert len(parsed.tokens) == 1\nE       AssertionError: assert 5 == 1\nE        +  where 5 = len([<Identifier 'foo' at 0x18ED1F1F1D0>, <Whitespace ' ' at 0x18ED1E2CE80>, <Assignment ':=' at 0x18ED1E2CFA0>, <Whitespace ' ' at 0x18ED1E2D000>, <Integer '1' at 0x18ED1E2D060>])\nE        +    where [<Identifier 'foo' at 0x18ED1F1F1D0>, <Whitespace ' ' at 0x18ED1E2CE80>, <Assignment ':=' at 0x18ED1E2CFA0>, <Whitespace ' ' at 0x18ED1E2D000>, <Integer '1' at 0x18ED1E2D060>] = <Statement 'foo :=...' at 0x18ED1F1FED0>.tokens\n\nrepos\\sqlparse\\tests\\test_grouping.py:23: AssertionError"", 's = ""x > DATE \'2020-01-01\'""\n\n    @pytest.mark.parametrize(\'s\', [""x > DATE \'2020-01-01\'"", ""x > TIMESTAMP \'2020-01-01 00:00:00\'""])\n    def test_grouping_typed_literal(s):\n        parsed = sqlparse.parse(s)[0]\n>       assert isinstance(parsed[0][4], sql.TypedLiteral)\n\nrepos\\sqlparse\\tests\\test_grouping.py:30: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Identifier \'x\' at 0x18ED1F1F850>, item = 4\n\n    def __getitem__(self, item):\n>       return self.tokens[item]\nE       IndexError: list index out of range\n\nrepos\\sqlparse\\sqlparse\\sql.py:140: IndexError', 's = ""x > TIMESTAMP \'2020-01-01 00:00:00\'""\n\n    @pytest.mark.parametrize(\'s\', [""x > DATE \'2020-01-01\'"", ""x > TIMESTAMP \'2020-01-01 00:00:00\'""])\n    def test_grouping_typed_literal(s):\n        parsed = sqlparse.parse(s)[0]\n>       assert isinstance(parsed[0][4], sql.TypedLiteral)\n\nrepos\\sqlparse\\tests\\test_grouping.py:30: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Identifier \'x\' at 0x18ED1E842D0>, item = 4\n\n    def __getitem__(self, item):\n>       return self.tokens[item]\nE       IndexError: list index out of range\n\nrepos\\sqlparse\\sqlparse\\sql.py:140: IndexError', ""s = 'select a from b where c < d + e', a = <class 'sqlparse.sql.Identifier'>\nb = <class 'sqlparse.sql.Identifier'>\n\n    @pytest.mark.parametrize('s, a, b', [\n        ('select a from b where c < d + e', sql.Identifier, sql.Identifier),\n        ('select a from b where c < d + interval \\'1 day\\'', sql.Identifier, sql.TypedLiteral),\n        ('select a from b where c < d + interval \\'6\\' month', sql.Identifier, sql.TypedLiteral),\n        ('select a from b where c < current_timestamp - interval \\'1 day\\'', sql.Token, sql.TypedLiteral),\n    ])\n    def test_compare_expr(s, a, b):\n        parsed = sqlparse.parse(s)[0]\n        assert str(parsed) == s\n        assert isinstance(parsed.tokens[2], sql.Identifier)\n        assert isinstance(parsed.tokens[6], sql.Identifier)\n        assert isinstance(parsed.tokens[8], sql.Where)\n        assert len(parsed.tokens) == 9\n        where = parsed.tokens[8]\n>       assert isinstance(where.tokens[2], sql.Comparison)\nE       AssertionError: assert False\nE        +  where False = isinstance(<Identifier 'c' at 0x18ED1F02B50>, <class 'sqlparse.sql.Comparison'>)\nE        +    where <class 'sqlparse.sql.Comparison'> = sql.Comparison\n\nrepos\\sqlparse\\tests\\test_grouping.py:47: AssertionError"", 's = ""select a from b where c < d + interval \'1 day\'""\na = <class \'sqlparse.sql.Identifier\'>, b = <class \'sqlparse.sql.TypedLiteral\'>\n\n    @pytest.mark.parametrize(\'s, a, b\', [\n        (\'select a from b where c < d + e\', sql.Identifier, sql.Identifier),\n        (\'select a from b where c < d + interval \\\'1 day\\\'\', sql.Identifier, sql.TypedLiteral),\n        (\'select a from b where c < d + interval \\\'6\\\' month\', sql.Identifier, sql.TypedLiteral),\n        (\'select a from b where c < current_timestamp - interval \\\'1 day\\\'\', sql.Token, sql.TypedLiteral),\n    ])\n    def test_compare_expr(s, a, b):\n        parsed = sqlparse.parse(s)[0]\n        assert str(parsed) == s\n        assert isinstance(parsed.tokens[2], sql.Identifier)\n        assert isinstance(parsed.tokens[6], sql.Identifier)\n        assert isinstance(parsed.tokens[8], sql.Where)\n        assert len(parsed.tokens) == 9\n        where = parsed.tokens[8]\n>       assert isinstance(where.tokens[2], sql.Comparison)\nE       AssertionError: assert False\nE        +  where False = isinstance(<Identifier \'c\' at 0x18ED1F035D0>, <class \'sqlparse.sql.Comparison\'>)\nE        +    where <class \'sqlparse.sql.Comparison\'> = sql.Comparison\n\nrepos\\sqlparse\\tests\\test_grouping.py:47: AssertionError', 's = ""select a from b where c < d + interval \'6\' month""\na = <class \'sqlparse.sql.Identifier\'>, b = <class \'sqlparse.sql.TypedLiteral\'>\n\n    @pytest.mark.parametrize(\'s, a, b\', [\n        (\'select a from b where c < d + e\', sql.Identifier, sql.Identifier),\n        (\'select a from b where c < d + interval \\\'1 day\\\'\', sql.Identifier, sql.TypedLiteral),\n        (\'select a from b where c < d + interval \\\'6\\\' month\', sql.Identifier, sql.TypedLiteral),\n        (\'select a from b where c < current_timestamp - interval \\\'1 day\\\'\', sql.Token, sql.TypedLiteral),\n    ])\n    def test_compare_expr(s, a, b):\n        parsed = sqlparse.parse(s)[0]\n        assert str(parsed) == s\n        assert isinstance(parsed.tokens[2], sql.Identifier)\n        assert isinstance(parsed.tokens[6], sql.Identifier)\n        assert isinstance(parsed.tokens[8], sql.Where)\n        assert len(parsed.tokens) == 9\n        where = parsed.tokens[8]\n>       assert isinstance(where.tokens[2], sql.Comparison)\nE       AssertionError: assert False\nE        +  where False = isinstance(<Identifier \'c\' at 0x18ED1E688D0>, <class \'sqlparse.sql.Comparison\'>)\nE        +    where <class \'sqlparse.sql.Comparison\'> = sql.Comparison\n\nrepos\\sqlparse\\tests\\test_grouping.py:47: AssertionError', 's = ""select a from b where c < current_timestamp - interval \'1 day\'""\na = <class \'sqlparse.sql.Token\'>, b = <class \'sqlparse.sql.TypedLiteral\'>\n\n    @pytest.mark.parametrize(\'s, a, b\', [\n        (\'select a from b where c < d + e\', sql.Identifier, sql.Identifier),\n        (\'select a from b where c < d + interval \\\'1 day\\\'\', sql.Identifier, sql.TypedLiteral),\n        (\'select a from b where c < d + interval \\\'6\\\' month\', sql.Identifier, sql.TypedLiteral),\n        (\'select a from b where c < current_timestamp - interval \\\'1 day\\\'\', sql.Token, sql.TypedLiteral),\n    ])\n    def test_compare_expr(s, a, b):\n        parsed = sqlparse.parse(s)[0]\n        assert str(parsed) == s\n        assert isinstance(parsed.tokens[2], sql.Identifier)\n        assert isinstance(parsed.tokens[6], sql.Identifier)\n        assert isinstance(parsed.tokens[8], sql.Where)\n        assert len(parsed.tokens) == 9\n        where = parsed.tokens[8]\n>       assert isinstance(where.tokens[2], sql.Comparison)\nE       AssertionError: assert False\nE        +  where False = isinstance(<Identifier \'c\' at 0x18ED1F00F50>, <class \'sqlparse.sql.Comparison\'>)\nE        +    where <class \'sqlparse.sql.Comparison\'> = sql.Comparison\n\nrepos\\sqlparse\\tests\\test_grouping.py:47: AssertionError', 'def test_grouping_identifiers():\n        s = \'select foo.bar from ""myscheme"".""table"" where fail. order\'\n        parsed = sqlparse.parse(s)[0]\n        assert str(parsed) == s\n        assert isinstance(parsed.tokens[2], sql.Identifier)\n>       assert isinstance(parsed.tokens[6], sql.Identifier)\nE       AssertionError: assert False\nE        +  where False = isinstance(<Whitespace \' \' at 0x18ED1E2E4A0>, <class \'sqlparse.sql.Identifier\'>)\nE        +    where <class \'sqlparse.sql.Identifier\'> = sql.Identifier\n\nrepos\\sqlparse\\tests\\test_grouping.py:66: AssertionError', ""s = '1 as f'\n\n    @pytest.mark.parametrize('s', [\n        '1 as f',\n        'foo as f',\n        'foo f',\n        '1/2 as f',\n        '1/2 f',\n        '1<2 as f',  # issue327\n        '1<2 f',\n    ])\n    def test_simple_identifiers(s):\n        parsed = sqlparse.parse(s)[0]\n>       assert isinstance(parsed.tokens[0], sql.Identifier)\nE       AssertionError: assert False\nE        +  where False = isinstance(<Integer '1' at 0x18ED1E2CEE0>, <class 'sqlparse.sql.Identifier'>)\nE        +    where <class 'sqlparse.sql.Identifier'> = sql.Identifier\n\nrepos\\sqlparse\\tests\\test_grouping.py:106: AssertionError"", ""s = '1/2 as f'\n\n    @pytest.mark.parametrize('s', [\n        '1 as f',\n        'foo as f',\n        'foo f',\n        '1/2 as f',\n        '1/2 f',\n        '1<2 as f',  # issue327\n        '1<2 f',\n    ])\n    def test_simple_identifiers(s):\n        parsed = sqlparse.parse(s)[0]\n>       assert isinstance(parsed.tokens[0], sql.Identifier)\nE       AssertionError: assert False\nE        +  where False = isinstance(<Integer '1' at 0x18ED1E2CB80>, <class 'sqlparse.sql.Identifier'>)\nE        +    where <class 'sqlparse.sql.Identifier'> = sql.Identifier\n\nrepos\\sqlparse\\tests\\test_grouping.py:106: AssertionError"", ""s = '1/2 f'\n\n    @pytest.mark.parametrize('s', [\n        '1 as f',\n        'foo as f',\n        'foo f',\n        '1/2 as f',\n        '1/2 f',\n        '1<2 as f',  # issue327\n        '1<2 f',\n    ])\n    def test_simple_identifiers(s):\n        parsed = sqlparse.parse(s)[0]\n>       assert isinstance(parsed.tokens[0], sql.Identifier)\nE       AssertionError: assert False\nE        +  where False = isinstance(<Integer '1' at 0x18ED1E64580>, <class 'sqlparse.sql.Identifier'>)\nE        +    where <class 'sqlparse.sql.Identifier'> = sql.Identifier\n\nrepos\\sqlparse\\tests\\test_grouping.py:106: AssertionError"", ""s = '1<2 as f'\n\n    @pytest.mark.parametrize('s', [\n        '1 as f',\n        'foo as f',\n        'foo f',\n        '1/2 as f',\n        '1/2 f',\n        '1<2 as f',  # issue327\n        '1<2 f',\n    ])\n    def test_simple_identifiers(s):\n        parsed = sqlparse.parse(s)[0]\n>       assert isinstance(parsed.tokens[0], sql.Identifier)\nE       AssertionError: assert False\nE        +  where False = isinstance(<Integer '1' at 0x18ED1E67640>, <class 'sqlparse.sql.Identifier'>)\nE        +    where <class 'sqlparse.sql.Identifier'> = sql.Identifier\n\nrepos\\sqlparse\\tests\\test_grouping.py:106: AssertionError"", ""s = '1<2 f'\n\n    @pytest.mark.parametrize('s', [\n        '1 as f',\n        'foo as f',\n        'foo f',\n        '1/2 as f',\n        '1/2 f',\n        '1<2 as f',  # issue327\n        '1<2 f',\n    ])\n    def test_simple_identifiers(s):\n        parsed = sqlparse.parse(s)[0]\n>       assert isinstance(parsed.tokens[0], sql.Identifier)\nE       AssertionError: assert False\nE        +  where False = isinstance(<Integer '1' at 0x18ED1E64280>, <class 'sqlparse.sql.Identifier'>)\nE        +    where <class 'sqlparse.sql.Identifier'> = sql.Identifier\n\nrepos\\sqlparse\\tests\\test_grouping.py:106: AssertionError"", ""s = 'foo, bar'\n\n    @pytest.mark.parametrize('s', [\n        'foo, bar',\n        'sum(a), sum(b)',\n        'sum(a) as x, b as y',\n        'sum(a)::integer, b',\n        'sum(a)/count(b) as x, y',\n        'sum(a)::integer as x, y',\n        'sum(a)::integer/count(b) as x, y',  # issue297\n    ])\n    def test_group_identifier_list(s):\n        parsed = sqlparse.parse(s)[0]\n>       assert isinstance(parsed.tokens[0], sql.IdentifierList)\nE       AssertionError: assert False\nE        +  where False = isinstance(<Identifier 'foo' at 0x18ED1FDCC50>, <class 'sqlparse.sql.IdentifierList'>)\nE        +    where <class 'sqlparse.sql.IdentifierList'> = sql.IdentifierList\n\nrepos\\sqlparse\\tests\\test_grouping.py:120: AssertionError"", ""s = 'sum(a), sum(b)'\n\n    @pytest.mark.parametrize('s', [\n        'foo, bar',\n        'sum(a), sum(b)',\n        'sum(a) as x, b as y',\n        'sum(a)::integer, b',\n        'sum(a)/count(b) as x, y',\n        'sum(a)::integer as x, y',\n        'sum(a)::integer/count(b) as x, y',  # issue297\n    ])\n    def test_group_identifier_list(s):\n        parsed = sqlparse.parse(s)[0]\n>       assert isinstance(parsed.tokens[0], sql.IdentifierList)\nE       AssertionError: assert False\nE        +  where False = isinstance(<Identifier 'sum' at 0x18ED1FDDAD0>, <class 'sqlparse.sql.IdentifierList'>)\nE        +    where <class 'sqlparse.sql.IdentifierList'> = sql.IdentifierList\n\nrepos\\sqlparse\\tests\\test_grouping.py:120: AssertionError"", ""s = 'sum(a) as x, b as y'\n\n    @pytest.mark.parametrize('s', [\n        'foo, bar',\n        'sum(a), sum(b)',\n        'sum(a) as x, b as y',\n        'sum(a)::integer, b',\n        'sum(a)/count(b) as x, y',\n        'sum(a)::integer as x, y',\n        'sum(a)::integer/count(b) as x, y',  # issue297\n    ])\n    def test_group_identifier_list(s):\n        parsed = sqlparse.parse(s)[0]\n>       assert isinstance(parsed.tokens[0], sql.IdentifierList)\nE       AssertionError: assert False\nE        +  where False = isinstance(<Identifier 'sum' at 0x18ED1FDE6D0>, <class 'sqlparse.sql.IdentifierList'>)\nE        +    where <class 'sqlparse.sql.IdentifierList'> = sql.IdentifierList\n\nrepos\\sqlparse\\tests\\test_grouping.py:120: AssertionError"", ""s = 'sum(a)::integer, b'\n\n    @pytest.mark.parametrize('s', [\n        'foo, bar',\n        'sum(a), sum(b)',\n        'sum(a) as x, b as y',\n        'sum(a)::integer, b',\n        'sum(a)/count(b) as x, y',\n        'sum(a)::integer as x, y',\n        'sum(a)::integer/count(b) as x, y',  # issue297\n    ])\n    def test_group_identifier_list(s):\n        parsed = sqlparse.parse(s)[0]\n>       assert isinstance(parsed.tokens[0], sql.IdentifierList)\nE       AssertionError: assert False\nE        +  where False = isinstance(<Identifier 'sum' at 0x18ED1FDF0D0>, <class 'sqlparse.sql.IdentifierList'>)\nE        +    where <class 'sqlparse.sql.IdentifierList'> = sql.IdentifierList\n\nrepos\\sqlparse\\tests\\test_grouping.py:120: AssertionError"", ""s = 'sum(a)/count(b) as x, y'\n\n    @pytest.mark.parametrize('s', [\n        'foo, bar',\n        'sum(a), sum(b)',\n        'sum(a) as x, b as y',\n        'sum(a)::integer, b',\n        'sum(a)/count(b) as x, y',\n        'sum(a)::integer as x, y',\n        'sum(a)::integer/count(b) as x, y',  # issue297\n    ])\n    def test_group_identifier_list(s):\n        parsed = sqlparse.parse(s)[0]\n>       assert isinstance(parsed.tokens[0], sql.IdentifierList)\nE       AssertionError: assert False\nE        +  where False = isinstance(<Identifier 'sum' at 0x18ED1DD8050>, <class 'sqlparse.sql.IdentifierList'>)\nE        +    where <class 'sqlparse.sql.IdentifierList'> = sql.IdentifierList\n\nrepos\\sqlparse\\tests\\test_grouping.py:120: AssertionError"", ""s = 'sum(a)::integer as x, y'\n\n    @pytest.mark.parametrize('s', [\n        'foo, bar',\n        'sum(a), sum(b)',\n        'sum(a) as x, b as y',\n        'sum(a)::integer, b',\n        'sum(a)/count(b) as x, y',\n        'sum(a)::integer as x, y',\n        'sum(a)::integer/count(b) as x, y',  # issue297\n    ])\n    def test_group_identifier_list(s):\n        parsed = sqlparse.parse(s)[0]\n>       assert isinstance(parsed.tokens[0], sql.IdentifierList)\nE       AssertionError: assert False\nE        +  where False = isinstance(<Identifier 'sum' at 0x18ED1FDD750>, <class 'sqlparse.sql.IdentifierList'>)\nE        +    where <class 'sqlparse.sql.IdentifierList'> = sql.IdentifierList\n\nrepos\\sqlparse\\tests\\test_grouping.py:120: AssertionError"", ""s = 'sum(a)::integer/count(b) as x, y'\n\n    @pytest.mark.parametrize('s', [\n        'foo, bar',\n        'sum(a), sum(b)',\n        'sum(a) as x, b as y',\n        'sum(a)::integer, b',\n        'sum(a)/count(b) as x, y',\n        'sum(a)::integer as x, y',\n        'sum(a)::integer/count(b) as x, y',  # issue297\n    ])\n    def test_group_identifier_list(s):\n        parsed = sqlparse.parse(s)[0]\n>       assert isinstance(parsed.tokens[0], sql.IdentifierList)\nE       AssertionError: assert False\nE        +  where False = isinstance(<Identifier 'sum' at 0x18ED1EB1DD0>, <class 'sqlparse.sql.IdentifierList'>)\nE        +    where <class 'sqlparse.sql.IdentifierList'> = sql.IdentifierList\n\nrepos\\sqlparse\\tests\\test_grouping.py:120: AssertionError"", ""def test_grouping_identifier_wildcard():\n        p = sqlparse.parse('a.*, b.id')[0]\n>       assert isinstance(p.tokens[0], sql.IdentifierList)\nE       AssertionError: assert False\nE        +  where False = isinstance(<Identifier 'a.' at 0x18ED1E846D0>, <class 'sqlparse.sql.IdentifierList'>)\nE        +    where <class 'sqlparse.sql.IdentifierList'> = sql.IdentifierList\n\nrepos\\sqlparse\\tests\\test_grouping.py:125: AssertionError"", ""def test_grouping_identifier_name_wildcard():\n        p = sqlparse.parse('a.*')[0]\n        t = p.tokens[0]\n>       assert t.get_name() == '*'\nE       AssertionError: assert None == '*'\nE        +  where None = get_name()\nE        +    where get_name = <Identifier 'a.' at 0x18ED1D27250>.get_name\n\nrepos\\sqlparse\\tests\\test_grouping.py:133: AssertionError"", 'def test_grouping_identifier_invalid():\n        p = sqlparse.parse(\'a.\')[0]\n        assert isinstance(p.tokens[0], sql.Identifier)\n        assert p.tokens[0].has_alias() is False\n        assert p.tokens[0].get_name() is None\n        assert p.tokens[0].get_real_name() is None\n>       assert p.tokens[0].get_parent_name() == \'a\'\n\nrepos\\sqlparse\\tests\\test_grouping.py:143: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\sql.py:316: in get_parent_name\n    _, prev_ = self.token_prev(dot_idx)\nrepos\\sqlparse\\sqlparse\\sql.py:241: in token_prev\n    return self.token_next(idx, skip_ws, skip_cm, _reverse=True)\nrepos\\sqlparse\\sqlparse\\sql.py:244: in token_next\n    return self._token_matching(idx, skip_ws, skip_cm, _reverse)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Identifier \'a.\' at 0x18ED1E6BA50>, funcs = (1,), start = True\nend = False, reverse = True\n\n    def _token_matching(self, funcs, start=0, end=None, reverse=False):\n        """"""next token that match functions""""""\n        if start is None:\n            return None\n        if not isinstance(funcs, (list, tuple)):\n            funcs = (funcs,)\n        if reverse:\n>           assert end is None\nE           AssertionError\n\nrepos\\sqlparse\\sqlparse\\sql.py:195: AssertionError', ""s = 'foo as (select *)'\n\n    @pytest.mark.parametrize('s', ['foo as (select *)', 'foo as(select *)'])\n    def test_grouping_identifer_as(s):\n        # issue507\n        p = sqlparse.parse(s)[0]\n        assert isinstance(p.tokens[0], sql.Identifier)\n>       token = p.tokens[0].tokens[2]\nE       IndexError: list index out of range\n\nrepos\\sqlparse\\tests\\test_grouping.py:160: IndexError"", ""s = 'foo as(select *)'\n\n    @pytest.mark.parametrize('s', ['foo as (select *)', 'foo as(select *)'])\n    def test_grouping_identifer_as(s):\n        # issue507\n        p = sqlparse.parse(s)[0]\n        assert isinstance(p.tokens[0], sql.Identifier)\n>       token = p.tokens[0].tokens[2]\nE       IndexError: list index out of range\n\nrepos\\sqlparse\\tests\\test_grouping.py:160: IndexError"", ""def test_grouping_identifier_function():\n        p = sqlparse.parse('foo() as bar')[0]\n        assert isinstance(p.tokens[0], sql.Identifier)\n>       assert isinstance(p.tokens[0].tokens[0], sql.Function)\nE       AssertionError: assert False\nE        +  where False = isinstance(<Name 'foo' at 0x18ED1E66440>, <class 'sqlparse.sql.Function'>)\nE        +    where <class 'sqlparse.sql.Function'> = sql.Function\n\nrepos\\sqlparse\\tests\\test_grouping.py:176: AssertionError"", ""s = 'foo+100'\n\n    @pytest.mark.parametrize('s', ['foo+100', 'foo + 100', 'foo*100'])\n    def test_grouping_operation(s):\n        p = sqlparse.parse(s)[0]\n>       assert isinstance(p.tokens[0], sql.Operation)\nE       AssertionError: assert False\nE        +  where False = isinstance(<Identifier 'foo' at 0x18ED1F1F1D0>, <class 'sqlparse.sql.Operation'>)\nE        +    where <class 'sqlparse.sql.Operation'> = sql.Operation\n\nrepos\\sqlparse\\tests\\test_grouping.py:200: AssertionError"", ""s = 'foo + 100'\n\n    @pytest.mark.parametrize('s', ['foo+100', 'foo + 100', 'foo*100'])\n    def test_grouping_operation(s):\n        p = sqlparse.parse(s)[0]\n>       assert isinstance(p.tokens[0], sql.Operation)\nE       AssertionError: assert False\nE        +  where False = isinstance(<Identifier 'foo' at 0x18ED1E6B4D0>, <class 'sqlparse.sql.Operation'>)\nE        +    where <class 'sqlparse.sql.Operation'> = sql.Operation\n\nrepos\\sqlparse\\tests\\test_grouping.py:200: AssertionError"", ""s = 'foo*100'\n\n    @pytest.mark.parametrize('s', ['foo+100', 'foo + 100', 'foo*100'])\n    def test_grouping_operation(s):\n        p = sqlparse.parse(s)[0]\n>       assert isinstance(p.tokens[0], sql.Operation)\nE       AssertionError: assert False\nE        +  where False = isinstance(<Identifier 'foo' at 0x18ED1DB69D0>, <class 'sqlparse.sql.Operation'>)\nE        +    where <class 'sqlparse.sql.Operation'> = sql.Operation\n\nrepos\\sqlparse\\tests\\test_grouping.py:200: AssertionError"", ""def test_grouping_identifier_list():\n        p = sqlparse.parse('a, b, c')[0]\n>       assert isinstance(p.tokens[0], sql.IdentifierList)\nE       AssertionError: assert False\nE        +  where False = isinstance(<Identifier 'a' at 0x18ED1E74150>, <class 'sqlparse.sql.IdentifierList'>)\nE        +    where <class 'sqlparse.sql.IdentifierList'> = sql.IdentifierList\n\nrepos\\sqlparse\\tests\\test_grouping.py:205: AssertionError"", 'def test_grouping_identifier_list_subquery():\n        """"""identifier lists should still work in subqueries with aliases""""""\n        p = sqlparse.parse(""select * from (""\n                           ""select a, b + c as d from table) sub"")[0]\n        subquery = p.tokens[-1].tokens[0]\n>       idx, iden_list = subquery.token_next_by(i=sql.IdentifierList)\nE       AttributeError: \'Token\' object has no attribute \'token_next_by\'\n\nrepos\\sqlparse\\tests\\test_grouping.py:215: AttributeError', ""def test_grouping_identifier_list_case():\n        p = sqlparse.parse('a, case when 1 then 2 else 3 end as b, c')[0]\n>       assert isinstance(p.tokens[0], sql.IdentifierList)\nE       AssertionError: assert False\nE        +  where False = isinstance(<Identifier 'a' at 0x18ED1FDFBD0>, <class 'sqlparse.sql.IdentifierList'>)\nE        +    where <class 'sqlparse.sql.IdentifierList'> = sql.IdentifierList\n\nrepos\\sqlparse\\tests\\test_grouping.py:224: AssertionError"", 'def test_grouping_identifier_list_other():\n        # issue2\n        p = sqlparse.parse(""select *, null, 1, \'foo\', bar from mytable, x"")[0]\n>       assert isinstance(p.tokens[2], sql.IdentifierList)\nE       AssertionError: assert False\nE        +  where False = isinstance(<Wildcard \'*\' at 0x18ED1E8BA60>, <class \'sqlparse.sql.IdentifierList\'>)\nE        +    where <class \'sqlparse.sql.IdentifierList\'> = sql.IdentifierList\n\nrepos\\sqlparse\\tests\\test_grouping.py:232: AssertionError', 'def test_grouping_identifier_list_with_inline_comments():\n        # issue163\n>       p = sqlparse.parse(\'foo /* a comment */, bar\')[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:238: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\utils.py:74: in wrapped_f\n    f(tlist)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:319: in group_comments\n    eidx, end = tlist.token_prev(eidx, skip_ws=False)\nrepos\\sqlparse\\sqlparse\\sql.py:241: in token_prev\n    return self.token_next(idx, skip_ws, skip_cm, _reverse=True)\nrepos\\sqlparse\\sqlparse\\sql.py:244: in token_next\n    return self._token_matching(idx, skip_ws, skip_cm, _reverse)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Statement \'foo /*...\' at 0x18ED1F02850>, funcs = (3,), start = False\nend = False, reverse = True\n\n    def _token_matching(self, funcs, start=0, end=None, reverse=False):\n        """"""next token that match functions""""""\n        if start is None:\n            return None\n        if not isinstance(funcs, (list, tuple)):\n            funcs = (funcs,)\n        if reverse:\n>           assert end is None\nE           AssertionError\n\nrepos\\sqlparse\\sqlparse\\sql.py:195: AssertionError', 'def test_grouping_identifier_list_with_order():\n        # issue101\n>       p = sqlparse.parse(\'1, 2 desc, 3\')[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:251: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\utils.py:74: in wrapped_f\n    f(tlist)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:388: in group_order\n    pidx, prev_ = tlist.token_prev(tidx)\nrepos\\sqlparse\\sqlparse\\sql.py:241: in token_prev\n    return self.token_next(idx, skip_ws, skip_cm, _reverse=True)\nrepos\\sqlparse\\sqlparse\\sql.py:244: in token_next\n    return self._token_matching(idx, skip_ws, skip_cm, _reverse)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Statement \'1, 2 d...\' at 0x18ED1F01650>, funcs = (5,), start = True\nend = False, reverse = True\n\n    def _token_matching(self, funcs, start=0, end=None, reverse=False):\n        """"""next token that match functions""""""\n        if start is None:\n            return None\n        if not isinstance(funcs, (list, tuple)):\n            funcs = (funcs,)\n        if reverse:\n>           assert end is None\nE           AssertionError\n\nrepos\\sqlparse\\sqlparse\\sql.py:195: AssertionError', 'def test_grouping_nested_identifier_with_order():\n        # issue745\n>       p = sqlparse.parse(\'(a desc)\')[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:259: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\utils.py:73: in wrapped_f\n    wrapped_f(sgroup)\nrepos\\sqlparse\\sqlparse\\utils.py:74: in wrapped_f\n    f(tlist)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:388: in group_order\n    pidx, prev_ = tlist.token_prev(tidx)\nrepos\\sqlparse\\sqlparse\\sql.py:241: in token_prev\n    return self.token_next(idx, skip_ws, skip_cm, _reverse=True)\nrepos\\sqlparse\\sqlparse\\sql.py:244: in token_next\n    return self._token_matching(idx, skip_ws, skip_cm, _reverse)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Parenthesis \'(a des...\' at 0x18ED1F971D0>, funcs = (3,), start = True\nend = False, reverse = True\n\n    def _token_matching(self, funcs, start=0, end=None, reverse=False):\n        """"""next token that match functions""""""\n        if start is None:\n            return None\n        if not isinstance(funcs, (list, tuple)):\n            funcs = (funcs,)\n        if reverse:\n>           assert end is None\nE           AssertionError\n\nrepos\\sqlparse\\sqlparse\\sql.py:195: AssertionError', 'def test_grouping_where():\n        s = \'select * from foo where bar = 1 order by id desc\'\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:267: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\utils.py:74: in wrapped_f\n    f(tlist)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:388: in group_order\n    pidx, prev_ = tlist.token_prev(tidx)\nrepos\\sqlparse\\sqlparse\\sql.py:241: in token_prev\n    return self.token_next(idx, skip_ws, skip_cm, _reverse=True)\nrepos\\sqlparse\\sqlparse\\sql.py:244: in token_next\n    return self._token_matching(idx, skip_ws, skip_cm, _reverse)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Statement \'select...\' at 0x18ED1F956D0>, funcs = (13,), start = True\nend = False, reverse = True\n\n    def _token_matching(self, funcs, start=0, end=None, reverse=False):\n        """"""next token that match functions""""""\n        if start is None:\n            return None\n        if not isinstance(funcs, (list, tuple)):\n            funcs = (funcs,)\n        if reverse:\n>           assert end is None\nE           AssertionError\n\nrepos\\sqlparse\\sqlparse\\sql.py:195: AssertionError', ""sql = 'select foo::integer from bar', expected = 'integer'\n\n    @pytest.mark.parametrize('sql, expected', [\n        # note: typecast needs to be 2nd token for this test\n        ('select foo::integer from bar', 'integer'),\n        ('select (current_database())::information_schema.sql_identifier',\n         'information_schema.sql_identifier'),\n    ])\n    def test_grouping_typecast(sql, expected):\n        p = sqlparse.parse(sql)[0]\n>       assert p.tokens[2].get_typecast() == expected\nE       AssertionError: assert None == 'integer'\nE        +  where None = get_typecast()\nE        +    where get_typecast = <Identifier 'foo' at 0x18ED1F967D0>.get_typecast\n\nrepos\\sqlparse\\tests\\test_grouping.py:310: AssertionError"", ""sql = 'select (current_database())::information_schema.sql_identifier'\nexpected = 'information_schema.sql_identifier'\n\n    @pytest.mark.parametrize('sql, expected', [\n        # note: typecast needs to be 2nd token for this test\n        ('select foo::integer from bar', 'integer'),\n        ('select (current_database())::information_schema.sql_identifier',\n         'information_schema.sql_identifier'),\n    ])\n    def test_grouping_typecast(sql, expected):\n        p = sqlparse.parse(sql)[0]\n>       assert p.tokens[2].get_typecast() == expected\nE       AttributeError: 'Parenthesis' object has no attribute 'get_typecast'\n\nrepos\\sqlparse\\tests\\test_grouping.py:310: AttributeError"", ""def test_grouping_alias():\n        s = 'select foo as bar from mytable'\n        p = sqlparse.parse(s)[0]\n        assert str(p) == s\n        assert p.tokens[2].get_real_name() == 'foo'\n>       assert p.tokens[2].get_alias() == 'bar'\nE       AssertionError: assert None == 'bar'\nE        +  where None = get_alias()\nE        +    where get_alias = <Identifier 'foo' at 0x18ED202CDD0>.get_alias\n\nrepos\\sqlparse\\tests\\test_grouping.py:318: AssertionError"", ""def test_grouping_alias_case():\n        # see issue46\n        p = sqlparse.parse('CASE WHEN 1 THEN 2 ELSE 3 END foo')[0]\n>       assert len(p.tokens) == 1\nE       AssertionError: assert 3 == 1\nE        +  where 3 = len([<Case 'CASE W...' at 0x18ED202DBD0>, <Whitespace ' ' at 0x18ED1DE1540>, <Identifier 'foo' at 0x18ED202DD50>])\nE        +    where [<Case 'CASE W...' at 0x18ED202DBD0>, <Whitespace ' ' at 0x18ED1DE1540>, <Identifier 'foo' at 0x18ED202DD50>] = <Statement 'CASE W...' at 0x18ED202F750>.tokens\n\nrepos\\sqlparse\\tests\\test_grouping.py:338: AssertionError"", ""def test_grouping_alias_ctas():\n        p = sqlparse.parse('CREATE TABLE tbl1 AS SELECT coalesce(t1.col1, 0) AS col1 FROM t1')[0]\n>       assert p.tokens[10].get_alias() == 'col1'\nE       AssertionError: assert None == 'col1'\nE        +  where None = get_alias()\nE        +    where get_alias = <Identifier 'coales...' at 0x18ED202D850>.get_alias\n\nrepos\\sqlparse\\tests\\test_grouping.py:344: AssertionError"", ""s = 'foo.bar'\n\n    @pytest.mark.parametrize('s', ['foo.bar', 'x, y', 'x > y', 'x / y'])\n    def test_grouping_alias_returns_none(s):\n        # see issue185 and issue445\n        p = sqlparse.parse(s)[0]\n>       assert len(p.tokens) == 1\nE       AssertionError: assert 2 == 1\nE        +  where 2 = len([<Identifier 'foo.' at 0x18ED202CA50>, <Identifier 'bar' at 0x18ED202C750>])\nE        +    where [<Identifier 'foo.' at 0x18ED202CA50>, <Identifier 'bar' at 0x18ED202C750>] = <Statement 'foo.bar' at 0x18ED202DDD0>.tokens\n\nrepos\\sqlparse\\tests\\test_grouping.py:361: AssertionError"", ""s = 'x, y'\n\n    @pytest.mark.parametrize('s', ['foo.bar', 'x, y', 'x > y', 'x / y'])\n    def test_grouping_alias_returns_none(s):\n        # see issue185 and issue445\n        p = sqlparse.parse(s)[0]\n>       assert len(p.tokens) == 1\nE       AssertionError: assert 4 == 1\nE        +  where 4 = len([<Identifier 'x' at 0x18ED202FED0>, <Punctuation ',' at 0x18ED1C63160>, <Whitespace ' ' at 0x18ED1C60D00>, <Identifier 'y' at 0x18ED202FF50>])\nE        +    where [<Identifier 'x' at 0x18ED202FED0>, <Punctuation ',' at 0x18ED1C63160>, <Whitespace ' ' at 0x18ED1C60D00>, <Identifier 'y' at 0x18ED202FF50>] = <Statement 'x, y' at 0x18ED202FB50>.tokens\n\nrepos\\sqlparse\\tests\\test_grouping.py:361: AssertionError"", ""s = 'x > y'\n\n    @pytest.mark.parametrize('s', ['foo.bar', 'x, y', 'x > y', 'x / y'])\n    def test_grouping_alias_returns_none(s):\n        # see issue185 and issue445\n        p = sqlparse.parse(s)[0]\n>       assert len(p.tokens) == 1\nE       AssertionError: assert 5 == 1\nE        +  where 5 = len([<Identifier 'x' at 0x18ED1EAC050>, <Whitespace ' ' at 0x18ED1E8BBE0>, <Comparison '>' at 0x18ED1E88DC0>, <Whitespace ' ' at 0x18ED1E8B880>, <Identifier 'y' at 0x18ED1EAC0D0>])\nE        +    where [<Identifier 'x' at 0x18ED1EAC050>, <Whitespace ' ' at 0x18ED1E8BBE0>, <Comparison '>' at 0x18ED1E88DC0>, <Whitespace ' ' at 0x18ED1E8B880>, <Identifier 'y' at 0x18ED1EAC0D0>] = <Statement 'x > y' at 0x18ED202C6D0>.tokens\n\nrepos\\sqlparse\\tests\\test_grouping.py:361: AssertionError"", ""s = 'x / y'\n\n    @pytest.mark.parametrize('s', ['foo.bar', 'x, y', 'x > y', 'x / y'])\n    def test_grouping_alias_returns_none(s):\n        # see issue185 and issue445\n        p = sqlparse.parse(s)[0]\n>       assert len(p.tokens) == 1\nE       AssertionError: assert 5 == 1\nE        +  where 5 = len([<Identifier 'x' at 0x18ED1EAC8D0>, <Whitespace ' ' at 0x18ED1E88280>, <Operator '/' at 0x18ED1E88820>, <Whitespace ' ' at 0x18ED1E8BB20>, <Identifier 'y' at 0x18ED1EAC950>])\nE        +    where [<Identifier 'x' at 0x18ED1EAC8D0>, <Whitespace ' ' at 0x18ED1E88280>, <Operator '/' at 0x18ED1E88820>, <Whitespace ' ' at 0x18ED1E8BB20>, <Identifier 'y' at 0x18ED1EAC950>] = <Statement 'x / y' at 0x18ED1EAC850>.tokens\n\nrepos\\sqlparse\\tests\\test_grouping.py:361: AssertionError"", ""def test_grouping_idlist_function():\n        # see issue10 too\n        p = sqlparse.parse('foo(1) x, bar')[0]\n>       assert isinstance(p.tokens[0], sql.IdentifierList)\nE       AssertionError: assert False\nE        +  where False = isinstance(<Identifier 'foo' at 0x18ED202E7D0>, <class 'sqlparse.sql.IdentifierList'>)\nE        +    where <class 'sqlparse.sql.IdentifierList'> = sql.IdentifierList\n\nrepos\\sqlparse\\tests\\test_grouping.py:368: AssertionError"", ""def test_grouping_comparison_exclude():\n        # make sure operators are not handled too lazy\n        p = sqlparse.parse('(=)')[0]\n        assert isinstance(p.tokens[0], sql.Parenthesis)\n        assert not isinstance(p.tokens[0].tokens[1], sql.Comparison)\n        p = sqlparse.parse('(a=1)')[0]\n>       assert isinstance(p.tokens[0].tokens[1], sql.Comparison)\nE       AssertionError: assert False\nE        +  where False = isinstance(<Identifier 'a' at 0x18ED19F0950>, <class 'sqlparse.sql.Comparison'>)\nE        +    where <class 'sqlparse.sql.Comparison'> = sql.Comparison\n\nrepos\\sqlparse\\tests\\test_grouping.py:377: AssertionError"", ""def test_grouping_function():\n        p = sqlparse.parse('foo()')[0]\n>       assert isinstance(p.tokens[0], sql.Function)\nE       AssertionError: assert False\nE        +  where False = isinstance(<Identifier 'foo' at 0x18ED1F94550>, <class 'sqlparse.sql.Function'>)\nE        +    where <class 'sqlparse.sql.Function'> = sql.Function\n\nrepos\\sqlparse\\tests\\test_grouping.py:384: AssertionError"", 'def test_grouping_varchar():\n        p = sqlparse.parse(\'""text"" Varchar(50) NOT NULL\')[0]\n>       assert isinstance(p.tokens[2], sql.Function)\nE       AssertionError: assert False\nE        +  where False = isinstance(<Identifier \'Varchar\' at 0x18ED1EACBD0>, <class \'sqlparse.sql.Function\'>)\nE        +    where <class \'sqlparse.sql.Function\'> = sql.Function\n\nrepos\\sqlparse\\tests\\test_grouping.py:408: AssertionError', ""def test_identifier_with_operators():\n        # issue 53\n        p = sqlparse.parse('foo||bar')[0]\n>       assert len(p.tokens) == 1\nE       AssertionError: assert 3 == 1\nE        +  where 3 = len([<Identifier 'foo' at 0x18ED1EAD8D0>, <Operator '||' at 0x18ED1C5D420>, <Identifier 'bar' at 0x18ED1EADAD0>])\nE        +    where [<Identifier 'foo' at 0x18ED1EAD8D0>, <Operator '||' at 0x18ED1C5D420>, <Identifier 'bar' at 0x18ED1EADAD0>] = <Statement 'foo||b...' at 0x18ED1EAD950>.tokens\n\nrepos\\sqlparse\\tests\\test_grouping.py:425: AssertionError"", ""def test_identifier_with_op_trailing_ws():\n        # make sure trailing whitespace isn't grouped with identifier\n        p = sqlparse.parse('foo || bar ')[0]\n>       assert len(p.tokens) == 2\nE       AssertionError: assert 6 == 2\nE        +  where 6 = len([<Identifier 'foo' at 0x18ED1EAE150>, <Whitespace ' ' at 0x18ED1E65EA0>, <Operator '||' at 0x18ED1E65120>, <Whitespace ' ' at 0x18ED1E65480>, <Identifier 'bar' at 0x18ED1EAE1D0>, <Whitespace ' ' at 0x18ED1E67EE0>])\nE        +    where [<Identifier 'foo' at 0x18ED1EAE150>, <Whitespace ' ' at 0x18ED1E65EA0>, <Operator '||' at 0x18ED1E65120>, <Whitespace ' ' at 0x18ED1E65480>, <Identifier 'bar' at 0x18ED1EAE1D0>, <Whitespace ' ' at 0x18ED1E67EE0>] = <Statement 'foo ||...' at 0x18ED1EADF50>.tokens\n\nrepos\\sqlparse\\tests\\test_grouping.py:436: AssertionError"", 'def test_identifier_with_string_literals():\n        p = sqlparse.parse(""foo + \'bar\'"")[0]\n>       assert len(p.tokens) == 1\nE       assert 5 == 1\nE        +  where 5 = len([<Identifier \'foo\' at 0x18ED1EAD250>, <Whitespace \' \' at 0x18ED1C98760>, <Operator \'+\' at 0x18ED1C98940>, <Whitespace \' \' at 0x18ED1C99660>, <Single ""\'bar\'"" at 0x18ED1C98100>])\nE        +    where [<Identifier \'foo\' at 0x18ED1EAD250>, <Whitespace \' \' at 0x18ED1C98760>, <Operator \'+\' at 0x18ED1C98940>, <Whitespace \' \' at 0x18ED1C99660>, <Single ""\'bar\'"" at 0x18ED1C98100>] = <Statement \'foo + ...\' at 0x18ED1EAD2D0>.tokens\n\nrepos\\sqlparse\\tests\\test_grouping.py:443: AssertionError', 'def test_identifier_consumes_ordering():\n        # issue89\n>       p = sqlparse.parse(\'select * from foo order by c1 desc, c2, c3\')[0]\n\nrepos\\sqlparse\\tests\\test_grouping.py:458: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\utils.py:74: in wrapped_f\n    f(tlist)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:388: in group_order\n    pidx, prev_ = tlist.token_prev(tidx)\nrepos\\sqlparse\\sqlparse\\sql.py:241: in token_prev\n    return self.token_next(idx, skip_ws, skip_cm, _reverse=True)\nrepos\\sqlparse\\sqlparse\\sql.py:244: in token_next\n    return self._token_matching(idx, skip_ws, skip_cm, _reverse)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Statement \'select...\' at 0x18ED1EAEB50>, funcs = (12,), start = True\nend = False, reverse = True\n\n    def _token_matching(self, funcs, start=0, end=None, reverse=False):\n        """"""next token that match functions""""""\n        if start is None:\n            return None\n        if not isinstance(funcs, (list, tuple)):\n            funcs = (funcs,)\n        if reverse:\n>           assert end is None\nE           AssertionError\n\nrepos\\sqlparse\\sqlparse\\sql.py:195: AssertionError', ""def test_comparison_with_keywords():\n        # issue90\n        # in fact these are assignments, but for now we don't distinguish them\n        p = sqlparse.parse('foo = NULL')[0]\n>       assert len(p.tokens) == 1\nE       AssertionError: assert 5 == 1\nE        +  where 5 = len([<Identifier 'foo' at 0x18ED1F799D0>, <Whitespace ' ' at 0x18ED1DE11E0>, <Comparison '=' at 0x18ED1DE3040>, <Whitespace ' ' at 0x18ED1DE0040>, <Keyword 'NULL' at 0x18ED1DE2A40>])\nE        +    where [<Identifier 'foo' at 0x18ED1F799D0>, <Whitespace ' ' at 0x18ED1DE11E0>, <Comparison '=' at 0x18ED1DE3040>, <Whitespace ' ' at 0x18ED1DE0040>, <Keyword 'NULL' at 0x18ED1DE2A40>] = <Statement 'foo = ...' at 0x18ED1F79A50>.tokens\n\nrepos\\sqlparse\\tests\\test_grouping.py:472: AssertionError"", ""def test_comparison_with_floats():\n        # issue145\n        p = sqlparse.parse('foo = 25.5')[0]\n>       assert len(p.tokens) == 1\nE       AssertionError: assert 5 == 1\nE        +  where 5 = len([<Identifier 'foo' at 0x18ED1F7B2D0>, <Whitespace ' ' at 0x18ED1DE2C20>, <Comparison '=' at 0x18ED1DE3100>, <Whitespace ' ' at 0x18ED1DE1DE0>, <Float '25.5' at 0x18ED1DE33A0>])\nE        +    where [<Identifier 'foo' at 0x18ED1F7B2D0>, <Whitespace ' ' at 0x18ED1DE2C20>, <Comparison '=' at 0x18ED1DE3100>, <Whitespace ' ' at 0x18ED1DE1DE0>, <Float '25.5' at 0x18ED1DE33A0>] = <Statement 'foo = ...' at 0x18ED1F7B450>.tokens\n\nrepos\\sqlparse\\tests\\test_grouping.py:486: AssertionError"", ""def test_comparison_with_parenthesis():\n        # issue23\n        p = sqlparse.parse('(3 + 4) = 7')[0]\n>       assert len(p.tokens) == 1\nE       AssertionError: assert 5 == 1\nE        +  where 5 = len([<Parenthesis '(3 + 4)' at 0x18ED202E4D0>, <Whitespace ' ' at 0x18ED1C98100>, <Comparison '=' at 0x18ED1C99C00>, <Whitespace ' ' at 0x18ED1C993C0>, <Integer '7' at 0x18ED1C983A0>])\nE        +    where [<Parenthesis '(3 + 4)' at 0x18ED202E4D0>, <Whitespace ' ' at 0x18ED1C98100>, <Comparison '=' at 0x18ED1C99C00>, <Whitespace ' ' at 0x18ED1C993C0>, <Integer '7' at 0x18ED1C983A0>] = <Statement '(3 + 4...' at 0x18ED202E750>.tokens\n\nrepos\\sqlparse\\tests\\test_grouping.py:496: AssertionError"", 'operator = \'=\'\n\n    @pytest.mark.parametrize(\'operator\', (\n        \'=\', \'!=\', \'>\', \'<\', \'<=\', \'>=\', \'~\', \'~~\', \'!~~\',\n        \'LIKE\', \'NOT LIKE\', \'ILIKE\', \'NOT ILIKE\',\n    ))\n    def test_comparison_with_strings(operator):\n        # issue148\n        p = sqlparse.parse(f""foo {operator} \'bar\'"")[0]\n>       assert len(p.tokens) == 1\nE       assert 5 == 1\nE        +  where 5 = len([<Identifier \'foo\' at 0x18ED1EAEBD0>, <Whitespace \' \' at 0x18ED1E65120>, <Comparison \'=\' at 0x18ED1C5E3E0>, <Whitespace \' \' at 0x18ED1C5D060>, <Single ""\'bar\'"" at 0x18ED1C5F6A0>])\nE        +    where [<Identifier \'foo\' at 0x18ED1EAEBD0>, <Whitespace \' \' at 0x18ED1E65120>, <Comparison \'=\' at 0x18ED1C5E3E0>, <Whitespace \' \' at 0x18ED1C5D060>, <Single ""\'bar\'"" at 0x18ED1C5F6A0>] = <Statement \'foo = ...\' at 0x18ED1EAF8D0>.tokens\n\nrepos\\sqlparse\\tests\\test_grouping.py:510: AssertionError', 'operator = \'!=\'\n\n    @pytest.mark.parametrize(\'operator\', (\n        \'=\', \'!=\', \'>\', \'<\', \'<=\', \'>=\', \'~\', \'~~\', \'!~~\',\n        \'LIKE\', \'NOT LIKE\', \'ILIKE\', \'NOT ILIKE\',\n    ))\n    def test_comparison_with_strings(operator):\n        # issue148\n        p = sqlparse.parse(f""foo {operator} \'bar\'"")[0]\n>       assert len(p.tokens) == 1\nE       assert 5 == 1\nE        +  where 5 = len([<Identifier \'foo\' at 0x18ED1EAE1D0>, <Whitespace \' \' at 0x18ED1C5E2C0>, <Comparison \'!=\' at 0x18ED1C5D5A0>, <Whitespace \' \' at 0x18ED1C5D2A0>, <Single ""\'bar\'"" at 0x18ED1C5F280>])\nE        +    where [<Identifier \'foo\' at 0x18ED1EAE1D0>, <Whitespace \' \' at 0x18ED1C5E2C0>, <Comparison \'!=\' at 0x18ED1C5D5A0>, <Whitespace \' \' at 0x18ED1C5D2A0>, <Single ""\'bar\'"" at 0x18ED1C5F280>] = <Statement \'foo !=...\' at 0x18ED1EADF50>.tokens\n\nrepos\\sqlparse\\tests\\test_grouping.py:510: AssertionError', 'operator = \'>\'\n\n    @pytest.mark.parametrize(\'operator\', (\n        \'=\', \'!=\', \'>\', \'<\', \'<=\', \'>=\', \'~\', \'~~\', \'!~~\',\n        \'LIKE\', \'NOT LIKE\', \'ILIKE\', \'NOT ILIKE\',\n    ))\n    def test_comparison_with_strings(operator):\n        # issue148\n        p = sqlparse.parse(f""foo {operator} \'bar\'"")[0]\n>       assert len(p.tokens) == 1\nE       assert 5 == 1\nE        +  where 5 = len([<Identifier \'foo\' at 0x18ED1F7A4D0>, <Whitespace \' \' at 0x18ED1C5D540>, <Comparison \'>\' at 0x18ED1C5E860>, <Whitespace \' \' at 0x18ED1C5F400>, <Single ""\'bar\'"" at 0x18ED1C5DA80>])\nE        +    where [<Identifier \'foo\' at 0x18ED1F7A4D0>, <Whitespace \' \' at 0x18ED1C5D540>, <Comparison \'>\' at 0x18ED1C5E860>, <Whitespace \' \' at 0x18ED1C5F400>, <Single ""\'bar\'"" at 0x18ED1C5DA80>] = <Statement \'foo > ...\' at 0x18ED1F7A750>.tokens\n\nrepos\\sqlparse\\tests\\test_grouping.py:510: AssertionError', 'operator = \'<\'\n\n    @pytest.mark.parametrize(\'operator\', (\n        \'=\', \'!=\', \'>\', \'<\', \'<=\', \'>=\', \'~\', \'~~\', \'!~~\',\n        \'LIKE\', \'NOT LIKE\', \'ILIKE\', \'NOT ILIKE\',\n    ))\n    def test_comparison_with_strings(operator):\n        # issue148\n        p = sqlparse.parse(f""foo {operator} \'bar\'"")[0]\n>       assert len(p.tokens) == 1\nE       assert 5 == 1\nE        +  where 5 = len([<Identifier \'foo\' at 0x18ED1F7B4D0>, <Whitespace \' \' at 0x18ED1DE3AC0>, <Comparison \'<\' at 0x18ED1DE2A40>, <Whitespace \' \' at 0x18ED1DE0040>, <Single ""\'bar\'"" at 0x18ED1DE15A0>])\nE        +    where [<Identifier \'foo\' at 0x18ED1F7B4D0>, <Whitespace \' \' at 0x18ED1DE3AC0>, <Comparison \'<\' at 0x18ED1DE2A40>, <Whitespace \' \' at 0x18ED1DE0040>, <Single ""\'bar\'"" at 0x18ED1DE15A0>] = <Statement \'foo < ...\' at 0x18ED1F7B3D0>.tokens\n\nrepos\\sqlparse\\tests\\test_grouping.py:510: AssertionError', 'operator = \'<=\'\n\n    @pytest.mark.parametrize(\'operator\', (\n        \'=\', \'!=\', \'>\', \'<\', \'<=\', \'>=\', \'~\', \'~~\', \'!~~\',\n        \'LIKE\', \'NOT LIKE\', \'ILIKE\', \'NOT ILIKE\',\n    ))\n    def test_comparison_with_strings(operator):\n        # issue148\n        p = sqlparse.parse(f""foo {operator} \'bar\'"")[0]\n>       assert len(p.tokens) == 1\nE       assert 5 == 1\nE        +  where 5 = len([<Identifier \'foo\' at 0x18ED1F79A50>, <Whitespace \' \' at 0x18ED1DE13C0>, <Comparison \'<=\' at 0x18ED1DE3CA0>, <Whitespace \' \' at 0x18ED1DE25C0>, <Single ""\'bar\'"" at 0x18ED1DE2F80>])\nE        +    where [<Identifier \'foo\' at 0x18ED1F79A50>, <Whitespace \' \' at 0x18ED1DE13C0>, <Comparison \'<=\' at 0x18ED1DE3CA0>, <Whitespace \' \' at 0x18ED1DE25C0>, <Single ""\'bar\'"" at 0x18ED1DE2F80>] = <Statement \'foo <=...\' at 0x18ED1F799D0>.tokens\n\nrepos\\sqlparse\\tests\\test_grouping.py:510: AssertionError', 'operator = \'>=\'\n\n    @pytest.mark.parametrize(\'operator\', (\n        \'=\', \'!=\', \'>\', \'<\', \'<=\', \'>=\', \'~\', \'~~\', \'!~~\',\n        \'LIKE\', \'NOT LIKE\', \'ILIKE\', \'NOT ILIKE\',\n    ))\n    def test_comparison_with_strings(operator):\n        # issue148\n        p = sqlparse.parse(f""foo {operator} \'bar\'"")[0]\n>       assert len(p.tokens) == 1\nE       assert 5 == 1\nE        +  where 5 = len([<Identifier \'foo\' at 0x18ED1F79150>, <Whitespace \' \' at 0x18ED1C40040>, <Comparison \'>=\' at 0x18ED1C42320>, <Whitespace \' \' at 0x18ED1C43280>, <Single ""\'bar\'"" at 0x18ED1C404C0>])\nE        +    where [<Identifier \'foo\' at 0x18ED1F79150>, <Whitespace \' \' at 0x18ED1C40040>, <Comparison \'>=\' at 0x18ED1C42320>, <Whitespace \' \' at 0x18ED1C43280>, <Single ""\'bar\'"" at 0x18ED1C404C0>] = <Statement \'foo >=...\' at 0x18ED1F790D0>.tokens\n\nrepos\\sqlparse\\tests\\test_grouping.py:510: AssertionError', 'operator = \'~\'\n\n    @pytest.mark.parametrize(\'operator\', (\n        \'=\', \'!=\', \'>\', \'<\', \'<=\', \'>=\', \'~\', \'~~\', \'!~~\',\n        \'LIKE\', \'NOT LIKE\', \'ILIKE\', \'NOT ILIKE\',\n    ))\n    def test_comparison_with_strings(operator):\n        # issue148\n        p = sqlparse.parse(f""foo {operator} \'bar\'"")[0]\n>       assert len(p.tokens) == 1\nE       assert 5 == 1\nE        +  where 5 = len([<Identifier \'foo\' at 0x18ED1F785D0>, <Whitespace \' \' at 0x18ED1C63160>, <Comparison \'~\' at 0x18ED1C62500>, <Whitespace \' \' at 0x18ED1C617E0>, <Single ""\'bar\'"" at 0x18ED1C60220>])\nE        +    where [<Identifier \'foo\' at 0x18ED1F785D0>, <Whitespace \' \' at 0x18ED1C63160>, <Comparison \'~\' at 0x18ED1C62500>, <Whitespace \' \' at 0x18ED1C617E0>, <Single ""\'bar\'"" at 0x18ED1C60220>] = <Statement \'foo ~ ...\' at 0x18ED1F796D0>.tokens\n\nrepos\\sqlparse\\tests\\test_grouping.py:510: AssertionError', 'operator = \'~~\'\n\n    @pytest.mark.parametrize(\'operator\', (\n        \'=\', \'!=\', \'>\', \'<\', \'<=\', \'>=\', \'~\', \'~~\', \'!~~\',\n        \'LIKE\', \'NOT LIKE\', \'ILIKE\', \'NOT ILIKE\',\n    ))\n    def test_comparison_with_strings(operator):\n        # issue148\n        p = sqlparse.parse(f""foo {operator} \'bar\'"")[0]\n>       assert len(p.tokens) == 1\nE       assert 5 == 1\nE        +  where 5 = len([<Identifier \'foo\' at 0x18ED20C1350>, <Whitespace \' \' at 0x18ED1C4A3E0>, <Comparison \'~~\' at 0x18ED1C4A1A0>, <Whitespace \' \' at 0x18ED1C49D20>, <Single ""\'bar\'"" at 0x18ED1C483A0>])\nE        +    where [<Identifier \'foo\' at 0x18ED20C1350>, <Whitespace \' \' at 0x18ED1C4A3E0>, <Comparison \'~~\' at 0x18ED1C4A1A0>, <Whitespace \' \' at 0x18ED1C49D20>, <Single ""\'bar\'"" at 0x18ED1C483A0>] = <Statement \'foo ~~...\' at 0x18ED20C12D0>.tokens\n\nrepos\\sqlparse\\tests\\test_grouping.py:510: AssertionError', 'operator = \'!~~\'\n\n    @pytest.mark.parametrize(\'operator\', (\n        \'=\', \'!=\', \'>\', \'<\', \'<=\', \'>=\', \'~\', \'~~\', \'!~~\',\n        \'LIKE\', \'NOT LIKE\', \'ILIKE\', \'NOT ILIKE\',\n    ))\n    def test_comparison_with_strings(operator):\n        # issue148\n        p = sqlparse.parse(f""foo {operator} \'bar\'"")[0]\n>       assert len(p.tokens) == 1\nE       assert 5 == 1\nE        +  where 5 = len([<Identifier \'foo\' at 0x18ED20C1BD0>, <Whitespace \' \' at 0x18ED1C4BC40>, <Comparison \'!~~\' at 0x18ED1C48D00>, <Whitespace \' \' at 0x18ED1C4B760>, <Single ""\'bar\'"" at 0x18ED1C4A2C0>])\nE        +    where [<Identifier \'foo\' at 0x18ED20C1BD0>, <Whitespace \' \' at 0x18ED1C4BC40>, <Comparison \'!~~\' at 0x18ED1C48D00>, <Whitespace \' \' at 0x18ED1C4B760>, <Single ""\'bar\'"" at 0x18ED1C4A2C0>] = <Statement \'foo !~...\' at 0x18ED20C1CD0>.tokens\n\nrepos\\sqlparse\\tests\\test_grouping.py:510: AssertionError', 'operator = \'LIKE\'\n\n    @pytest.mark.parametrize(\'operator\', (\n        \'=\', \'!=\', \'>\', \'<\', \'<=\', \'>=\', \'~\', \'~~\', \'!~~\',\n        \'LIKE\', \'NOT LIKE\', \'ILIKE\', \'NOT ILIKE\',\n    ))\n    def test_comparison_with_strings(operator):\n        # issue148\n        p = sqlparse.parse(f""foo {operator} \'bar\'"")[0]\n>       assert len(p.tokens) == 1\nE       assert 5 == 1\nE        +  where 5 = len([<Identifier \'foo\' at 0x18ED20C26D0>, <Whitespace \' \' at 0x18ED1C4B400>, <Comparison \'LIKE\' at 0x18ED1C49180>, <Whitespace \' \' at 0x18ED1C48E20>, <Single ""\'bar\'"" at 0x18ED1C4AB00>])\nE        +    where [<Identifier \'foo\' at 0x18ED20C26D0>, <Whitespace \' \' at 0x18ED1C4B400>, <Comparison \'LIKE\' at 0x18ED1C49180>, <Whitespace \' \' at 0x18ED1C48E20>, <Single ""\'bar\'"" at 0x18ED1C4AB00>] = <Statement \'foo LI...\' at 0x18ED20C2750>.tokens\n\nrepos\\sqlparse\\tests\\test_grouping.py:510: AssertionError', 'operator = \'NOT LIKE\'\n\n    @pytest.mark.parametrize(\'operator\', (\n        \'=\', \'!=\', \'>\', \'<\', \'<=\', \'>=\', \'~\', \'~~\', \'!~~\',\n        \'LIKE\', \'NOT LIKE\', \'ILIKE\', \'NOT ILIKE\',\n    ))\n    def test_comparison_with_strings(operator):\n        # issue148\n        p = sqlparse.parse(f""foo {operator} \'bar\'"")[0]\n>       assert len(p.tokens) == 1\nE       assert 5 == 1\nE        +  where 5 = len([<Identifier \'foo\' at 0x18ED20C2E50>, <Whitespace \' \' at 0x18ED1C49900>, <Comparison \'NOT LI...\' at 0x18ED1C4B640>, <Whitespace \' \' at 0x18ED1C48CA0>, <Single ""\'bar\'"" at 0x18ED1C49360>])\nE        +    where [<Identifier \'foo\' at 0x18ED20C2E50>, <Whitespace \' \' at 0x18ED1C49900>, <Comparison \'NOT LI...\' at 0x18ED1C4B640>, <Whitespace \' \' at 0x18ED1C48CA0>, <Single ""\'bar\'"" at 0x18ED1C49360>] = <Statement \'foo NO...\' at 0x18ED20C2DD0>.tokens\n\nrepos\\sqlparse\\tests\\test_grouping.py:510: AssertionError', 'operator = \'ILIKE\'\n\n    @pytest.mark.parametrize(\'operator\', (\n        \'=\', \'!=\', \'>\', \'<\', \'<=\', \'>=\', \'~\', \'~~\', \'!~~\',\n        \'LIKE\', \'NOT LIKE\', \'ILIKE\', \'NOT ILIKE\',\n    ))\n    def test_comparison_with_strings(operator):\n        # issue148\n        p = sqlparse.parse(f""foo {operator} \'bar\'"")[0]\n>       assert len(p.tokens) == 1\nE       assert 5 == 1\nE        +  where 5 = len([<Identifier \'foo\' at 0x18ED1F785D0>, <Whitespace \' \' at 0x18ED1AD56C0>, <Comparison \'ILIKE\' at 0x18ED1AD72E0>, <Whitespace \' \' at 0x18ED1AD7340>, <Single ""\'bar\'"" at 0x18ED1AD7FA0>])\nE        +    where [<Identifier \'foo\' at 0x18ED1F785D0>, <Whitespace \' \' at 0x18ED1AD56C0>, <Comparison \'ILIKE\' at 0x18ED1AD72E0>, <Whitespace \' \' at 0x18ED1AD7340>, <Single ""\'bar\'"" at 0x18ED1AD7FA0>] = <Statement \'foo IL...\' at 0x18ED1F78E50>.tokens\n\nrepos\\sqlparse\\tests\\test_grouping.py:510: AssertionError', 'operator = \'NOT ILIKE\'\n\n    @pytest.mark.parametrize(\'operator\', (\n        \'=\', \'!=\', \'>\', \'<\', \'<=\', \'>=\', \'~\', \'~~\', \'!~~\',\n        \'LIKE\', \'NOT LIKE\', \'ILIKE\', \'NOT ILIKE\',\n    ))\n    def test_comparison_with_strings(operator):\n        # issue148\n        p = sqlparse.parse(f""foo {operator} \'bar\'"")[0]\n>       assert len(p.tokens) == 1\nE       assert 5 == 1\nE        +  where 5 = len([<Identifier \'foo\' at 0x18ED1F79A50>, <Whitespace \' \' at 0x18ED1C48700>, <Comparison \'NOT IL...\' at 0x18ED1C4A260>, <Whitespace \' \' at 0x18ED1C48880>, <Single ""\'bar\'"" at 0x18ED1C49B40>])\nE        +    where [<Identifier \'foo\' at 0x18ED1F79A50>, <Whitespace \' \' at 0x18ED1C48700>, <Comparison \'NOT IL...\' at 0x18ED1C4A260>, <Whitespace \' \' at 0x18ED1C48880>, <Single ""\'bar\'"" at 0x18ED1C49B40>] = <Statement \'foo NO...\' at 0x18ED1F788D0>.tokens\n\nrepos\\sqlparse\\tests\\test_grouping.py:510: AssertionError', 'def test_like_and_ilike_comparison():\n        def validate_where_clause(where_clause, expected_tokens):\n            assert len(where_clause.tokens) == len(expected_tokens)\n            for where_token, expected_token in zip(where_clause, expected_tokens):\n                expected_ttype, expected_value = expected_token\n                if where_token.ttype is not None:\n                    assert where_token.match(expected_ttype, expected_value, regex=True)\n                else:\n                    # Certain tokens, such as comparison tokens, do not define a ttype that can be\n                    # matched against. For these tokens, we ensure that the token instance is of\n                    # the expected type and has a value conforming to specified regular expression\n                    import re\n                    assert (isinstance(where_token, expected_ttype)\n                            and re.match(expected_value, where_token.value))\n    \n        [p1] = sqlparse.parse(""select * from mytable where mytable.mycolumn LIKE \'expr%\' limit 5;"")\n        [p1_where] = [token for token in p1 if isinstance(token, sql.Where)]\n>       validate_where_clause(p1_where, [\n            (T.Keyword, ""where""),\n            (T.Whitespace, None),\n            (sql.Comparison, r""mytable.mycolumn LIKE.*""),\n            (T.Whitespace, None),\n        ])\n\nrepos\\sqlparse\\tests\\test_grouping.py:533: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nwhere_clause = <Where \'where ...\' at 0x18ED1EAE350>\nexpected_tokens = [(Token.Keyword, \'where\'), (Token.Text.Whitespace, None), (<class \'sqlparse.sql.Comparison\'>, \'mytable.mycolumn LIKE.*\'), (Token.Text.Whitespace, None)]\n\n    def validate_where_clause(where_clause, expected_tokens):\n>       assert len(where_clause.tokens) == len(expected_tokens)\nE       AssertionError: assert 9 == 4\nE        +  where 9 = len([<Keyword \'where\' at 0x18ED1C4B100>, <Whitespace \' \' at 0x18ED1C4B700>, <Identifier \'mytabl...\' at 0x18ED202C450>, <Identifier \'mycolu...\' at 0x18ED19F2F50>, <Whitespace \' \' at 0x18ED1C492A0>, <Comparison \'LIKE\' at 0x18ED1C49960>, ...])\nE        +    where [<Keyword \'where\' at 0x18ED1C4B100>, <Whitespace \' \' at 0x18ED1C4B700>, <Identifier \'mytabl...\' at 0x18ED202C450>, <Identifier \'mycolu...\' at 0x18ED19F2F50>, <Whitespace \' \' at 0x18ED1C492A0>, <Comparison \'LIKE\' at 0x18ED1C49960>, ...] = <Where \'where ...\' at 0x18ED1EAE350>.tokens\nE        +  and   4 = len([(Token.Keyword, \'where\'), (Token.Text.Whitespace, None), (<class \'sqlparse.sql.Comparison\'>, \'mytable.mycolumn LIKE.*\'), (Token.Text.Whitespace, None)])\n\nrepos\\sqlparse\\tests\\test_grouping.py:518: AssertionError', ""def test_comparison_with_functions():\n        # issue230\n        p = sqlparse.parse('foo = DATE(bar.baz)')[0]\n>       assert len(p.tokens) == 1\nE       AssertionError: assert 6 == 1\nE        +  where 6 = len([<Identifier 'foo' at 0x18ED20C30D0>, <Whitespace ' ' at 0x18ED1C49F60>, <Comparison '=' at 0x18ED1C4B8E0>, <Whitespace ' ' at 0x18ED1C48220>, <Identifier 'DATE' at 0x18ED20C32D0>, <Parenthesis '(bar.b...' at 0x18ED20C3050>])\nE        +    where [<Identifier 'foo' at 0x18ED20C30D0>, <Whitespace ' ' at 0x18ED1C49F60>, <Comparison '=' at 0x18ED1C4B8E0>, <Whitespace ' ' at 0x18ED1C48220>, <Identifier 'DATE' at 0x18ED20C32D0>, <Parenthesis '(bar.b...' at 0x18ED20C3050>] = <Statement 'foo = ...' at 0x18ED20C39D0>.tokens\n\nrepos\\sqlparse\\tests\\test_grouping.py:554: AssertionError"", 'def test_comparison_with_typed_literal():\n        p = sqlparse.parse(""foo = DATE \'bar.baz\'"")[0]\n>       assert len(p.tokens) == 1\nE       AssertionError: assert 7 == 1\nE        +  where 7 = len([<Identifier \'foo\' at 0x18ED20C26D0>, <Whitespace \' \' at 0x18ED1C49BA0>, <Comparison \'=\' at 0x18ED1C4BEE0>, <Whitespace \' \' at 0x18ED1C48280>, <Builtin \'DATE\' at 0x18ED1C4A380>, <Whitespace \' \' at 0x18ED1C49420>, ...])\nE        +    where [<Identifier \'foo\' at 0x18ED20C26D0>, <Whitespace \' \' at 0x18ED1C49BA0>, <Comparison \'=\' at 0x18ED1C4BEE0>, <Whitespace \' \' at 0x18ED1C48280>, <Builtin \'DATE\' at 0x18ED1C4A380>, <Whitespace \' \' at 0x18ED1C49420>, ...] = <Statement \'foo = ...\' at 0x18ED20C3750>.tokens\n\nrepos\\sqlparse\\tests\\test_grouping.py:577: AssertionError', ""def test_aliased_column_without_as():\n        p = sqlparse.parse('foo bar')[0].tokens\n>       assert len(p) == 1\nE       AssertionError: assert 3 == 1\nE        +  where 3 = len([<Identifier 'foo' at 0x18ED1CF0950>, <Whitespace ' ' at 0x18ED1DE2F80>, <Identifier 'bar' at 0x18ED1CF0B50>])\n\nrepos\\sqlparse\\tests\\test_grouping.py:632: AssertionError"", 'def test_qualified_function():\n        p = sqlparse.parse(\'foo()\')[0].tokens[0]\n>       assert p.get_parent_name() is None\n\nrepos\\sqlparse\\tests\\test_grouping.py:644: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\sql.py:316: in get_parent_name\n    _, prev_ = self.token_prev(dot_idx)\nrepos\\sqlparse\\sqlparse\\sql.py:241: in token_prev\n    return self.token_next(idx, skip_ws, skip_cm, _reverse=True)\nrepos\\sqlparse\\sqlparse\\sql.py:244: in token_next\n    return self._token_matching(idx, skip_ws, skip_cm, _reverse)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Identifier \'foo\' at 0x18ED20C1350>, funcs = (None,), start = True\nend = False, reverse = True\n\n    def _token_matching(self, funcs, start=0, end=None, reverse=False):\n        """"""next token that match functions""""""\n        if start is None:\n            return None\n        if not isinstance(funcs, (list, tuple)):\n            funcs = (funcs,)\n        if reverse:\n>           assert end is None\nE           AssertionError\n\nrepos\\sqlparse\\sqlparse\\sql.py:195: AssertionError', 'def test_aliased_function_without_as():\n        p = sqlparse.parse(\'foo() bar\')[0].tokens[0]\n>       assert p.get_parent_name() is None\n\nrepos\\sqlparse\\tests\\test_grouping.py:654: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\sql.py:316: in get_parent_name\n    _, prev_ = self.token_prev(dot_idx)\nrepos\\sqlparse\\sqlparse\\sql.py:241: in token_prev\n    return self.token_next(idx, skip_ws, skip_cm, _reverse=True)\nrepos\\sqlparse\\sqlparse\\sql.py:244: in token_next\n    return self._token_matching(idx, skip_ws, skip_cm, _reverse)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Identifier \'foo\' at 0x18ED1CF1DD0>, funcs = (None,), start = True\nend = False, reverse = True\n\n    def _token_matching(self, funcs, start=0, end=None, reverse=False):\n        """"""next token that match functions""""""\n        if start is None:\n            return None\n        if not isinstance(funcs, (list, tuple)):\n            funcs = (funcs,)\n        if reverse:\n>           assert end is None\nE           AssertionError\n\nrepos\\sqlparse\\sqlparse\\sql.py:195: AssertionError', ""def test_aliased_literal_without_as():\n        p = sqlparse.parse('1 foo')[0].tokens\n>       assert len(p) == 1\nE       AssertionError: assert 3 == 1\nE        +  where 3 = len([<Integer '1' at 0x18ED1E2C9A0>, <Whitespace ' ' at 0x18ED1E2F6A0>, <Identifier 'foo' at 0x18ED20C0B50>])\n\nrepos\\sqlparse\\tests\\test_grouping.py:666: AssertionError"", 'def test_grouping_create_table():\n        p = sqlparse.parse(""create table db.tbl (a string)"")[0].tokens\n>       assert p[4].value == ""db.tbl""\nE       AssertionError: assert \'db.\' == \'db.tbl\'\nE         \nE         - db.tbl\nE         + db.\n\nrepos\\sqlparse\\tests\\test_grouping.py:679: AssertionError', ""def test_parse_within():\n        s = 'foo(col1, col2)'\n        p = sqlparse.parse(s)[0]\n>       col1 = p.tokens[0].tokens[1].tokens[1].tokens[0]\nE       IndexError: list index out of range\n\nrepos\\sqlparse\\tests\\test_parse.py:39: IndexError"", ""def test_parse_access_symbol():\n        # see issue27\n        t = sqlparse.parse('select a.[foo bar] as foo')[0].tokens\n        assert isinstance(t[-1], sql.Identifier)\n        assert t[-1].get_name() == 'foo'\n>       assert t[-1].get_real_name() == '[foo bar]'\nE       AssertionError: assert 'foo' == '[foo bar]'\nE         \nE         - [foo bar]\nE         + foo\n\nrepos\\sqlparse\\tests\\test_parse.py:91: AssertionError"", ""def test_parse_square_brackets_notation_isnt_too_greedy():\n        # see issue153\n        t = sqlparse.parse('[foo], [bar]')[0].tokens\n>       assert isinstance(t[0], sql.IdentifierList)\nE       AssertionError: assert False\nE        +  where False = isinstance(<Identifier '[foo]' at 0x18ED1CF1AD0>, <class 'sqlparse.sql.IdentifierList'>)\nE        +    where <class 'sqlparse.sql.IdentifierList'> = sql.IdentifierList\n\nrepos\\sqlparse\\tests\\test_parse.py:98: AssertionError"", ""def test_parse_keyword_like_identifier():\n        # see issue47\n        t = sqlparse.parse('foo.key')[0].tokens\n>       assert len(t) == 1\nE       AssertionError: assert 2 == 1\nE        +  where 2 = len([<Identifier 'foo.' at 0x18ED1D66050>, <Identifier 'key' at 0x18ED1D660D0>])\n\nrepos\\sqlparse\\tests\\test_parse.py:113: AssertionError"", ""def test_parse_function_parameter():\n        # see issue94\n>       t = sqlparse.parse('abs(some_col)')[0].tokens[0].get_parameters()\nE       AttributeError: 'Identifier' object has no attribute 'get_parameters'\n\nrepos\\sqlparse\\tests\\test_parse.py:119: AttributeError"", ""def test_parse_function_param_single_literal():\n>       t = sqlparse.parse('foo(5)')[0].tokens[0].get_parameters()\nE       AttributeError: 'Identifier' object has no attribute 'get_parameters'\n\nrepos\\sqlparse\\tests\\test_parse.py:125: AttributeError"", ""def test_parse_nested_function():\n>       t = sqlparse.parse('foo(bar(5))')[0].tokens[0].get_parameters()\nE       AttributeError: 'Identifier' object has no attribute 'get_parameters'\n\nrepos\\sqlparse\\tests\\test_parse.py:131: AttributeError"", 'def test_parse_casted_params():\n>       t = sqlparse.parse(""foo(DATE \'2023-11-14\', TIMESTAMP \'2023-11-15\')"")[0].tokens[0].get_parameters()\nE       AttributeError: \'Identifier\' object has no attribute \'get_parameters\'\n\nrepos\\sqlparse\\tests\\test_parse.py:137: AttributeError', ""def test_parse_div_operator():\n        p = sqlparse.parse('col1 DIV 5 AS div_col1')[0].tokens\n>       assert p[0].tokens[0].tokens[2].ttype is T.Operator\nE       AttributeError: 'Token' object has no attribute 'tokens'\n\nrepos\\sqlparse\\tests\\test_parse.py:143: AttributeError"", 'def test_quoted_identifier():\n        t = sqlparse.parse(\'select x.y as ""z"" from foo\')[0].tokens\n        assert isinstance(t[2], sql.Identifier)\n>       assert t[2].get_name() == \'z\'\nE       AssertionError: assert None == \'z\'\nE        +  where None = get_name()\nE        +    where get_name = <Identifier \'x.\' at 0x18ED1D75C50>.get_name\n\nrepos\\sqlparse\\tests\\test_parse.py:150: AssertionError', ""def test_sqlite_identifiers():\n        # Make sure we still parse sqlite style escapes\n        p = sqlparse.parse('[col1],[col2]')[0].tokens\n>       id_names = [id_.get_name() for id_ in p[0].get_identifiers()]\nE       AttributeError: 'Identifier' object has no attribute 'get_identifiers'\n\nrepos\\sqlparse\\tests\\test_parse.py:246: AttributeError"", ""def test_array_index_function_result():\n        p = sqlparse.parse('somefunc()[1]')[0].tokens\n>       assert len(p) == 1\nE       AssertionError: assert 3 == 1\nE        +  where 3 = len([<Identifier 'somefu...' at 0x18ED1D7C650>, <Parenthesis '()' at 0x18ED1D7C050>, <SquareBrackets '[1]' at 0x18ED1D7C150>])\n\nrepos\\sqlparse\\tests\\test_parse.py:275: AssertionError"", ""def test_schema_qualified_array_index():\n        p = sqlparse.parse('schem.col[1]')[0].tokens\n>       assert len(p) == 1\nE       AssertionError: assert 2 == 1\nE        +  where 2 = len([<Identifier 'schem.' at 0x18ED1D76ED0>, <Identifier 'col[1]' at 0x18ED1D769D0>])\n\nrepos\\sqlparse\\tests\\test_parse.py:281: AssertionError"", ""def test_aliased_array_index():\n        p = sqlparse.parse('col[1] x')[0].tokens\n>       assert len(p) == 1\nE       AssertionError: assert 3 == 1\nE        +  where 3 = len([<Identifier 'col[1]' at 0x18ED1D74E50>, <Whitespace ' ' at 0x18ED1D1E920>, <Identifier 'x' at 0x18ED1D74ED0>])\n\nrepos\\sqlparse\\tests\\test_parse.py:289: AssertionError"", 'def test_pprint():\n        p = sqlparse.parse(\'select a0, b0, c0, d0, e0 from \'\n                           \'(select * from dual) q0 where 1=1 and 2=2\')[0]\n        output = StringIO()\n    \n        p._pprint_tree(f=output)\n        pprint = \'\\n\'.join([\n            ""|- 0 DML \'select\'"",\n            ""|- 1 Whitespace \' \'"",\n            ""|- 2 IdentifierList \'a0, b0...\'"",\n            ""|  |- 0 Identifier \'a0\'"",\n            ""|  |  `- 0 Name \'a0\'"",\n            ""|  |- 1 Punctuation \',\'"",\n            ""|  |- 2 Whitespace \' \'"",\n            ""|  |- 3 Identifier \'b0\'"",\n            ""|  |  `- 0 Name \'b0\'"",\n            ""|  |- 4 Punctuation \',\'"",\n            ""|  |- 5 Whitespace \' \'"",\n            ""|  |- 6 Identifier \'c0\'"",\n            ""|  |  `- 0 Name \'c0\'"",\n            ""|  |- 7 Punctuation \',\'"",\n            ""|  |- 8 Whitespace \' \'"",\n            ""|  |- 9 Identifier \'d0\'"",\n            ""|  |  `- 0 Name \'d0\'"",\n            ""|  |- 10 Punctuation \',\'"",\n            ""|  |- 11 Whitespace \' \'"",\n            ""|  `- 12 Identifier \'e0\'"",\n            ""|     `- 0 Name \'e0\'"",\n            ""|- 3 Whitespace \' \'"",\n            ""|- 4 Keyword \'from\'"",\n            ""|- 5 Whitespace \' \'"",\n            ""|- 6 Identifier \'(selec...\'"",\n            ""|  |- 0 Parenthesis \'(selec...\'"",\n            ""|  |  |- 0 Punctuation \'(\'"",\n            ""|  |  |- 1 DML \'select\'"",\n            ""|  |  |- 2 Whitespace \' \'"",\n            ""|  |  |- 3 Wildcard \'*\'"",\n            ""|  |  |- 4 Whitespace \' \'"",\n            ""|  |  |- 5 Keyword \'from\'"",\n            ""|  |  |- 6 Whitespace \' \'"",\n            ""|  |  |- 7 Identifier \'dual\'"",\n            ""|  |  |  `- 0 Name \'dual\'"",\n            ""|  |  `- 8 Punctuation \')\'"",\n            ""|  |- 1 Whitespace \' \'"",\n            ""|  `- 2 Identifier \'q0\'"",\n            ""|     `- 0 Name \'q0\'"",\n            ""|- 7 Whitespace \' \'"",\n            ""`- 8 Where \'where ...\'"",\n            ""   |- 0 Keyword \'where\'"",\n            ""   |- 1 Whitespace \' \'"",\n            ""   |- 2 Comparison \'1=1\'"",\n            ""   |  |- 0 Integer \'1\'"",\n            ""   |  |- 1 Comparison \'=\'"",\n            ""   |  `- 2 Integer \'1\'"",\n            ""   |- 3 Whitespace \' \'"",\n            ""   |- 4 Keyword \'and\'"",\n            ""   |- 5 Whitespace \' \'"",\n            ""   `- 6 Comparison \'2=2\'"",\n            ""      |- 0 Integer \'2\'"",\n            ""      |- 1 Comparison \'=\'"",\n            ""      `- 2 Integer \'2\'"",\n            """"])\n>       assert output.getvalue() == pprint\nE       assert ""|- 0 DML \'se...Integer \'2\'\\n"" == ""|- 0 DML \'se...Integer \'2\'\\n""\nE         \nE           |- 0 DML \'select\'\nE           |- 1 Whitespace \' \'\nE         - |- 2 IdentifierList \'a0, b0...\'\nE         - |  |- 0 Identifier \'a0\'\nE         ? ---   ^\nE         + |- 2 Identifier \'a0\'...\nE         \nE         ...Full output truncated (115 lines hidden), use \'-vv\' to show\n\nrepos\\sqlparse\\tests\\test_parse.py:401: AssertionError', ""def test_wildcard_multiplication():\n        p = sqlparse.parse('select * from dual')[0]\n        assert p.tokens[2].ttype == T.Wildcard\n    \n        p = sqlparse.parse('select a0.* from dual a0')[0]\n>       assert p.tokens[2][2].ttype == T.Wildcard\n\nrepos\\sqlparse\\tests\\test_parse.py:409: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Identifier 'a0.' at 0x18ED1D7EFD0>, item = 2\n\n    def __getitem__(self, item):\n>       return self.tokens[item]\nE       IndexError: list index out of range\n\nrepos\\sqlparse\\sqlparse\\sql.py:140: IndexError"", 'def test_get_real_name():\n        # issue 369\n        s = ""update a t set t.b=1""\n        stmts = sqlparse.parse(s)\n        assert len(stmts) == 1\n        assert \'a\' == stmts[0].tokens[2].get_real_name()\n>       assert \'t\' == stmts[0].tokens[2].get_alias()\nE       AssertionError: assert \'t\' == None\nE        +  where None = get_alias()\nE        +    where get_alias = <Identifier \'a\' at 0x18ED1FB0ED0>.get_alias\n\nrepos\\sqlparse\\tests\\test_parse.py:466: AssertionError', 'def test_configurable_keywords():\n        sql = """"""select * from foo BACON SPAM EGGS;""""""\n        tokens = sqlparse.parse(sql)[0]\n    \n>       assert list(\n            (t.ttype, t.value)\n            for t in tokens\n            if t.ttype not in sqlparse.tokens.Whitespace\n        ) == [\n            (sqlparse.tokens.Keyword.DML, ""select""),\n            (sqlparse.tokens.Wildcard, ""*""),\n            (sqlparse.tokens.Keyword, ""from""),\n            (None, ""foo BACON""),\n            (None, ""SPAM EGGS""),\n            (sqlparse.tokens.Punctuation, "";""),\n        ]\nE       AssertionError: assert [(Token.Keywo... \'SPAM\'), ...] == [(Token.Keywo...tuation, \';\')]\nE         \nE         At index 3 diff: (None, \'foo\') != (None, \'foo BACON\')\nE         Left contains 2 more items, first extra item: (None, \'EGGS\')\nE         \nE         Full diff:\nE           [\nE               (...\nE         \nE         ...Full output truncated (36 lines hidden), use \'-vv\' to show\n\nrepos\\sqlparse\\tests\\test_parse.py:512: AssertionError', 'def test_issue35():\n        # missing space before LIMIT. Updated for #321\n>       sql = sqlparse.format(""select * from foo where bar = 1 limit 1"",\n                              reindent=True)\n\nrepos\\sqlparse\\tests\\test_regressions.py:48: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return \'\'.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:44: in run\n    filter_.process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:240: in process\n    self._process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:102: in _process\n    func(tlist)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:233: in _process_default\n    self._split_statements(tlist) if stmts else None\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:89: in _split_statements\n    pidx, prev_ = tlist.token_prev(tidx, skip_ws=False)\nrepos\\sqlparse\\sqlparse\\sql.py:241: in token_prev\n    return self.token_next(idx, skip_ws, skip_cm, _reverse=True)\nrepos\\sqlparse\\sqlparse\\sql.py:244: in token_next\n    return self._token_matching(idx, skip_ws, skip_cm, _reverse)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Statement \'select...\' at 0x18ED1D810D0>, funcs = (0,), start = False\nend = False, reverse = True\n\n    def _token_matching(self, funcs, start=0, end=None, reverse=False):\n        """"""next token that match functions""""""\n        if start is None:\n            return None\n        if not isinstance(funcs, (list, tuple)):\n            funcs = (funcs,)\n        if reverse:\n>           assert end is None\nE           AssertionError\n\nrepos\\sqlparse\\sqlparse\\sql.py:195: AssertionError', 'def test_issue38():\n>       sql = sqlparse.format(""SELECT foo; -- comment"", strip_comments=True)\n\nrepos\\sqlparse\\tests\\test_regressions.py:58: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return \'\'.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:44: in run\n    filter_.process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\others.py:78: in process\n    StripCommentsFilter._process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\others.py:54: in _process\n    pidx, prev_ = tlist.token_prev(tidx, skip_ws=False)\nrepos\\sqlparse\\sqlparse\\sql.py:241: in token_prev\n    return self.token_next(idx, skip_ws, skip_cm, _reverse=True)\nrepos\\sqlparse\\sqlparse\\sql.py:244: in token_next\n    return self._token_matching(idx, skip_ws, skip_cm, _reverse)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Statement \'SELECT...\' at 0x18ED2038650>, funcs = (5,), start = False\nend = False, reverse = True\n\n    def _token_matching(self, funcs, start=0, end=None, reverse=False):\n        """"""next token that match functions""""""\n        if start is None:\n            return None\n        if not isinstance(funcs, (list, tuple)):\n            funcs = (funcs,)\n        if reverse:\n>           assert end is None\nE           AssertionError\n\nrepos\\sqlparse\\sqlparse\\sql.py:195: AssertionError', ""def test_issue39():\n        p = sqlparse.parse('select user.id from user')[0]\n>       assert len(p.tokens) == 7\nE       AssertionError: assert 8 == 7\nE        +  where 8 = len([<DML 'select' at 0x18ED1E2E680>, <Whitespace ' ' at 0x18ED1E2F760>, <Identifier 'user.' at 0x18ED1D5FF50>, <Identifier 'id' at 0x18ED1D5E050>, <Whitespace ' ' at 0x18ED1E2EBC0>, <Keyword 'from' at 0x18ED1E2F460>, ...])\nE        +    where [<DML 'select' at 0x18ED1E2E680>, <Whitespace ' ' at 0x18ED1E2F760>, <Identifier 'user.' at 0x18ED1D5FF50>, <Identifier 'id' at 0x18ED1D5E050>, <Whitespace ' ' at 0x18ED1E2EBC0>, <Keyword 'from' at 0x18ED1E2F460>, ...] = <Statement 'select...' at 0x18ED1A4B3D0>.tokens\n\nrepos\\sqlparse\\tests\\test_regressions.py:66: AssertionError"", ""def test_issue40():\n        # make sure identifier lists in subselects are grouped\n        p = sqlparse.parse('SELECT id, name FROM '\n                           '(SELECT id, name FROM bar) as foo')[0]\n>       assert len(p.tokens) == 7\nE       AssertionError: assert 14 == 7\nE        +  where 14 = len([<DML 'SELECT' at 0x18ED1E2FF40>, <Whitespace ' ' at 0x18ED1E2EDA0>, <Identifier 'id' at 0x18ED1D81E50>, <Punctuation ',' at 0x18ED1E2EFE0>, <Whitespace ' ' at 0x18ED1E2CAC0>, <Identifier 'name' at 0x18ED1D80450>, ...])\nE        +    where [<DML 'SELECT' at 0x18ED1E2FF40>, <Whitespace ' ' at 0x18ED1E2EDA0>, <Identifier 'id' at 0x18ED1D81E50>, <Punctuation ',' at 0x18ED1E2EFE0>, <Whitespace ' ' at 0x18ED1E2CAC0>, <Identifier 'name' at 0x18ED1D80450>, ...] = <Statement 'SELECT...' at 0x18ED1D80C50>.tokens\n\nrepos\\sqlparse\\tests\\test_regressions.py:79: AssertionError"", 's = \'select x.y::text as z from foo\', func_name = \'get_name\', result = \'z\'\n\n    @pytest.mark.parametrize(\'s\', [\'select x.y::text as z from foo\',\n                                   \'select x.y::text as ""z"" from foo\',\n                                   \'select x.""y""::text as z from foo\',\n                                   \'select x.""y""::text as ""z"" from foo\',\n                                   \'select ""x"".y::text as z from foo\',\n                                   \'select ""x"".y::text as ""z"" from foo\',\n                                   \'select ""x"".""y""::text as z from foo\',\n                                   \'select ""x"".""y""::text as ""z"" from foo\'])\n    @pytest.mark.parametrize(\'func_name, result\', [(\'get_name\', \'z\'),\n                                                   (\'get_real_name\', \'y\'),\n                                                   (\'get_parent_name\', \'x\'),\n                                                   (\'get_alias\', \'z\'),\n                                                   (\'get_typecast\', \'text\')])\n    def test_issue78(s, func_name, result):\n        # the bug author provided this nice examples, let\'s use them!\n        p = sqlparse.parse(s)[0]\n        i = p.tokens[2]\n        assert isinstance(i, sql.Identifier)\n    \n        func = getattr(i, func_name)\n>       assert func() == result\nE       AssertionError: assert None == \'z\'\nE        +  where None = get_name()\n\nrepos\\sqlparse\\tests\\test_regressions.py:125: AssertionError', 's = \'select x.y::text as ""z"" from foo\', func_name = \'get_name\', result = \'z\'\n\n    @pytest.mark.parametrize(\'s\', [\'select x.y::text as z from foo\',\n                                   \'select x.y::text as ""z"" from foo\',\n                                   \'select x.""y""::text as z from foo\',\n                                   \'select x.""y""::text as ""z"" from foo\',\n                                   \'select ""x"".y::text as z from foo\',\n                                   \'select ""x"".y::text as ""z"" from foo\',\n                                   \'select ""x"".""y""::text as z from foo\',\n                                   \'select ""x"".""y""::text as ""z"" from foo\'])\n    @pytest.mark.parametrize(\'func_name, result\', [(\'get_name\', \'z\'),\n                                                   (\'get_real_name\', \'y\'),\n                                                   (\'get_parent_name\', \'x\'),\n                                                   (\'get_alias\', \'z\'),\n                                                   (\'get_typecast\', \'text\')])\n    def test_issue78(s, func_name, result):\n        # the bug author provided this nice examples, let\'s use them!\n        p = sqlparse.parse(s)[0]\n        i = p.tokens[2]\n        assert isinstance(i, sql.Identifier)\n    \n        func = getattr(i, func_name)\n>       assert func() == result\nE       AssertionError: assert None == \'z\'\nE        +  where None = get_name()\n\nrepos\\sqlparse\\tests\\test_regressions.py:125: AssertionError', 's = \'select x.""y""::text as z from foo\', func_name = \'get_name\', result = \'z\'\n\n    @pytest.mark.parametrize(\'s\', [\'select x.y::text as z from foo\',\n                                   \'select x.y::text as ""z"" from foo\',\n                                   \'select x.""y""::text as z from foo\',\n                                   \'select x.""y""::text as ""z"" from foo\',\n                                   \'select ""x"".y::text as z from foo\',\n                                   \'select ""x"".y::text as ""z"" from foo\',\n                                   \'select ""x"".""y""::text as z from foo\',\n                                   \'select ""x"".""y""::text as ""z"" from foo\'])\n    @pytest.mark.parametrize(\'func_name, result\', [(\'get_name\', \'z\'),\n                                                   (\'get_real_name\', \'y\'),\n                                                   (\'get_parent_name\', \'x\'),\n                                                   (\'get_alias\', \'z\'),\n                                                   (\'get_typecast\', \'text\')])\n    def test_issue78(s, func_name, result):\n        # the bug author provided this nice examples, let\'s use them!\n        p = sqlparse.parse(s)[0]\n        i = p.tokens[2]\n        assert isinstance(i, sql.Identifier)\n    \n        func = getattr(i, func_name)\n>       assert func() == result\nE       AssertionError: assert None == \'z\'\nE        +  where None = get_name()\n\nrepos\\sqlparse\\tests\\test_regressions.py:125: AssertionError', 's = \'select x.""y""::text as ""z"" from foo\', func_name = \'get_name\', result = \'z\'\n\n    @pytest.mark.parametrize(\'s\', [\'select x.y::text as z from foo\',\n                                   \'select x.y::text as ""z"" from foo\',\n                                   \'select x.""y""::text as z from foo\',\n                                   \'select x.""y""::text as ""z"" from foo\',\n                                   \'select ""x"".y::text as z from foo\',\n                                   \'select ""x"".y::text as ""z"" from foo\',\n                                   \'select ""x"".""y""::text as z from foo\',\n                                   \'select ""x"".""y""::text as ""z"" from foo\'])\n    @pytest.mark.parametrize(\'func_name, result\', [(\'get_name\', \'z\'),\n                                                   (\'get_real_name\', \'y\'),\n                                                   (\'get_parent_name\', \'x\'),\n                                                   (\'get_alias\', \'z\'),\n                                                   (\'get_typecast\', \'text\')])\n    def test_issue78(s, func_name, result):\n        # the bug author provided this nice examples, let\'s use them!\n        p = sqlparse.parse(s)[0]\n        i = p.tokens[2]\n        assert isinstance(i, sql.Identifier)\n    \n        func = getattr(i, func_name)\n>       assert func() == result\nE       AssertionError: assert None == \'z\'\nE        +  where None = get_name()\n\nrepos\\sqlparse\\tests\\test_regressions.py:125: AssertionError', 's = \'select ""x"".y::text as z from foo\', func_name = \'get_name\', result = \'z\'\n\n    @pytest.mark.parametrize(\'s\', [\'select x.y::text as z from foo\',\n                                   \'select x.y::text as ""z"" from foo\',\n                                   \'select x.""y""::text as z from foo\',\n                                   \'select x.""y""::text as ""z"" from foo\',\n                                   \'select ""x"".y::text as z from foo\',\n                                   \'select ""x"".y::text as ""z"" from foo\',\n                                   \'select ""x"".""y""::text as z from foo\',\n                                   \'select ""x"".""y""::text as ""z"" from foo\'])\n    @pytest.mark.parametrize(\'func_name, result\', [(\'get_name\', \'z\'),\n                                                   (\'get_real_name\', \'y\'),\n                                                   (\'get_parent_name\', \'x\'),\n                                                   (\'get_alias\', \'z\'),\n                                                   (\'get_typecast\', \'text\')])\n    def test_issue78(s, func_name, result):\n        # the bug author provided this nice examples, let\'s use them!\n        p = sqlparse.parse(s)[0]\n        i = p.tokens[2]\n        assert isinstance(i, sql.Identifier)\n    \n        func = getattr(i, func_name)\n>       assert func() == result\nE       AssertionError: assert None == \'z\'\nE        +  where None = get_name()\n\nrepos\\sqlparse\\tests\\test_regressions.py:125: AssertionError', 's = \'select ""x"".y::text as ""z"" from foo\', func_name = \'get_name\', result = \'z\'\n\n    @pytest.mark.parametrize(\'s\', [\'select x.y::text as z from foo\',\n                                   \'select x.y::text as ""z"" from foo\',\n                                   \'select x.""y""::text as z from foo\',\n                                   \'select x.""y""::text as ""z"" from foo\',\n                                   \'select ""x"".y::text as z from foo\',\n                                   \'select ""x"".y::text as ""z"" from foo\',\n                                   \'select ""x"".""y""::text as z from foo\',\n                                   \'select ""x"".""y""::text as ""z"" from foo\'])\n    @pytest.mark.parametrize(\'func_name, result\', [(\'get_name\', \'z\'),\n                                                   (\'get_real_name\', \'y\'),\n                                                   (\'get_parent_name\', \'x\'),\n                                                   (\'get_alias\', \'z\'),\n                                                   (\'get_typecast\', \'text\')])\n    def test_issue78(s, func_name, result):\n        # the bug author provided this nice examples, let\'s use them!\n        p = sqlparse.parse(s)[0]\n        i = p.tokens[2]\n        assert isinstance(i, sql.Identifier)\n    \n        func = getattr(i, func_name)\n>       assert func() == result\nE       AssertionError: assert None == \'z\'\nE        +  where None = get_name()\n\nrepos\\sqlparse\\tests\\test_regressions.py:125: AssertionError', 's = \'select ""x"".""y""::text as z from foo\', func_name = \'get_name\', result = \'z\'\n\n    @pytest.mark.parametrize(\'s\', [\'select x.y::text as z from foo\',\n                                   \'select x.y::text as ""z"" from foo\',\n                                   \'select x.""y""::text as z from foo\',\n                                   \'select x.""y""::text as ""z"" from foo\',\n                                   \'select ""x"".y::text as z from foo\',\n                                   \'select ""x"".y::text as ""z"" from foo\',\n                                   \'select ""x"".""y""::text as z from foo\',\n                                   \'select ""x"".""y""::text as ""z"" from foo\'])\n    @pytest.mark.parametrize(\'func_name, result\', [(\'get_name\', \'z\'),\n                                                   (\'get_real_name\', \'y\'),\n                                                   (\'get_parent_name\', \'x\'),\n                                                   (\'get_alias\', \'z\'),\n                                                   (\'get_typecast\', \'text\')])\n    def test_issue78(s, func_name, result):\n        # the bug author provided this nice examples, let\'s use them!\n        p = sqlparse.parse(s)[0]\n        i = p.tokens[2]\n        assert isinstance(i, sql.Identifier)\n    \n        func = getattr(i, func_name)\n>       assert func() == result\nE       AssertionError: assert None == \'z\'\nE        +  where None = get_name()\n\nrepos\\sqlparse\\tests\\test_regressions.py:125: AssertionError', 's = \'select ""x"".""y""::text as ""z"" from foo\', func_name = \'get_name\', result = \'z\'\n\n    @pytest.mark.parametrize(\'s\', [\'select x.y::text as z from foo\',\n                                   \'select x.y::text as ""z"" from foo\',\n                                   \'select x.""y""::text as z from foo\',\n                                   \'select x.""y""::text as ""z"" from foo\',\n                                   \'select ""x"".y::text as z from foo\',\n                                   \'select ""x"".y::text as ""z"" from foo\',\n                                   \'select ""x"".""y""::text as z from foo\',\n                                   \'select ""x"".""y""::text as ""z"" from foo\'])\n    @pytest.mark.parametrize(\'func_name, result\', [(\'get_name\', \'z\'),\n                                                   (\'get_real_name\', \'y\'),\n                                                   (\'get_parent_name\', \'x\'),\n                                                   (\'get_alias\', \'z\'),\n                                                   (\'get_typecast\', \'text\')])\n    def test_issue78(s, func_name, result):\n        # the bug author provided this nice examples, let\'s use them!\n        p = sqlparse.parse(s)[0]\n        i = p.tokens[2]\n        assert isinstance(i, sql.Identifier)\n    \n        func = getattr(i, func_name)\n>       assert func() == result\nE       AssertionError: assert None == \'z\'\nE        +  where None = get_name()\n\nrepos\\sqlparse\\tests\\test_regressions.py:125: AssertionError', 's = \'select x.y::text as z from foo\', func_name = \'get_real_name\', result = \'y\'\n\n    @pytest.mark.parametrize(\'s\', [\'select x.y::text as z from foo\',\n                                   \'select x.y::text as ""z"" from foo\',\n                                   \'select x.""y""::text as z from foo\',\n                                   \'select x.""y""::text as ""z"" from foo\',\n                                   \'select ""x"".y::text as z from foo\',\n                                   \'select ""x"".y::text as ""z"" from foo\',\n                                   \'select ""x"".""y""::text as z from foo\',\n                                   \'select ""x"".""y""::text as ""z"" from foo\'])\n    @pytest.mark.parametrize(\'func_name, result\', [(\'get_name\', \'z\'),\n                                                   (\'get_real_name\', \'y\'),\n                                                   (\'get_parent_name\', \'x\'),\n                                                   (\'get_alias\', \'z\'),\n                                                   (\'get_typecast\', \'text\')])\n    def test_issue78(s, func_name, result):\n        # the bug author provided this nice examples, let\'s use them!\n        p = sqlparse.parse(s)[0]\n        i = p.tokens[2]\n        assert isinstance(i, sql.Identifier)\n    \n        func = getattr(i, func_name)\n>       assert func() == result\nE       AssertionError: assert None == \'y\'\nE        +  where None = get_real_name()\n\nrepos\\sqlparse\\tests\\test_regressions.py:125: AssertionError', 's = \'select x.y::text as ""z"" from foo\', func_name = \'get_real_name\'\nresult = \'y\'\n\n    @pytest.mark.parametrize(\'s\', [\'select x.y::text as z from foo\',\n                                   \'select x.y::text as ""z"" from foo\',\n                                   \'select x.""y""::text as z from foo\',\n                                   \'select x.""y""::text as ""z"" from foo\',\n                                   \'select ""x"".y::text as z from foo\',\n                                   \'select ""x"".y::text as ""z"" from foo\',\n                                   \'select ""x"".""y""::text as z from foo\',\n                                   \'select ""x"".""y""::text as ""z"" from foo\'])\n    @pytest.mark.parametrize(\'func_name, result\', [(\'get_name\', \'z\'),\n                                                   (\'get_real_name\', \'y\'),\n                                                   (\'get_parent_name\', \'x\'),\n                                                   (\'get_alias\', \'z\'),\n                                                   (\'get_typecast\', \'text\')])\n    def test_issue78(s, func_name, result):\n        # the bug author provided this nice examples, let\'s use them!\n        p = sqlparse.parse(s)[0]\n        i = p.tokens[2]\n        assert isinstance(i, sql.Identifier)\n    \n        func = getattr(i, func_name)\n>       assert func() == result\nE       AssertionError: assert None == \'y\'\nE        +  where None = get_real_name()\n\nrepos\\sqlparse\\tests\\test_regressions.py:125: AssertionError', 's = \'select x.""y""::text as z from foo\', func_name = \'get_real_name\'\nresult = \'y\'\n\n    @pytest.mark.parametrize(\'s\', [\'select x.y::text as z from foo\',\n                                   \'select x.y::text as ""z"" from foo\',\n                                   \'select x.""y""::text as z from foo\',\n                                   \'select x.""y""::text as ""z"" from foo\',\n                                   \'select ""x"".y::text as z from foo\',\n                                   \'select ""x"".y::text as ""z"" from foo\',\n                                   \'select ""x"".""y""::text as z from foo\',\n                                   \'select ""x"".""y""::text as ""z"" from foo\'])\n    @pytest.mark.parametrize(\'func_name, result\', [(\'get_name\', \'z\'),\n                                                   (\'get_real_name\', \'y\'),\n                                                   (\'get_parent_name\', \'x\'),\n                                                   (\'get_alias\', \'z\'),\n                                                   (\'get_typecast\', \'text\')])\n    def test_issue78(s, func_name, result):\n        # the bug author provided this nice examples, let\'s use them!\n        p = sqlparse.parse(s)[0]\n        i = p.tokens[2]\n        assert isinstance(i, sql.Identifier)\n    \n        func = getattr(i, func_name)\n>       assert func() == result\nE       AssertionError: assert None == \'y\'\nE        +  where None = get_real_name()\n\nrepos\\sqlparse\\tests\\test_regressions.py:125: AssertionError', 's = \'select x.""y""::text as ""z"" from foo\', func_name = \'get_real_name\'\nresult = \'y\'\n\n    @pytest.mark.parametrize(\'s\', [\'select x.y::text as z from foo\',\n                                   \'select x.y::text as ""z"" from foo\',\n                                   \'select x.""y""::text as z from foo\',\n                                   \'select x.""y""::text as ""z"" from foo\',\n                                   \'select ""x"".y::text as z from foo\',\n                                   \'select ""x"".y::text as ""z"" from foo\',\n                                   \'select ""x"".""y""::text as z from foo\',\n                                   \'select ""x"".""y""::text as ""z"" from foo\'])\n    @pytest.mark.parametrize(\'func_name, result\', [(\'get_name\', \'z\'),\n                                                   (\'get_real_name\', \'y\'),\n                                                   (\'get_parent_name\', \'x\'),\n                                                   (\'get_alias\', \'z\'),\n                                                   (\'get_typecast\', \'text\')])\n    def test_issue78(s, func_name, result):\n        # the bug author provided this nice examples, let\'s use them!\n        p = sqlparse.parse(s)[0]\n        i = p.tokens[2]\n        assert isinstance(i, sql.Identifier)\n    \n        func = getattr(i, func_name)\n>       assert func() == result\nE       AssertionError: assert None == \'y\'\nE        +  where None = get_real_name()\n\nrepos\\sqlparse\\tests\\test_regressions.py:125: AssertionError', 's = \'select ""x"".y::text as z from foo\', func_name = \'get_real_name\'\nresult = \'y\'\n\n    @pytest.mark.parametrize(\'s\', [\'select x.y::text as z from foo\',\n                                   \'select x.y::text as ""z"" from foo\',\n                                   \'select x.""y""::text as z from foo\',\n                                   \'select x.""y""::text as ""z"" from foo\',\n                                   \'select ""x"".y::text as z from foo\',\n                                   \'select ""x"".y::text as ""z"" from foo\',\n                                   \'select ""x"".""y""::text as z from foo\',\n                                   \'select ""x"".""y""::text as ""z"" from foo\'])\n    @pytest.mark.parametrize(\'func_name, result\', [(\'get_name\', \'z\'),\n                                                   (\'get_real_name\', \'y\'),\n                                                   (\'get_parent_name\', \'x\'),\n                                                   (\'get_alias\', \'z\'),\n                                                   (\'get_typecast\', \'text\')])\n    def test_issue78(s, func_name, result):\n        # the bug author provided this nice examples, let\'s use them!\n        p = sqlparse.parse(s)[0]\n        i = p.tokens[2]\n        assert isinstance(i, sql.Identifier)\n    \n        func = getattr(i, func_name)\n>       assert func() == result\nE       AssertionError: assert None == \'y\'\nE        +  where None = get_real_name()\n\nrepos\\sqlparse\\tests\\test_regressions.py:125: AssertionError', 's = \'select ""x"".y::text as ""z"" from foo\', func_name = \'get_real_name\'\nresult = \'y\'\n\n    @pytest.mark.parametrize(\'s\', [\'select x.y::text as z from foo\',\n                                   \'select x.y::text as ""z"" from foo\',\n                                   \'select x.""y""::text as z from foo\',\n                                   \'select x.""y""::text as ""z"" from foo\',\n                                   \'select ""x"".y::text as z from foo\',\n                                   \'select ""x"".y::text as ""z"" from foo\',\n                                   \'select ""x"".""y""::text as z from foo\',\n                                   \'select ""x"".""y""::text as ""z"" from foo\'])\n    @pytest.mark.parametrize(\'func_name, result\', [(\'get_name\', \'z\'),\n                                                   (\'get_real_name\', \'y\'),\n                                                   (\'get_parent_name\', \'x\'),\n                                                   (\'get_alias\', \'z\'),\n                                                   (\'get_typecast\', \'text\')])\n    def test_issue78(s, func_name, result):\n        # the bug author provided this nice examples, let\'s use them!\n        p = sqlparse.parse(s)[0]\n        i = p.tokens[2]\n        assert isinstance(i, sql.Identifier)\n    \n        func = getattr(i, func_name)\n>       assert func() == result\nE       AssertionError: assert None == \'y\'\nE        +  where None = get_real_name()\n\nrepos\\sqlparse\\tests\\test_regressions.py:125: AssertionError', 's = \'select ""x"".""y""::text as z from foo\', func_name = \'get_real_name\'\nresult = \'y\'\n\n    @pytest.mark.parametrize(\'s\', [\'select x.y::text as z from foo\',\n                                   \'select x.y::text as ""z"" from foo\',\n                                   \'select x.""y""::text as z from foo\',\n                                   \'select x.""y""::text as ""z"" from foo\',\n                                   \'select ""x"".y::text as z from foo\',\n                                   \'select ""x"".y::text as ""z"" from foo\',\n                                   \'select ""x"".""y""::text as z from foo\',\n                                   \'select ""x"".""y""::text as ""z"" from foo\'])\n    @pytest.mark.parametrize(\'func_name, result\', [(\'get_name\', \'z\'),\n                                                   (\'get_real_name\', \'y\'),\n                                                   (\'get_parent_name\', \'x\'),\n                                                   (\'get_alias\', \'z\'),\n                                                   (\'get_typecast\', \'text\')])\n    def test_issue78(s, func_name, result):\n        # the bug author provided this nice examples, let\'s use them!\n        p = sqlparse.parse(s)[0]\n        i = p.tokens[2]\n        assert isinstance(i, sql.Identifier)\n    \n        func = getattr(i, func_name)\n>       assert func() == result\nE       AssertionError: assert None == \'y\'\nE        +  where None = get_real_name()\n\nrepos\\sqlparse\\tests\\test_regressions.py:125: AssertionError', 's = \'select ""x"".""y""::text as ""z"" from foo\', func_name = \'get_real_name\'\nresult = \'y\'\n\n    @pytest.mark.parametrize(\'s\', [\'select x.y::text as z from foo\',\n                                   \'select x.y::text as ""z"" from foo\',\n                                   \'select x.""y""::text as z from foo\',\n                                   \'select x.""y""::text as ""z"" from foo\',\n                                   \'select ""x"".y::text as z from foo\',\n                                   \'select ""x"".y::text as ""z"" from foo\',\n                                   \'select ""x"".""y""::text as z from foo\',\n                                   \'select ""x"".""y""::text as ""z"" from foo\'])\n    @pytest.mark.parametrize(\'func_name, result\', [(\'get_name\', \'z\'),\n                                                   (\'get_real_name\', \'y\'),\n                                                   (\'get_parent_name\', \'x\'),\n                                                   (\'get_alias\', \'z\'),\n                                                   (\'get_typecast\', \'text\')])\n    def test_issue78(s, func_name, result):\n        # the bug author provided this nice examples, let\'s use them!\n        p = sqlparse.parse(s)[0]\n        i = p.tokens[2]\n        assert isinstance(i, sql.Identifier)\n    \n        func = getattr(i, func_name)\n>       assert func() == result\nE       AssertionError: assert None == \'y\'\nE        +  where None = get_real_name()\n\nrepos\\sqlparse\\tests\\test_regressions.py:125: AssertionError', 's = \'select x.y::text as z from foo\', func_name = \'get_parent_name\'\nresult = \'x\'\n\n    @pytest.mark.parametrize(\'s\', [\'select x.y::text as z from foo\',\n                                   \'select x.y::text as ""z"" from foo\',\n                                   \'select x.""y""::text as z from foo\',\n                                   \'select x.""y""::text as ""z"" from foo\',\n                                   \'select ""x"".y::text as z from foo\',\n                                   \'select ""x"".y::text as ""z"" from foo\',\n                                   \'select ""x"".""y""::text as z from foo\',\n                                   \'select ""x"".""y""::text as ""z"" from foo\'])\n    @pytest.mark.parametrize(\'func_name, result\', [(\'get_name\', \'z\'),\n                                                   (\'get_real_name\', \'y\'),\n                                                   (\'get_parent_name\', \'x\'),\n                                                   (\'get_alias\', \'z\'),\n                                                   (\'get_typecast\', \'text\')])\n    def test_issue78(s, func_name, result):\n        # the bug author provided this nice examples, let\'s use them!\n        p = sqlparse.parse(s)[0]\n        i = p.tokens[2]\n        assert isinstance(i, sql.Identifier)\n    \n        func = getattr(i, func_name)\n>       assert func() == result\n\nrepos\\sqlparse\\tests\\test_regressions.py:125: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\sql.py:316: in get_parent_name\n    _, prev_ = self.token_prev(dot_idx)\nrepos\\sqlparse\\sqlparse\\sql.py:241: in token_prev\n    return self.token_next(idx, skip_ws, skip_cm, _reverse=True)\nrepos\\sqlparse\\sqlparse\\sql.py:244: in token_next\n    return self._token_matching(idx, skip_ws, skip_cm, _reverse)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Identifier \'x.\' at 0x18ED1FA8C50>, funcs = (1,), start = True\nend = False, reverse = True\n\n    def _token_matching(self, funcs, start=0, end=None, reverse=False):\n        """"""next token that match functions""""""\n        if start is None:\n            return None\n        if not isinstance(funcs, (list, tuple)):\n            funcs = (funcs,)\n        if reverse:\n>           assert end is None\nE           AssertionError\n\nrepos\\sqlparse\\sqlparse\\sql.py:195: AssertionError', 's = \'select x.y::text as ""z"" from foo\', func_name = \'get_parent_name\'\nresult = \'x\'\n\n    @pytest.mark.parametrize(\'s\', [\'select x.y::text as z from foo\',\n                                   \'select x.y::text as ""z"" from foo\',\n                                   \'select x.""y""::text as z from foo\',\n                                   \'select x.""y""::text as ""z"" from foo\',\n                                   \'select ""x"".y::text as z from foo\',\n                                   \'select ""x"".y::text as ""z"" from foo\',\n                                   \'select ""x"".""y""::text as z from foo\',\n                                   \'select ""x"".""y""::text as ""z"" from foo\'])\n    @pytest.mark.parametrize(\'func_name, result\', [(\'get_name\', \'z\'),\n                                                   (\'get_real_name\', \'y\'),\n                                                   (\'get_parent_name\', \'x\'),\n                                                   (\'get_alias\', \'z\'),\n                                                   (\'get_typecast\', \'text\')])\n    def test_issue78(s, func_name, result):\n        # the bug author provided this nice examples, let\'s use them!\n        p = sqlparse.parse(s)[0]\n        i = p.tokens[2]\n        assert isinstance(i, sql.Identifier)\n    \n        func = getattr(i, func_name)\n>       assert func() == result\n\nrepos\\sqlparse\\tests\\test_regressions.py:125: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\sql.py:316: in get_parent_name\n    _, prev_ = self.token_prev(dot_idx)\nrepos\\sqlparse\\sqlparse\\sql.py:241: in token_prev\n    return self.token_next(idx, skip_ws, skip_cm, _reverse=True)\nrepos\\sqlparse\\sqlparse\\sql.py:244: in token_next\n    return self._token_matching(idx, skip_ws, skip_cm, _reverse)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Identifier \'x.\' at 0x18ED1FB3AD0>, funcs = (1,), start = True\nend = False, reverse = True\n\n    def _token_matching(self, funcs, start=0, end=None, reverse=False):\n        """"""next token that match functions""""""\n        if start is None:\n            return None\n        if not isinstance(funcs, (list, tuple)):\n            funcs = (funcs,)\n        if reverse:\n>           assert end is None\nE           AssertionError\n\nrepos\\sqlparse\\sqlparse\\sql.py:195: AssertionError', 's = \'select x.""y""::text as z from foo\', func_name = \'get_parent_name\'\nresult = \'x\'\n\n    @pytest.mark.parametrize(\'s\', [\'select x.y::text as z from foo\',\n                                   \'select x.y::text as ""z"" from foo\',\n                                   \'select x.""y""::text as z from foo\',\n                                   \'select x.""y""::text as ""z"" from foo\',\n                                   \'select ""x"".y::text as z from foo\',\n                                   \'select ""x"".y::text as ""z"" from foo\',\n                                   \'select ""x"".""y""::text as z from foo\',\n                                   \'select ""x"".""y""::text as ""z"" from foo\'])\n    @pytest.mark.parametrize(\'func_name, result\', [(\'get_name\', \'z\'),\n                                                   (\'get_real_name\', \'y\'),\n                                                   (\'get_parent_name\', \'x\'),\n                                                   (\'get_alias\', \'z\'),\n                                                   (\'get_typecast\', \'text\')])\n    def test_issue78(s, func_name, result):\n        # the bug author provided this nice examples, let\'s use them!\n        p = sqlparse.parse(s)[0]\n        i = p.tokens[2]\n        assert isinstance(i, sql.Identifier)\n    \n        func = getattr(i, func_name)\n>       assert func() == result\n\nrepos\\sqlparse\\tests\\test_regressions.py:125: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\sql.py:316: in get_parent_name\n    _, prev_ = self.token_prev(dot_idx)\nrepos\\sqlparse\\sqlparse\\sql.py:241: in token_prev\n    return self.token_next(idx, skip_ws, skip_cm, _reverse=True)\nrepos\\sqlparse\\sqlparse\\sql.py:244: in token_next\n    return self._token_matching(idx, skip_ws, skip_cm, _reverse)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Identifier \'x.\' at 0x18ED1D82750>, funcs = (1,), start = True\nend = False, reverse = True\n\n    def _token_matching(self, funcs, start=0, end=None, reverse=False):\n        """"""next token that match functions""""""\n        if start is None:\n            return None\n        if not isinstance(funcs, (list, tuple)):\n            funcs = (funcs,)\n        if reverse:\n>           assert end is None\nE           AssertionError\n\nrepos\\sqlparse\\sqlparse\\sql.py:195: AssertionError', 's = \'select x.""y""::text as ""z"" from foo\', func_name = \'get_parent_name\'\nresult = \'x\'\n\n    @pytest.mark.parametrize(\'s\', [\'select x.y::text as z from foo\',\n                                   \'select x.y::text as ""z"" from foo\',\n                                   \'select x.""y""::text as z from foo\',\n                                   \'select x.""y""::text as ""z"" from foo\',\n                                   \'select ""x"".y::text as z from foo\',\n                                   \'select ""x"".y::text as ""z"" from foo\',\n                                   \'select ""x"".""y""::text as z from foo\',\n                                   \'select ""x"".""y""::text as ""z"" from foo\'])\n    @pytest.mark.parametrize(\'func_name, result\', [(\'get_name\', \'z\'),\n                                                   (\'get_real_name\', \'y\'),\n                                                   (\'get_parent_name\', \'x\'),\n                                                   (\'get_alias\', \'z\'),\n                                                   (\'get_typecast\', \'text\')])\n    def test_issue78(s, func_name, result):\n        # the bug author provided this nice examples, let\'s use them!\n        p = sqlparse.parse(s)[0]\n        i = p.tokens[2]\n        assert isinstance(i, sql.Identifier)\n    \n        func = getattr(i, func_name)\n>       assert func() == result\n\nrepos\\sqlparse\\tests\\test_regressions.py:125: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\sql.py:316: in get_parent_name\n    _, prev_ = self.token_prev(dot_idx)\nrepos\\sqlparse\\sqlparse\\sql.py:241: in token_prev\n    return self.token_next(idx, skip_ws, skip_cm, _reverse=True)\nrepos\\sqlparse\\sqlparse\\sql.py:244: in token_next\n    return self._token_matching(idx, skip_ws, skip_cm, _reverse)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Identifier \'x.\' at 0x18ED1A915D0>, funcs = (1,), start = True\nend = False, reverse = True\n\n    def _token_matching(self, funcs, start=0, end=None, reverse=False):\n        """"""next token that match functions""""""\n        if start is None:\n            return None\n        if not isinstance(funcs, (list, tuple)):\n            funcs = (funcs,)\n        if reverse:\n>           assert end is None\nE           AssertionError\n\nrepos\\sqlparse\\sqlparse\\sql.py:195: AssertionError', 's = \'select ""x"".y::text as z from foo\', func_name = \'get_parent_name\'\nresult = \'x\'\n\n    @pytest.mark.parametrize(\'s\', [\'select x.y::text as z from foo\',\n                                   \'select x.y::text as ""z"" from foo\',\n                                   \'select x.""y""::text as z from foo\',\n                                   \'select x.""y""::text as ""z"" from foo\',\n                                   \'select ""x"".y::text as z from foo\',\n                                   \'select ""x"".y::text as ""z"" from foo\',\n                                   \'select ""x"".""y""::text as z from foo\',\n                                   \'select ""x"".""y""::text as ""z"" from foo\'])\n    @pytest.mark.parametrize(\'func_name, result\', [(\'get_name\', \'z\'),\n                                                   (\'get_real_name\', \'y\'),\n                                                   (\'get_parent_name\', \'x\'),\n                                                   (\'get_alias\', \'z\'),\n                                                   (\'get_typecast\', \'text\')])\n    def test_issue78(s, func_name, result):\n        # the bug author provided this nice examples, let\'s use them!\n        p = sqlparse.parse(s)[0]\n        i = p.tokens[2]\n        assert isinstance(i, sql.Identifier)\n    \n        func = getattr(i, func_name)\n>       assert func() == result\n\nrepos\\sqlparse\\tests\\test_regressions.py:125: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\sql.py:316: in get_parent_name\n    _, prev_ = self.token_prev(dot_idx)\nrepos\\sqlparse\\sqlparse\\sql.py:241: in token_prev\n    return self.token_next(idx, skip_ws, skip_cm, _reverse=True)\nrepos\\sqlparse\\sqlparse\\sql.py:244: in token_next\n    return self._token_matching(idx, skip_ws, skip_cm, _reverse)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Identifier \'""x"".\' at 0x18ED1FAAD50>, funcs = (1,), start = True\nend = False, reverse = True\n\n    def _token_matching(self, funcs, start=0, end=None, reverse=False):\n        """"""next token that match functions""""""\n        if start is None:\n            return None\n        if not isinstance(funcs, (list, tuple)):\n            funcs = (funcs,)\n        if reverse:\n>           assert end is None\nE           AssertionError\n\nrepos\\sqlparse\\sqlparse\\sql.py:195: AssertionError', 's = \'select ""x"".y::text as ""z"" from foo\', func_name = \'get_parent_name\'\nresult = \'x\'\n\n    @pytest.mark.parametrize(\'s\', [\'select x.y::text as z from foo\',\n                                   \'select x.y::text as ""z"" from foo\',\n                                   \'select x.""y""::text as z from foo\',\n                                   \'select x.""y""::text as ""z"" from foo\',\n                                   \'select ""x"".y::text as z from foo\',\n                                   \'select ""x"".y::text as ""z"" from foo\',\n                                   \'select ""x"".""y""::text as z from foo\',\n                                   \'select ""x"".""y""::text as ""z"" from foo\'])\n    @pytest.mark.parametrize(\'func_name, result\', [(\'get_name\', \'z\'),\n                                                   (\'get_real_name\', \'y\'),\n                                                   (\'get_parent_name\', \'x\'),\n                                                   (\'get_alias\', \'z\'),\n                                                   (\'get_typecast\', \'text\')])\n    def test_issue78(s, func_name, result):\n        # the bug author provided this nice examples, let\'s use them!\n        p = sqlparse.parse(s)[0]\n        i = p.tokens[2]\n        assert isinstance(i, sql.Identifier)\n    \n        func = getattr(i, func_name)\n>       assert func() == result\n\nrepos\\sqlparse\\tests\\test_regressions.py:125: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\sql.py:316: in get_parent_name\n    _, prev_ = self.token_prev(dot_idx)\nrepos\\sqlparse\\sqlparse\\sql.py:241: in token_prev\n    return self.token_next(idx, skip_ws, skip_cm, _reverse=True)\nrepos\\sqlparse\\sqlparse\\sql.py:244: in token_next\n    return self._token_matching(idx, skip_ws, skip_cm, _reverse)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Identifier \'""x"".\' at 0x18ED1D9B6D0>, funcs = (1,), start = True\nend = False, reverse = True\n\n    def _token_matching(self, funcs, start=0, end=None, reverse=False):\n        """"""next token that match functions""""""\n        if start is None:\n            return None\n        if not isinstance(funcs, (list, tuple)):\n            funcs = (funcs,)\n        if reverse:\n>           assert end is None\nE           AssertionError\n\nrepos\\sqlparse\\sqlparse\\sql.py:195: AssertionError', 's = \'select ""x"".""y""::text as z from foo\', func_name = \'get_parent_name\'\nresult = \'x\'\n\n    @pytest.mark.parametrize(\'s\', [\'select x.y::text as z from foo\',\n                                   \'select x.y::text as ""z"" from foo\',\n                                   \'select x.""y""::text as z from foo\',\n                                   \'select x.""y""::text as ""z"" from foo\',\n                                   \'select ""x"".y::text as z from foo\',\n                                   \'select ""x"".y::text as ""z"" from foo\',\n                                   \'select ""x"".""y""::text as z from foo\',\n                                   \'select ""x"".""y""::text as ""z"" from foo\'])\n    @pytest.mark.parametrize(\'func_name, result\', [(\'get_name\', \'z\'),\n                                                   (\'get_real_name\', \'y\'),\n                                                   (\'get_parent_name\', \'x\'),\n                                                   (\'get_alias\', \'z\'),\n                                                   (\'get_typecast\', \'text\')])\n    def test_issue78(s, func_name, result):\n        # the bug author provided this nice examples, let\'s use them!\n        p = sqlparse.parse(s)[0]\n        i = p.tokens[2]\n        assert isinstance(i, sql.Identifier)\n    \n        func = getattr(i, func_name)\n>       assert func() == result\n\nrepos\\sqlparse\\tests\\test_regressions.py:125: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\sql.py:316: in get_parent_name\n    _, prev_ = self.token_prev(dot_idx)\nrepos\\sqlparse\\sqlparse\\sql.py:241: in token_prev\n    return self.token_next(idx, skip_ws, skip_cm, _reverse=True)\nrepos\\sqlparse\\sqlparse\\sql.py:244: in token_next\n    return self._token_matching(idx, skip_ws, skip_cm, _reverse)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Identifier \'""x"".\' at 0x18ED1FABDD0>, funcs = (1,), start = True\nend = False, reverse = True\n\n    def _token_matching(self, funcs, start=0, end=None, reverse=False):\n        """"""next token that match functions""""""\n        if start is None:\n            return None\n        if not isinstance(funcs, (list, tuple)):\n            funcs = (funcs,)\n        if reverse:\n>           assert end is None\nE           AssertionError\n\nrepos\\sqlparse\\sqlparse\\sql.py:195: AssertionError', 's = \'select ""x"".""y""::text as ""z"" from foo\', func_name = \'get_parent_name\'\nresult = \'x\'\n\n    @pytest.mark.parametrize(\'s\', [\'select x.y::text as z from foo\',\n                                   \'select x.y::text as ""z"" from foo\',\n                                   \'select x.""y""::text as z from foo\',\n                                   \'select x.""y""::text as ""z"" from foo\',\n                                   \'select ""x"".y::text as z from foo\',\n                                   \'select ""x"".y::text as ""z"" from foo\',\n                                   \'select ""x"".""y""::text as z from foo\',\n                                   \'select ""x"".""y""::text as ""z"" from foo\'])\n    @pytest.mark.parametrize(\'func_name, result\', [(\'get_name\', \'z\'),\n                                                   (\'get_real_name\', \'y\'),\n                                                   (\'get_parent_name\', \'x\'),\n                                                   (\'get_alias\', \'z\'),\n                                                   (\'get_typecast\', \'text\')])\n    def test_issue78(s, func_name, result):\n        # the bug author provided this nice examples, let\'s use them!\n        p = sqlparse.parse(s)[0]\n        i = p.tokens[2]\n        assert isinstance(i, sql.Identifier)\n    \n        func = getattr(i, func_name)\n>       assert func() == result\n\nrepos\\sqlparse\\tests\\test_regressions.py:125: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\sql.py:316: in get_parent_name\n    _, prev_ = self.token_prev(dot_idx)\nrepos\\sqlparse\\sqlparse\\sql.py:241: in token_prev\n    return self.token_next(idx, skip_ws, skip_cm, _reverse=True)\nrepos\\sqlparse\\sqlparse\\sql.py:244: in token_next\n    return self._token_matching(idx, skip_ws, skip_cm, _reverse)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Identifier \'""x"".\' at 0x18ED1D5AB50>, funcs = (1,), start = True\nend = False, reverse = True\n\n    def _token_matching(self, funcs, start=0, end=None, reverse=False):\n        """"""next token that match functions""""""\n        if start is None:\n            return None\n        if not isinstance(funcs, (list, tuple)):\n            funcs = (funcs,)\n        if reverse:\n>           assert end is None\nE           AssertionError\n\nrepos\\sqlparse\\sqlparse\\sql.py:195: AssertionError', 's = \'select x.y::text as z from foo\', func_name = \'get_alias\', result = \'z\'\n\n    @pytest.mark.parametrize(\'s\', [\'select x.y::text as z from foo\',\n                                   \'select x.y::text as ""z"" from foo\',\n                                   \'select x.""y""::text as z from foo\',\n                                   \'select x.""y""::text as ""z"" from foo\',\n                                   \'select ""x"".y::text as z from foo\',\n                                   \'select ""x"".y::text as ""z"" from foo\',\n                                   \'select ""x"".""y""::text as z from foo\',\n                                   \'select ""x"".""y""::text as ""z"" from foo\'])\n    @pytest.mark.parametrize(\'func_name, result\', [(\'get_name\', \'z\'),\n                                                   (\'get_real_name\', \'y\'),\n                                                   (\'get_parent_name\', \'x\'),\n                                                   (\'get_alias\', \'z\'),\n                                                   (\'get_typecast\', \'text\')])\n    def test_issue78(s, func_name, result):\n        # the bug author provided this nice examples, let\'s use them!\n        p = sqlparse.parse(s)[0]\n        i = p.tokens[2]\n        assert isinstance(i, sql.Identifier)\n    \n        func = getattr(i, func_name)\n>       assert func() == result\nE       AssertionError: assert None == \'z\'\nE        +  where None = get_alias()\n\nrepos\\sqlparse\\tests\\test_regressions.py:125: AssertionError', 's = \'select x.y::text as ""z"" from foo\', func_name = \'get_alias\', result = \'z\'\n\n    @pytest.mark.parametrize(\'s\', [\'select x.y::text as z from foo\',\n                                   \'select x.y::text as ""z"" from foo\',\n                                   \'select x.""y""::text as z from foo\',\n                                   \'select x.""y""::text as ""z"" from foo\',\n                                   \'select ""x"".y::text as z from foo\',\n                                   \'select ""x"".y::text as ""z"" from foo\',\n                                   \'select ""x"".""y""::text as z from foo\',\n                                   \'select ""x"".""y""::text as ""z"" from foo\'])\n    @pytest.mark.parametrize(\'func_name, result\', [(\'get_name\', \'z\'),\n                                                   (\'get_real_name\', \'y\'),\n                                                   (\'get_parent_name\', \'x\'),\n                                                   (\'get_alias\', \'z\'),\n                                                   (\'get_typecast\', \'text\')])\n    def test_issue78(s, func_name, result):\n        # the bug author provided this nice examples, let\'s use them!\n        p = sqlparse.parse(s)[0]\n        i = p.tokens[2]\n        assert isinstance(i, sql.Identifier)\n    \n        func = getattr(i, func_name)\n>       assert func() == result\nE       AssertionError: assert None == \'z\'\nE        +  where None = get_alias()\n\nrepos\\sqlparse\\tests\\test_regressions.py:125: AssertionError', 's = \'select x.""y""::text as z from foo\', func_name = \'get_alias\', result = \'z\'\n\n    @pytest.mark.parametrize(\'s\', [\'select x.y::text as z from foo\',\n                                   \'select x.y::text as ""z"" from foo\',\n                                   \'select x.""y""::text as z from foo\',\n                                   \'select x.""y""::text as ""z"" from foo\',\n                                   \'select ""x"".y::text as z from foo\',\n                                   \'select ""x"".y::text as ""z"" from foo\',\n                                   \'select ""x"".""y""::text as z from foo\',\n                                   \'select ""x"".""y""::text as ""z"" from foo\'])\n    @pytest.mark.parametrize(\'func_name, result\', [(\'get_name\', \'z\'),\n                                                   (\'get_real_name\', \'y\'),\n                                                   (\'get_parent_name\', \'x\'),\n                                                   (\'get_alias\', \'z\'),\n                                                   (\'get_typecast\', \'text\')])\n    def test_issue78(s, func_name, result):\n        # the bug author provided this nice examples, let\'s use them!\n        p = sqlparse.parse(s)[0]\n        i = p.tokens[2]\n        assert isinstance(i, sql.Identifier)\n    \n        func = getattr(i, func_name)\n>       assert func() == result\nE       AssertionError: assert None == \'z\'\nE        +  where None = get_alias()\n\nrepos\\sqlparse\\tests\\test_regressions.py:125: AssertionError', 's = \'select x.""y""::text as ""z"" from foo\', func_name = \'get_alias\', result = \'z\'\n\n    @pytest.mark.parametrize(\'s\', [\'select x.y::text as z from foo\',\n                                   \'select x.y::text as ""z"" from foo\',\n                                   \'select x.""y""::text as z from foo\',\n                                   \'select x.""y""::text as ""z"" from foo\',\n                                   \'select ""x"".y::text as z from foo\',\n                                   \'select ""x"".y::text as ""z"" from foo\',\n                                   \'select ""x"".""y""::text as z from foo\',\n                                   \'select ""x"".""y""::text as ""z"" from foo\'])\n    @pytest.mark.parametrize(\'func_name, result\', [(\'get_name\', \'z\'),\n                                                   (\'get_real_name\', \'y\'),\n                                                   (\'get_parent_name\', \'x\'),\n                                                   (\'get_alias\', \'z\'),\n                                                   (\'get_typecast\', \'text\')])\n    def test_issue78(s, func_name, result):\n        # the bug author provided this nice examples, let\'s use them!\n        p = sqlparse.parse(s)[0]\n        i = p.tokens[2]\n        assert isinstance(i, sql.Identifier)\n    \n        func = getattr(i, func_name)\n>       assert func() == result\nE       AssertionError: assert None == \'z\'\nE        +  where None = get_alias()\n\nrepos\\sqlparse\\tests\\test_regressions.py:125: AssertionError', 's = \'select ""x"".y::text as z from foo\', func_name = \'get_alias\', result = \'z\'\n\n    @pytest.mark.parametrize(\'s\', [\'select x.y::text as z from foo\',\n                                   \'select x.y::text as ""z"" from foo\',\n                                   \'select x.""y""::text as z from foo\',\n                                   \'select x.""y""::text as ""z"" from foo\',\n                                   \'select ""x"".y::text as z from foo\',\n                                   \'select ""x"".y::text as ""z"" from foo\',\n                                   \'select ""x"".""y""::text as z from foo\',\n                                   \'select ""x"".""y""::text as ""z"" from foo\'])\n    @pytest.mark.parametrize(\'func_name, result\', [(\'get_name\', \'z\'),\n                                                   (\'get_real_name\', \'y\'),\n                                                   (\'get_parent_name\', \'x\'),\n                                                   (\'get_alias\', \'z\'),\n                                                   (\'get_typecast\', \'text\')])\n    def test_issue78(s, func_name, result):\n        # the bug author provided this nice examples, let\'s use them!\n        p = sqlparse.parse(s)[0]\n        i = p.tokens[2]\n        assert isinstance(i, sql.Identifier)\n    \n        func = getattr(i, func_name)\n>       assert func() == result\nE       AssertionError: assert None == \'z\'\nE        +  where None = get_alias()\n\nrepos\\sqlparse\\tests\\test_regressions.py:125: AssertionError', 's = \'select ""x"".y::text as ""z"" from foo\', func_name = \'get_alias\', result = \'z\'\n\n    @pytest.mark.parametrize(\'s\', [\'select x.y::text as z from foo\',\n                                   \'select x.y::text as ""z"" from foo\',\n                                   \'select x.""y""::text as z from foo\',\n                                   \'select x.""y""::text as ""z"" from foo\',\n                                   \'select ""x"".y::text as z from foo\',\n                                   \'select ""x"".y::text as ""z"" from foo\',\n                                   \'select ""x"".""y""::text as z from foo\',\n                                   \'select ""x"".""y""::text as ""z"" from foo\'])\n    @pytest.mark.parametrize(\'func_name, result\', [(\'get_name\', \'z\'),\n                                                   (\'get_real_name\', \'y\'),\n                                                   (\'get_parent_name\', \'x\'),\n                                                   (\'get_alias\', \'z\'),\n                                                   (\'get_typecast\', \'text\')])\n    def test_issue78(s, func_name, result):\n        # the bug author provided this nice examples, let\'s use them!\n        p = sqlparse.parse(s)[0]\n        i = p.tokens[2]\n        assert isinstance(i, sql.Identifier)\n    \n        func = getattr(i, func_name)\n>       assert func() == result\nE       AssertionError: assert None == \'z\'\nE        +  where None = get_alias()\n\nrepos\\sqlparse\\tests\\test_regressions.py:125: AssertionError', 's = \'select ""x"".""y""::text as z from foo\', func_name = \'get_alias\', result = \'z\'\n\n    @pytest.mark.parametrize(\'s\', [\'select x.y::text as z from foo\',\n                                   \'select x.y::text as ""z"" from foo\',\n                                   \'select x.""y""::text as z from foo\',\n                                   \'select x.""y""::text as ""z"" from foo\',\n                                   \'select ""x"".y::text as z from foo\',\n                                   \'select ""x"".y::text as ""z"" from foo\',\n                                   \'select ""x"".""y""::text as z from foo\',\n                                   \'select ""x"".""y""::text as ""z"" from foo\'])\n    @pytest.mark.parametrize(\'func_name, result\', [(\'get_name\', \'z\'),\n                                                   (\'get_real_name\', \'y\'),\n                                                   (\'get_parent_name\', \'x\'),\n                                                   (\'get_alias\', \'z\'),\n                                                   (\'get_typecast\', \'text\')])\n    def test_issue78(s, func_name, result):\n        # the bug author provided this nice examples, let\'s use them!\n        p = sqlparse.parse(s)[0]\n        i = p.tokens[2]\n        assert isinstance(i, sql.Identifier)\n    \n        func = getattr(i, func_name)\n>       assert func() == result\nE       AssertionError: assert None == \'z\'\nE        +  where None = get_alias()\n\nrepos\\sqlparse\\tests\\test_regressions.py:125: AssertionError', 's = \'select ""x"".""y""::text as ""z"" from foo\', func_name = \'get_alias\'\nresult = \'z\'\n\n    @pytest.mark.parametrize(\'s\', [\'select x.y::text as z from foo\',\n                                   \'select x.y::text as ""z"" from foo\',\n                                   \'select x.""y""::text as z from foo\',\n                                   \'select x.""y""::text as ""z"" from foo\',\n                                   \'select ""x"".y::text as z from foo\',\n                                   \'select ""x"".y::text as ""z"" from foo\',\n                                   \'select ""x"".""y""::text as z from foo\',\n                                   \'select ""x"".""y""::text as ""z"" from foo\'])\n    @pytest.mark.parametrize(\'func_name, result\', [(\'get_name\', \'z\'),\n                                                   (\'get_real_name\', \'y\'),\n                                                   (\'get_parent_name\', \'x\'),\n                                                   (\'get_alias\', \'z\'),\n                                                   (\'get_typecast\', \'text\')])\n    def test_issue78(s, func_name, result):\n        # the bug author provided this nice examples, let\'s use them!\n        p = sqlparse.parse(s)[0]\n        i = p.tokens[2]\n        assert isinstance(i, sql.Identifier)\n    \n        func = getattr(i, func_name)\n>       assert func() == result\nE       AssertionError: assert None == \'z\'\nE        +  where None = get_alias()\n\nrepos\\sqlparse\\tests\\test_regressions.py:125: AssertionError', 's = \'select x.y::text as z from foo\', func_name = \'get_typecast\'\nresult = \'text\'\n\n    @pytest.mark.parametrize(\'s\', [\'select x.y::text as z from foo\',\n                                   \'select x.y::text as ""z"" from foo\',\n                                   \'select x.""y""::text as z from foo\',\n                                   \'select x.""y""::text as ""z"" from foo\',\n                                   \'select ""x"".y::text as z from foo\',\n                                   \'select ""x"".y::text as ""z"" from foo\',\n                                   \'select ""x"".""y""::text as z from foo\',\n                                   \'select ""x"".""y""::text as ""z"" from foo\'])\n    @pytest.mark.parametrize(\'func_name, result\', [(\'get_name\', \'z\'),\n                                                   (\'get_real_name\', \'y\'),\n                                                   (\'get_parent_name\', \'x\'),\n                                                   (\'get_alias\', \'z\'),\n                                                   (\'get_typecast\', \'text\')])\n    def test_issue78(s, func_name, result):\n        # the bug author provided this nice examples, let\'s use them!\n        p = sqlparse.parse(s)[0]\n        i = p.tokens[2]\n        assert isinstance(i, sql.Identifier)\n    \n        func = getattr(i, func_name)\n>       assert func() == result\nE       AssertionError: assert None == \'text\'\nE        +  where None = get_typecast()\n\nrepos\\sqlparse\\tests\\test_regressions.py:125: AssertionError', 's = \'select x.y::text as ""z"" from foo\', func_name = \'get_typecast\'\nresult = \'text\'\n\n    @pytest.mark.parametrize(\'s\', [\'select x.y::text as z from foo\',\n                                   \'select x.y::text as ""z"" from foo\',\n                                   \'select x.""y""::text as z from foo\',\n                                   \'select x.""y""::text as ""z"" from foo\',\n                                   \'select ""x"".y::text as z from foo\',\n                                   \'select ""x"".y::text as ""z"" from foo\',\n                                   \'select ""x"".""y""::text as z from foo\',\n                                   \'select ""x"".""y""::text as ""z"" from foo\'])\n    @pytest.mark.parametrize(\'func_name, result\', [(\'get_name\', \'z\'),\n                                                   (\'get_real_name\', \'y\'),\n                                                   (\'get_parent_name\', \'x\'),\n                                                   (\'get_alias\', \'z\'),\n                                                   (\'get_typecast\', \'text\')])\n    def test_issue78(s, func_name, result):\n        # the bug author provided this nice examples, let\'s use them!\n        p = sqlparse.parse(s)[0]\n        i = p.tokens[2]\n        assert isinstance(i, sql.Identifier)\n    \n        func = getattr(i, func_name)\n>       assert func() == result\nE       AssertionError: assert None == \'text\'\nE        +  where None = get_typecast()\n\nrepos\\sqlparse\\tests\\test_regressions.py:125: AssertionError', 's = \'select x.""y""::text as z from foo\', func_name = \'get_typecast\'\nresult = \'text\'\n\n    @pytest.mark.parametrize(\'s\', [\'select x.y::text as z from foo\',\n                                   \'select x.y::text as ""z"" from foo\',\n                                   \'select x.""y""::text as z from foo\',\n                                   \'select x.""y""::text as ""z"" from foo\',\n                                   \'select ""x"".y::text as z from foo\',\n                                   \'select ""x"".y::text as ""z"" from foo\',\n                                   \'select ""x"".""y""::text as z from foo\',\n                                   \'select ""x"".""y""::text as ""z"" from foo\'])\n    @pytest.mark.parametrize(\'func_name, result\', [(\'get_name\', \'z\'),\n                                                   (\'get_real_name\', \'y\'),\n                                                   (\'get_parent_name\', \'x\'),\n                                                   (\'get_alias\', \'z\'),\n                                                   (\'get_typecast\', \'text\')])\n    def test_issue78(s, func_name, result):\n        # the bug author provided this nice examples, let\'s use them!\n        p = sqlparse.parse(s)[0]\n        i = p.tokens[2]\n        assert isinstance(i, sql.Identifier)\n    \n        func = getattr(i, func_name)\n>       assert func() == result\nE       AssertionError: assert None == \'text\'\nE        +  where None = get_typecast()\n\nrepos\\sqlparse\\tests\\test_regressions.py:125: AssertionError', 's = \'select x.""y""::text as ""z"" from foo\', func_name = \'get_typecast\'\nresult = \'text\'\n\n    @pytest.mark.parametrize(\'s\', [\'select x.y::text as z from foo\',\n                                   \'select x.y::text as ""z"" from foo\',\n                                   \'select x.""y""::text as z from foo\',\n                                   \'select x.""y""::text as ""z"" from foo\',\n                                   \'select ""x"".y::text as z from foo\',\n                                   \'select ""x"".y::text as ""z"" from foo\',\n                                   \'select ""x"".""y""::text as z from foo\',\n                                   \'select ""x"".""y""::text as ""z"" from foo\'])\n    @pytest.mark.parametrize(\'func_name, result\', [(\'get_name\', \'z\'),\n                                                   (\'get_real_name\', \'y\'),\n                                                   (\'get_parent_name\', \'x\'),\n                                                   (\'get_alias\', \'z\'),\n                                                   (\'get_typecast\', \'text\')])\n    def test_issue78(s, func_name, result):\n        # the bug author provided this nice examples, let\'s use them!\n        p = sqlparse.parse(s)[0]\n        i = p.tokens[2]\n        assert isinstance(i, sql.Identifier)\n    \n        func = getattr(i, func_name)\n>       assert func() == result\nE       AssertionError: assert None == \'text\'\nE        +  where None = get_typecast()\n\nrepos\\sqlparse\\tests\\test_regressions.py:125: AssertionError', 's = \'select ""x"".y::text as z from foo\', func_name = \'get_typecast\'\nresult = \'text\'\n\n    @pytest.mark.parametrize(\'s\', [\'select x.y::text as z from foo\',\n                                   \'select x.y::text as ""z"" from foo\',\n                                   \'select x.""y""::text as z from foo\',\n                                   \'select x.""y""::text as ""z"" from foo\',\n                                   \'select ""x"".y::text as z from foo\',\n                                   \'select ""x"".y::text as ""z"" from foo\',\n                                   \'select ""x"".""y""::text as z from foo\',\n                                   \'select ""x"".""y""::text as ""z"" from foo\'])\n    @pytest.mark.parametrize(\'func_name, result\', [(\'get_name\', \'z\'),\n                                                   (\'get_real_name\', \'y\'),\n                                                   (\'get_parent_name\', \'x\'),\n                                                   (\'get_alias\', \'z\'),\n                                                   (\'get_typecast\', \'text\')])\n    def test_issue78(s, func_name, result):\n        # the bug author provided this nice examples, let\'s use them!\n        p = sqlparse.parse(s)[0]\n        i = p.tokens[2]\n        assert isinstance(i, sql.Identifier)\n    \n        func = getattr(i, func_name)\n>       assert func() == result\nE       AssertionError: assert None == \'text\'\nE        +  where None = get_typecast()\n\nrepos\\sqlparse\\tests\\test_regressions.py:125: AssertionError', 's = \'select ""x"".y::text as ""z"" from foo\', func_name = \'get_typecast\'\nresult = \'text\'\n\n    @pytest.mark.parametrize(\'s\', [\'select x.y::text as z from foo\',\n                                   \'select x.y::text as ""z"" from foo\',\n                                   \'select x.""y""::text as z from foo\',\n                                   \'select x.""y""::text as ""z"" from foo\',\n                                   \'select ""x"".y::text as z from foo\',\n                                   \'select ""x"".y::text as ""z"" from foo\',\n                                   \'select ""x"".""y""::text as z from foo\',\n                                   \'select ""x"".""y""::text as ""z"" from foo\'])\n    @pytest.mark.parametrize(\'func_name, result\', [(\'get_name\', \'z\'),\n                                                   (\'get_real_name\', \'y\'),\n                                                   (\'get_parent_name\', \'x\'),\n                                                   (\'get_alias\', \'z\'),\n                                                   (\'get_typecast\', \'text\')])\n    def test_issue78(s, func_name, result):\n        # the bug author provided this nice examples, let\'s use them!\n        p = sqlparse.parse(s)[0]\n        i = p.tokens[2]\n        assert isinstance(i, sql.Identifier)\n    \n        func = getattr(i, func_name)\n>       assert func() == result\nE       AssertionError: assert None == \'text\'\nE        +  where None = get_typecast()\n\nrepos\\sqlparse\\tests\\test_regressions.py:125: AssertionError', 's = \'select ""x"".""y""::text as z from foo\', func_name = \'get_typecast\'\nresult = \'text\'\n\n    @pytest.mark.parametrize(\'s\', [\'select x.y::text as z from foo\',\n                                   \'select x.y::text as ""z"" from foo\',\n                                   \'select x.""y""::text as z from foo\',\n                                   \'select x.""y""::text as ""z"" from foo\',\n                                   \'select ""x"".y::text as z from foo\',\n                                   \'select ""x"".y::text as ""z"" from foo\',\n                                   \'select ""x"".""y""::text as z from foo\',\n                                   \'select ""x"".""y""::text as ""z"" from foo\'])\n    @pytest.mark.parametrize(\'func_name, result\', [(\'get_name\', \'z\'),\n                                                   (\'get_real_name\', \'y\'),\n                                                   (\'get_parent_name\', \'x\'),\n                                                   (\'get_alias\', \'z\'),\n                                                   (\'get_typecast\', \'text\')])\n    def test_issue78(s, func_name, result):\n        # the bug author provided this nice examples, let\'s use them!\n        p = sqlparse.parse(s)[0]\n        i = p.tokens[2]\n        assert isinstance(i, sql.Identifier)\n    \n        func = getattr(i, func_name)\n>       assert func() == result\nE       AssertionError: assert None == \'text\'\nE        +  where None = get_typecast()\n\nrepos\\sqlparse\\tests\\test_regressions.py:125: AssertionError', 's = \'select ""x"".""y""::text as ""z"" from foo\', func_name = \'get_typecast\'\nresult = \'text\'\n\n    @pytest.mark.parametrize(\'s\', [\'select x.y::text as z from foo\',\n                                   \'select x.y::text as ""z"" from foo\',\n                                   \'select x.""y""::text as z from foo\',\n                                   \'select x.""y""::text as ""z"" from foo\',\n                                   \'select ""x"".y::text as z from foo\',\n                                   \'select ""x"".y::text as ""z"" from foo\',\n                                   \'select ""x"".""y""::text as z from foo\',\n                                   \'select ""x"".""y""::text as ""z"" from foo\'])\n    @pytest.mark.parametrize(\'func_name, result\', [(\'get_name\', \'z\'),\n                                                   (\'get_real_name\', \'y\'),\n                                                   (\'get_parent_name\', \'x\'),\n                                                   (\'get_alias\', \'z\'),\n                                                   (\'get_typecast\', \'text\')])\n    def test_issue78(s, func_name, result):\n        # the bug author provided this nice examples, let\'s use them!\n        p = sqlparse.parse(s)[0]\n        i = p.tokens[2]\n        assert isinstance(i, sql.Identifier)\n    \n        func = getattr(i, func_name)\n>       assert func() == result\nE       AssertionError: assert None == \'text\'\nE        +  where None = get_typecast()\n\nrepos\\sqlparse\\tests\\test_regressions.py:125: AssertionError', 'def test_comment_encoding_when_reindent():\n        # There was an UnicodeEncodeError in the reindent filter that\n        # casted every comment followed by a keyword to str.\n        sql = \'select foo -- Comment containing Ümläuts\\nfrom bar\'\n>       formatted = sqlparse.format(sql, reindent=True)\n\nrepos\\sqlparse\\tests\\test_regressions.py:154: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return \'\'.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\utils.py:74: in wrapped_f\n    f(tlist)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:319: in group_comments\n    eidx, end = tlist.token_prev(eidx, skip_ws=False)\nrepos\\sqlparse\\sqlparse\\sql.py:241: in token_prev\n    return self.token_next(idx, skip_ws, skip_cm, _reverse=True)\nrepos\\sqlparse\\sqlparse\\sql.py:244: in token_next\n    return self._token_matching(idx, skip_ws, skip_cm, _reverse)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Statement \'select...\' at 0x18ED1D5BDD0>, funcs = (5,), start = False\nend = False, reverse = True\n\n    def _token_matching(self, funcs, start=0, end=None, reverse=False):\n        """"""next token that match functions""""""\n        if start is None:\n            return None\n        if not isinstance(funcs, (list, tuple)):\n            funcs = (funcs,)\n        if reverse:\n>           assert end is None\nE           AssertionError\n\nrepos\\sqlparse\\sqlparse\\sql.py:195: AssertionError', 'def test_parse_sql_with_binary():\n        # See https://github.com/andialbrecht/sqlparse/pull/88\n        # digest = \'\x82|Ë\x0eê\x8aplL4¡h\x91øN{\'\n        digest = \'\\x82|\\xcb\\x0e\\xea\\x8aplL4\\xa1h\\x91\\xf8N{\'\n        sql = f""select * from foo where bar = \'{digest}\'""\n>       formatted = sqlparse.format(sql, reindent=True)\n\nrepos\\sqlparse\\tests\\test_regressions.py:163: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return \'\'.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:44: in run\n    filter_.process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:240: in process\n    self._process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:102: in _process\n    func(tlist)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:233: in _process_default\n    self._split_statements(tlist) if stmts else None\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:89: in _split_statements\n    pidx, prev_ = tlist.token_prev(tidx, skip_ws=False)\nrepos\\sqlparse\\sqlparse\\sql.py:241: in token_prev\n    return self.token_next(idx, skip_ws, skip_cm, _reverse=True)\nrepos\\sqlparse\\sqlparse\\sql.py:244: in token_next\n    return self._token_matching(idx, skip_ws, skip_cm, _reverse)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Statement \'select...\' at 0x18ED1D9B2D0>, funcs = (0,), start = False\nend = False, reverse = True\n\n    def _token_matching(self, funcs, start=0, end=None, reverse=False):\n        """"""next token that match functions""""""\n        if start is None:\n            return None\n        if not isinstance(funcs, (list, tuple)):\n            funcs = (funcs,)\n        if reverse:\n>           assert end is None\nE           AssertionError\n\nrepos\\sqlparse\\sqlparse\\sql.py:195: AssertionError', 'load_file = <function load_file.<locals>.make_load_file at 0x0000018ED1F9C860>\n\n    def test_format_accepts_encoding(load_file):\n        # issue20\n        sql = load_file(\'test_cp1251.sql\', \'cp1251\')\n>       formatted = sqlparse.format(sql, reindent=True, encoding=\'cp1251\')\n\nrepos\\sqlparse\\tests\\test_regressions.py:181: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return \'\'.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:44: in run\n    filter_.process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:240: in process\n    self._process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:102: in _process\n    func(tlist)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:233: in _process_default\n    self._split_statements(tlist) if stmts else None\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:89: in _split_statements\n    pidx, prev_ = tlist.token_prev(tidx, skip_ws=False)\nrepos\\sqlparse\\sqlparse\\sql.py:241: in token_prev\n    return self.token_next(idx, skip_ws, skip_cm, _reverse=True)\nrepos\\sqlparse\\sqlparse\\sql.py:244: in token_next\n    return self._token_matching(idx, skip_ws, skip_cm, _reverse)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Statement \'insert...\' at 0x18ED2053E50>, funcs = (0,), start = False\nend = False, reverse = True\n\n    def _token_matching(self, funcs, start=0, end=None, reverse=False):\n        """"""next token that match functions""""""\n        if start is None:\n            return None\n        if not isinstance(funcs, (list, tuple)):\n            funcs = (funcs,)\n        if reverse:\n>           assert end is None\nE           AssertionError\n\nrepos\\sqlparse\\sqlparse\\sql.py:195: AssertionError', 'get_stream = <function get_stream.<locals>.make_stream at 0x0000018ED1F9D080>\n\n    def test_stream(get_stream):\n        with get_stream(""stream.sql"") as stream:\n>           p = sqlparse.parse(stream)[0]\n\nrepos\\sqlparse\\tests\\test_regressions.py:189: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\utils.py:74: in wrapped_f\n    f(tlist)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:319: in group_comments\n    eidx, end = tlist.token_prev(eidx, skip_ws=False)\nrepos\\sqlparse\\sqlparse\\sql.py:241: in token_prev\n    return self.token_next(idx, skip_ws, skip_cm, _reverse=True)\nrepos\\sqlparse\\sqlparse\\sql.py:244: in token_next\n    return self._token_matching(idx, skip_ws, skip_cm, _reverse)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Statement \'-- thi...\' at 0x18ED2053F50>, funcs = (1,), start = False\nend = False, reverse = True\n\n    def _token_matching(self, funcs, start=0, end=None, reverse=False):\n        """"""next token that match functions""""""\n        if start is None:\n            return None\n        if not isinstance(funcs, (list, tuple)):\n            funcs = (funcs,)\n        if reverse:\n>           assert end is None\nE           AssertionError\n\nrepos\\sqlparse\\sqlparse\\sql.py:195: AssertionError', 'def test_issue90():\n        sql = (\'UPDATE ""gallery_photo"" SET ""owner_id"" = 4018, ""deleted_at"" = NULL,\'\n               \' ""width"" = NULL, ""height"" = NULL, ""rating_votes"" = 0,\'\n               \' ""rating_score"" = 0, ""thumbnail_width"" = NULL,\'\n               \' ""thumbnail_height"" = NULL, ""price"" = 1, ""description"" = NULL\')\n>       formatted = sqlparse.format(sql, reindent=True)\n\nrepos\\sqlparse\\tests\\test_regressions.py:198: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return \'\'.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:44: in run\n    filter_.process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:240: in process\n    self._process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:102: in _process\n    func(tlist)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:233: in _process_default\n    self._split_statements(tlist) if stmts else None\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:89: in _split_statements\n    pidx, prev_ = tlist.token_prev(tidx, skip_ws=False)\nrepos\\sqlparse\\sqlparse\\sql.py:241: in token_prev\n    return self.token_next(idx, skip_ws, skip_cm, _reverse=True)\nrepos\\sqlparse\\sqlparse\\sql.py:244: in token_next\n    return self._token_matching(idx, skip_ws, skip_cm, _reverse)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Statement \'UPDATE...\' at 0x18ED20535D0>, funcs = (0,), start = False\nend = False, reverse = True\n\n    def _token_matching(self, funcs, start=0, end=None, reverse=False):\n        """"""next token that match functions""""""\n        if start is None:\n            return None\n        if not isinstance(funcs, (list, tuple)):\n            funcs = (funcs,)\n        if reverse:\n>           assert end is None\nE           AssertionError\n\nrepos\\sqlparse\\sqlparse\\sql.py:195: AssertionError', 'def test_except_formatting():\n        sql = \'SELECT 1 FROM foo WHERE 2 = 3 EXCEPT SELECT 2 FROM bar WHERE 1 = 2\'\n>       formatted = sqlparse.format(sql, reindent=True)\n\nrepos\\sqlparse\\tests\\test_regressions.py:216: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return \'\'.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:44: in run\n    filter_.process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:240: in process\n    self._process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:102: in _process\n    func(tlist)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:233: in _process_default\n    self._split_statements(tlist) if stmts else None\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:89: in _split_statements\n    pidx, prev_ = tlist.token_prev(tidx, skip_ws=False)\nrepos\\sqlparse\\sqlparse\\sql.py:241: in token_prev\n    return self.token_next(idx, skip_ws, skip_cm, _reverse=True)\nrepos\\sqlparse\\sqlparse\\sql.py:244: in token_next\n    return self._token_matching(idx, skip_ws, skip_cm, _reverse)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Statement \'SELECT...\' at 0x18ED20BBBD0>, funcs = (0,), start = False\nend = False, reverse = True\n\n    def _token_matching(self, funcs, start=0, end=None, reverse=False):\n        """"""next token that match functions""""""\n        if start is None:\n            return None\n        if not isinstance(funcs, (list, tuple)):\n            funcs = (funcs,)\n        if reverse:\n>           assert end is None\nE           AssertionError\n\nrepos\\sqlparse\\sqlparse\\sql.py:195: AssertionError', 'def test_null_with_as():\n        sql = \'SELECT NULL AS c1, NULL AS c2 FROM t1\'\n>       formatted = sqlparse.format(sql, reindent=True)\n\nrepos\\sqlparse\\tests\\test_regressions.py:230: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return \'\'.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:44: in run\n    filter_.process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:240: in process\n    self._process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:102: in _process\n    func(tlist)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:233: in _process_default\n    self._split_statements(tlist) if stmts else None\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:89: in _split_statements\n    pidx, prev_ = tlist.token_prev(tidx, skip_ws=False)\nrepos\\sqlparse\\sqlparse\\sql.py:241: in token_prev\n    return self.token_next(idx, skip_ws, skip_cm, _reverse=True)\nrepos\\sqlparse\\sqlparse\\sql.py:244: in token_next\n    return self._token_matching(idx, skip_ws, skip_cm, _reverse)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Statement \'SELECT...\' at 0x18ED20541D0>, funcs = (0,), start = False\nend = False, reverse = True\n\n    def _token_matching(self, funcs, start=0, end=None, reverse=False):\n        """"""next token that match functions""""""\n        if start is None:\n            return None\n        if not isinstance(funcs, (list, tuple)):\n            funcs = (funcs,)\n        if reverse:\n>           assert end is None\nE           AssertionError\n\nrepos\\sqlparse\\sqlparse\\sql.py:195: AssertionError', 'filepath = <function filepath.<locals>.make_filepath at 0x0000018ED1F9D120>\n\n    def test_issue190_open_file(filepath):\n        path = filepath(\'stream.sql\')\n        with open(path) as stream:\n>           p = sqlparse.parse(stream)[0]\n\nrepos\\sqlparse\\tests\\test_regressions.py:241: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\utils.py:74: in wrapped_f\n    f(tlist)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:319: in group_comments\n    eidx, end = tlist.token_prev(eidx, skip_ws=False)\nrepos\\sqlparse\\sqlparse\\sql.py:241: in token_prev\n    return self.token_next(idx, skip_ws, skip_cm, _reverse=True)\nrepos\\sqlparse\\sqlparse\\sql.py:244: in token_next\n    return self._token_matching(idx, skip_ws, skip_cm, _reverse)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Statement \'-- thi...\' at 0x18ED2056050>, funcs = (1,), start = False\nend = False, reverse = True\n\n    def _token_matching(self, funcs, start=0, end=None, reverse=False):\n        """"""next token that match functions""""""\n        if start is None:\n            return None\n        if not isinstance(funcs, (list, tuple)):\n            funcs = (funcs,)\n        if reverse:\n>           assert end is None\nE           AssertionError\n\nrepos\\sqlparse\\sqlparse\\sql.py:195: AssertionError', 'def test_issue186_get_type():\n        sql = ""-- comment\\ninsert into foo""\n>       p = sqlparse.parse(sql)[0]\n\nrepos\\sqlparse\\tests\\test_regressions.py:272: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\utils.py:74: in wrapped_f\n    f(tlist)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:319: in group_comments\n    eidx, end = tlist.token_prev(eidx, skip_ws=False)\nrepos\\sqlparse\\sqlparse\\sql.py:241: in token_prev\n    return self.token_next(idx, skip_ws, skip_cm, _reverse=True)\nrepos\\sqlparse\\sqlparse\\sql.py:244: in token_next\n    return self._token_matching(idx, skip_ws, skip_cm, _reverse)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Statement \'-- com...\' at 0x18ED2055C50>, funcs = (1,), start = False\nend = False, reverse = True\n\n    def _token_matching(self, funcs, start=0, end=None, reverse=False):\n        """"""next token that match functions""""""\n        if start is None:\n            return None\n        if not isinstance(funcs, (list, tuple)):\n            funcs = (funcs,)\n        if reverse:\n>           assert end is None\nE           AssertionError\n\nrepos\\sqlparse\\sqlparse\\sql.py:195: AssertionError', ""def test_issue227_gettype_cte():\n        select_stmt = sqlparse.parse('SELECT 1, 2, 3 FROM foo;')\n        assert select_stmt[0].get_type() == 'SELECT'\n        with_stmt = sqlparse.parse('WITH foo AS (SELECT 1, 2, 3)'\n                                   'SELECT * FROM foo;')\n>       assert with_stmt[0].get_type() == 'SELECT'\nE       AssertionError: assert 'UNKNOWN' == 'SELECT'\nE         \nE         - SELECT\nE         + UNKNOWN\n\nrepos\\sqlparse\\tests\\test_regressions.py:293: AssertionError"", 'def test_issue207_runaway_format():\n        sql = \'select 1 from (select 1 as one, 2 as two, 3 from dual) t0\'\n>       p = sqlparse.format(sql, reindent=True)\n\nrepos\\sqlparse\\tests\\test_regressions.py:303: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return \'\'.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:44: in run\n    filter_.process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:240: in process\n    self._process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:102: in _process\n    func(tlist)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:233: in _process_default\n    self._split_statements(tlist) if stmts else None\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:89: in _split_statements\n    pidx, prev_ = tlist.token_prev(tidx, skip_ws=False)\nrepos\\sqlparse\\sqlparse\\sql.py:241: in token_prev\n    return self.token_next(idx, skip_ws, skip_cm, _reverse=True)\nrepos\\sqlparse\\sqlparse\\sql.py:244: in token_next\n    return self._token_matching(idx, skip_ws, skip_cm, _reverse)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Statement \'select...\' at 0x18ED20B6650>, funcs = (0,), start = False\nend = False, reverse = True\n\n    def _token_matching(self, funcs, start=0, end=None, reverse=False):\n        """"""next token that match functions""""""\n        if start is None:\n            return None\n        if not isinstance(funcs, (list, tuple)):\n            funcs = (funcs,)\n        if reverse:\n>           assert end is None\nE           AssertionError\n\nrepos\\sqlparse\\sqlparse\\sql.py:195: AssertionError', 'def test_token_next_doesnt_ignore_skip_cm():\n        sql = \'--comment\\nselect 1\'\n>       tok = sqlparse.parse(sql)[0].token_next(-1, skip_cm=True)[1]\n\nrepos\\sqlparse\\tests\\test_regressions.py:315: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\utils.py:74: in wrapped_f\n    f(tlist)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:319: in group_comments\n    eidx, end = tlist.token_prev(eidx, skip_ws=False)\nrepos\\sqlparse\\sqlparse\\sql.py:241: in token_prev\n    return self.token_next(idx, skip_ws, skip_cm, _reverse=True)\nrepos\\sqlparse\\sqlparse\\sql.py:244: in token_next\n    return self._token_matching(idx, skip_ws, skip_cm, _reverse)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Statement \'--comm...\' at 0x18ED20B67D0>, funcs = (1,), start = False\nend = False, reverse = True\n\n    def _token_matching(self, funcs, start=0, end=None, reverse=False):\n        """"""next token that match functions""""""\n        if start is None:\n            return None\n        if not isinstance(funcs, (list, tuple)):\n            funcs = (funcs,)\n        if reverse:\n>           assert end is None\nE           AssertionError\n\nrepos\\sqlparse\\sqlparse\\sql.py:195: AssertionError', 'def test_issue315_utf8_by_default():\n        # Make sure the lexer can handle utf-8 string by default correctly\n        # digest = \'齐天大圣.カラフルな雲.사랑해요\'\n        # The digest contains Chinese, Japanese and Korean characters\n        # All in \'utf-8\' encoding.\n        digest = (\n            \'\\xe9\\xbd\\x90\\xe5\\xa4\\xa9\\xe5\\xa4\\xa7\\xe5\\x9c\\xa3.\'\n            \'\\xe3\\x82\\xab\\xe3\\x83\\xa9\\xe3\\x83\\x95\\xe3\\x83\\xab\\xe3\\x81\\xaa\\xe9\'\n            \'\\x9b\\xb2.\'\n            \'\\xec\\x82\\xac\\xeb\\x9e\\x91\\xed\\x95\\xb4\\xec\\x9a\\x94\'\n        )\n        sql = f""select * from foo where bar = \'{digest}\'""\n>       formatted = sqlparse.format(sql, reindent=True)\n\nrepos\\sqlparse\\tests\\test_regressions.py:340: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return \'\'.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:44: in run\n    filter_.process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:240: in process\n    self._process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:102: in _process\n    func(tlist)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:233: in _process_default\n    self._split_statements(tlist) if stmts else None\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:89: in _split_statements\n    pidx, prev_ = tlist.token_prev(tidx, skip_ws=False)\nrepos\\sqlparse\\sqlparse\\sql.py:241: in token_prev\n    return self.token_next(idx, skip_ws, skip_cm, _reverse=True)\nrepos\\sqlparse\\sqlparse\\sql.py:244: in token_next\n    return self._token_matching(idx, skip_ws, skip_cm, _reverse)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Statement \'select...\' at 0x18ED20B61D0>, funcs = (0,), start = False\nend = False, reverse = True\n\n    def _token_matching(self, funcs, start=0, end=None, reverse=False):\n        """"""next token that match functions""""""\n        if start is None:\n            return None\n        if not isinstance(funcs, (list, tuple)):\n            funcs = (funcs,)\n        if reverse:\n>           assert end is None\nE           AssertionError\n\nrepos\\sqlparse\\sqlparse\\sql.py:195: AssertionError', ""def test_issue322_concurrently_is_keyword():\n        s = 'CREATE INDEX CONCURRENTLY myindex ON mytable(col1);'\n        p = sqlparse.parse(s)[0]\n    \n>       assert len(p.tokens) == 12\nE       AssertionError: assert 13 == 12\nE        +  where 13 = len([<DDL 'CREATE' at 0x18ED1DF3460>, <Whitespace ' ' at 0x18ED1DF2C80>, <Keyword 'INDEX' at 0x18ED1DF34C0>, <Whitespace ' ' at 0x18ED1DF2DA0>, <Keyword 'CONCUR...' at 0x18ED1DF2F80>, <Whitespace ' ' at 0x18ED1DF30A0>, ...])\nE        +    where [<DDL 'CREATE' at 0x18ED1DF3460>, <Whitespace ' ' at 0x18ED1DF2C80>, <Keyword 'INDEX' at 0x18ED1DF34C0>, <Whitespace ' ' at 0x18ED1DF2DA0>, <Keyword 'CONCUR...' at 0x18ED1DF2F80>, <Whitespace ' ' at 0x18ED1DF30A0>, ...] = <Statement 'CREATE...' at 0x18ED20B5050>.tokens\n\nrepos\\sqlparse\\tests\\test_regressions.py:349: AssertionError"", ""def test_issue489_tzcasts():\n        p = sqlparse.parse('select bar at time zone \\'UTC\\' as foo')[0]\n>       assert p.tokens[-1].has_alias() is True\nE       AssertionError: assert False is True\nE        +  where False = has_alias()\nE        +    where has_alias = <Identifier 'foo' at 0x18ED20BD450>.has_alias\n\nrepos\\sqlparse\\tests\\test_regressions.py:404: AssertionError"", 'def test_issue562_tzcasts():\n        # Test that whitespace between \'from\' and \'bar\' is retained\n>       formatted = sqlparse.format(\n            \'SELECT f(HOUR from bar AT TIME ZONE \\\'UTC\\\') from foo\', reindent=True\n        )\n\nrepos\\sqlparse\\tests\\test_regressions.py:410: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return \'\'.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:44: in run\n    filter_.process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:240: in process\n    self._process(stmt)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:102: in _process\n    func(tlist)\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:233: in _process_default\n    self._split_statements(tlist) if stmts else None\nrepos\\sqlparse\\sqlparse\\filters\\reindent.py:89: in _split_statements\n    pidx, prev_ = tlist.token_prev(tidx, skip_ws=False)\nrepos\\sqlparse\\sqlparse\\sql.py:241: in token_prev\n    return self.token_next(idx, skip_ws, skip_cm, _reverse=True)\nrepos\\sqlparse\\sqlparse\\sql.py:244: in token_next\n    return self._token_matching(idx, skip_ws, skip_cm, _reverse)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Statement \'SELECT...\' at 0x18ED20BCFD0>, funcs = (0,), start = False\nend = False, reverse = True\n\n    def _token_matching(self, funcs, start=0, end=None, reverse=False):\n        """"""next token that match functions""""""\n        if start is None:\n            return None\n        if not isinstance(funcs, (list, tuple)):\n            funcs = (funcs,)\n        if reverse:\n>           assert end is None\nE           AssertionError\n\nrepos\\sqlparse\\sqlparse\\sql.py:195: AssertionError', ""def test_format_invalid_where_clause():\n        # did raise ValueError\n        formatted = sqlparse.format('where, foo', reindent=True)\n>       assert formatted == 'where, foo'\nE       AssertionError: assert '\\nwhere, foo' == 'where, foo'\nE         \nE         + \nE           where, foo\n\nrepos\\sqlparse\\tests\\test_regressions.py:426: AssertionError"", 'def test_comment_between_cte_clauses_issue632():\n>       p, = sqlparse.parse(""""""\n            WITH foo AS (),\n                 -- A comment before baz subquery\n                 baz AS ()\n            SELECT * FROM baz;"""""")\n\nrepos\\sqlparse\\tests\\test_regressions.py:437: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\utils.py:74: in wrapped_f\n    f(tlist)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:319: in group_comments\n    eidx, end = tlist.token_prev(eidx, skip_ws=False)\nrepos\\sqlparse\\sqlparse\\sql.py:241: in token_prev\n    return self.token_next(idx, skip_ws, skip_cm, _reverse=True)\nrepos\\sqlparse\\sqlparse\\sql.py:244: in token_next\n    return self._token_matching(idx, skip_ws, skip_cm, _reverse)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Statement \' ...\' at 0x18ED20B6550>, funcs = (33,), start = False\nend = False, reverse = True\n\n    def _token_matching(self, funcs, start=0, end=None, reverse=False):\n        """"""next token that match functions""""""\n        if start is None:\n            return None\n        if not isinstance(funcs, (list, tuple)):\n            funcs = (funcs,)\n        if reverse:\n>           assert end is None\nE           AssertionError\n\nrepos\\sqlparse\\sqlparse\\sql.py:195: AssertionError', 'load_file = <function load_file.<locals>.make_load_file at 0x0000018ED1F9E8E0>\nfn = \'function_psql4.sql\'\n\n    @pytest.mark.parametrize(\'fn\', [\'function.sql\',\n                                    \'function_psql.sql\',\n                                    \'function_psql2.sql\',\n                                    \'function_psql3.sql\',\n                                    \'function_psql4.sql\'])\n    def test_split_create_function(load_file, fn):\n        sql = load_file(fn)\n>       stmts = sqlparse.parse(sql)\n\nrepos\\sqlparse\\tests\\test_split.py:32: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\utils.py:74: in wrapped_f\n    f(tlist)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:319: in group_comments\n    eidx, end = tlist.token_prev(eidx, skip_ws=False)\nrepos\\sqlparse\\sqlparse\\sql.py:241: in token_prev\n    return self.token_next(idx, skip_ws, skip_cm, _reverse=True)\nrepos\\sqlparse\\sqlparse\\sql.py:244: in token_next\n    return self._token_matching(idx, skip_ws, skip_cm, _reverse)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Statement \'CREATE...\' at 0x18ED20150D0>, funcs = (17,), start = False\nend = False, reverse = True\n\n    def _token_matching(self, funcs, start=0, end=None, reverse=False):\n        """"""next token that match functions""""""\n        if start is None:\n            return None\n        if not isinstance(funcs, (list, tuple)):\n            funcs = (funcs,)\n        if reverse:\n>           assert end is None\nE           AssertionError\n\nrepos\\sqlparse\\sqlparse\\sql.py:195: AssertionError', 'load_file = <function load_file.<locals>.make_load_file at 0x0000018ED1F9EE80>\n\n    def test_split_dashcomments(load_file):\n        sql = load_file(\'dashcomment.sql\')\n>       stmts = sqlparse.parse(sql)\n\nrepos\\sqlparse\\tests\\test_split.py:39: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\utils.py:74: in wrapped_f\n    f(tlist)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:319: in group_comments\n    eidx, end = tlist.token_prev(eidx, skip_ws=False)\nrepos\\sqlparse\\sqlparse\\sql.py:241: in token_prev\n    return self.token_next(idx, skip_ws, skip_cm, _reverse=True)\nrepos\\sqlparse\\sqlparse\\sql.py:244: in token_next\n    return self._token_matching(idx, skip_ws, skip_cm, _reverse)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Statement \' --sel...\' at 0x18ED20B6DD0>, funcs = (2,), start = False\nend = False, reverse = True\n\n    def _token_matching(self, funcs, start=0, end=None, reverse=False):\n        """"""next token that match functions""""""\n        if start is None:\n            return None\n        if not isinstance(funcs, (list, tuple)):\n            funcs = (funcs,)\n        if reverse:\n>           assert end is None\nE           AssertionError\n\nrepos\\sqlparse\\sqlparse\\sql.py:195: AssertionError', 'load_file = <function load_file.<locals>.make_load_file at 0x0000018ED1F9F100>\n\n    def test_split_begintag_2(load_file):\n        sql = load_file(\'begintag_2.sql\')\n>       stmts = sqlparse.parse(sql)\n\nrepos\\sqlparse\\tests\\test_split.py:62: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\utils.py:74: in wrapped_f\n    f(tlist)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:319: in group_comments\n    eidx, end = tlist.token_prev(eidx, skip_ws=False)\nrepos\\sqlparse\\sqlparse\\sql.py:241: in token_prev\n    return self.token_next(idx, skip_ws, skip_cm, _reverse=True)\nrepos\\sqlparse\\sqlparse\\sql.py:244: in token_next\n    return self._token_matching(idx, skip_ws, skip_cm, _reverse)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Statement \'CREATE...\' at 0x18ED20AF750>, funcs = (13,), start = False\nend = False, reverse = True\n\n    def _token_matching(self, funcs, start=0, end=None, reverse=False):\n        """"""next token that match functions""""""\n        if start is None:\n            return None\n        if not isinstance(funcs, (list, tuple)):\n            funcs = (funcs,)\n        if reverse:\n>           assert end is None\nE           AssertionError\n\nrepos\\sqlparse\\sqlparse\\sql.py:195: AssertionError', 'def test_split_comment_with_umlaut():\n        sql = (\'select * from foo;\\n\'\n               \'-- Testing an umlaut: ä\\n\'\n               \'select * from bar;\')\n>       stmts = sqlparse.parse(sql)\n\nrepos\\sqlparse\\tests\\test_split.py:78: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\utils.py:74: in wrapped_f\n    f(tlist)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:319: in group_comments\n    eidx, end = tlist.token_prev(eidx, skip_ws=False)\nrepos\\sqlparse\\sqlparse\\sql.py:241: in token_prev\n    return self.token_next(idx, skip_ws, skip_cm, _reverse=True)\nrepos\\sqlparse\\sqlparse\\sql.py:244: in token_next\n    return self._token_matching(idx, skip_ws, skip_cm, _reverse)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Statement \' -- Te...\' at 0x18ED2017CD0>, funcs = (2,), start = False\nend = False, reverse = True\n\n    def _token_matching(self, funcs, start=0, end=None, reverse=False):\n        """"""next token that match functions""""""\n        if start is None:\n            return None\n        if not isinstance(funcs, (list, tuple)):\n            funcs = (funcs,)\n        if reverse:\n>           assert end is None\nE           AssertionError\n\nrepos\\sqlparse\\sqlparse\\sql.py:195: AssertionError', 'def test_tokenlist_repr():\n        p = sqlparse.parse(\'foo, bar, baz\')[0]\n        tst = ""<IdentifierList \'foo, b...\' at 0x""\n>       assert repr(p.tokens[0])[:len(tst)] == tst\nE       assert ""<Identifier ... 0x18ED1F921D"" == ""<IdentifierL..., b...\' at 0x""\nE         \nE         - <IdentifierList \'foo, b...\' at 0x\nE         + <Identifier \'foo\' at 0x18ED1F921D\n\nrepos\\sqlparse\\tests\\test_tokenize.py:93: AssertionError', 's = \'ASC\'\n\n    @pytest.mark.parametrize(\'s\', [\n        \'ASC\', \'DESC\',\n        \'NULLS FIRST\', \'NULLS LAST\',\n        \'ASC NULLS FIRST\', \'ASC NULLS LAST\',\n        \'DESC NULLS FIRST\', \'DESC NULLS LAST\',\n    ])\n    def test_parse_order(s):  # issue487\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_tokenize.py:179: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\utils.py:74: in wrapped_f\n    f(tlist)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:388: in group_order\n    pidx, prev_ = tlist.token_prev(tidx)\nrepos\\sqlparse\\sqlparse\\sql.py:241: in token_prev\n    return self.token_next(idx, skip_ws, skip_cm, _reverse=True)\nrepos\\sqlparse\\sqlparse\\sql.py:244: in token_next\n    return self._token_matching(idx, skip_ws, skip_cm, _reverse)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Statement \'ASC\' at 0x18ED1F178D0>, funcs = (0,), start = True\nend = False, reverse = True\n\n    def _token_matching(self, funcs, start=0, end=None, reverse=False):\n        """"""next token that match functions""""""\n        if start is None:\n            return None\n        if not isinstance(funcs, (list, tuple)):\n            funcs = (funcs,)\n        if reverse:\n>           assert end is None\nE           AssertionError\n\nrepos\\sqlparse\\sqlparse\\sql.py:195: AssertionError', 's = \'DESC\'\n\n    @pytest.mark.parametrize(\'s\', [\n        \'ASC\', \'DESC\',\n        \'NULLS FIRST\', \'NULLS LAST\',\n        \'ASC NULLS FIRST\', \'ASC NULLS LAST\',\n        \'DESC NULLS FIRST\', \'DESC NULLS LAST\',\n    ])\n    def test_parse_order(s):  # issue487\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_tokenize.py:179: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\utils.py:74: in wrapped_f\n    f(tlist)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:388: in group_order\n    pidx, prev_ = tlist.token_prev(tidx)\nrepos\\sqlparse\\sqlparse\\sql.py:241: in token_prev\n    return self.token_next(idx, skip_ws, skip_cm, _reverse=True)\nrepos\\sqlparse\\sqlparse\\sql.py:244: in token_next\n    return self._token_matching(idx, skip_ws, skip_cm, _reverse)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Statement \'DESC\' at 0x18ED1F14BD0>, funcs = (0,), start = True\nend = False, reverse = True\n\n    def _token_matching(self, funcs, start=0, end=None, reverse=False):\n        """"""next token that match functions""""""\n        if start is None:\n            return None\n        if not isinstance(funcs, (list, tuple)):\n            funcs = (funcs,)\n        if reverse:\n>           assert end is None\nE           AssertionError\n\nrepos\\sqlparse\\sqlparse\\sql.py:195: AssertionError', 's = \'NULLS FIRST\'\n\n    @pytest.mark.parametrize(\'s\', [\n        \'ASC\', \'DESC\',\n        \'NULLS FIRST\', \'NULLS LAST\',\n        \'ASC NULLS FIRST\', \'ASC NULLS LAST\',\n        \'DESC NULLS FIRST\', \'DESC NULLS LAST\',\n    ])\n    def test_parse_order(s):  # issue487\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_tokenize.py:179: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\utils.py:74: in wrapped_f\n    f(tlist)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:388: in group_order\n    pidx, prev_ = tlist.token_prev(tidx)\nrepos\\sqlparse\\sqlparse\\sql.py:241: in token_prev\n    return self.token_next(idx, skip_ws, skip_cm, _reverse=True)\nrepos\\sqlparse\\sqlparse\\sql.py:244: in token_next\n    return self._token_matching(idx, skip_ws, skip_cm, _reverse)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Statement \'NULLS ...\' at 0x18ED1F16250>, funcs = (0,), start = True\nend = False, reverse = True\n\n    def _token_matching(self, funcs, start=0, end=None, reverse=False):\n        """"""next token that match functions""""""\n        if start is None:\n            return None\n        if not isinstance(funcs, (list, tuple)):\n            funcs = (funcs,)\n        if reverse:\n>           assert end is None\nE           AssertionError\n\nrepos\\sqlparse\\sqlparse\\sql.py:195: AssertionError', 's = \'NULLS LAST\'\n\n    @pytest.mark.parametrize(\'s\', [\n        \'ASC\', \'DESC\',\n        \'NULLS FIRST\', \'NULLS LAST\',\n        \'ASC NULLS FIRST\', \'ASC NULLS LAST\',\n        \'DESC NULLS FIRST\', \'DESC NULLS LAST\',\n    ])\n    def test_parse_order(s):  # issue487\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_tokenize.py:179: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\utils.py:74: in wrapped_f\n    f(tlist)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:388: in group_order\n    pidx, prev_ = tlist.token_prev(tidx)\nrepos\\sqlparse\\sqlparse\\sql.py:241: in token_prev\n    return self.token_next(idx, skip_ws, skip_cm, _reverse=True)\nrepos\\sqlparse\\sqlparse\\sql.py:244: in token_next\n    return self._token_matching(idx, skip_ws, skip_cm, _reverse)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Statement \'NULLS ...\' at 0x18ED1FFF850>, funcs = (0,), start = True\nend = False, reverse = True\n\n    def _token_matching(self, funcs, start=0, end=None, reverse=False):\n        """"""next token that match functions""""""\n        if start is None:\n            return None\n        if not isinstance(funcs, (list, tuple)):\n            funcs = (funcs,)\n        if reverse:\n>           assert end is None\nE           AssertionError\n\nrepos\\sqlparse\\sqlparse\\sql.py:195: AssertionError', 's = \'ASC NULLS FIRST\'\n\n    @pytest.mark.parametrize(\'s\', [\n        \'ASC\', \'DESC\',\n        \'NULLS FIRST\', \'NULLS LAST\',\n        \'ASC NULLS FIRST\', \'ASC NULLS LAST\',\n        \'DESC NULLS FIRST\', \'DESC NULLS LAST\',\n    ])\n    def test_parse_order(s):  # issue487\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_tokenize.py:179: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\utils.py:74: in wrapped_f\n    f(tlist)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:388: in group_order\n    pidx, prev_ = tlist.token_prev(tidx)\nrepos\\sqlparse\\sqlparse\\sql.py:241: in token_prev\n    return self.token_next(idx, skip_ws, skip_cm, _reverse=True)\nrepos\\sqlparse\\sqlparse\\sql.py:244: in token_next\n    return self._token_matching(idx, skip_ws, skip_cm, _reverse)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Statement \'ASC NU...\' at 0x18ED1F923D0>, funcs = (0,), start = True\nend = False, reverse = True\n\n    def _token_matching(self, funcs, start=0, end=None, reverse=False):\n        """"""next token that match functions""""""\n        if start is None:\n            return None\n        if not isinstance(funcs, (list, tuple)):\n            funcs = (funcs,)\n        if reverse:\n>           assert end is None\nE           AssertionError\n\nrepos\\sqlparse\\sqlparse\\sql.py:195: AssertionError', 's = \'ASC NULLS LAST\'\n\n    @pytest.mark.parametrize(\'s\', [\n        \'ASC\', \'DESC\',\n        \'NULLS FIRST\', \'NULLS LAST\',\n        \'ASC NULLS FIRST\', \'ASC NULLS LAST\',\n        \'DESC NULLS FIRST\', \'DESC NULLS LAST\',\n    ])\n    def test_parse_order(s):  # issue487\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_tokenize.py:179: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\utils.py:74: in wrapped_f\n    f(tlist)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:388: in group_order\n    pidx, prev_ = tlist.token_prev(tidx)\nrepos\\sqlparse\\sqlparse\\sql.py:241: in token_prev\n    return self.token_next(idx, skip_ws, skip_cm, _reverse=True)\nrepos\\sqlparse\\sqlparse\\sql.py:244: in token_next\n    return self._token_matching(idx, skip_ws, skip_cm, _reverse)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Statement \'ASC NU...\' at 0x18ED1FFF9D0>, funcs = (0,), start = True\nend = False, reverse = True\n\n    def _token_matching(self, funcs, start=0, end=None, reverse=False):\n        """"""next token that match functions""""""\n        if start is None:\n            return None\n        if not isinstance(funcs, (list, tuple)):\n            funcs = (funcs,)\n        if reverse:\n>           assert end is None\nE           AssertionError\n\nrepos\\sqlparse\\sqlparse\\sql.py:195: AssertionError', 's = \'DESC NULLS FIRST\'\n\n    @pytest.mark.parametrize(\'s\', [\n        \'ASC\', \'DESC\',\n        \'NULLS FIRST\', \'NULLS LAST\',\n        \'ASC NULLS FIRST\', \'ASC NULLS LAST\',\n        \'DESC NULLS FIRST\', \'DESC NULLS LAST\',\n    ])\n    def test_parse_order(s):  # issue487\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_tokenize.py:179: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\utils.py:74: in wrapped_f\n    f(tlist)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:388: in group_order\n    pidx, prev_ = tlist.token_prev(tidx)\nrepos\\sqlparse\\sqlparse\\sql.py:241: in token_prev\n    return self.token_next(idx, skip_ws, skip_cm, _reverse=True)\nrepos\\sqlparse\\sqlparse\\sql.py:244: in token_next\n    return self._token_matching(idx, skip_ws, skip_cm, _reverse)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Statement \'DESC N...\' at 0x18ED1FFF4D0>, funcs = (0,), start = True\nend = False, reverse = True\n\n    def _token_matching(self, funcs, start=0, end=None, reverse=False):\n        """"""next token that match functions""""""\n        if start is None:\n            return None\n        if not isinstance(funcs, (list, tuple)):\n            funcs = (funcs,)\n        if reverse:\n>           assert end is None\nE           AssertionError\n\nrepos\\sqlparse\\sqlparse\\sql.py:195: AssertionError', 's = \'DESC NULLS LAST\'\n\n    @pytest.mark.parametrize(\'s\', [\n        \'ASC\', \'DESC\',\n        \'NULLS FIRST\', \'NULLS LAST\',\n        \'ASC NULLS FIRST\', \'ASC NULLS LAST\',\n        \'DESC NULLS FIRST\', \'DESC NULLS LAST\',\n    ])\n    def test_parse_order(s):  # issue487\n>       p = sqlparse.parse(s)[0]\n\nrepos\\sqlparse\\tests\\test_tokenize.py:179: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:30: in parse\n    return tuple(parsestream(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:41: in run\n    stmt = grouping.group(stmt)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:450: in group\n    func(stmt)\nrepos\\sqlparse\\sqlparse\\utils.py:74: in wrapped_f\n    f(tlist)\nrepos\\sqlparse\\sqlparse\\engine\\grouping.py:388: in group_order\n    pidx, prev_ = tlist.token_prev(tidx)\nrepos\\sqlparse\\sqlparse\\sql.py:241: in token_prev\n    return self.token_next(idx, skip_ws, skip_cm, _reverse=True)\nrepos\\sqlparse\\sqlparse\\sql.py:244: in token_next\n    return self._token_matching(idx, skip_ws, skip_cm, _reverse)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <Statement \'DESC N...\' at 0x18ED217C7D0>, funcs = (0,), start = True\nend = False, reverse = True\n\n    def _token_matching(self, funcs, start=0, end=None, reverse=False):\n        """"""next token that match functions""""""\n        if start is None:\n            return None\n        if not isinstance(funcs, (list, tuple)):\n            funcs = (funcs,)\n        if reverse:\n>           assert end is None\nE           AssertionError\n\nrepos\\sqlparse\\sqlparse\\sql.py:195: AssertionError']",sqlparse/token_next,LLM
sqlparse,validate_options,"def validate_options(options):
    """"""Validates options.""""""
    kwcase = options.get('keyword_case')
    if kwcase not in [None, 'upper', 'lower', 'capitalize']:
        raise SQLParseError('Invalid value for keyword_case: {!r}'.format(kwcase))
    idcase = options.get('identifier_case')
    if idcase not in [None, 'upper', 'lower', 'capitalize']:
        raise SQLParseError('Invalid value for identifier_case: {!r}'.format(idcase))
    ofrmt = options.get('output_format')
    if ofrmt not in [None, 'sql', 'python', 'php']:
        raise SQLParseError('Unknown output format: {!r}'.format(ofrmt))
    strip_comments = options.get('strip_comments', False)
    if strip_comments not in [True, False]:
        raise SQLParseError('Invalid value for strip_comments: {!r}'.format(strip_comments))
    space_around_operators = options.get('use_space_around_operators', False)
    if space_around_operators not in [True, False]:
        raise SQLParseError('Invalid value for use_space_around_operators: {!r}'.format(space_around_operators))
    strip_ws = options.get('strip_whitespace', False)
    if strip_ws not in [True, False]:
        raise SQLParseError('Invalid value for strip_whitespace: {!r}'.format(strip_ws))
    truncate_strings = options.get('truncate_strings')
    if truncate_strings is not None:
        try:
            truncate_strings = int(truncate_strings)
        except (ValueError, TypeError):
            raise SQLParseError('Invalid value for truncate_strings: {!r}'.format(truncate_strings))
        if truncate_strings <= 1:
            raise SQLParseError('Invalid value for truncate_strings: {!r}'.format(truncate_strings))
        options['truncate_strings'] = truncate_strings
        options['truncate_char'] = options.get('truncate_char', '[...]')
    indent_columns = options.get('indent_columns', False)
    if indent_columns not in [True, False]:
        raise SQLParseError('Invalid value for indent_columns: {!r}'.format(indent_columns))
    elif indent_columns:
        options['reindent'] = True
    options['indent_columns'] = indent_columns
    reindent = options.get('reindent', False)
    if reindent not in [True, False]:
        raise SQLParseError('Invalid value for reindent: {!r}'.format(reindent))
    elif reindent:
        options['strip_whitespace'] = True
    reindent_aligned = options.get('reindent_aligned', False)
    if reindent_aligned not in [True, False]:
        raise SQLParseError('Invalid value for reindent_aligned: {!r}'.format(reindent))
    elif reindent_aligned:
        options['strip_whitespace'] = True
    indent_after_first = options.get('indent_after_first', False)
    if indent_after_first not in [True, False]:
        raise SQLParseError('Invalid value for indent_after_first: {!r}'.format(indent_after_first))
    options['indent_after_first'] = indent_after_first
    indent_tabs = options.get('indent_tabs', False)
    if indent_tabs not in [True, False]:
        raise SQLParseError('Invalid value for indent_tabs: {!r}'.format(indent_tabs))
    elif indent_tabs:
        options['indent_char'] = '\t'
    else:
        options['indent_char'] = ' '
    indent_width = options.get('indent_width', 2)
    try:
        indent_width = int(indent_width)
    except (TypeError, ValueError):
        raise SQLParseError('indent_width requires an integer')
    if indent_width < 1:
        raise SQLParseError('indent_width requires a positive integer')
    options['indent_width'] = indent_width
    wrap_after = options.get('wrap_after', 0)
    try:
        wrap_after = int(wrap_after)
    except (TypeError, ValueError):
        raise SQLParseError('wrap_after requires an integer')
    if wrap_after < 0:
        raise SQLParseError('wrap_after requires a positive integer')
    options['wrap_after'] = wrap_after
    comma_first = options.get('comma_first', False)
    if comma_first not in [True, False]:
        raise SQLParseError('comma_first requires a boolean value')
    options['comma_first'] = comma_first
    compact = options.get('compact', False)
    if compact not in [True, False]:
        raise SQLParseError('compact requires a boolean value')
    options['compact'] = compact
    right_margin = options.get('right_margin')
    if right_margin is not None:
        try:
            right_margin = int(right_margin)
        except (TypeError, ValueError):
            raise SQLParseError('right_margin requires an integer')
        if right_margin < 10:
            raise SQLParseError('right_margin requires an integer > 10')
    options['right_margin'] = right_margin
    return options","The function `validate_options` is designed to ensure that the input options provided to it meet specific criteria and are valid for a SQL parsing operation. It checks various aspects such as keyword case, identifier case, output format, strip comments, whitespace handling, string truncation, indentation settings, wrapping parameters, comma placement, compact mode, and right margin width. If any of the options do not meet the required criteria, an exception is raised. The function ultimately returns the validated options for further processing in the SQL parsing operation.",1,"def validate_options(options):
    for key in options:
        if key == 'keyword_case' and options[key] not in ['upper', 'lower']:
            raise ValueError(""Keyword case must be either 'upper' or 'lower'"")
        elif key == 'identifier_case' and options[key] not in ['upper', 'lower']:
            raise ValueError(""Identifier case must be either 'upper' or 'lower'"")
        elif key == 'output_format' and options[key] not in ['json', 'xml', 'csv']:
            raise ValueError(""Output format must be either 'json', 'xml', or 'csv'"")
        elif key == 'strip_comments' and not isinstance(options[key], bool):
            raise ValueError(""Strip comments must be a boolean value"")
        elif key == 'indentation_settings' and not isinstance(options[key], int):
            raise ValueError(""Indentation settings must be an integer"")
        elif key == 'compact_mode' and not isinstance(options[key], bool):
            raise ValueError(""Compact mode must be a boolean value"")
        elif key == 'right_margin_width' and not isinstance(options[key], int):
            raise ValueError(""Right margin width must be an integer"")

    return options","['./repos/sqlparse\\tests', './repos/sqlparse\\tests\\test_cli.py::test_cli_main_empty', './repos/sqlparse\\tests\\test_cli.py::test_parser_empty', './repos/sqlparse\\tests\\test_cli.py::test_main_help', './repos/sqlparse\\tests\\test_cli.py::test_valid_args', './repos/sqlparse\\tests\\test_cli.py::test_invalid_choice', './repos/sqlparse\\tests\\test_cli.py::test_invalid_args', './repos/sqlparse\\tests\\test_cli.py::test_invalid_infile', './repos/sqlparse\\tests\\test_cli.py::test_invalid_outfile', './repos/sqlparse\\tests\\test_cli.py::test_stdout', './repos/sqlparse\\tests\\test_cli.py::test_script', './repos/sqlparse\\tests\\test_cli.py::test_encoding_stdout', './repos/sqlparse\\tests\\test_cli.py::test_encoding_output_file', './repos/sqlparse\\tests\\test_cli.py::test_encoding_stdin', './repos/sqlparse\\tests\\test_cli.py::test_encoding', './repos/sqlparse\\tests\\test_format.py::test_format_column_ordering', './repos/sqlparse\\tests\\test_format.py::test_truncate_strings', './repos/sqlparse\\tests\\test_format.py::test_truncate_strings_invalid_option2', './repos/sqlparse\\tests\\test_format.py::test_truncate_strings_doesnt_truncate_identifiers', './repos/sqlparse\\tests\\test_format.py::test_having_produces_newline', './repos/sqlparse\\tests\\test_format.py::test_format_right_margin_invalid_option', './repos/sqlparse\\tests\\test_format.py::test_format_right_margin', './repos/sqlparse\\tests\\test_format.py::test_format_json_ops', './repos/sqlparse\\tests\\test_format.py::test_compact', './repos/sqlparse\\tests\\test_format.py::test_strip_ws_removes_trailing_ws_in_groups', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_parenthesis', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_assignment', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_typed_literal', './repos/sqlparse\\tests\\test_grouping.py::test_compare_expr', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifiers', './repos/sqlparse\\tests\\test_grouping.py::test_simple_identifiers', './repos/sqlparse\\tests\\test_grouping.py::test_group_identifier_list', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifier_wildcard', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifier_name_wildcard', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifier_invalid', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifier_invalid_in_middle', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifer_as', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifier_as_invalid', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifier_function', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_operation', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifier_list', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifier_list_subquery', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifier_list_case', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifier_list_other', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifier_list_with_inline_comments', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifiers_with_operators', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_identifier_list_with_order', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_nested_identifier_with_order', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_where', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_where_union', './repos/sqlparse\\tests\\test_grouping.py::test_returning_kw_ends_where_clause', './repos/sqlparse\\tests\\test_grouping.py::test_into_kw_ends_where_clause', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_typecast', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_alias', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_alias_case', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_alias_ctas', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_subquery_no_parens', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_alias_returns_none', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_idlist_function', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_comparison_exclude', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_function', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_function_not_in', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_varchar', './repos/sqlparse\\tests\\test_grouping.py::test_statement_get_type', './repos/sqlparse\\tests\\test_grouping.py::test_identifier_with_operators', './repos/sqlparse\\tests\\test_grouping.py::test_identifier_with_op_trailing_ws', './repos/sqlparse\\tests\\test_grouping.py::test_identifier_with_string_literals', './repos/sqlparse\\tests\\test_grouping.py::test_identifier_consumes_ordering', './repos/sqlparse\\tests\\test_grouping.py::test_comparison_with_keywords', './repos/sqlparse\\tests\\test_grouping.py::test_comparison_with_floats', './repos/sqlparse\\tests\\test_grouping.py::test_comparison_with_parenthesis', './repos/sqlparse\\tests\\test_grouping.py::test_comparison_with_strings', './repos/sqlparse\\tests\\test_grouping.py::test_like_and_ilike_comparison', './repos/sqlparse\\tests\\test_grouping.py::test_comparison_with_functions', './repos/sqlparse\\tests\\test_grouping.py::test_comparison_with_typed_literal', './repos/sqlparse\\tests\\test_grouping.py::test_forloops', './repos/sqlparse\\tests\\test_grouping.py::test_nested_for', './repos/sqlparse\\tests\\test_grouping.py::test_begin', './repos/sqlparse\\tests\\test_grouping.py::test_keyword_followed_by_parenthesis', './repos/sqlparse\\tests\\test_grouping.py::test_nested_begin', './repos/sqlparse\\tests\\test_grouping.py::test_aliased_column_without_as', './repos/sqlparse\\tests\\test_grouping.py::test_qualified_function', './repos/sqlparse\\tests\\test_grouping.py::test_aliased_function_without_as', './repos/sqlparse\\tests\\test_grouping.py::test_aliased_literal_without_as', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_as_cte', './repos/sqlparse\\tests\\test_grouping.py::test_grouping_create_table', './repos/sqlparse\\tests\\test_parse.py::test_parse_tokenize', './repos/sqlparse\\tests\\test_parse.py::test_parse_multistatement', './repos/sqlparse\\tests\\test_parse.py::test_parse_newlines', './repos/sqlparse\\tests\\test_parse.py::test_parse_within', './repos/sqlparse\\tests\\test_parse.py::test_parse_child_of', './repos/sqlparse\\tests\\test_parse.py::test_parse_has_ancestor', './repos/sqlparse\\tests\\test_parse.py::test_parse_float', './repos/sqlparse\\tests\\test_parse.py::test_parse_placeholder', './repos/sqlparse\\tests\\test_parse.py::test_parse_modulo_not_placeholder', './repos/sqlparse\\tests\\test_parse.py::test_parse_access_symbol', './repos/sqlparse\\tests\\test_parse.py::test_parse_square_brackets_notation_isnt_too_greedy', './repos/sqlparse\\tests\\test_parse.py::test_parse_square_brackets_notation_isnt_too_greedy2', './repos/sqlparse\\tests\\test_parse.py::test_parse_keyword_like_identifier', './repos/sqlparse\\tests\\test_parse.py::test_parse_function_parameter', './repos/sqlparse\\tests\\test_parse.py::test_parse_function_param_single_literal', './repos/sqlparse\\tests\\test_parse.py::test_parse_nested_function', './repos/sqlparse\\tests\\test_parse.py::test_parse_casted_params', './repos/sqlparse\\tests\\test_parse.py::test_parse_div_operator', './repos/sqlparse\\tests\\test_parse.py::test_quoted_identifier', './repos/sqlparse\\tests\\test_parse.py::test_valid_identifier_names', './repos/sqlparse\\tests\\test_parse.py::test_psql_quotation_marks', './repos/sqlparse\\tests\\test_parse.py::test_double_precision_is_builtin', './repos/sqlparse\\tests\\test_parse.py::test_placeholder', './repos/sqlparse\\tests\\test_parse.py::test_scientific_numbers', './repos/sqlparse\\tests\\test_parse.py::test_single_quotes_are_strings', './repos/sqlparse\\tests\\test_parse.py::test_double_quotes_are_identifiers', './repos/sqlparse\\tests\\test_parse.py::test_single_quotes_with_linebreaks', './repos/sqlparse\\tests\\test_parse.py::test_sqlite_identifiers', './repos/sqlparse\\tests\\test_parse.py::test_simple_1d_array_index', './repos/sqlparse\\tests\\test_parse.py::test_2d_array_index', './repos/sqlparse\\tests\\test_parse.py::test_array_index_function_result', './repos/sqlparse\\tests\\test_parse.py::test_schema_qualified_array_index', './repos/sqlparse\\tests\\test_parse.py::test_aliased_array_index', './repos/sqlparse\\tests\\test_parse.py::test_array_literal', './repos/sqlparse\\tests\\test_parse.py::test_typed_array_definition', './repos/sqlparse\\tests\\test_parse.py::test_single_line_comments', './repos/sqlparse\\tests\\test_parse.py::test_names_and_special_names', './repos/sqlparse\\tests\\test_parse.py::test_get_token_at_offset', './repos/sqlparse\\tests\\test_parse.py::test_pprint', './repos/sqlparse\\tests\\test_parse.py::test_wildcard_multiplication', './repos/sqlparse\\tests\\test_parse.py::test_stmt_tokens_parents', './repos/sqlparse\\tests\\test_parse.py::test_dbldollar_as_literal', './repos/sqlparse\\tests\\test_parse.py::test_non_ascii', './repos/sqlparse\\tests\\test_parse.py::test_get_real_name', './repos/sqlparse\\tests\\test_parse.py::test_from_subquery', './repos/sqlparse\\tests\\test_parse.py::test_parenthesis', './repos/sqlparse\\tests\\test_parse.py::test_configurable_keywords', './repos/sqlparse\\tests\\test_parse.py::test_configurable_regex', './repos/sqlparse\\tests\\test_parse.py::test_json_operators', './repos/sqlparse\\tests\\test_regressions.py::test_issue9', './repos/sqlparse\\tests\\test_regressions.py::test_issue13', './repos/sqlparse\\tests\\test_regressions.py::test_issue26', './repos/sqlparse\\tests\\test_regressions.py::test_issue34', './repos/sqlparse\\tests\\test_regressions.py::test_issue35', './repos/sqlparse\\tests\\test_regressions.py::test_issue38', './repos/sqlparse\\tests\\test_regressions.py::test_issue39', './repos/sqlparse\\tests\\test_regressions.py::test_issue40', './repos/sqlparse\\tests\\test_regressions.py::test_issue78', './repos/sqlparse\\tests\\test_regressions.py::test_issue83', './repos/sqlparse\\tests\\test_regressions.py::test_comment_encoding_when_reindent', './repos/sqlparse\\tests\\test_regressions.py::test_parse_sql_with_binary', './repos/sqlparse\\tests\\test_regressions.py::test_dont_alias_keywords', './repos/sqlparse\\tests\\test_regressions.py::test_format_accepts_encoding', './repos/sqlparse\\tests\\test_regressions.py::test_stream', './repos/sqlparse\\tests\\test_regressions.py::test_issue90', './repos/sqlparse\\tests\\test_regressions.py::test_except_formatting', './repos/sqlparse\\tests\\test_regressions.py::test_null_with_as', './repos/sqlparse\\tests\\test_regressions.py::test_issue190_open_file', './repos/sqlparse\\tests\\test_regressions.py::test_issue193_splitting_function', './repos/sqlparse\\tests\\test_regressions.py::test_issue194_splitting_function', './repos/sqlparse\\tests\\test_regressions.py::test_issue186_get_type', './repos/sqlparse\\tests\\test_regressions.py::test_issue212_py2unicode', './repos/sqlparse\\tests\\test_regressions.py::test_issue213_leadingws', './repos/sqlparse\\tests\\test_regressions.py::test_issue227_gettype_cte', './repos/sqlparse\\tests\\test_regressions.py::test_issue207_runaway_format', './repos/sqlparse\\tests\\test_regressions.py::test_token_next_doesnt_ignore_skip_cm', './repos/sqlparse\\tests\\test_regressions.py::test_issue284_as_grouping', './repos/sqlparse\\tests\\test_regressions.py::test_issue315_utf8_by_default', './repos/sqlparse\\tests\\test_regressions.py::test_issue322_concurrently_is_keyword', './repos/sqlparse\\tests\\test_regressions.py::test_issue359_index_error_assignments', './repos/sqlparse\\tests\\test_regressions.py::test_issue469_copy_as_psql_command', './repos/sqlparse\\tests\\test_regressions.py::test_issue484_comments_and_newlines', './repos/sqlparse\\tests\\test_regressions.py::test_issue485_split_multi', './repos/sqlparse\\tests\\test_regressions.py::test_issue489_tzcasts', './repos/sqlparse\\tests\\test_regressions.py::test_issue562_tzcasts', './repos/sqlparse\\tests\\test_regressions.py::test_as_in_parentheses_indents', './repos/sqlparse\\tests\\test_regressions.py::test_format_invalid_where_clause', './repos/sqlparse\\tests\\test_regressions.py::test_splitting_at_and_backticks_issue588', './repos/sqlparse\\tests\\test_regressions.py::test_comment_between_cte_clauses_issue632', './repos/sqlparse\\tests\\test_regressions.py::test_copy_issue672', './repos/sqlparse\\tests\\test_regressions.py::test_primary_key_issue740', './repos/sqlparse\\tests\\test_regressions.py::test_max_recursion', './repos/sqlparse\\tests\\test_split.py::test_split_semicolon', './repos/sqlparse\\tests\\test_split.py::test_split_backslash', './repos/sqlparse\\tests\\test_split.py::test_split_create_function', './repos/sqlparse\\tests\\test_split.py::test_split_dashcomments', './repos/sqlparse\\tests\\test_split.py::test_split_dashcomments_eol', './repos/sqlparse\\tests\\test_split.py::test_split_begintag', './repos/sqlparse\\tests\\test_split.py::test_split_begintag_2', './repos/sqlparse\\tests\\test_split.py::test_split_dropif', './repos/sqlparse\\tests\\test_split.py::test_split_comment_with_umlaut', './repos/sqlparse\\tests\\test_split.py::test_split_comment_end_of_line', './repos/sqlparse\\tests\\test_split.py::test_split_casewhen', './repos/sqlparse\\tests\\test_split.py::test_split_casewhen_procedure', './repos/sqlparse\\tests\\test_split.py::test_split_cursor_declare', './repos/sqlparse\\tests\\test_split.py::test_split_if_function', './repos/sqlparse\\tests\\test_split.py::test_split_stream', './repos/sqlparse\\tests\\test_split.py::test_split_encoding_parsestream', './repos/sqlparse\\tests\\test_split.py::test_split_unicode_parsestream', './repos/sqlparse\\tests\\test_split.py::test_split_simple', './repos/sqlparse\\tests\\test_split.py::test_split_ignores_empty_newlines', './repos/sqlparse\\tests\\test_split.py::test_split_quotes_with_new_line', './repos/sqlparse\\tests\\test_split.py::test_split_mysql_handler_for', './repos/sqlparse\\tests\\test_split.py::test_split_strip_semicolon', './repos/sqlparse\\tests\\test_split.py::test_split_strip_semicolon_procedure', './repos/sqlparse\\tests\\test_split.py::test_split_go', './repos/sqlparse\\tests\\test_split.py::test_split_multiple_case_in_begin', './repos/sqlparse\\tests\\test_tokenize.py::test_tokenize_simple', './repos/sqlparse\\tests\\test_tokenize.py::test_tokenize_backticks', './repos/sqlparse\\tests\\test_tokenize.py::test_tokenize_linebreaks', './repos/sqlparse\\tests\\test_tokenize.py::test_tokenize_inline_keywords', './repos/sqlparse\\tests\\test_tokenize.py::test_tokenize_negative_numbers', './repos/sqlparse\\tests\\test_tokenize.py::test_token_str', './repos/sqlparse\\tests\\test_tokenize.py::test_token_repr', './repos/sqlparse\\tests\\test_tokenize.py::test_token_flatten', './repos/sqlparse\\tests\\test_tokenize.py::test_tokenlist_repr', './repos/sqlparse\\tests\\test_tokenize.py::test_single_quotes', './repos/sqlparse\\tests\\test_tokenize.py::test_tokenlist_first', './repos/sqlparse\\tests\\test_tokenize.py::test_tokenlist_token_matching', './repos/sqlparse\\tests\\test_tokenize.py::test_stream_simple', './repos/sqlparse\\tests\\test_tokenize.py::test_stream_error', './repos/sqlparse\\tests\\test_tokenize.py::test_parse_join', './repos/sqlparse\\tests\\test_tokenize.py::test_parse_union', './repos/sqlparse\\tests\\test_tokenize.py::test_parse_endifloop', './repos/sqlparse\\tests\\test_tokenize.py::test_parse_order', './repos/sqlparse\\tests\\test_tokenize.py::test_parse_identifiers', './repos/sqlparse\\tests\\test_tokenize.py::test_parse_group_by', './repos/sqlparse\\tests\\test_tokenize.py::test_parse_order_by', './repos/sqlparse\\tests\\test_tokenize.py::test_parse_window_as', './repos/sqlparse\\tests\\test_tokenize.py::test_like_and_ilike_parsed_as_comparisons', './repos/sqlparse\\tests\\test_tokenize.py::test_near_like_and_ilike_parsed_appropriately', './repos/sqlparse\\tests\\test_tokenize.py::test_parse_tzcast', './repos/sqlparse\\tests\\test_tokenize.py::test_cli_commands', './repos/sqlparse\\tests\\test_utils.py::test_remove_quotes']","388 Passed, 73 Failed",388,73,"['tests/test_cli.py::test_valid_args', 'tests/test_cli.py::test_invalid_args', 'tests/test_cli.py::test_stdout', 'tests/test_cli.py::test_encoding_stdout[encoding_utf8.sql-utf-8]', 'tests/test_cli.py::test_encoding_stdout[encoding_gbk.sql-gbk]', 'tests/test_cli.py::test_encoding_output_file[encoding_utf8.sql-utf-8]', 'tests/test_cli.py::test_encoding_output_file[encoding_gbk.sql-gbk]', 'tests/test_cli.py::test_encoding_stdin[encoding_utf8.sql-utf-8]', 'tests/test_cli.py::test_encoding_stdin[encoding_gbk.sql-gbk]', 'tests/test_cli.py::test_encoding', 'tests/test_format.py::TestFormat::test_keywordcase', 'tests/test_format.py::TestFormat::test_keywordcase_invalid_option', 'tests/test_format.py::TestFormat::test_identifiercase', 'tests/test_format.py::TestFormat::test_identifiercase_invalid_option', 'tests/test_format.py::TestFormat::test_strip_comments_invalid_option', 'tests/test_format.py::TestFormat::test_strip_ws_invalid_option', 'tests/test_format.py::TestFormatReindentAligned::test_basic', 'tests/test_format.py::TestFormatReindentAligned::test_joins', 'tests/test_format.py::TestFormatReindentAligned::test_case_statement', 'tests/test_format.py::TestFormatReindentAligned::test_case_statement_with_between', 'tests/test_format.py::TestFormatReindentAligned::test_group_by', 'tests/test_format.py::TestFormatReindentAligned::test_group_by_subquery', 'tests/test_format.py::TestFormatReindentAligned::test_window_functions', 'tests/test_format.py::TestFormatReindent::test_option', 'tests/test_format.py::TestFormatReindent::test_stmts', 'tests/test_format.py::TestFormatReindent::test_keywords', 'tests/test_format.py::TestFormatReindent::test_keywords_between', 'tests/test_format.py::TestFormatReindent::test_parenthesis', 'tests/test_format.py::TestFormatReindent::test_where', 'tests/test_format.py::TestFormatReindent::test_join', 'tests/test_format.py::TestFormatReindent::test_identifier_list', 'tests/test_format.py::TestFormatReindent::test_identifier_list_with_wrap_after', 'tests/test_format.py::TestFormatReindent::test_identifier_list_comment_first', 'tests/test_format.py::TestFormatReindent::test_identifier_list_with_functions', 'tests/test_format.py::TestFormatReindent::test_long_identifier_list_with_functions', 'tests/test_format.py::TestFormatReindent::test_case', 'tests/test_format.py::TestFormatReindent::test_case2', 'tests/test_format.py::TestFormatReindent::test_nested_identifier_list', 'tests/test_format.py::TestFormatReindent::test_duplicate_linebreaks', 'tests/test_format.py::TestFormatReindent::test_keywordfunctions', 'tests/test_format.py::TestFormatReindent::test_identifier_and_functions', 'tests/test_format.py::TestFormatReindent::test_insert_values', 'tests/test_format.py::TestOutputFormat::test_python', 'tests/test_format.py::TestOutputFormat::test_python_multiple_statements', 'tests/test_format.py::TestOutputFormat::test_php', 'tests/test_format.py::TestOutputFormat::test_sql', 'tests/test_format.py::TestOutputFormat::test_invalid_option', 'tests/test_format.py::test_format_column_ordering', 'tests/test_format.py::test_truncate_strings', 'tests/test_format.py::test_truncate_strings_invalid_option2[bar]', 'tests/test_format.py::test_truncate_strings_invalid_option2[-1]', 'tests/test_format.py::test_truncate_strings_invalid_option2[0]', 'tests/test_format.py::test_truncate_strings_doesnt_truncate_identifiers[select verrrylongcolumn from foo]', 'tests/test_format.py::test_truncate_strings_doesnt_truncate_identifiers[select ""verrrylongcolumn"" from ""foo""]', 'tests/test_format.py::test_having_produces_newline', 'tests/test_format.py::test_format_right_margin_invalid_option[ten]', 'tests/test_format.py::test_format_right_margin_invalid_option[2]', 'tests/test_format.py::test_format_json_ops', 'tests/test_format.py::test_compact[case when foo then 1 else bar end-case\\n    when foo then 1\\n    else bar\\nend-case when foo then 1 else bar end]', 'tests/test_regressions.py::test_issue35', 'tests/test_regressions.py::test_issue40', 'tests/test_regressions.py::test_comment_encoding_when_reindent', 'tests/test_regressions.py::test_parse_sql_with_binary', 'tests/test_regressions.py::test_format_accepts_encoding', 'tests/test_regressions.py::test_issue90', 'tests/test_regressions.py::test_except_formatting', 'tests/test_regressions.py::test_null_with_as', 'tests/test_regressions.py::test_issue207_runaway_format', 'tests/test_regressions.py::test_issue315_utf8_by_default', 'tests/test_regressions.py::test_issue469_copy_as_psql_command', 'tests/test_regressions.py::test_issue562_tzcasts', 'tests/test_regressions.py::test_as_in_parentheses_indents', 'tests/test_regressions.py::test_format_invalid_where_clause']","['filepath = <function filepath.<locals>.make_filepath at 0x00000142B9EBE520>\n\n    def test_valid_args(filepath):\n        # test doesn\'t abort\n        path = filepath(\'function.sql\')\n>       assert sqlparse.cli.main([path, \'-r\']) is not None\n\nrepos\\sqlparse\\tests\\test_cli.py:30: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\cli.py:194: in main\n    formatter_opts = sqlparse.formatter.validate_options(formatter_opts)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\noptions = {\'comma_first\': False, \'compact\': False, \'encoding\': \'utf-8\', \'filename\': \'C:\\\\Users\\\\serine.sefardjelah\\\\OneDrive\\\\travail_PFE\\\\clean\\\\repos\\\\sqlparse\\\\tests\\\\files\\\\function.sql\', ...}\n\n    def validate_options(options):\n        for key in options:\n            if key == \'keyword_case\' and options[key] not in [\'upper\', \'lower\']:\n>               raise ValueError(""Keyword case must be either \'upper\' or \'lower\'"")\nE               ValueError: Keyword case must be either \'upper\' or \'lower\'\n\nrepos\\sqlparse\\sqlparse\\formatter.py:8: ValueError', 'filepath = <function filepath.<locals>.make_filepath at 0x00000142B9EBDE40>\ncapsys = <_pytest.capture.CaptureFixture object at 0x00000142B955EBA0>\n\n    def test_invalid_args(filepath, capsys):\n        path = filepath(\'function.sql\')\n>       sqlparse.cli.main([path, \'-r\', \'--indent_width\', \'0\'])\n\nrepos\\sqlparse\\tests\\test_cli.py:41: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\cli.py:194: in main\n    formatter_opts = sqlparse.formatter.validate_options(formatter_opts)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\noptions = {\'comma_first\': False, \'compact\': False, \'encoding\': \'utf-8\', \'filename\': \'C:\\\\Users\\\\serine.sefardjelah\\\\OneDrive\\\\travail_PFE\\\\clean\\\\repos\\\\sqlparse\\\\tests\\\\files\\\\function.sql\', ...}\n\n    def validate_options(options):\n        for key in options:\n            if key == \'keyword_case\' and options[key] not in [\'upper\', \'lower\']:\n>               raise ValueError(""Keyword case must be either \'upper\' or \'lower\'"")\nE               ValueError: Keyword case must be either \'upper\' or \'lower\'\n\nrepos\\sqlparse\\sqlparse\\formatter.py:8: ValueError', 'filepath = <function filepath.<locals>.make_filepath at 0x00000142B9FAD300>\nload_file = <function load_file.<locals>.make_load_file at 0x00000142B9FAD6C0>\ncapsys = <_pytest.capture.CaptureFixture object at 0x00000142B9D16780>\n\n    def test_stdout(filepath, load_file, capsys):\n        path = filepath(\'begintag.sql\')\n        expected = load_file(\'begintag.sql\')\n>       sqlparse.cli.main([path])\n\nrepos\\sqlparse\\tests\\test_cli.py:65: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\cli.py:194: in main\n    formatter_opts = sqlparse.formatter.validate_options(formatter_opts)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\noptions = {\'comma_first\': False, \'compact\': False, \'encoding\': \'utf-8\', \'filename\': \'C:\\\\Users\\\\serine.sefardjelah\\\\OneDrive\\\\travail_PFE\\\\clean\\\\repos\\\\sqlparse\\\\tests\\\\files\\\\begintag.sql\', ...}\n\n    def validate_options(options):\n        for key in options:\n            if key == \'keyword_case\' and options[key] not in [\'upper\', \'lower\']:\n>               raise ValueError(""Keyword case must be either \'upper\' or \'lower\'"")\nE               ValueError: Keyword case must be either \'upper\' or \'lower\'\n\nrepos\\sqlparse\\sqlparse\\formatter.py:8: ValueError', 'fpath = \'encoding_utf8.sql\', encoding = \'utf-8\'\nfilepath = <function filepath.<locals>.make_filepath at 0x00000142B9FADB20>\nload_file = <function load_file.<locals>.make_load_file at 0x00000142B9FAD260>\ncapfd = <_pytest.capture.CaptureFixture object at 0x00000142B9D16D70>\n\n    @pytest.mark.parametrize(\'fpath, encoding\', (\n        (\'encoding_utf8.sql\', \'utf-8\'),\n        (\'encoding_gbk.sql\', \'gbk\'),\n    ))\n    def test_encoding_stdout(fpath, encoding, filepath, load_file, capfd):\n        path = filepath(fpath)\n        expected = load_file(fpath, encoding)\n>       sqlparse.cli.main([path, \'--encoding\', encoding])\n\nrepos\\sqlparse\\tests\\test_cli.py:83: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\cli.py:194: in main\n    formatter_opts = sqlparse.formatter.validate_options(formatter_opts)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\noptions = {\'comma_first\': False, \'compact\': False, \'encoding\': \'utf-8\', \'filename\': \'C:\\\\Users\\\\serine.sefardjelah\\\\OneDrive\\\\travail_PFE\\\\clean\\\\repos\\\\sqlparse\\\\tests\\\\files\\\\encoding_utf8.sql\', ...}\n\n    def validate_options(options):\n        for key in options:\n            if key == \'keyword_case\' and options[key] not in [\'upper\', \'lower\']:\n>               raise ValueError(""Keyword case must be either \'upper\' or \'lower\'"")\nE               ValueError: Keyword case must be either \'upper\' or \'lower\'\n\nrepos\\sqlparse\\sqlparse\\formatter.py:8: ValueError', 'fpath = \'encoding_gbk.sql\', encoding = \'gbk\'\nfilepath = <function filepath.<locals>.make_filepath at 0x00000142B9FAEA20>\nload_file = <function load_file.<locals>.make_load_file at 0x00000142B9FAE980>\ncapfd = <_pytest.capture.CaptureFixture object at 0x00000142B9E957F0>\n\n    @pytest.mark.parametrize(\'fpath, encoding\', (\n        (\'encoding_utf8.sql\', \'utf-8\'),\n        (\'encoding_gbk.sql\', \'gbk\'),\n    ))\n    def test_encoding_stdout(fpath, encoding, filepath, load_file, capfd):\n        path = filepath(fpath)\n        expected = load_file(fpath, encoding)\n>       sqlparse.cli.main([path, \'--encoding\', encoding])\n\nrepos\\sqlparse\\tests\\test_cli.py:83: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\cli.py:194: in main\n    formatter_opts = sqlparse.formatter.validate_options(formatter_opts)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\noptions = {\'comma_first\': False, \'compact\': False, \'encoding\': \'gbk\', \'filename\': \'C:\\\\Users\\\\serine.sefardjelah\\\\OneDrive\\\\travail_PFE\\\\clean\\\\repos\\\\sqlparse\\\\tests\\\\files\\\\encoding_gbk.sql\', ...}\n\n    def validate_options(options):\n        for key in options:\n            if key == \'keyword_case\' and options[key] not in [\'upper\', \'lower\']:\n>               raise ValueError(""Keyword case must be either \'upper\' or \'lower\'"")\nE               ValueError: Keyword case must be either \'upper\' or \'lower\'\n\nrepos\\sqlparse\\sqlparse\\formatter.py:8: ValueError', 'fpath = \'encoding_utf8.sql\', encoding = \'utf-8\'\nfilepath = <function filepath.<locals>.make_filepath at 0x00000142B9FAFA60>\nload_file = <function load_file.<locals>.make_load_file at 0x00000142B9FAF9C0>\ntmpdir = local(\'C:\\\\Users\\\\serine.sefardjelah\\\\AppData\\\\Local\\\\Temp\\\\pytest-of-serine.sefardjelah\\\\pytest-2390\\\\test_encoding_output_file_enco0\')\n\n    @pytest.mark.parametrize(\'fpath, encoding\', (\n        (\'encoding_utf8.sql\', \'utf-8\'),\n        (\'encoding_gbk.sql\', \'gbk\'),\n    ))\n    def test_encoding_output_file(fpath, encoding, filepath, load_file, tmpdir):\n        in_path = filepath(fpath)\n        expected = load_file(fpath, encoding)\n        out_path = tmpdir.dirname + \'/encoding_out.sql\'\n>       sqlparse.cli.main([in_path, \'--encoding\', encoding, \'-o\', out_path])\n\nrepos\\sqlparse\\tests\\test_cli.py:96: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\cli.py:194: in main\n    formatter_opts = sqlparse.formatter.validate_options(formatter_opts)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\noptions = {\'comma_first\': False, \'compact\': False, \'encoding\': \'utf-8\', \'filename\': \'C:\\\\Users\\\\serine.sefardjelah\\\\OneDrive\\\\travail_PFE\\\\clean\\\\repos\\\\sqlparse\\\\tests\\\\files\\\\encoding_utf8.sql\', ...}\n\n    def validate_options(options):\n        for key in options:\n            if key == \'keyword_case\' and options[key] not in [\'upper\', \'lower\']:\n>               raise ValueError(""Keyword case must be either \'upper\' or \'lower\'"")\nE               ValueError: Keyword case must be either \'upper\' or \'lower\'\n\nrepos\\sqlparse\\sqlparse\\formatter.py:8: ValueError', 'fpath = \'encoding_gbk.sql\', encoding = \'gbk\'\nfilepath = <function filepath.<locals>.make_filepath at 0x00000142B9FAFE20>\nload_file = <function load_file.<locals>.make_load_file at 0x00000142B9FAFF60>\ntmpdir = local(\'C:\\\\Users\\\\serine.sefardjelah\\\\AppData\\\\Local\\\\Temp\\\\pytest-of-serine.sefardjelah\\\\pytest-2390\\\\test_encoding_output_file_enco1\')\n\n    @pytest.mark.parametrize(\'fpath, encoding\', (\n        (\'encoding_utf8.sql\', \'utf-8\'),\n        (\'encoding_gbk.sql\', \'gbk\'),\n    ))\n    def test_encoding_output_file(fpath, encoding, filepath, load_file, tmpdir):\n        in_path = filepath(fpath)\n        expected = load_file(fpath, encoding)\n        out_path = tmpdir.dirname + \'/encoding_out.sql\'\n>       sqlparse.cli.main([in_path, \'--encoding\', encoding, \'-o\', out_path])\n\nrepos\\sqlparse\\tests\\test_cli.py:96: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\cli.py:194: in main\n    formatter_opts = sqlparse.formatter.validate_options(formatter_opts)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\noptions = {\'comma_first\': False, \'compact\': False, \'encoding\': \'gbk\', \'filename\': \'C:\\\\Users\\\\serine.sefardjelah\\\\OneDrive\\\\travail_PFE\\\\clean\\\\repos\\\\sqlparse\\\\tests\\\\files\\\\encoding_gbk.sql\', ...}\n\n    def validate_options(options):\n        for key in options:\n            if key == \'keyword_case\' and options[key] not in [\'upper\', \'lower\']:\n>               raise ValueError(""Keyword case must be either \'upper\' or \'lower\'"")\nE               ValueError: Keyword case must be either \'upper\' or \'lower\'\n\nrepos\\sqlparse\\sqlparse\\formatter.py:8: ValueError', 'fpath = \'encoding_utf8.sql\', encoding = \'utf-8\'\nfilepath = <function filepath.<locals>.make_filepath at 0x00000142BA03C5E0>\nload_file = <function load_file.<locals>.make_load_file at 0x00000142BA03C680>\ncapfd = <_pytest.capture.CaptureFixture object at 0x00000142BA015AE0>\n\n    @pytest.mark.parametrize(\'fpath, encoding\', (\n        (\'encoding_utf8.sql\', \'utf-8\'),\n        (\'encoding_gbk.sql\', \'gbk\'),\n    ))\n    def test_encoding_stdin(fpath, encoding, filepath, load_file, capfd):\n        path = filepath(fpath)\n        expected = load_file(fpath, encoding)\n        old_stdin = sys.stdin\n        with open(path) as f:\n            sys.stdin = f\n>           sqlparse.cli.main([\'-\', \'--encoding\', encoding])\n\nrepos\\sqlparse\\tests\\test_cli.py:111: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\cli.py:194: in main\n    formatter_opts = sqlparse.formatter.validate_options(formatter_opts)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\noptions = {\'comma_first\': False, \'compact\': False, \'encoding\': \'utf-8\', \'filename\': \'-\', ...}\n\n    def validate_options(options):\n        for key in options:\n            if key == \'keyword_case\' and options[key] not in [\'upper\', \'lower\']:\n>               raise ValueError(""Keyword case must be either \'upper\' or \'lower\'"")\nE               ValueError: Keyword case must be either \'upper\' or \'lower\'\n\nrepos\\sqlparse\\sqlparse\\formatter.py:8: ValueError', 'fpath = \'encoding_gbk.sql\', encoding = \'gbk\'\nfilepath = <function filepath.<locals>.make_filepath at 0x00000142BA03CD60>\nload_file = <function load_file.<locals>.make_load_file at 0x00000142BA03DB20>\ncapfd = <_pytest.capture.CaptureFixture object at 0x00000142BA016580>\n\n    @pytest.mark.parametrize(\'fpath, encoding\', (\n        (\'encoding_utf8.sql\', \'utf-8\'),\n        (\'encoding_gbk.sql\', \'gbk\'),\n    ))\n    def test_encoding_stdin(fpath, encoding, filepath, load_file, capfd):\n        path = filepath(fpath)\n        expected = load_file(fpath, encoding)\n        old_stdin = sys.stdin\n        with open(path) as f:\n            sys.stdin = f\n>           sqlparse.cli.main([\'-\', \'--encoding\', encoding])\n\nrepos\\sqlparse\\tests\\test_cli.py:111: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\cli.py:194: in main\n    formatter_opts = sqlparse.formatter.validate_options(formatter_opts)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\noptions = {\'comma_first\': False, \'compact\': False, \'encoding\': \'gbk\', \'filename\': \'-\', ...}\n\n    def validate_options(options):\n        for key in options:\n            if key == \'keyword_case\' and options[key] not in [\'upper\', \'lower\']:\n>               raise ValueError(""Keyword case must be either \'upper\' or \'lower\'"")\nE               ValueError: Keyword case must be either \'upper\' or \'lower\'\n\nrepos\\sqlparse\\sqlparse\\formatter.py:8: ValueError', 'filepath = <function filepath.<locals>.make_filepath at 0x00000142BA03E200>\ncapsys = <_pytest.capture.CaptureFixture object at 0x00000142B9FF1A50>\n\n    def test_encoding(filepath, capsys):\n        path = filepath(\'test_cp1251.sql\')\n        expected = \'insert into foo values (1); -- Песня про надежду\\n\'\n>       sqlparse.cli.main([path, \'--encoding=cp1251\'])\n\nrepos\\sqlparse\\tests\\test_cli.py:120: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\cli.py:194: in main\n    formatter_opts = sqlparse.formatter.validate_options(formatter_opts)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\noptions = {\'comma_first\': False, \'compact\': False, \'encoding\': \'cp1251\', \'filename\': \'C:\\\\Users\\\\serine.sefardjelah\\\\OneDrive\\\\travail_PFE\\\\clean\\\\repos\\\\sqlparse\\\\tests\\\\files\\\\test_cp1251.sql\', ...}\n\n    def validate_options(options):\n        for key in options:\n            if key == \'keyword_case\' and options[key] not in [\'upper\', \'lower\']:\n>               raise ValueError(""Keyword case must be either \'upper\' or \'lower\'"")\nE               ValueError: Keyword case must be either \'upper\' or \'lower\'\n\nrepos\\sqlparse\\sqlparse\\formatter.py:8: ValueError', 'self = <tests.test_format.TestFormat object at 0x00000142B9B7A210>\n\n    def test_keywordcase(self):\n        sql = \'select * from bar; -- select foo\\n\'\n        res = sqlparse.format(sql, keyword_case=\'upper\')\n        assert res == \'SELECT * FROM bar; -- select foo\\n\'\n>       res = sqlparse.format(sql, keyword_case=\'capitalize\')\n\nrepos\\sqlparse\\tests\\test_format.py:12: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:56: in format\n    options = formatter.validate_options(options)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\noptions = {\'keyword_case\': \'capitalize\'}\n\n    def validate_options(options):\n        for key in options:\n            if key == \'keyword_case\' and options[key] not in [\'upper\', \'lower\']:\n>               raise ValueError(""Keyword case must be either \'upper\' or \'lower\'"")\nE               ValueError: Keyword case must be either \'upper\' or \'lower\'\n\nrepos\\sqlparse\\sqlparse\\formatter.py:8: ValueError', 'self = <tests.test_format.TestFormat object at 0x00000142B9B7A350>\n\n    def test_keywordcase_invalid_option(self):\n        sql = \'select * from bar; -- select foo\\n\'\n        with pytest.raises(SQLParseError):\n>           sqlparse.format(sql, keyword_case=\'foo\')\n\nrepos\\sqlparse\\tests\\test_format.py:20: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:56: in format\n    options = formatter.validate_options(options)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\noptions = {\'keyword_case\': \'foo\'}\n\n    def validate_options(options):\n        for key in options:\n            if key == \'keyword_case\' and options[key] not in [\'upper\', \'lower\']:\n>               raise ValueError(""Keyword case must be either \'upper\' or \'lower\'"")\nE               ValueError: Keyword case must be either \'upper\' or \'lower\'\n\nrepos\\sqlparse\\sqlparse\\formatter.py:8: ValueError', 'self = <tests.test_format.TestFormat object at 0x00000142B9B66FD0>\n\n    def test_identifiercase(self):\n        sql = \'select * from bar; -- select foo\\n\'\n        res = sqlparse.format(sql, identifier_case=\'upper\')\n        assert res == \'select * from BAR; -- select foo\\n\'\n>       res = sqlparse.format(sql, identifier_case=\'capitalize\')\n\nrepos\\sqlparse\\tests\\test_format.py:26: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:56: in format\n    options = formatter.validate_options(options)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\noptions = {\'identifier_case\': \'capitalize\'}\n\n    def validate_options(options):\n        for key in options:\n            if key == \'keyword_case\' and options[key] not in [\'upper\', \'lower\']:\n                raise ValueError(""Keyword case must be either \'upper\' or \'lower\'"")\n            elif key == \'identifier_case\' and options[key] not in [\'upper\', \'lower\']:\n>               raise ValueError(""Identifier case must be either \'upper\' or \'lower\'"")\nE               ValueError: Identifier case must be either \'upper\' or \'lower\'\n\nrepos\\sqlparse\\sqlparse\\formatter.py:10: ValueError', 'self = <tests.test_format.TestFormat object at 0x00000142B9B67A80>\n\n    def test_identifiercase_invalid_option(self):\n        sql = \'select * from bar; -- select foo\\n\'\n        with pytest.raises(SQLParseError):\n>           sqlparse.format(sql, identifier_case=\'foo\')\n\nrepos\\sqlparse\\tests\\test_format.py:34: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:56: in format\n    options = formatter.validate_options(options)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\noptions = {\'identifier_case\': \'foo\'}\n\n    def validate_options(options):\n        for key in options:\n            if key == \'keyword_case\' and options[key] not in [\'upper\', \'lower\']:\n                raise ValueError(""Keyword case must be either \'upper\' or \'lower\'"")\n            elif key == \'identifier_case\' and options[key] not in [\'upper\', \'lower\']:\n>               raise ValueError(""Identifier case must be either \'upper\' or \'lower\'"")\nE               ValueError: Identifier case must be either \'upper\' or \'lower\'\n\nrepos\\sqlparse\\sqlparse\\formatter.py:10: ValueError', 'self = <tests.test_format.TestFormat object at 0x00000142B9B5BBD0>\n\n    def test_strip_comments_invalid_option(self):\n        sql = \'select-- foo\\nfrom -- bar\\nwhere\'\n        with pytest.raises(SQLParseError):\n>           sqlparse.format(sql, strip_comments=None)\n\nrepos\\sqlparse\\tests\\test_format.py:68: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:56: in format\n    options = formatter.validate_options(options)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\noptions = {\'strip_comments\': None}\n\n    def validate_options(options):\n        for key in options:\n            if key == \'keyword_case\' and options[key] not in [\'upper\', \'lower\']:\n                raise ValueError(""Keyword case must be either \'upper\' or \'lower\'"")\n            elif key == \'identifier_case\' and options[key] not in [\'upper\', \'lower\']:\n                raise ValueError(""Identifier case must be either \'upper\' or \'lower\'"")\n            elif key == \'output_format\' and options[key] not in [\'json\', \'xml\', \'csv\']:\n                raise ValueError(""Output format must be either \'json\', \'xml\', or \'csv\'"")\n            elif key == \'strip_comments\' and (not isinstance(options[key], bool)):\n>               raise ValueError(\'Strip comments must be a boolean value\')\nE               ValueError: Strip comments must be a boolean value\n\nrepos\\sqlparse\\sqlparse\\formatter.py:14: ValueError', ""self = <tests.test_format.TestFormat object at 0x00000142B9D00AD0>\n\n    def test_strip_ws_invalid_option(self):\n        s = 'select -- foo\\nfrom    bar\\n'\n>       with pytest.raises(SQLParseError):\nE       Failed: DID NOT RAISE <class 'sqlparse.exceptions.SQLParseError'>\n\nrepos\\sqlparse\\tests\\test_format.py:138: Failed"", 'self = <tests.test_format.TestFormatReindentAligned object at 0x00000142B9B7A990>\n\n    def test_basic(self):\n        sql = """"""\n            select a, b as bb,c from table\n            join (select a * 2 as a from new_table) other\n            on table.a = other.a\n            where c is true\n            and b between 3 and 4\n            or d is \'blue\'\n            limit 10\n            """"""\n    \n>       assert self.formatter(sql) == \'\\n\'.join([\n            \'select a,\',\n            \'       b as bb,\',\n            \'       c\',\n            \'  from table\',\n            \'  join (\',\n            \'        select a * 2 as a\',\n            \'          from new_table\',\n            \'       ) other\',\n            \'    on table.a = other.a\',\n            \' where c is true\',\n            \'   and b between 3 and 4\',\n            ""    or d is \'blue\'"",\n            \' limit 10\'])\n\nrepos\\sqlparse\\tests\\test_format.py:182: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:169: in formatter\n    return sqlparse.format(sql, reindent_aligned=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:57: in format\n    stack = formatter.build_filter_stack(stack, options)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nstack = <sqlparse.engine.filter_stack.FilterStack object at 0x00000142B9CF1D30>\noptions = {\'reindent_aligned\': True}\n\n    def build_filter_stack(stack, options):\n        """"""Setup and return a filter stack.\n    \n        Args:\n          stack: :class:`~sqlparse.filters.FilterStack` instance\n          options: Dictionary with options validated by validate_options.\n        """"""\n        if options.get(\'keyword_case\'):\n            stack.preprocess.append(filters.KeywordCaseFilter(options[\'keyword_case\']))\n        if options.get(\'identifier_case\'):\n            stack.preprocess.append(filters.IdentifierCaseFilter(options[\'identifier_case\']))\n        if options.get(\'truncate_strings\'):\n            stack.preprocess.append(filters.TruncateStringFilter(width=options[\'truncate_strings\'], char=options[\'truncate_char\']))\n        if options.get(\'use_space_around_operators\', False):\n            stack.enable_grouping()\n            stack.stmtprocess.append(filters.SpacesAroundOperatorsFilter())\n        if options.get(\'strip_comments\'):\n            stack.enable_grouping()\n            stack.stmtprocess.append(filters.StripCommentsFilter())\n        if options.get(\'strip_whitespace\') or options.get(\'reindent\'):\n            stack.enable_grouping()\n            stack.stmtprocess.append(filters.StripWhitespaceFilter())\n        if options.get(\'reindent\'):\n            stack.enable_grouping()\n            stack.stmtprocess.append(filters.ReindentFilter(char=options[\'indent_char\'], width=options[\'indent_width\'], indent_after_first=options[\'indent_after_first\'], indent_columns=options[\'indent_columns\'], wrap_after=options[\'wrap_after\'], comma_first=options[\'comma_first\'], compact=options[\'compact\']))\n        if options.get(\'reindent_aligned\', False):\n            stack.enable_grouping()\n>           stack.stmtprocess.append(filters.AlignedIndentFilter(char=options[\'indent_char\']))\nE           KeyError: \'indent_char\'\n\nrepos\\sqlparse\\sqlparse\\formatter.py:50: KeyError', 'self = <tests.test_format.TestFormatReindentAligned object at 0x00000142B9B79E50>\n\n    def test_joins(self):\n        sql = """"""\n            select * from a\n            join b on a.one = b.one\n            left join c on c.two = a.two and c.three = a.three\n            full outer join d on d.three = a.three\n            cross join e on e.four = a.four\n            join f using (one, two, three)\n            """"""\n>       assert self.formatter(sql) == \'\\n\'.join([\n            \'select *\',\n            \'  from a\',\n            \'  join b\',\n            \'    on a.one = b.one\',\n            \'  left join c\',\n            \'    on c.two = a.two\',\n            \'   and c.three = a.three\',\n            \'  full outer join d\',\n            \'    on d.three = a.three\',\n            \' cross join e\',\n            \'    on e.four = a.four\',\n            \'  join f using (one, two, three)\'])\n\nrepos\\sqlparse\\tests\\test_format.py:206: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:169: in formatter\n    return sqlparse.format(sql, reindent_aligned=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:57: in format\n    stack = formatter.build_filter_stack(stack, options)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nstack = <sqlparse.engine.filter_stack.FilterStack object at 0x00000142B9C72430>\noptions = {\'reindent_aligned\': True}\n\n    def build_filter_stack(stack, options):\n        """"""Setup and return a filter stack.\n    \n        Args:\n          stack: :class:`~sqlparse.filters.FilterStack` instance\n          options: Dictionary with options validated by validate_options.\n        """"""\n        if options.get(\'keyword_case\'):\n            stack.preprocess.append(filters.KeywordCaseFilter(options[\'keyword_case\']))\n        if options.get(\'identifier_case\'):\n            stack.preprocess.append(filters.IdentifierCaseFilter(options[\'identifier_case\']))\n        if options.get(\'truncate_strings\'):\n            stack.preprocess.append(filters.TruncateStringFilter(width=options[\'truncate_strings\'], char=options[\'truncate_char\']))\n        if options.get(\'use_space_around_operators\', False):\n            stack.enable_grouping()\n            stack.stmtprocess.append(filters.SpacesAroundOperatorsFilter())\n        if options.get(\'strip_comments\'):\n            stack.enable_grouping()\n            stack.stmtprocess.append(filters.StripCommentsFilter())\n        if options.get(\'strip_whitespace\') or options.get(\'reindent\'):\n            stack.enable_grouping()\n            stack.stmtprocess.append(filters.StripWhitespaceFilter())\n        if options.get(\'reindent\'):\n            stack.enable_grouping()\n            stack.stmtprocess.append(filters.ReindentFilter(char=options[\'indent_char\'], width=options[\'indent_width\'], indent_after_first=options[\'indent_after_first\'], indent_columns=options[\'indent_columns\'], wrap_after=options[\'wrap_after\'], comma_first=options[\'comma_first\'], compact=options[\'compact\']))\n        if options.get(\'reindent_aligned\', False):\n            stack.enable_grouping()\n>           stack.stmtprocess.append(filters.AlignedIndentFilter(char=options[\'indent_char\']))\nE           KeyError: \'indent_char\'\n\nrepos\\sqlparse\\sqlparse\\formatter.py:50: KeyError', 'self = <tests.test_format.TestFormatReindentAligned object at 0x00000142B9B67CE0>\n\n    def test_case_statement(self):\n        sql = """"""\n            select a,\n            case when a = 0\n            then 1\n            when bb = 1 then 1\n            when c = 2 then 2\n            else 0 end as d,\n            extra_col\n            from table\n            where c is true\n            and b between 3 and 4\n            """"""\n>       assert self.formatter(sql) == \'\\n\'.join([\n            \'select a,\',\n            \'       case when a = 0  then 1\',\n            \'            when bb = 1 then 1\',\n            \'            when c = 2  then 2\',\n            \'            else 0\',\n            \'             end as d,\',\n            \'       extra_col\',\n            \'  from table\',\n            \' where c is true\',\n            \'   and b between 3 and 4\'])\n\nrepos\\sqlparse\\tests\\test_format.py:233: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:169: in formatter\n    return sqlparse.format(sql, reindent_aligned=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:57: in format\n    stack = formatter.build_filter_stack(stack, options)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nstack = <sqlparse.engine.filter_stack.FilterStack object at 0x00000142B9C72820>\noptions = {\'reindent_aligned\': True}\n\n    def build_filter_stack(stack, options):\n        """"""Setup and return a filter stack.\n    \n        Args:\n          stack: :class:`~sqlparse.filters.FilterStack` instance\n          options: Dictionary with options validated by validate_options.\n        """"""\n        if options.get(\'keyword_case\'):\n            stack.preprocess.append(filters.KeywordCaseFilter(options[\'keyword_case\']))\n        if options.get(\'identifier_case\'):\n            stack.preprocess.append(filters.IdentifierCaseFilter(options[\'identifier_case\']))\n        if options.get(\'truncate_strings\'):\n            stack.preprocess.append(filters.TruncateStringFilter(width=options[\'truncate_strings\'], char=options[\'truncate_char\']))\n        if options.get(\'use_space_around_operators\', False):\n            stack.enable_grouping()\n            stack.stmtprocess.append(filters.SpacesAroundOperatorsFilter())\n        if options.get(\'strip_comments\'):\n            stack.enable_grouping()\n            stack.stmtprocess.append(filters.StripCommentsFilter())\n        if options.get(\'strip_whitespace\') or options.get(\'reindent\'):\n            stack.enable_grouping()\n            stack.stmtprocess.append(filters.StripWhitespaceFilter())\n        if options.get(\'reindent\'):\n            stack.enable_grouping()\n            stack.stmtprocess.append(filters.ReindentFilter(char=options[\'indent_char\'], width=options[\'indent_width\'], indent_after_first=options[\'indent_after_first\'], indent_columns=options[\'indent_columns\'], wrap_after=options[\'wrap_after\'], comma_first=options[\'comma_first\'], compact=options[\'compact\']))\n        if options.get(\'reindent_aligned\', False):\n            stack.enable_grouping()\n>           stack.stmtprocess.append(filters.AlignedIndentFilter(char=options[\'indent_char\']))\nE           KeyError: \'indent_char\'\n\nrepos\\sqlparse\\sqlparse\\formatter.py:50: KeyError', 'self = <tests.test_format.TestFormatReindentAligned object at 0x00000142B9B67BB0>\n\n    def test_case_statement_with_between(self):\n        sql = """"""\n            select a,\n            case when a = 0\n            then 1\n            when bb = 1 then 1\n            when c = 2 then 2\n            when d between 3 and 5 then 3\n            else 0 end as d,\n            extra_col\n            from table\n            where c is true\n            and b between 3 and 4\n            """"""\n>       assert self.formatter(sql) == \'\\n\'.join([\n            \'select a,\',\n            \'       case when a = 0             then 1\',\n            \'            when bb = 1            then 1\',\n            \'            when c = 2             then 2\',\n            \'            when d between 3 and 5 then 3\',\n            \'            else 0\',\n            \'             end as d,\',\n            \'       extra_col\',\n            \'  from table\',\n            \' where c is true\',\n            \'   and b between 3 and 4\'])\n\nrepos\\sqlparse\\tests\\test_format.py:259: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:169: in formatter\n    return sqlparse.format(sql, reindent_aligned=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:57: in format\n    stack = formatter.build_filter_stack(stack, options)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nstack = <sqlparse.engine.filter_stack.FilterStack object at 0x00000142BA03BB60>\noptions = {\'reindent_aligned\': True}\n\n    def build_filter_stack(stack, options):\n        """"""Setup and return a filter stack.\n    \n        Args:\n          stack: :class:`~sqlparse.filters.FilterStack` instance\n          options: Dictionary with options validated by validate_options.\n        """"""\n        if options.get(\'keyword_case\'):\n            stack.preprocess.append(filters.KeywordCaseFilter(options[\'keyword_case\']))\n        if options.get(\'identifier_case\'):\n            stack.preprocess.append(filters.IdentifierCaseFilter(options[\'identifier_case\']))\n        if options.get(\'truncate_strings\'):\n            stack.preprocess.append(filters.TruncateStringFilter(width=options[\'truncate_strings\'], char=options[\'truncate_char\']))\n        if options.get(\'use_space_around_operators\', False):\n            stack.enable_grouping()\n            stack.stmtprocess.append(filters.SpacesAroundOperatorsFilter())\n        if options.get(\'strip_comments\'):\n            stack.enable_grouping()\n            stack.stmtprocess.append(filters.StripCommentsFilter())\n        if options.get(\'strip_whitespace\') or options.get(\'reindent\'):\n            stack.enable_grouping()\n            stack.stmtprocess.append(filters.StripWhitespaceFilter())\n        if options.get(\'reindent\'):\n            stack.enable_grouping()\n            stack.stmtprocess.append(filters.ReindentFilter(char=options[\'indent_char\'], width=options[\'indent_width\'], indent_after_first=options[\'indent_after_first\'], indent_columns=options[\'indent_columns\'], wrap_after=options[\'wrap_after\'], comma_first=options[\'comma_first\'], compact=options[\'compact\']))\n        if options.get(\'reindent_aligned\', False):\n            stack.enable_grouping()\n>           stack.stmtprocess.append(filters.AlignedIndentFilter(char=options[\'indent_char\']))\nE           KeyError: \'indent_char\'\n\nrepos\\sqlparse\\sqlparse\\formatter.py:50: KeyError', 'self = <tests.test_format.TestFormatReindentAligned object at 0x00000142B9CFA7B0>\n\n    def test_group_by(self):\n        sql = """"""\n            select a, b, c, sum(x) as sum_x, count(y) as cnt_y\n            from table\n            group by a,b,c\n            having sum(x) > 1\n            and count(y) > 5\n            order by 3,2,1\n            """"""\n>       assert self.formatter(sql) == \'\\n\'.join([\n            \'select a,\',\n            \'       b,\',\n            \'       c,\',\n            \'       sum(x) as sum_x,\',\n            \'       count(y) as cnt_y\',\n            \'  from table\',\n            \' group by a,\',\n            \'          b,\',\n            \'          c\',\n            \'having sum(x) > 1\',\n            \'   and count(y) > 5\',\n            \' order by 3,\',\n            \'          2,\',\n            \'          1\'])\n\nrepos\\sqlparse\\tests\\test_format.py:281: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:169: in formatter\n    return sqlparse.format(sql, reindent_aligned=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:57: in format\n    stack = formatter.build_filter_stack(stack, options)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nstack = <sqlparse.engine.filter_stack.FilterStack object at 0x00000142BA104050>\noptions = {\'reindent_aligned\': True}\n\n    def build_filter_stack(stack, options):\n        """"""Setup and return a filter stack.\n    \n        Args:\n          stack: :class:`~sqlparse.filters.FilterStack` instance\n          options: Dictionary with options validated by validate_options.\n        """"""\n        if options.get(\'keyword_case\'):\n            stack.preprocess.append(filters.KeywordCaseFilter(options[\'keyword_case\']))\n        if options.get(\'identifier_case\'):\n            stack.preprocess.append(filters.IdentifierCaseFilter(options[\'identifier_case\']))\n        if options.get(\'truncate_strings\'):\n            stack.preprocess.append(filters.TruncateStringFilter(width=options[\'truncate_strings\'], char=options[\'truncate_char\']))\n        if options.get(\'use_space_around_operators\', False):\n            stack.enable_grouping()\n            stack.stmtprocess.append(filters.SpacesAroundOperatorsFilter())\n        if options.get(\'strip_comments\'):\n            stack.enable_grouping()\n            stack.stmtprocess.append(filters.StripCommentsFilter())\n        if options.get(\'strip_whitespace\') or options.get(\'reindent\'):\n            stack.enable_grouping()\n            stack.stmtprocess.append(filters.StripWhitespaceFilter())\n        if options.get(\'reindent\'):\n            stack.enable_grouping()\n            stack.stmtprocess.append(filters.ReindentFilter(char=options[\'indent_char\'], width=options[\'indent_width\'], indent_after_first=options[\'indent_after_first\'], indent_columns=options[\'indent_columns\'], wrap_after=options[\'wrap_after\'], comma_first=options[\'comma_first\'], compact=options[\'compact\']))\n        if options.get(\'reindent_aligned\', False):\n            stack.enable_grouping()\n>           stack.stmtprocess.append(filters.AlignedIndentFilter(char=options[\'indent_char\']))\nE           KeyError: \'indent_char\'\n\nrepos\\sqlparse\\sqlparse\\formatter.py:50: KeyError', 'self = <tests.test_format.TestFormatReindentAligned object at 0x00000142B9B5B790>\n\n    def test_group_by_subquery(self):\n        # TODO: add subquery alias when test_identifier_list_subquery fixed\n        sql = """"""\n            select *, sum_b + 2 as mod_sum\n            from (\n              select a, sum(b) as sum_b\n              from table\n              group by a,z)\n            order by 1,2\n            """"""\n>       assert self.formatter(sql) == \'\\n\'.join([\n            \'select *,\',\n            \'       sum_b + 2 as mod_sum\',\n            \'  from (\',\n            \'        select a,\',\n            \'               sum(b) as sum_b\',\n            \'          from table\',\n            \'         group by a,\',\n            \'                  z\',\n            \'       )\',\n            \' order by 1,\',\n            \'          2\'])\n\nrepos\\sqlparse\\tests\\test_format.py:307: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:169: in formatter\n    return sqlparse.format(sql, reindent_aligned=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:57: in format\n    stack = formatter.build_filter_stack(stack, options)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nstack = <sqlparse.engine.filter_stack.FilterStack object at 0x00000142BA107A80>\noptions = {\'reindent_aligned\': True}\n\n    def build_filter_stack(stack, options):\n        """"""Setup and return a filter stack.\n    \n        Args:\n          stack: :class:`~sqlparse.filters.FilterStack` instance\n          options: Dictionary with options validated by validate_options.\n        """"""\n        if options.get(\'keyword_case\'):\n            stack.preprocess.append(filters.KeywordCaseFilter(options[\'keyword_case\']))\n        if options.get(\'identifier_case\'):\n            stack.preprocess.append(filters.IdentifierCaseFilter(options[\'identifier_case\']))\n        if options.get(\'truncate_strings\'):\n            stack.preprocess.append(filters.TruncateStringFilter(width=options[\'truncate_strings\'], char=options[\'truncate_char\']))\n        if options.get(\'use_space_around_operators\', False):\n            stack.enable_grouping()\n            stack.stmtprocess.append(filters.SpacesAroundOperatorsFilter())\n        if options.get(\'strip_comments\'):\n            stack.enable_grouping()\n            stack.stmtprocess.append(filters.StripCommentsFilter())\n        if options.get(\'strip_whitespace\') or options.get(\'reindent\'):\n            stack.enable_grouping()\n            stack.stmtprocess.append(filters.StripWhitespaceFilter())\n        if options.get(\'reindent\'):\n            stack.enable_grouping()\n            stack.stmtprocess.append(filters.ReindentFilter(char=options[\'indent_char\'], width=options[\'indent_width\'], indent_after_first=options[\'indent_after_first\'], indent_columns=options[\'indent_columns\'], wrap_after=options[\'wrap_after\'], comma_first=options[\'comma_first\'], compact=options[\'compact\']))\n        if options.get(\'reindent_aligned\', False):\n            stack.enable_grouping()\n>           stack.stmtprocess.append(filters.AlignedIndentFilter(char=options[\'indent_char\']))\nE           KeyError: \'indent_char\'\n\nrepos\\sqlparse\\sqlparse\\formatter.py:50: KeyError', 'self = <tests.test_format.TestFormatReindentAligned object at 0x00000142B9B5BDF0>\n\n    def test_window_functions(self):\n        sql = """"""\n            select a,\n            SUM(a) OVER (PARTITION BY b ORDER BY c ROWS\n            BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) as sum_a,\n            ROW_NUMBER() OVER\n            (PARTITION BY b, c ORDER BY d DESC) as row_num\n            from table""""""\n>       assert self.formatter(sql) == \'\\n\'.join([\n            \'select a,\',\n            \'       SUM(a) OVER (PARTITION BY b ORDER BY c ROWS \'\n            \'BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) as sum_a,\',\n            \'       ROW_NUMBER() OVER \'\n            \'(PARTITION BY b, c ORDER BY d DESC) as row_num\',\n            \'  from table\'])\n\nrepos\\sqlparse\\tests\\test_format.py:328: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:169: in formatter\n    return sqlparse.format(sql, reindent_aligned=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:57: in format\n    stack = formatter.build_filter_stack(stack, options)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nstack = <sqlparse.engine.filter_stack.FilterStack object at 0x00000142BA104830>\noptions = {\'reindent_aligned\': True}\n\n    def build_filter_stack(stack, options):\n        """"""Setup and return a filter stack.\n    \n        Args:\n          stack: :class:`~sqlparse.filters.FilterStack` instance\n          options: Dictionary with options validated by validate_options.\n        """"""\n        if options.get(\'keyword_case\'):\n            stack.preprocess.append(filters.KeywordCaseFilter(options[\'keyword_case\']))\n        if options.get(\'identifier_case\'):\n            stack.preprocess.append(filters.IdentifierCaseFilter(options[\'identifier_case\']))\n        if options.get(\'truncate_strings\'):\n            stack.preprocess.append(filters.TruncateStringFilter(width=options[\'truncate_strings\'], char=options[\'truncate_char\']))\n        if options.get(\'use_space_around_operators\', False):\n            stack.enable_grouping()\n            stack.stmtprocess.append(filters.SpacesAroundOperatorsFilter())\n        if options.get(\'strip_comments\'):\n            stack.enable_grouping()\n            stack.stmtprocess.append(filters.StripCommentsFilter())\n        if options.get(\'strip_whitespace\') or options.get(\'reindent\'):\n            stack.enable_grouping()\n            stack.stmtprocess.append(filters.StripWhitespaceFilter())\n        if options.get(\'reindent\'):\n            stack.enable_grouping()\n            stack.stmtprocess.append(filters.ReindentFilter(char=options[\'indent_char\'], width=options[\'indent_width\'], indent_after_first=options[\'indent_after_first\'], indent_columns=options[\'indent_columns\'], wrap_after=options[\'wrap_after\'], comma_first=options[\'comma_first\'], compact=options[\'compact\']))\n        if options.get(\'reindent_aligned\', False):\n            stack.enable_grouping()\n>           stack.stmtprocess.append(filters.AlignedIndentFilter(char=options[\'indent_char\']))\nE           KeyError: \'indent_char\'\n\nrepos\\sqlparse\\sqlparse\\formatter.py:50: KeyError', 'self = <tests.test_format.TestFormatReindent object at 0x00000142B9B7AD50>\n\n    def test_option(self):\n        with pytest.raises(SQLParseError):\n>           sqlparse.format(\'foo\', reindent=2)\n\nrepos\\sqlparse\\tests\\test_format.py:367: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:57: in format\n    stack = formatter.build_filter_stack(stack, options)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nstack = <sqlparse.engine.filter_stack.FilterStack object at 0x00000142B9CFC280>\noptions = {\'reindent\': 2}\n\n    def build_filter_stack(stack, options):\n        """"""Setup and return a filter stack.\n    \n        Args:\n          stack: :class:`~sqlparse.filters.FilterStack` instance\n          options: Dictionary with options validated by validate_options.\n        """"""\n        if options.get(\'keyword_case\'):\n            stack.preprocess.append(filters.KeywordCaseFilter(options[\'keyword_case\']))\n        if options.get(\'identifier_case\'):\n            stack.preprocess.append(filters.IdentifierCaseFilter(options[\'identifier_case\']))\n        if options.get(\'truncate_strings\'):\n            stack.preprocess.append(filters.TruncateStringFilter(width=options[\'truncate_strings\'], char=options[\'truncate_char\']))\n        if options.get(\'use_space_around_operators\', False):\n            stack.enable_grouping()\n            stack.stmtprocess.append(filters.SpacesAroundOperatorsFilter())\n        if options.get(\'strip_comments\'):\n            stack.enable_grouping()\n            stack.stmtprocess.append(filters.StripCommentsFilter())\n        if options.get(\'strip_whitespace\') or options.get(\'reindent\'):\n            stack.enable_grouping()\n            stack.stmtprocess.append(filters.StripWhitespaceFilter())\n        if options.get(\'reindent\'):\n            stack.enable_grouping()\n>           stack.stmtprocess.append(filters.ReindentFilter(char=options[\'indent_char\'], width=options[\'indent_width\'], indent_after_first=options[\'indent_after_first\'], indent_columns=options[\'indent_columns\'], wrap_after=options[\'wrap_after\'], comma_first=options[\'comma_first\'], compact=options[\'compact\']))\nE           KeyError: \'indent_char\'\n\nrepos\\sqlparse\\sqlparse\\formatter.py:47: KeyError', 'self = <tests.test_format.TestFormatReindent object at 0x00000142B9B7AE90>\n\n    def test_stmts(self):\n        f = lambda sql: sqlparse.format(sql, reindent=True)\n        s = \'select foo; select bar\'\n>       assert f(s) == \'select foo;\\n\\nselect bar\'\n\nrepos\\sqlparse\\tests\\test_format.py:384: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:382: in <lambda>\n    f = lambda sql: sqlparse.format(sql, reindent=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:57: in format\n    stack = formatter.build_filter_stack(stack, options)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nstack = <sqlparse.engine.filter_stack.FilterStack object at 0x00000142B9CF1D30>\noptions = {\'reindent\': True}\n\n    def build_filter_stack(stack, options):\n        """"""Setup and return a filter stack.\n    \n        Args:\n          stack: :class:`~sqlparse.filters.FilterStack` instance\n          options: Dictionary with options validated by validate_options.\n        """"""\n        if options.get(\'keyword_case\'):\n            stack.preprocess.append(filters.KeywordCaseFilter(options[\'keyword_case\']))\n        if options.get(\'identifier_case\'):\n            stack.preprocess.append(filters.IdentifierCaseFilter(options[\'identifier_case\']))\n        if options.get(\'truncate_strings\'):\n            stack.preprocess.append(filters.TruncateStringFilter(width=options[\'truncate_strings\'], char=options[\'truncate_char\']))\n        if options.get(\'use_space_around_operators\', False):\n            stack.enable_grouping()\n            stack.stmtprocess.append(filters.SpacesAroundOperatorsFilter())\n        if options.get(\'strip_comments\'):\n            stack.enable_grouping()\n            stack.stmtprocess.append(filters.StripCommentsFilter())\n        if options.get(\'strip_whitespace\') or options.get(\'reindent\'):\n            stack.enable_grouping()\n            stack.stmtprocess.append(filters.StripWhitespaceFilter())\n        if options.get(\'reindent\'):\n            stack.enable_grouping()\n>           stack.stmtprocess.append(filters.ReindentFilter(char=options[\'indent_char\'], width=options[\'indent_width\'], indent_after_first=options[\'indent_after_first\'], indent_columns=options[\'indent_columns\'], wrap_after=options[\'wrap_after\'], comma_first=options[\'comma_first\'], compact=options[\'compact\']))\nE           KeyError: \'indent_char\'\n\nrepos\\sqlparse\\sqlparse\\formatter.py:47: KeyError', 'self = <tests.test_format.TestFormatReindent object at 0x00000142B9D14180>\n\n    def test_keywords(self):\n        f = lambda sql: sqlparse.format(sql, reindent=True)\n        s = \'select * from foo union select * from bar;\'\n>       assert f(s) == \'\\n\'.join([\n            \'select *\',\n            \'from foo\',\n            \'union\',\n            \'select *\',\n            \'from bar;\'])\n\nrepos\\sqlparse\\tests\\test_format.py:393: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:391: in <lambda>\n    f = lambda sql: sqlparse.format(sql, reindent=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:57: in format\n    stack = formatter.build_filter_stack(stack, options)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nstack = <sqlparse.engine.filter_stack.FilterStack object at 0x00000142B9CF2660>\noptions = {\'reindent\': True}\n\n    def build_filter_stack(stack, options):\n        """"""Setup and return a filter stack.\n    \n        Args:\n          stack: :class:`~sqlparse.filters.FilterStack` instance\n          options: Dictionary with options validated by validate_options.\n        """"""\n        if options.get(\'keyword_case\'):\n            stack.preprocess.append(filters.KeywordCaseFilter(options[\'keyword_case\']))\n        if options.get(\'identifier_case\'):\n            stack.preprocess.append(filters.IdentifierCaseFilter(options[\'identifier_case\']))\n        if options.get(\'truncate_strings\'):\n            stack.preprocess.append(filters.TruncateStringFilter(width=options[\'truncate_strings\'], char=options[\'truncate_char\']))\n        if options.get(\'use_space_around_operators\', False):\n            stack.enable_grouping()\n            stack.stmtprocess.append(filters.SpacesAroundOperatorsFilter())\n        if options.get(\'strip_comments\'):\n            stack.enable_grouping()\n            stack.stmtprocess.append(filters.StripCommentsFilter())\n        if options.get(\'strip_whitespace\') or options.get(\'reindent\'):\n            stack.enable_grouping()\n            stack.stmtprocess.append(filters.StripWhitespaceFilter())\n        if options.get(\'reindent\'):\n            stack.enable_grouping()\n>           stack.stmtprocess.append(filters.ReindentFilter(char=options[\'indent_char\'], width=options[\'indent_width\'], indent_after_first=options[\'indent_after_first\'], indent_columns=options[\'indent_columns\'], wrap_after=options[\'wrap_after\'], comma_first=options[\'comma_first\'], compact=options[\'compact\']))\nE           KeyError: \'indent_char\'\n\nrepos\\sqlparse\\sqlparse\\formatter.py:47: KeyError', 'self = <tests.test_format.TestFormatReindent object at 0x00000142B9D142B0>\n\n    def test_keywords_between(self):\n        # issue 14\n        # don\'t break AND after BETWEEN\n        f = lambda sql: sqlparse.format(sql, reindent=True)\n        s = \'and foo between 1 and 2 and bar = 3\'\n>       assert f(s) == \'\\n\'.join([\n            \'\',\n            \'and foo between 1 and 2\',\n            \'and bar = 3\'])\n\nrepos\\sqlparse\\tests\\test_format.py:405: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:403: in <lambda>\n    f = lambda sql: sqlparse.format(sql, reindent=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:57: in format\n    stack = formatter.build_filter_stack(stack, options)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nstack = <sqlparse.engine.filter_stack.FilterStack object at 0x00000142BA106970>\noptions = {\'reindent\': True}\n\n    def build_filter_stack(stack, options):\n        """"""Setup and return a filter stack.\n    \n        Args:\n          stack: :class:`~sqlparse.filters.FilterStack` instance\n          options: Dictionary with options validated by validate_options.\n        """"""\n        if options.get(\'keyword_case\'):\n            stack.preprocess.append(filters.KeywordCaseFilter(options[\'keyword_case\']))\n        if options.get(\'identifier_case\'):\n            stack.preprocess.append(filters.IdentifierCaseFilter(options[\'identifier_case\']))\n        if options.get(\'truncate_strings\'):\n            stack.preprocess.append(filters.TruncateStringFilter(width=options[\'truncate_strings\'], char=options[\'truncate_char\']))\n        if options.get(\'use_space_around_operators\', False):\n            stack.enable_grouping()\n            stack.stmtprocess.append(filters.SpacesAroundOperatorsFilter())\n        if options.get(\'strip_comments\'):\n            stack.enable_grouping()\n            stack.stmtprocess.append(filters.StripCommentsFilter())\n        if options.get(\'strip_whitespace\') or options.get(\'reindent\'):\n            stack.enable_grouping()\n            stack.stmtprocess.append(filters.StripWhitespaceFilter())\n        if options.get(\'reindent\'):\n            stack.enable_grouping()\n>           stack.stmtprocess.append(filters.ReindentFilter(char=options[\'indent_char\'], width=options[\'indent_width\'], indent_after_first=options[\'indent_after_first\'], indent_columns=options[\'indent_columns\'], wrap_after=options[\'wrap_after\'], comma_first=options[\'comma_first\'], compact=options[\'compact\']))\nE           KeyError: \'indent_char\'\n\nrepos\\sqlparse\\sqlparse\\formatter.py:47: KeyError', 'self = <tests.test_format.TestFormatReindent object at 0x00000142B9D20290>\n\n    def test_parenthesis(self):\n        f = lambda sql: sqlparse.format(sql, reindent=True)\n        s = \'select count(*) from (select * from foo);\'\n>       assert f(s) == \'\\n\'.join([\n            \'select count(*)\',\n            \'from\',\n            \'  (select *\',\n            \'   from foo);\'])\n\nrepos\\sqlparse\\tests\\test_format.py:413: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:411: in <lambda>\n    f = lambda sql: sqlparse.format(sql, reindent=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:57: in format\n    stack = formatter.build_filter_stack(stack, options)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nstack = <sqlparse.engine.filter_stack.FilterStack object at 0x00000142BA105710>\noptions = {\'reindent\': True}\n\n    def build_filter_stack(stack, options):\n        """"""Setup and return a filter stack.\n    \n        Args:\n          stack: :class:`~sqlparse.filters.FilterStack` instance\n          options: Dictionary with options validated by validate_options.\n        """"""\n        if options.get(\'keyword_case\'):\n            stack.preprocess.append(filters.KeywordCaseFilter(options[\'keyword_case\']))\n        if options.get(\'identifier_case\'):\n            stack.preprocess.append(filters.IdentifierCaseFilter(options[\'identifier_case\']))\n        if options.get(\'truncate_strings\'):\n            stack.preprocess.append(filters.TruncateStringFilter(width=options[\'truncate_strings\'], char=options[\'truncate_char\']))\n        if options.get(\'use_space_around_operators\', False):\n            stack.enable_grouping()\n            stack.stmtprocess.append(filters.SpacesAroundOperatorsFilter())\n        if options.get(\'strip_comments\'):\n            stack.enable_grouping()\n            stack.stmtprocess.append(filters.StripCommentsFilter())\n        if options.get(\'strip_whitespace\') or options.get(\'reindent\'):\n            stack.enable_grouping()\n            stack.stmtprocess.append(filters.StripWhitespaceFilter())\n        if options.get(\'reindent\'):\n            stack.enable_grouping()\n>           stack.stmtprocess.append(filters.ReindentFilter(char=options[\'indent_char\'], width=options[\'indent_width\'], indent_after_first=options[\'indent_after_first\'], indent_columns=options[\'indent_columns\'], wrap_after=options[\'wrap_after\'], comma_first=options[\'comma_first\'], compact=options[\'compact\']))\nE           KeyError: \'indent_char\'\n\nrepos\\sqlparse\\sqlparse\\formatter.py:47: KeyError', 'self = <tests.test_format.TestFormatReindent object at 0x00000142B9B5BF00>\n\n    def test_where(self):\n        f = lambda sql: sqlparse.format(sql, reindent=True)\n        s = \'select * from foo where bar = 1 and baz = 2 or bzz = 3;\'\n>       assert f(s) == \'\\n\'.join([\n            \'select *\',\n            \'from foo\',\n            \'where bar = 1\',\n            \'  and baz = 2\',\n            \'  or bzz = 3;\'])\n\nrepos\\sqlparse\\tests\\test_format.py:427: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:425: in <lambda>\n    f = lambda sql: sqlparse.format(sql, reindent=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:57: in format\n    stack = formatter.build_filter_stack(stack, options)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nstack = <sqlparse.engine.filter_stack.FilterStack object at 0x00000142BA105E80>\noptions = {\'reindent\': True}\n\n    def build_filter_stack(stack, options):\n        """"""Setup and return a filter stack.\n    \n        Args:\n          stack: :class:`~sqlparse.filters.FilterStack` instance\n          options: Dictionary with options validated by validate_options.\n        """"""\n        if options.get(\'keyword_case\'):\n            stack.preprocess.append(filters.KeywordCaseFilter(options[\'keyword_case\']))\n        if options.get(\'identifier_case\'):\n            stack.preprocess.append(filters.IdentifierCaseFilter(options[\'identifier_case\']))\n        if options.get(\'truncate_strings\'):\n            stack.preprocess.append(filters.TruncateStringFilter(width=options[\'truncate_strings\'], char=options[\'truncate_char\']))\n        if options.get(\'use_space_around_operators\', False):\n            stack.enable_grouping()\n            stack.stmtprocess.append(filters.SpacesAroundOperatorsFilter())\n        if options.get(\'strip_comments\'):\n            stack.enable_grouping()\n            stack.stmtprocess.append(filters.StripCommentsFilter())\n        if options.get(\'strip_whitespace\') or options.get(\'reindent\'):\n            stack.enable_grouping()\n            stack.stmtprocess.append(filters.StripWhitespaceFilter())\n        if options.get(\'reindent\'):\n            stack.enable_grouping()\n>           stack.stmtprocess.append(filters.ReindentFilter(char=options[\'indent_char\'], width=options[\'indent_width\'], indent_after_first=options[\'indent_after_first\'], indent_columns=options[\'indent_columns\'], wrap_after=options[\'wrap_after\'], comma_first=options[\'comma_first\'], compact=options[\'compact\']))\nE           KeyError: \'indent_char\'\n\nrepos\\sqlparse\\sqlparse\\formatter.py:47: KeyError', 'self = <tests.test_format.TestFormatReindent object at 0x00000142B9D24050>\n\n    def test_join(self):\n        f = lambda sql: sqlparse.format(sql, reindent=True)\n        s = \'select * from foo join bar on 1 = 2\'\n>       assert f(s) == \'\\n\'.join([\n            \'select *\',\n            \'from foo\',\n            \'join bar on 1 = 2\'])\n\nrepos\\sqlparse\\tests\\test_format.py:445: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:443: in <lambda>\n    f = lambda sql: sqlparse.format(sql, reindent=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:57: in format\n    stack = formatter.build_filter_stack(stack, options)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nstack = <sqlparse.engine.filter_stack.FilterStack object at 0x00000142BA105DA0>\noptions = {\'reindent\': True}\n\n    def build_filter_stack(stack, options):\n        """"""Setup and return a filter stack.\n    \n        Args:\n          stack: :class:`~sqlparse.filters.FilterStack` instance\n          options: Dictionary with options validated by validate_options.\n        """"""\n        if options.get(\'keyword_case\'):\n            stack.preprocess.append(filters.KeywordCaseFilter(options[\'keyword_case\']))\n        if options.get(\'identifier_case\'):\n            stack.preprocess.append(filters.IdentifierCaseFilter(options[\'identifier_case\']))\n        if options.get(\'truncate_strings\'):\n            stack.preprocess.append(filters.TruncateStringFilter(width=options[\'truncate_strings\'], char=options[\'truncate_char\']))\n        if options.get(\'use_space_around_operators\', False):\n            stack.enable_grouping()\n            stack.stmtprocess.append(filters.SpacesAroundOperatorsFilter())\n        if options.get(\'strip_comments\'):\n            stack.enable_grouping()\n            stack.stmtprocess.append(filters.StripCommentsFilter())\n        if options.get(\'strip_whitespace\') or options.get(\'reindent\'):\n            stack.enable_grouping()\n            stack.stmtprocess.append(filters.StripWhitespaceFilter())\n        if options.get(\'reindent\'):\n            stack.enable_grouping()\n>           stack.stmtprocess.append(filters.ReindentFilter(char=options[\'indent_char\'], width=options[\'indent_width\'], indent_after_first=options[\'indent_after_first\'], indent_columns=options[\'indent_columns\'], wrap_after=options[\'wrap_after\'], comma_first=options[\'comma_first\'], compact=options[\'compact\']))\nE           KeyError: \'indent_char\'\n\nrepos\\sqlparse\\sqlparse\\formatter.py:47: KeyError', 'self = <tests.test_format.TestFormatReindent object at 0x00000142B9CE4D50>\n\n    def test_identifier_list(self):\n        f = lambda sql: sqlparse.format(sql, reindent=True)\n        s = \'select foo, bar, baz from table1, table2 where 1 = 2\'\n>       assert f(s) == \'\\n\'.join([\n            \'select foo,\',\n            \'       bar,\',\n            \'       baz\',\n            \'from table1,\',\n            \'     table2\',\n            \'where 1 = 2\'])\n\nrepos\\sqlparse\\tests\\test_format.py:468: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:466: in <lambda>\n    f = lambda sql: sqlparse.format(sql, reindent=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:57: in format\n    stack = formatter.build_filter_stack(stack, options)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nstack = <sqlparse.engine.filter_stack.FilterStack object at 0x00000142BA106430>\noptions = {\'reindent\': True}\n\n    def build_filter_stack(stack, options):\n        """"""Setup and return a filter stack.\n    \n        Args:\n          stack: :class:`~sqlparse.filters.FilterStack` instance\n          options: Dictionary with options validated by validate_options.\n        """"""\n        if options.get(\'keyword_case\'):\n            stack.preprocess.append(filters.KeywordCaseFilter(options[\'keyword_case\']))\n        if options.get(\'identifier_case\'):\n            stack.preprocess.append(filters.IdentifierCaseFilter(options[\'identifier_case\']))\n        if options.get(\'truncate_strings\'):\n            stack.preprocess.append(filters.TruncateStringFilter(width=options[\'truncate_strings\'], char=options[\'truncate_char\']))\n        if options.get(\'use_space_around_operators\', False):\n            stack.enable_grouping()\n            stack.stmtprocess.append(filters.SpacesAroundOperatorsFilter())\n        if options.get(\'strip_comments\'):\n            stack.enable_grouping()\n            stack.stmtprocess.append(filters.StripCommentsFilter())\n        if options.get(\'strip_whitespace\') or options.get(\'reindent\'):\n            stack.enable_grouping()\n            stack.stmtprocess.append(filters.StripWhitespaceFilter())\n        if options.get(\'reindent\'):\n            stack.enable_grouping()\n>           stack.stmtprocess.append(filters.ReindentFilter(char=options[\'indent_char\'], width=options[\'indent_width\'], indent_after_first=options[\'indent_after_first\'], indent_columns=options[\'indent_columns\'], wrap_after=options[\'wrap_after\'], comma_first=options[\'comma_first\'], compact=options[\'compact\']))\nE           KeyError: \'indent_char\'\n\nrepos\\sqlparse\\sqlparse\\formatter.py:47: KeyError', 'self = <tests.test_format.TestFormatReindent object at 0x00000142B9CE4E50>\n\n    def test_identifier_list_with_wrap_after(self):\n        f = lambda sql: sqlparse.format(sql, reindent=True, wrap_after=14)\n        s = \'select foo, bar, baz from table1, table2 where 1 = 2\'\n>       assert f(s) == \'\\n\'.join([\n            \'select foo, bar,\',\n            \'       baz\',\n            \'from table1, table2\',\n            \'where 1 = 2\'])\n\nrepos\\sqlparse\\tests\\test_format.py:485: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:483: in <lambda>\n    f = lambda sql: sqlparse.format(sql, reindent=True, wrap_after=14)\nrepos\\sqlparse\\sqlparse\\__init__.py:57: in format\n    stack = formatter.build_filter_stack(stack, options)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nstack = <sqlparse.engine.filter_stack.FilterStack object at 0x00000142BA106C80>\noptions = {\'reindent\': True, \'wrap_after\': 14}\n\n    def build_filter_stack(stack, options):\n        """"""Setup and return a filter stack.\n    \n        Args:\n          stack: :class:`~sqlparse.filters.FilterStack` instance\n          options: Dictionary with options validated by validate_options.\n        """"""\n        if options.get(\'keyword_case\'):\n            stack.preprocess.append(filters.KeywordCaseFilter(options[\'keyword_case\']))\n        if options.get(\'identifier_case\'):\n            stack.preprocess.append(filters.IdentifierCaseFilter(options[\'identifier_case\']))\n        if options.get(\'truncate_strings\'):\n            stack.preprocess.append(filters.TruncateStringFilter(width=options[\'truncate_strings\'], char=options[\'truncate_char\']))\n        if options.get(\'use_space_around_operators\', False):\n            stack.enable_grouping()\n            stack.stmtprocess.append(filters.SpacesAroundOperatorsFilter())\n        if options.get(\'strip_comments\'):\n            stack.enable_grouping()\n            stack.stmtprocess.append(filters.StripCommentsFilter())\n        if options.get(\'strip_whitespace\') or options.get(\'reindent\'):\n            stack.enable_grouping()\n            stack.stmtprocess.append(filters.StripWhitespaceFilter())\n        if options.get(\'reindent\'):\n            stack.enable_grouping()\n>           stack.stmtprocess.append(filters.ReindentFilter(char=options[\'indent_char\'], width=options[\'indent_width\'], indent_after_first=options[\'indent_after_first\'], indent_columns=options[\'indent_columns\'], wrap_after=options[\'wrap_after\'], comma_first=options[\'comma_first\'], compact=options[\'compact\']))\nE           KeyError: \'indent_char\'\n\nrepos\\sqlparse\\sqlparse\\formatter.py:47: KeyError', 'self = <tests.test_format.TestFormatReindent object at 0x00000142B9C2E5D0>\n\n    def test_identifier_list_comment_first(self):\n        f = lambda sql: sqlparse.format(sql, reindent=True, comma_first=True)\n        # not the 3: It cleans up whitespace too!\n        s = \'select foo, bar, baz from table where foo in (1, 2,3)\'\n>       assert f(s) == \'\\n\'.join([\n            \'select foo\',\n            \'     , bar\',\n            \'     , baz\',\n            \'from table\',\n            \'where foo in (1\',\n            \'            , 2\',\n            \'            , 3)\'])\n\nrepos\\sqlparse\\tests\\test_format.py:495: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:492: in <lambda>\n    f = lambda sql: sqlparse.format(sql, reindent=True, comma_first=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:57: in format\n    stack = formatter.build_filter_stack(stack, options)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nstack = <sqlparse.engine.filter_stack.FilterStack object at 0x00000142BA13F850>\noptions = {\'comma_first\': True, \'reindent\': True}\n\n    def build_filter_stack(stack, options):\n        """"""Setup and return a filter stack.\n    \n        Args:\n          stack: :class:`~sqlparse.filters.FilterStack` instance\n          options: Dictionary with options validated by validate_options.\n        """"""\n        if options.get(\'keyword_case\'):\n            stack.preprocess.append(filters.KeywordCaseFilter(options[\'keyword_case\']))\n        if options.get(\'identifier_case\'):\n            stack.preprocess.append(filters.IdentifierCaseFilter(options[\'identifier_case\']))\n        if options.get(\'truncate_strings\'):\n            stack.preprocess.append(filters.TruncateStringFilter(width=options[\'truncate_strings\'], char=options[\'truncate_char\']))\n        if options.get(\'use_space_around_operators\', False):\n            stack.enable_grouping()\n            stack.stmtprocess.append(filters.SpacesAroundOperatorsFilter())\n        if options.get(\'strip_comments\'):\n            stack.enable_grouping()\n            stack.stmtprocess.append(filters.StripCommentsFilter())\n        if options.get(\'strip_whitespace\') or options.get(\'reindent\'):\n            stack.enable_grouping()\n            stack.stmtprocess.append(filters.StripWhitespaceFilter())\n        if options.get(\'reindent\'):\n            stack.enable_grouping()\n>           stack.stmtprocess.append(filters.ReindentFilter(char=options[\'indent_char\'], width=options[\'indent_width\'], indent_after_first=options[\'indent_after_first\'], indent_columns=options[\'indent_columns\'], wrap_after=options[\'wrap_after\'], comma_first=options[\'comma_first\'], compact=options[\'compact\']))\nE           KeyError: \'indent_char\'\n\nrepos\\sqlparse\\sqlparse\\formatter.py:47: KeyError', 'self = <tests.test_format.TestFormatReindent object at 0x00000142B9C2E6C0>\n\n    def test_identifier_list_with_functions(self):\n        f = lambda sql: sqlparse.format(sql, reindent=True)\n        s = (""select \'abc\' as foo, coalesce(col1, col2)||col3 as bar,""\n             ""col3 from my_table"")\n>       assert f(s) == \'\\n\'.join([\n            ""select \'abc\' as foo,"",\n            ""       coalesce(col1, col2)||col3 as bar,"",\n            ""       col3"",\n            ""from my_table""])\n\nrepos\\sqlparse\\tests\\test_format.py:508: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:505: in <lambda>\n    f = lambda sql: sqlparse.format(sql, reindent=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:57: in format\n    stack = formatter.build_filter_stack(stack, options)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nstack = <sqlparse.engine.filter_stack.FilterStack object at 0x00000142BA13FEE0>\noptions = {\'reindent\': True}\n\n    def build_filter_stack(stack, options):\n        """"""Setup and return a filter stack.\n    \n        Args:\n          stack: :class:`~sqlparse.filters.FilterStack` instance\n          options: Dictionary with options validated by validate_options.\n        """"""\n        if options.get(\'keyword_case\'):\n            stack.preprocess.append(filters.KeywordCaseFilter(options[\'keyword_case\']))\n        if options.get(\'identifier_case\'):\n            stack.preprocess.append(filters.IdentifierCaseFilter(options[\'identifier_case\']))\n        if options.get(\'truncate_strings\'):\n            stack.preprocess.append(filters.TruncateStringFilter(width=options[\'truncate_strings\'], char=options[\'truncate_char\']))\n        if options.get(\'use_space_around_operators\', False):\n            stack.enable_grouping()\n            stack.stmtprocess.append(filters.SpacesAroundOperatorsFilter())\n        if options.get(\'strip_comments\'):\n            stack.enable_grouping()\n            stack.stmtprocess.append(filters.StripCommentsFilter())\n        if options.get(\'strip_whitespace\') or options.get(\'reindent\'):\n            stack.enable_grouping()\n            stack.stmtprocess.append(filters.StripWhitespaceFilter())\n        if options.get(\'reindent\'):\n            stack.enable_grouping()\n>           stack.stmtprocess.append(filters.ReindentFilter(char=options[\'indent_char\'], width=options[\'indent_width\'], indent_after_first=options[\'indent_after_first\'], indent_columns=options[\'indent_columns\'], wrap_after=options[\'wrap_after\'], comma_first=options[\'comma_first\'], compact=options[\'compact\']))\nE           KeyError: \'indent_char\'\n\nrepos\\sqlparse\\sqlparse\\formatter.py:47: KeyError', 'self = <tests.test_format.TestFormatReindent object at 0x00000142B9C783D0>\n\n    def test_long_identifier_list_with_functions(self):\n        f = lambda sql: sqlparse.format(sql, reindent=True, wrap_after=30)\n        s = (""select \'abc\' as foo, json_build_object(\'a\',  a,""\n             ""\'b\', b, \'c\', c, \'d\', d, \'e\', e) as col2""\n             ""col3 from my_table"")\n>       assert f(s) == \'\\n\'.join([\n            ""select \'abc\' as foo,"",\n            ""       json_build_object(\'a\',"",\n            ""         a, \'b\', b, \'c\', c, \'d\', d,"",\n            ""         \'e\', e) as col2col3"",\n            ""from my_table""])\n\nrepos\\sqlparse\\tests\\test_format.py:519: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:515: in <lambda>\n    f = lambda sql: sqlparse.format(sql, reindent=True, wrap_after=30)\nrepos\\sqlparse\\sqlparse\\__init__.py:57: in format\n    stack = formatter.build_filter_stack(stack, options)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nstack = <sqlparse.engine.filter_stack.FilterStack object at 0x00000142BA13EBA0>\noptions = {\'reindent\': True, \'wrap_after\': 30}\n\n    def build_filter_stack(stack, options):\n        """"""Setup and return a filter stack.\n    \n        Args:\n          stack: :class:`~sqlparse.filters.FilterStack` instance\n          options: Dictionary with options validated by validate_options.\n        """"""\n        if options.get(\'keyword_case\'):\n            stack.preprocess.append(filters.KeywordCaseFilter(options[\'keyword_case\']))\n        if options.get(\'identifier_case\'):\n            stack.preprocess.append(filters.IdentifierCaseFilter(options[\'identifier_case\']))\n        if options.get(\'truncate_strings\'):\n            stack.preprocess.append(filters.TruncateStringFilter(width=options[\'truncate_strings\'], char=options[\'truncate_char\']))\n        if options.get(\'use_space_around_operators\', False):\n            stack.enable_grouping()\n            stack.stmtprocess.append(filters.SpacesAroundOperatorsFilter())\n        if options.get(\'strip_comments\'):\n            stack.enable_grouping()\n            stack.stmtprocess.append(filters.StripCommentsFilter())\n        if options.get(\'strip_whitespace\') or options.get(\'reindent\'):\n            stack.enable_grouping()\n            stack.stmtprocess.append(filters.StripWhitespaceFilter())\n        if options.get(\'reindent\'):\n            stack.enable_grouping()\n>           stack.stmtprocess.append(filters.ReindentFilter(char=options[\'indent_char\'], width=options[\'indent_width\'], indent_after_first=options[\'indent_after_first\'], indent_columns=options[\'indent_columns\'], wrap_after=options[\'wrap_after\'], comma_first=options[\'comma_first\'], compact=options[\'compact\']))\nE           KeyError: \'indent_char\'\n\nrepos\\sqlparse\\sqlparse\\formatter.py:47: KeyError', 'self = <tests.test_format.TestFormatReindent object at 0x00000142B9C782F0>\n\n    def test_case(self):\n        f = lambda sql: sqlparse.format(sql, reindent=True)\n        s = \'case when foo = 1 then 2 when foo = 3 then 4 else 5 end\'\n>       assert f(s) == \'\\n\'.join([\n            \'case\',\n            \'    when foo = 1 then 2\',\n            \'    when foo = 3 then 4\',\n            \'    else 5\',\n            \'end\'])\n\nrepos\\sqlparse\\tests\\test_format.py:529: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:527: in <lambda>\n    f = lambda sql: sqlparse.format(sql, reindent=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:57: in format\n    stack = formatter.build_filter_stack(stack, options)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nstack = <sqlparse.engine.filter_stack.FilterStack object at 0x00000142BA13C910>\noptions = {\'reindent\': True}\n\n    def build_filter_stack(stack, options):\n        """"""Setup and return a filter stack.\n    \n        Args:\n          stack: :class:`~sqlparse.filters.FilterStack` instance\n          options: Dictionary with options validated by validate_options.\n        """"""\n        if options.get(\'keyword_case\'):\n            stack.preprocess.append(filters.KeywordCaseFilter(options[\'keyword_case\']))\n        if options.get(\'identifier_case\'):\n            stack.preprocess.append(filters.IdentifierCaseFilter(options[\'identifier_case\']))\n        if options.get(\'truncate_strings\'):\n            stack.preprocess.append(filters.TruncateStringFilter(width=options[\'truncate_strings\'], char=options[\'truncate_char\']))\n        if options.get(\'use_space_around_operators\', False):\n            stack.enable_grouping()\n            stack.stmtprocess.append(filters.SpacesAroundOperatorsFilter())\n        if options.get(\'strip_comments\'):\n            stack.enable_grouping()\n            stack.stmtprocess.append(filters.StripCommentsFilter())\n        if options.get(\'strip_whitespace\') or options.get(\'reindent\'):\n            stack.enable_grouping()\n            stack.stmtprocess.append(filters.StripWhitespaceFilter())\n        if options.get(\'reindent\'):\n            stack.enable_grouping()\n>           stack.stmtprocess.append(filters.ReindentFilter(char=options[\'indent_char\'], width=options[\'indent_width\'], indent_after_first=options[\'indent_after_first\'], indent_columns=options[\'indent_columns\'], wrap_after=options[\'wrap_after\'], comma_first=options[\'comma_first\'], compact=options[\'compact\']))\nE           KeyError: \'indent_char\'\n\nrepos\\sqlparse\\sqlparse\\formatter.py:47: KeyError', 'self = <tests.test_format.TestFormatReindent object at 0x00000142B9CA6000>\n\n    def test_case2(self):\n        f = lambda sql: sqlparse.format(sql, reindent=True)\n        s = \'case(foo) when bar = 1 then 2 else 3 end\'\n>       assert f(s) == \'\\n\'.join([\n            \'case(foo)\',\n            \'    when bar = 1 then 2\',\n            \'    else 3\',\n            \'end\'])\n\nrepos\\sqlparse\\tests\\test_format.py:539: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:537: in <lambda>\n    f = lambda sql: sqlparse.format(sql, reindent=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:57: in format\n    stack = formatter.build_filter_stack(stack, options)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nstack = <sqlparse.engine.filter_stack.FilterStack object at 0x00000142BA13C980>\noptions = {\'reindent\': True}\n\n    def build_filter_stack(stack, options):\n        """"""Setup and return a filter stack.\n    \n        Args:\n          stack: :class:`~sqlparse.filters.FilterStack` instance\n          options: Dictionary with options validated by validate_options.\n        """"""\n        if options.get(\'keyword_case\'):\n            stack.preprocess.append(filters.KeywordCaseFilter(options[\'keyword_case\']))\n        if options.get(\'identifier_case\'):\n            stack.preprocess.append(filters.IdentifierCaseFilter(options[\'identifier_case\']))\n        if options.get(\'truncate_strings\'):\n            stack.preprocess.append(filters.TruncateStringFilter(width=options[\'truncate_strings\'], char=options[\'truncate_char\']))\n        if options.get(\'use_space_around_operators\', False):\n            stack.enable_grouping()\n            stack.stmtprocess.append(filters.SpacesAroundOperatorsFilter())\n        if options.get(\'strip_comments\'):\n            stack.enable_grouping()\n            stack.stmtprocess.append(filters.StripCommentsFilter())\n        if options.get(\'strip_whitespace\') or options.get(\'reindent\'):\n            stack.enable_grouping()\n            stack.stmtprocess.append(filters.StripWhitespaceFilter())\n        if options.get(\'reindent\'):\n            stack.enable_grouping()\n>           stack.stmtprocess.append(filters.ReindentFilter(char=options[\'indent_char\'], width=options[\'indent_width\'], indent_after_first=options[\'indent_after_first\'], indent_columns=options[\'indent_columns\'], wrap_after=options[\'wrap_after\'], comma_first=options[\'comma_first\'], compact=options[\'compact\']))\nE           KeyError: \'indent_char\'\n\nrepos\\sqlparse\\sqlparse\\formatter.py:47: KeyError', 'self = <tests.test_format.TestFormatReindent object at 0x00000142B9B22ED0>\n\n    def test_nested_identifier_list(self):\n        # issue4\n        f = lambda sql: sqlparse.format(sql, reindent=True)\n        s = \'(foo as bar, bar1, bar2 as bar3, b4 as b5)\'\n>       assert f(s) == \'\\n\'.join([\n            \'(foo as bar,\',\n            \' bar1,\',\n            \' bar2 as bar3,\',\n            \' b4 as b5)\'])\n\nrepos\\sqlparse\\tests\\test_format.py:549: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:547: in <lambda>\n    f = lambda sql: sqlparse.format(sql, reindent=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:57: in format\n    stack = formatter.build_filter_stack(stack, options)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nstack = <sqlparse.engine.filter_stack.FilterStack object at 0x00000142BA13D080>\noptions = {\'reindent\': True}\n\n    def build_filter_stack(stack, options):\n        """"""Setup and return a filter stack.\n    \n        Args:\n          stack: :class:`~sqlparse.filters.FilterStack` instance\n          options: Dictionary with options validated by validate_options.\n        """"""\n        if options.get(\'keyword_case\'):\n            stack.preprocess.append(filters.KeywordCaseFilter(options[\'keyword_case\']))\n        if options.get(\'identifier_case\'):\n            stack.preprocess.append(filters.IdentifierCaseFilter(options[\'identifier_case\']))\n        if options.get(\'truncate_strings\'):\n            stack.preprocess.append(filters.TruncateStringFilter(width=options[\'truncate_strings\'], char=options[\'truncate_char\']))\n        if options.get(\'use_space_around_operators\', False):\n            stack.enable_grouping()\n            stack.stmtprocess.append(filters.SpacesAroundOperatorsFilter())\n        if options.get(\'strip_comments\'):\n            stack.enable_grouping()\n            stack.stmtprocess.append(filters.StripCommentsFilter())\n        if options.get(\'strip_whitespace\') or options.get(\'reindent\'):\n            stack.enable_grouping()\n            stack.stmtprocess.append(filters.StripWhitespaceFilter())\n        if options.get(\'reindent\'):\n            stack.enable_grouping()\n>           stack.stmtprocess.append(filters.ReindentFilter(char=options[\'indent_char\'], width=options[\'indent_width\'], indent_after_first=options[\'indent_after_first\'], indent_columns=options[\'indent_columns\'], wrap_after=options[\'wrap_after\'], comma_first=options[\'comma_first\'], compact=options[\'compact\']))\nE           KeyError: \'indent_char\'\n\nrepos\\sqlparse\\sqlparse\\formatter.py:47: KeyError', 'self = <tests.test_format.TestFormatReindent object at 0x00000142B9B237D0>\n\n    def test_duplicate_linebreaks(self):\n        # issue3\n        f = lambda sql: sqlparse.format(sql, reindent=True)\n        s = \'select c1 -- column1\\nfrom foo\'\n>       assert f(s) == \'\\n\'.join([\n            \'select c1 -- column1\',\n            \'from foo\'])\n\nrepos\\sqlparse\\tests\\test_format.py:559: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:557: in <lambda>\n    f = lambda sql: sqlparse.format(sql, reindent=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:57: in format\n    stack = formatter.build_filter_stack(stack, options)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nstack = <sqlparse.engine.filter_stack.FilterStack object at 0x00000142BA13E120>\noptions = {\'reindent\': True}\n\n    def build_filter_stack(stack, options):\n        """"""Setup and return a filter stack.\n    \n        Args:\n          stack: :class:`~sqlparse.filters.FilterStack` instance\n          options: Dictionary with options validated by validate_options.\n        """"""\n        if options.get(\'keyword_case\'):\n            stack.preprocess.append(filters.KeywordCaseFilter(options[\'keyword_case\']))\n        if options.get(\'identifier_case\'):\n            stack.preprocess.append(filters.IdentifierCaseFilter(options[\'identifier_case\']))\n        if options.get(\'truncate_strings\'):\n            stack.preprocess.append(filters.TruncateStringFilter(width=options[\'truncate_strings\'], char=options[\'truncate_char\']))\n        if options.get(\'use_space_around_operators\', False):\n            stack.enable_grouping()\n            stack.stmtprocess.append(filters.SpacesAroundOperatorsFilter())\n        if options.get(\'strip_comments\'):\n            stack.enable_grouping()\n            stack.stmtprocess.append(filters.StripCommentsFilter())\n        if options.get(\'strip_whitespace\') or options.get(\'reindent\'):\n            stack.enable_grouping()\n            stack.stmtprocess.append(filters.StripWhitespaceFilter())\n        if options.get(\'reindent\'):\n            stack.enable_grouping()\n>           stack.stmtprocess.append(filters.ReindentFilter(char=options[\'indent_char\'], width=options[\'indent_width\'], indent_after_first=options[\'indent_after_first\'], indent_columns=options[\'indent_columns\'], wrap_after=options[\'wrap_after\'], comma_first=options[\'comma_first\'], compact=options[\'compact\']))\nE           KeyError: \'indent_char\'\n\nrepos\\sqlparse\\sqlparse\\formatter.py:47: KeyError', 'self = <tests.test_format.TestFormatReindent object at 0x00000142B9C297B0>\n\n    def test_keywordfunctions(self):\n        # issue36\n        f = lambda sql: sqlparse.format(sql, reindent=True)\n        s = \'select max(a) b, foo, bar\'\n>       assert f(s) == \'\\n\'.join([\n            \'select max(a) b,\',\n            \'       foo,\',\n            \'       bar\'])\n\nrepos\\sqlparse\\tests\\test_format.py:583: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:581: in <lambda>\n    f = lambda sql: sqlparse.format(sql, reindent=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:57: in format\n    stack = formatter.build_filter_stack(stack, options)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nstack = <sqlparse.engine.filter_stack.FilterStack object at 0x00000142BA13FC40>\noptions = {\'reindent\': True}\n\n    def build_filter_stack(stack, options):\n        """"""Setup and return a filter stack.\n    \n        Args:\n          stack: :class:`~sqlparse.filters.FilterStack` instance\n          options: Dictionary with options validated by validate_options.\n        """"""\n        if options.get(\'keyword_case\'):\n            stack.preprocess.append(filters.KeywordCaseFilter(options[\'keyword_case\']))\n        if options.get(\'identifier_case\'):\n            stack.preprocess.append(filters.IdentifierCaseFilter(options[\'identifier_case\']))\n        if options.get(\'truncate_strings\'):\n            stack.preprocess.append(filters.TruncateStringFilter(width=options[\'truncate_strings\'], char=options[\'truncate_char\']))\n        if options.get(\'use_space_around_operators\', False):\n            stack.enable_grouping()\n            stack.stmtprocess.append(filters.SpacesAroundOperatorsFilter())\n        if options.get(\'strip_comments\'):\n            stack.enable_grouping()\n            stack.stmtprocess.append(filters.StripCommentsFilter())\n        if options.get(\'strip_whitespace\') or options.get(\'reindent\'):\n            stack.enable_grouping()\n            stack.stmtprocess.append(filters.StripWhitespaceFilter())\n        if options.get(\'reindent\'):\n            stack.enable_grouping()\n>           stack.stmtprocess.append(filters.ReindentFilter(char=options[\'indent_char\'], width=options[\'indent_width\'], indent_after_first=options[\'indent_after_first\'], indent_columns=options[\'indent_columns\'], wrap_after=options[\'wrap_after\'], comma_first=options[\'comma_first\'], compact=options[\'compact\']))\nE           KeyError: \'indent_char\'\n\nrepos\\sqlparse\\sqlparse\\formatter.py:47: KeyError', 'self = <tests.test_format.TestFormatReindent object at 0x00000142B9C29860>\n\n    def test_identifier_and_functions(self):\n        # issue45\n        f = lambda sql: sqlparse.format(sql, reindent=True)\n        s = \'select foo.bar, nvl(1) from dual\'\n>       assert f(s) == \'\\n\'.join([\n            \'select foo.bar,\',\n            \'       nvl(1)\',\n            \'from dual\'])\n\nrepos\\sqlparse\\tests\\test_format.py:592: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:590: in <lambda>\n    f = lambda sql: sqlparse.format(sql, reindent=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:57: in format\n    stack = formatter.build_filter_stack(stack, options)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nstack = <sqlparse.engine.filter_stack.FilterStack object at 0x00000142BA13F620>\noptions = {\'reindent\': True}\n\n    def build_filter_stack(stack, options):\n        """"""Setup and return a filter stack.\n    \n        Args:\n          stack: :class:`~sqlparse.filters.FilterStack` instance\n          options: Dictionary with options validated by validate_options.\n        """"""\n        if options.get(\'keyword_case\'):\n            stack.preprocess.append(filters.KeywordCaseFilter(options[\'keyword_case\']))\n        if options.get(\'identifier_case\'):\n            stack.preprocess.append(filters.IdentifierCaseFilter(options[\'identifier_case\']))\n        if options.get(\'truncate_strings\'):\n            stack.preprocess.append(filters.TruncateStringFilter(width=options[\'truncate_strings\'], char=options[\'truncate_char\']))\n        if options.get(\'use_space_around_operators\', False):\n            stack.enable_grouping()\n            stack.stmtprocess.append(filters.SpacesAroundOperatorsFilter())\n        if options.get(\'strip_comments\'):\n            stack.enable_grouping()\n            stack.stmtprocess.append(filters.StripCommentsFilter())\n        if options.get(\'strip_whitespace\') or options.get(\'reindent\'):\n            stack.enable_grouping()\n            stack.stmtprocess.append(filters.StripWhitespaceFilter())\n        if options.get(\'reindent\'):\n            stack.enable_grouping()\n>           stack.stmtprocess.append(filters.ReindentFilter(char=options[\'indent_char\'], width=options[\'indent_width\'], indent_after_first=options[\'indent_after_first\'], indent_columns=options[\'indent_columns\'], wrap_after=options[\'wrap_after\'], comma_first=options[\'comma_first\'], compact=options[\'compact\']))\nE           KeyError: \'indent_char\'\n\nrepos\\sqlparse\\sqlparse\\formatter.py:47: KeyError', 'self = <tests.test_format.TestFormatReindent object at 0x00000142B9CDA8F0>\n\n    def test_insert_values(self):\n        # issue 329\n        f = lambda sql: sqlparse.format(sql, reindent=True)\n        s = \'insert into foo values (1, 2)\'\n>       assert f(s) == \'\\n\'.join([\n            \'insert into foo\',\n            \'values (1, 2)\'])\n\nrepos\\sqlparse\\tests\\test_format.py:601: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:599: in <lambda>\n    f = lambda sql: sqlparse.format(sql, reindent=True)\nrepos\\sqlparse\\sqlparse\\__init__.py:57: in format\n    stack = formatter.build_filter_stack(stack, options)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nstack = <sqlparse.engine.filter_stack.FilterStack object at 0x00000142B9CF2660>\noptions = {\'reindent\': True}\n\n    def build_filter_stack(stack, options):\n        """"""Setup and return a filter stack.\n    \n        Args:\n          stack: :class:`~sqlparse.filters.FilterStack` instance\n          options: Dictionary with options validated by validate_options.\n        """"""\n        if options.get(\'keyword_case\'):\n            stack.preprocess.append(filters.KeywordCaseFilter(options[\'keyword_case\']))\n        if options.get(\'identifier_case\'):\n            stack.preprocess.append(filters.IdentifierCaseFilter(options[\'identifier_case\']))\n        if options.get(\'truncate_strings\'):\n            stack.preprocess.append(filters.TruncateStringFilter(width=options[\'truncate_strings\'], char=options[\'truncate_char\']))\n        if options.get(\'use_space_around_operators\', False):\n            stack.enable_grouping()\n            stack.stmtprocess.append(filters.SpacesAroundOperatorsFilter())\n        if options.get(\'strip_comments\'):\n            stack.enable_grouping()\n            stack.stmtprocess.append(filters.StripCommentsFilter())\n        if options.get(\'strip_whitespace\') or options.get(\'reindent\'):\n            stack.enable_grouping()\n            stack.stmtprocess.append(filters.StripWhitespaceFilter())\n        if options.get(\'reindent\'):\n            stack.enable_grouping()\n>           stack.stmtprocess.append(filters.ReindentFilter(char=options[\'indent_char\'], width=options[\'indent_width\'], indent_after_first=options[\'indent_after_first\'], indent_columns=options[\'indent_columns\'], wrap_after=options[\'wrap_after\'], comma_first=options[\'comma_first\'], compact=options[\'compact\']))\nE           KeyError: \'indent_char\'\n\nrepos\\sqlparse\\sqlparse\\formatter.py:47: KeyError', 'self = <tests.test_format.TestOutputFormat object at 0x00000142B9B7AFD0>\n\n    def test_python(self):\n        sql = \'select * from foo;\'\n        f = lambda sql: sqlparse.format(sql, output_format=\'python\')\n>       assert f(sql) == ""sql = \'select * from foo;\'""\n\nrepos\\sqlparse\\tests\\test_format.py:645: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:644: in <lambda>\n    f = lambda sql: sqlparse.format(sql, output_format=\'python\')\nrepos\\sqlparse\\sqlparse\\__init__.py:56: in format\n    options = formatter.validate_options(options)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\noptions = {\'output_format\': \'python\'}\n\n    def validate_options(options):\n        for key in options:\n            if key == \'keyword_case\' and options[key] not in [\'upper\', \'lower\']:\n                raise ValueError(""Keyword case must be either \'upper\' or \'lower\'"")\n            elif key == \'identifier_case\' and options[key] not in [\'upper\', \'lower\']:\n                raise ValueError(""Identifier case must be either \'upper\' or \'lower\'"")\n            elif key == \'output_format\' and options[key] not in [\'json\', \'xml\', \'csv\']:\n>               raise ValueError(""Output format must be either \'json\', \'xml\', or \'csv\'"")\nE               ValueError: Output format must be either \'json\', \'xml\', or \'csv\'\n\nrepos\\sqlparse\\sqlparse\\formatter.py:12: ValueError', 'self = <tests.test_format.TestOutputFormat object at 0x00000142B9B7B110>\n\n    def test_python_multiple_statements(self):\n        sql = \'select * from foo; select 1 from dual\'\n        f = lambda sql: sqlparse.format(sql, output_format=\'python\')\n>       assert f(sql) == \'\\n\'.join([\n            ""sql = \'select * from foo; \'"",\n            ""sql2 = \'select 1 from dual\'""])\n\nrepos\\sqlparse\\tests\\test_format.py:655: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:654: in <lambda>\n    f = lambda sql: sqlparse.format(sql, output_format=\'python\')\nrepos\\sqlparse\\sqlparse\\__init__.py:56: in format\n    options = formatter.validate_options(options)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\noptions = {\'output_format\': \'python\'}\n\n    def validate_options(options):\n        for key in options:\n            if key == \'keyword_case\' and options[key] not in [\'upper\', \'lower\']:\n                raise ValueError(""Keyword case must be either \'upper\' or \'lower\'"")\n            elif key == \'identifier_case\' and options[key] not in [\'upper\', \'lower\']:\n                raise ValueError(""Identifier case must be either \'upper\' or \'lower\'"")\n            elif key == \'output_format\' and options[key] not in [\'json\', \'xml\', \'csv\']:\n>               raise ValueError(""Output format must be either \'json\', \'xml\', or \'csv\'"")\nE               ValueError: Output format must be either \'json\', \'xml\', or \'csv\'\n\nrepos\\sqlparse\\sqlparse\\formatter.py:12: ValueError', 'self = <tests.test_format.TestOutputFormat object at 0x00000142B9D14510>\n\n    def test_php(self):\n        sql = \'select * from foo;\'\n        f = lambda sql: sqlparse.format(sql, output_format=\'php\')\n>       assert f(sql) == \'$sql = ""select * from foo;"";\'\n\nrepos\\sqlparse\\tests\\test_format.py:673: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:672: in <lambda>\n    f = lambda sql: sqlparse.format(sql, output_format=\'php\')\nrepos\\sqlparse\\sqlparse\\__init__.py:56: in format\n    options = formatter.validate_options(options)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\noptions = {\'output_format\': \'php\'}\n\n    def validate_options(options):\n        for key in options:\n            if key == \'keyword_case\' and options[key] not in [\'upper\', \'lower\']:\n                raise ValueError(""Keyword case must be either \'upper\' or \'lower\'"")\n            elif key == \'identifier_case\' and options[key] not in [\'upper\', \'lower\']:\n                raise ValueError(""Identifier case must be either \'upper\' or \'lower\'"")\n            elif key == \'output_format\' and options[key] not in [\'json\', \'xml\', \'csv\']:\n>               raise ValueError(""Output format must be either \'json\', \'xml\', or \'csv\'"")\nE               ValueError: Output format must be either \'json\', \'xml\', or \'csv\'\n\nrepos\\sqlparse\\sqlparse\\formatter.py:12: ValueError', 'self = <tests.test_format.TestOutputFormat object at 0x00000142B9C88050>\n\n    def test_sql(self):\n        # ""sql"" is an allowed option but has no effect\n        sql = \'select * from foo;\'\n        f = lambda sql: sqlparse.format(sql, output_format=\'sql\')\n>       assert f(sql) == \'select * from foo;\'\n\nrepos\\sqlparse\\tests\\test_format.py:684: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\tests\\test_format.py:683: in <lambda>\n    f = lambda sql: sqlparse.format(sql, output_format=\'sql\')\nrepos\\sqlparse\\sqlparse\\__init__.py:56: in format\n    options = formatter.validate_options(options)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\noptions = {\'output_format\': \'sql\'}\n\n    def validate_options(options):\n        for key in options:\n            if key == \'keyword_case\' and options[key] not in [\'upper\', \'lower\']:\n                raise ValueError(""Keyword case must be either \'upper\' or \'lower\'"")\n            elif key == \'identifier_case\' and options[key] not in [\'upper\', \'lower\']:\n                raise ValueError(""Identifier case must be either \'upper\' or \'lower\'"")\n            elif key == \'output_format\' and options[key] not in [\'json\', \'xml\', \'csv\']:\n>               raise ValueError(""Output format must be either \'json\', \'xml\', or \'csv\'"")\nE               ValueError: Output format must be either \'json\', \'xml\', or \'csv\'\n\nrepos\\sqlparse\\sqlparse\\formatter.py:12: ValueError', 'self = <tests.test_format.TestOutputFormat object at 0x00000142B9D24160>\n\n    def test_invalid_option(self):\n        sql = \'select * from foo;\'\n        with pytest.raises(SQLParseError):\n>           sqlparse.format(sql, output_format=\'foo\')\n\nrepos\\sqlparse\\tests\\test_format.py:689: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:56: in format\n    options = formatter.validate_options(options)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\noptions = {\'output_format\': \'foo\'}\n\n    def validate_options(options):\n        for key in options:\n            if key == \'keyword_case\' and options[key] not in [\'upper\', \'lower\']:\n                raise ValueError(""Keyword case must be either \'upper\' or \'lower\'"")\n            elif key == \'identifier_case\' and options[key] not in [\'upper\', \'lower\']:\n                raise ValueError(""Identifier case must be either \'upper\' or \'lower\'"")\n            elif key == \'output_format\' and options[key] not in [\'json\', \'xml\', \'csv\']:\n>               raise ValueError(""Output format must be either \'json\', \'xml\', or \'csv\'"")\nE               ValueError: Output format must be either \'json\', \'xml\', or \'csv\'\n\nrepos\\sqlparse\\sqlparse\\formatter.py:12: ValueError', 'def test_format_column_ordering():\n        # issue89\n        sql = \'select * from foo order by c1 desc, c2, c3;\'\n>       formatted = sqlparse.format(sql, reindent=True)\n\nrepos\\sqlparse\\tests\\test_format.py:695: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:57: in format\n    stack = formatter.build_filter_stack(stack, options)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nstack = <sqlparse.engine.filter_stack.FilterStack object at 0x00000142BA0A06E0>\noptions = {\'reindent\': True}\n\n    def build_filter_stack(stack, options):\n        """"""Setup and return a filter stack.\n    \n        Args:\n          stack: :class:`~sqlparse.filters.FilterStack` instance\n          options: Dictionary with options validated by validate_options.\n        """"""\n        if options.get(\'keyword_case\'):\n            stack.preprocess.append(filters.KeywordCaseFilter(options[\'keyword_case\']))\n        if options.get(\'identifier_case\'):\n            stack.preprocess.append(filters.IdentifierCaseFilter(options[\'identifier_case\']))\n        if options.get(\'truncate_strings\'):\n            stack.preprocess.append(filters.TruncateStringFilter(width=options[\'truncate_strings\'], char=options[\'truncate_char\']))\n        if options.get(\'use_space_around_operators\', False):\n            stack.enable_grouping()\n            stack.stmtprocess.append(filters.SpacesAroundOperatorsFilter())\n        if options.get(\'strip_comments\'):\n            stack.enable_grouping()\n            stack.stmtprocess.append(filters.StripCommentsFilter())\n        if options.get(\'strip_whitespace\') or options.get(\'reindent\'):\n            stack.enable_grouping()\n            stack.stmtprocess.append(filters.StripWhitespaceFilter())\n        if options.get(\'reindent\'):\n            stack.enable_grouping()\n>           stack.stmtprocess.append(filters.ReindentFilter(char=options[\'indent_char\'], width=options[\'indent_width\'], indent_after_first=options[\'indent_after_first\'], indent_columns=options[\'indent_columns\'], wrap_after=options[\'wrap_after\'], comma_first=options[\'comma_first\'], compact=options[\'compact\']))\nE           KeyError: \'indent_char\'\n\nrepos\\sqlparse\\sqlparse\\formatter.py:47: KeyError', 'def test_truncate_strings():\n        sql = ""update foo set value = \'{}\';"".format(\'x\' * 1000)\n>       formatted = sqlparse.format(sql, truncate_strings=10)\n\nrepos\\sqlparse\\tests\\test_format.py:707: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:57: in format\n    stack = formatter.build_filter_stack(stack, options)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nstack = <sqlparse.engine.filter_stack.FilterStack object at 0x00000142BA0A0BB0>\noptions = {\'truncate_strings\': 10}\n\n    def build_filter_stack(stack, options):\n        """"""Setup and return a filter stack.\n    \n        Args:\n          stack: :class:`~sqlparse.filters.FilterStack` instance\n          options: Dictionary with options validated by validate_options.\n        """"""\n        if options.get(\'keyword_case\'):\n            stack.preprocess.append(filters.KeywordCaseFilter(options[\'keyword_case\']))\n        if options.get(\'identifier_case\'):\n            stack.preprocess.append(filters.IdentifierCaseFilter(options[\'identifier_case\']))\n        if options.get(\'truncate_strings\'):\n>           stack.preprocess.append(filters.TruncateStringFilter(width=options[\'truncate_strings\'], char=options[\'truncate_char\']))\nE           KeyError: \'truncate_char\'\n\nrepos\\sqlparse\\sqlparse\\formatter.py:35: KeyError', 'option = \'bar\'\n\n    @pytest.mark.parametrize(\'option\', [\'bar\', -1, 0])\n    def test_truncate_strings_invalid_option2(option):\n        with pytest.raises(SQLParseError):\n>           sqlparse.format(\'foo\', truncate_strings=option)\n\nrepos\\sqlparse\\tests\\test_format.py:716: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:57: in format\n    stack = formatter.build_filter_stack(stack, options)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nstack = <sqlparse.engine.filter_stack.FilterStack object at 0x00000142BA0A1080>\noptions = {\'truncate_strings\': \'bar\'}\n\n    def build_filter_stack(stack, options):\n        """"""Setup and return a filter stack.\n    \n        Args:\n          stack: :class:`~sqlparse.filters.FilterStack` instance\n          options: Dictionary with options validated by validate_options.\n        """"""\n        if options.get(\'keyword_case\'):\n            stack.preprocess.append(filters.KeywordCaseFilter(options[\'keyword_case\']))\n        if options.get(\'identifier_case\'):\n            stack.preprocess.append(filters.IdentifierCaseFilter(options[\'identifier_case\']))\n        if options.get(\'truncate_strings\'):\n>           stack.preprocess.append(filters.TruncateStringFilter(width=options[\'truncate_strings\'], char=options[\'truncate_char\']))\nE           KeyError: \'truncate_char\'\n\nrepos\\sqlparse\\sqlparse\\formatter.py:35: KeyError', 'option = -1\n\n    @pytest.mark.parametrize(\'option\', [\'bar\', -1, 0])\n    def test_truncate_strings_invalid_option2(option):\n        with pytest.raises(SQLParseError):\n>           sqlparse.format(\'foo\', truncate_strings=option)\n\nrepos\\sqlparse\\tests\\test_format.py:716: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:57: in format\n    stack = formatter.build_filter_stack(stack, options)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nstack = <sqlparse.engine.filter_stack.FilterStack object at 0x00000142BA0A0750>\noptions = {\'truncate_strings\': -1}\n\n    def build_filter_stack(stack, options):\n        """"""Setup and return a filter stack.\n    \n        Args:\n          stack: :class:`~sqlparse.filters.FilterStack` instance\n          options: Dictionary with options validated by validate_options.\n        """"""\n        if options.get(\'keyword_case\'):\n            stack.preprocess.append(filters.KeywordCaseFilter(options[\'keyword_case\']))\n        if options.get(\'identifier_case\'):\n            stack.preprocess.append(filters.IdentifierCaseFilter(options[\'identifier_case\']))\n        if options.get(\'truncate_strings\'):\n>           stack.preprocess.append(filters.TruncateStringFilter(width=options[\'truncate_strings\'], char=options[\'truncate_char\']))\nE           KeyError: \'truncate_char\'\n\nrepos\\sqlparse\\sqlparse\\formatter.py:35: KeyError', ""option = 0\n\n    @pytest.mark.parametrize('option', ['bar', -1, 0])\n    def test_truncate_strings_invalid_option2(option):\n>       with pytest.raises(SQLParseError):\nE       Failed: DID NOT RAISE <class 'sqlparse.exceptions.SQLParseError'>\n\nrepos\\sqlparse\\tests\\test_format.py:715: Failed"", 'sql = \'select verrrylongcolumn from foo\'\n\n    @pytest.mark.parametrize(\'sql\', [\n        \'select verrrylongcolumn from foo\',\n        \'select ""verrrylongcolumn"" from ""foo""\'])\n    def test_truncate_strings_doesnt_truncate_identifiers(sql):\n>       formatted = sqlparse.format(sql, truncate_strings=2)\n\nrepos\\sqlparse\\tests\\test_format.py:723: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:57: in format\n    stack = formatter.build_filter_stack(stack, options)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nstack = <sqlparse.engine.filter_stack.FilterStack object at 0x00000142BA0A1A20>\noptions = {\'truncate_strings\': 2}\n\n    def build_filter_stack(stack, options):\n        """"""Setup and return a filter stack.\n    \n        Args:\n          stack: :class:`~sqlparse.filters.FilterStack` instance\n          options: Dictionary with options validated by validate_options.\n        """"""\n        if options.get(\'keyword_case\'):\n            stack.preprocess.append(filters.KeywordCaseFilter(options[\'keyword_case\']))\n        if options.get(\'identifier_case\'):\n            stack.preprocess.append(filters.IdentifierCaseFilter(options[\'identifier_case\']))\n        if options.get(\'truncate_strings\'):\n>           stack.preprocess.append(filters.TruncateStringFilter(width=options[\'truncate_strings\'], char=options[\'truncate_char\']))\nE           KeyError: \'truncate_char\'\n\nrepos\\sqlparse\\sqlparse\\formatter.py:35: KeyError', 'sql = \'select ""verrrylongcolumn"" from ""foo""\'\n\n    @pytest.mark.parametrize(\'sql\', [\n        \'select verrrylongcolumn from foo\',\n        \'select ""verrrylongcolumn"" from ""foo""\'])\n    def test_truncate_strings_doesnt_truncate_identifiers(sql):\n>       formatted = sqlparse.format(sql, truncate_strings=2)\n\nrepos\\sqlparse\\tests\\test_format.py:723: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:57: in format\n    stack = formatter.build_filter_stack(stack, options)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nstack = <sqlparse.engine.filter_stack.FilterStack object at 0x00000142BA0A31C0>\noptions = {\'truncate_strings\': 2}\n\n    def build_filter_stack(stack, options):\n        """"""Setup and return a filter stack.\n    \n        Args:\n          stack: :class:`~sqlparse.filters.FilterStack` instance\n          options: Dictionary with options validated by validate_options.\n        """"""\n        if options.get(\'keyword_case\'):\n            stack.preprocess.append(filters.KeywordCaseFilter(options[\'keyword_case\']))\n        if options.get(\'identifier_case\'):\n            stack.preprocess.append(filters.IdentifierCaseFilter(options[\'identifier_case\']))\n        if options.get(\'truncate_strings\'):\n>           stack.preprocess.append(filters.TruncateStringFilter(width=options[\'truncate_strings\'], char=options[\'truncate_char\']))\nE           KeyError: \'truncate_char\'\n\nrepos\\sqlparse\\sqlparse\\formatter.py:35: KeyError', 'def test_having_produces_newline():\n        sql = (\'select * from foo, bar where bar.id = foo.bar_id \'\n               \'having sum(bar.value) > 100\')\n>       formatted = sqlparse.format(sql, reindent=True)\n\nrepos\\sqlparse\\tests\\test_format.py:730: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:57: in format\n    stack = formatter.build_filter_stack(stack, options)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nstack = <sqlparse.engine.filter_stack.FilterStack object at 0x00000142BA0A22E0>\noptions = {\'reindent\': True}\n\n    def build_filter_stack(stack, options):\n        """"""Setup and return a filter stack.\n    \n        Args:\n          stack: :class:`~sqlparse.filters.FilterStack` instance\n          options: Dictionary with options validated by validate_options.\n        """"""\n        if options.get(\'keyword_case\'):\n            stack.preprocess.append(filters.KeywordCaseFilter(options[\'keyword_case\']))\n        if options.get(\'identifier_case\'):\n            stack.preprocess.append(filters.IdentifierCaseFilter(options[\'identifier_case\']))\n        if options.get(\'truncate_strings\'):\n            stack.preprocess.append(filters.TruncateStringFilter(width=options[\'truncate_strings\'], char=options[\'truncate_char\']))\n        if options.get(\'use_space_around_operators\', False):\n            stack.enable_grouping()\n            stack.stmtprocess.append(filters.SpacesAroundOperatorsFilter())\n        if options.get(\'strip_comments\'):\n            stack.enable_grouping()\n            stack.stmtprocess.append(filters.StripCommentsFilter())\n        if options.get(\'strip_whitespace\') or options.get(\'reindent\'):\n            stack.enable_grouping()\n            stack.stmtprocess.append(filters.StripWhitespaceFilter())\n        if options.get(\'reindent\'):\n            stack.enable_grouping()\n>           stack.stmtprocess.append(filters.ReindentFilter(char=options[\'indent_char\'], width=options[\'indent_width\'], indent_after_first=options[\'indent_after_first\'], indent_columns=options[\'indent_columns\'], wrap_after=options[\'wrap_after\'], comma_first=options[\'comma_first\'], compact=options[\'compact\']))\nE           KeyError: \'indent_char\'\n\nrepos\\sqlparse\\sqlparse\\formatter.py:47: KeyError', ""right_margin = 'ten'\n\n    @pytest.mark.parametrize('right_margin', ['ten', 2])\n    def test_format_right_margin_invalid_option(right_margin):\n        with pytest.raises(SQLParseError):\n>           sqlparse.format('foo', right_margin=right_margin)\n\nrepos\\sqlparse\\tests\\test_format.py:743: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return ''.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:44: in run\n    filter_.process(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <sqlparse.filters.right_margin.RightMarginFilter object at 0x00000142B9EB6510>\ngroup = <Statement 'foo' at 0x142BA1BB450>\n\n    def process(self, group):\n        # return\n        # group.tokens = self._process(group, group.tokens)\n>       raise NotImplementedError\nE       NotImplementedError\n\nrepos\\sqlparse\\sqlparse\\filters\\right_margin.py:48: NotImplementedError"", ""right_margin = 2\n\n    @pytest.mark.parametrize('right_margin', ['ten', 2])\n    def test_format_right_margin_invalid_option(right_margin):\n        with pytest.raises(SQLParseError):\n>           sqlparse.format('foo', right_margin=right_margin)\n\nrepos\\sqlparse\\tests\\test_format.py:743: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:59: in format\n    return ''.join(stack.run(sql, encoding))\nrepos\\sqlparse\\sqlparse\\engine\\filter_stack.py:44: in run\n    filter_.process(stmt)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <sqlparse.filters.right_margin.RightMarginFilter object at 0x00000142B9DF8A50>\ngroup = <Statement 'foo' at 0x142BA1002D0>\n\n    def process(self, group):\n        # return\n        # group.tokens = self._process(group, group.tokens)\n>       raise NotImplementedError\nE       NotImplementedError\n\nrepos\\sqlparse\\sqlparse\\filters\\right_margin.py:48: NotImplementedError"", 'def test_format_json_ops():  # issue542\n>       formatted = sqlparse.format(\n            ""select foo->\'bar\', foo->\'bar\';"", reindent=True)\n\nrepos\\sqlparse\\tests\\test_format.py:753: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:57: in format\n    stack = formatter.build_filter_stack(stack, options)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nstack = <sqlparse.engine.filter_stack.FilterStack object at 0x00000142BA0DB1C0>\noptions = {\'reindent\': True}\n\n    def build_filter_stack(stack, options):\n        """"""Setup and return a filter stack.\n    \n        Args:\n          stack: :class:`~sqlparse.filters.FilterStack` instance\n          options: Dictionary with options validated by validate_options.\n        """"""\n        if options.get(\'keyword_case\'):\n            stack.preprocess.append(filters.KeywordCaseFilter(options[\'keyword_case\']))\n        if options.get(\'identifier_case\'):\n            stack.preprocess.append(filters.IdentifierCaseFilter(options[\'identifier_case\']))\n        if options.get(\'truncate_strings\'):\n            stack.preprocess.append(filters.TruncateStringFilter(width=options[\'truncate_strings\'], char=options[\'truncate_char\']))\n        if options.get(\'use_space_around_operators\', False):\n            stack.enable_grouping()\n            stack.stmtprocess.append(filters.SpacesAroundOperatorsFilter())\n        if options.get(\'strip_comments\'):\n            stack.enable_grouping()\n            stack.stmtprocess.append(filters.StripCommentsFilter())\n        if options.get(\'strip_whitespace\') or options.get(\'reindent\'):\n            stack.enable_grouping()\n            stack.stmtprocess.append(filters.StripWhitespaceFilter())\n        if options.get(\'reindent\'):\n            stack.enable_grouping()\n>           stack.stmtprocess.append(filters.ReindentFilter(char=options[\'indent_char\'], width=options[\'indent_width\'], indent_after_first=options[\'indent_after_first\'], indent_columns=options[\'indent_columns\'], wrap_after=options[\'wrap_after\'], comma_first=options[\'comma_first\'], compact=options[\'compact\']))\nE           KeyError: \'indent_char\'\n\nrepos\\sqlparse\\sqlparse\\formatter.py:47: KeyError', 'sql = \'case when foo then 1 else bar end\'\nexpected_normal = \'case\\n    when foo then 1\\n    else bar\\nend\'\nexpected_compact = \'case when foo then 1 else bar end\'\n\n    @pytest.mark.parametrize(\'sql, expected_normal, expected_compact\', [\n        (\'case when foo then 1 else bar end\',\n         \'case\\n    when foo then 1\\n    else bar\\nend\',\n         \'case when foo then 1 else bar end\')])\n    def test_compact(sql, expected_normal, expected_compact):  # issue783\n>       formatted_normal = sqlparse.format(sql, reindent=True)\n\nrepos\\sqlparse\\tests\\test_format.py:764: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:57: in format\n    stack = formatter.build_filter_stack(stack, options)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nstack = <sqlparse.engine.filter_stack.FilterStack object at 0x00000142BA0D8910>\noptions = {\'reindent\': True}\n\n    def build_filter_stack(stack, options):\n        """"""Setup and return a filter stack.\n    \n        Args:\n          stack: :class:`~sqlparse.filters.FilterStack` instance\n          options: Dictionary with options validated by validate_options.\n        """"""\n        if options.get(\'keyword_case\'):\n            stack.preprocess.append(filters.KeywordCaseFilter(options[\'keyword_case\']))\n        if options.get(\'identifier_case\'):\n            stack.preprocess.append(filters.IdentifierCaseFilter(options[\'identifier_case\']))\n        if options.get(\'truncate_strings\'):\n            stack.preprocess.append(filters.TruncateStringFilter(width=options[\'truncate_strings\'], char=options[\'truncate_char\']))\n        if options.get(\'use_space_around_operators\', False):\n            stack.enable_grouping()\n            stack.stmtprocess.append(filters.SpacesAroundOperatorsFilter())\n        if options.get(\'strip_comments\'):\n            stack.enable_grouping()\n            stack.stmtprocess.append(filters.StripCommentsFilter())\n        if options.get(\'strip_whitespace\') or options.get(\'reindent\'):\n            stack.enable_grouping()\n            stack.stmtprocess.append(filters.StripWhitespaceFilter())\n        if options.get(\'reindent\'):\n            stack.enable_grouping()\n>           stack.stmtprocess.append(filters.ReindentFilter(char=options[\'indent_char\'], width=options[\'indent_width\'], indent_after_first=options[\'indent_after_first\'], indent_columns=options[\'indent_columns\'], wrap_after=options[\'wrap_after\'], comma_first=options[\'comma_first\'], compact=options[\'compact\']))\nE           KeyError: \'indent_char\'\n\nrepos\\sqlparse\\sqlparse\\formatter.py:47: KeyError', 'def test_issue35():\n        # missing space before LIMIT. Updated for #321\n>       sql = sqlparse.format(""select * from foo where bar = 1 limit 1"",\n                              reindent=True)\n\nrepos\\sqlparse\\tests\\test_regressions.py:48: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:57: in format\n    stack = formatter.build_filter_stack(stack, options)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nstack = <sqlparse.engine.filter_stack.FilterStack object at 0x00000142B9DEC050>\noptions = {\'reindent\': True}\n\n    def build_filter_stack(stack, options):\n        """"""Setup and return a filter stack.\n    \n        Args:\n          stack: :class:`~sqlparse.filters.FilterStack` instance\n          options: Dictionary with options validated by validate_options.\n        """"""\n        if options.get(\'keyword_case\'):\n            stack.preprocess.append(filters.KeywordCaseFilter(options[\'keyword_case\']))\n        if options.get(\'identifier_case\'):\n            stack.preprocess.append(filters.IdentifierCaseFilter(options[\'identifier_case\']))\n        if options.get(\'truncate_strings\'):\n            stack.preprocess.append(filters.TruncateStringFilter(width=options[\'truncate_strings\'], char=options[\'truncate_char\']))\n        if options.get(\'use_space_around_operators\', False):\n            stack.enable_grouping()\n            stack.stmtprocess.append(filters.SpacesAroundOperatorsFilter())\n        if options.get(\'strip_comments\'):\n            stack.enable_grouping()\n            stack.stmtprocess.append(filters.StripCommentsFilter())\n        if options.get(\'strip_whitespace\') or options.get(\'reindent\'):\n            stack.enable_grouping()\n            stack.stmtprocess.append(filters.StripWhitespaceFilter())\n        if options.get(\'reindent\'):\n            stack.enable_grouping()\n>           stack.stmtprocess.append(filters.ReindentFilter(char=options[\'indent_char\'], width=options[\'indent_width\'], indent_after_first=options[\'indent_after_first\'], indent_columns=options[\'indent_columns\'], wrap_after=options[\'wrap_after\'], comma_first=options[\'comma_first\'], compact=options[\'compact\']))\nE           KeyError: \'indent_char\'\n\nrepos\\sqlparse\\sqlparse\\formatter.py:47: KeyError', 'def test_issue40():\n        # make sure identifier lists in subselects are grouped\n        p = sqlparse.parse(\'SELECT id, name FROM \'\n                           \'(SELECT id, name FROM bar) as foo\')[0]\n        assert len(p.tokens) == 7\n        assert p.tokens[2].__class__ == sql.IdentifierList\n        assert p.tokens[-1].__class__ == sql.Identifier\n        assert p.tokens[-1].get_name() == \'foo\'\n        sp = p.tokens[-1].tokens[0]\n        assert sp.tokens[3].__class__ == sql.IdentifierList\n        # make sure that formatting works as expected\n>       s = sqlparse.format(\'SELECT id ==  name FROM \'\n                            \'(SELECT id, name FROM bar)\', reindent=True)\n\nrepos\\sqlparse\\tests\\test_regressions.py:86: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:57: in format\n    stack = formatter.build_filter_stack(stack, options)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nstack = <sqlparse.engine.filter_stack.FilterStack object at 0x00000142B9D8DBE0>\noptions = {\'reindent\': True}\n\n    def build_filter_stack(stack, options):\n        """"""Setup and return a filter stack.\n    \n        Args:\n          stack: :class:`~sqlparse.filters.FilterStack` instance\n          options: Dictionary with options validated by validate_options.\n        """"""\n        if options.get(\'keyword_case\'):\n            stack.preprocess.append(filters.KeywordCaseFilter(options[\'keyword_case\']))\n        if options.get(\'identifier_case\'):\n            stack.preprocess.append(filters.IdentifierCaseFilter(options[\'identifier_case\']))\n        if options.get(\'truncate_strings\'):\n            stack.preprocess.append(filters.TruncateStringFilter(width=options[\'truncate_strings\'], char=options[\'truncate_char\']))\n        if options.get(\'use_space_around_operators\', False):\n            stack.enable_grouping()\n            stack.stmtprocess.append(filters.SpacesAroundOperatorsFilter())\n        if options.get(\'strip_comments\'):\n            stack.enable_grouping()\n            stack.stmtprocess.append(filters.StripCommentsFilter())\n        if options.get(\'strip_whitespace\') or options.get(\'reindent\'):\n            stack.enable_grouping()\n            stack.stmtprocess.append(filters.StripWhitespaceFilter())\n        if options.get(\'reindent\'):\n            stack.enable_grouping()\n>           stack.stmtprocess.append(filters.ReindentFilter(char=options[\'indent_char\'], width=options[\'indent_width\'], indent_after_first=options[\'indent_after_first\'], indent_columns=options[\'indent_columns\'], wrap_after=options[\'wrap_after\'], comma_first=options[\'comma_first\'], compact=options[\'compact\']))\nE           KeyError: \'indent_char\'\n\nrepos\\sqlparse\\sqlparse\\formatter.py:47: KeyError', 'def test_comment_encoding_when_reindent():\n        # There was an UnicodeEncodeError in the reindent filter that\n        # casted every comment followed by a keyword to str.\n        sql = \'select foo -- Comment containing Ümläuts\\nfrom bar\'\n>       formatted = sqlparse.format(sql, reindent=True)\n\nrepos\\sqlparse\\tests\\test_regressions.py:154: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:57: in format\n    stack = formatter.build_filter_stack(stack, options)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nstack = <sqlparse.engine.filter_stack.FilterStack object at 0x00000142B9E15010>\noptions = {\'reindent\': True}\n\n    def build_filter_stack(stack, options):\n        """"""Setup and return a filter stack.\n    \n        Args:\n          stack: :class:`~sqlparse.filters.FilterStack` instance\n          options: Dictionary with options validated by validate_options.\n        """"""\n        if options.get(\'keyword_case\'):\n            stack.preprocess.append(filters.KeywordCaseFilter(options[\'keyword_case\']))\n        if options.get(\'identifier_case\'):\n            stack.preprocess.append(filters.IdentifierCaseFilter(options[\'identifier_case\']))\n        if options.get(\'truncate_strings\'):\n            stack.preprocess.append(filters.TruncateStringFilter(width=options[\'truncate_strings\'], char=options[\'truncate_char\']))\n        if options.get(\'use_space_around_operators\', False):\n            stack.enable_grouping()\n            stack.stmtprocess.append(filters.SpacesAroundOperatorsFilter())\n        if options.get(\'strip_comments\'):\n            stack.enable_grouping()\n            stack.stmtprocess.append(filters.StripCommentsFilter())\n        if options.get(\'strip_whitespace\') or options.get(\'reindent\'):\n            stack.enable_grouping()\n            stack.stmtprocess.append(filters.StripWhitespaceFilter())\n        if options.get(\'reindent\'):\n            stack.enable_grouping()\n>           stack.stmtprocess.append(filters.ReindentFilter(char=options[\'indent_char\'], width=options[\'indent_width\'], indent_after_first=options[\'indent_after_first\'], indent_columns=options[\'indent_columns\'], wrap_after=options[\'wrap_after\'], comma_first=options[\'comma_first\'], compact=options[\'compact\']))\nE           KeyError: \'indent_char\'\n\nrepos\\sqlparse\\sqlparse\\formatter.py:47: KeyError', 'def test_parse_sql_with_binary():\n        # See https://github.com/andialbrecht/sqlparse/pull/88\n        # digest = \'\x82|Ë\x0eê\x8aplL4¡h\x91øN{\'\n        digest = \'\\x82|\\xcb\\x0e\\xea\\x8aplL4\\xa1h\\x91\\xf8N{\'\n        sql = f""select * from foo where bar = \'{digest}\'""\n>       formatted = sqlparse.format(sql, reindent=True)\n\nrepos\\sqlparse\\tests\\test_regressions.py:163: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:57: in format\n    stack = formatter.build_filter_stack(stack, options)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nstack = <sqlparse.engine.filter_stack.FilterStack object at 0x00000142B9DEFBD0>\noptions = {\'reindent\': True}\n\n    def build_filter_stack(stack, options):\n        """"""Setup and return a filter stack.\n    \n        Args:\n          stack: :class:`~sqlparse.filters.FilterStack` instance\n          options: Dictionary with options validated by validate_options.\n        """"""\n        if options.get(\'keyword_case\'):\n            stack.preprocess.append(filters.KeywordCaseFilter(options[\'keyword_case\']))\n        if options.get(\'identifier_case\'):\n            stack.preprocess.append(filters.IdentifierCaseFilter(options[\'identifier_case\']))\n        if options.get(\'truncate_strings\'):\n            stack.preprocess.append(filters.TruncateStringFilter(width=options[\'truncate_strings\'], char=options[\'truncate_char\']))\n        if options.get(\'use_space_around_operators\', False):\n            stack.enable_grouping()\n            stack.stmtprocess.append(filters.SpacesAroundOperatorsFilter())\n        if options.get(\'strip_comments\'):\n            stack.enable_grouping()\n            stack.stmtprocess.append(filters.StripCommentsFilter())\n        if options.get(\'strip_whitespace\') or options.get(\'reindent\'):\n            stack.enable_grouping()\n            stack.stmtprocess.append(filters.StripWhitespaceFilter())\n        if options.get(\'reindent\'):\n            stack.enable_grouping()\n>           stack.stmtprocess.append(filters.ReindentFilter(char=options[\'indent_char\'], width=options[\'indent_width\'], indent_after_first=options[\'indent_after_first\'], indent_columns=options[\'indent_columns\'], wrap_after=options[\'wrap_after\'], comma_first=options[\'comma_first\'], compact=options[\'compact\']))\nE           KeyError: \'indent_char\'\n\nrepos\\sqlparse\\sqlparse\\formatter.py:47: KeyError', 'load_file = <function load_file.<locals>.make_load_file at 0x00000142BA1F7420>\n\n    def test_format_accepts_encoding(load_file):\n        # issue20\n        sql = load_file(\'test_cp1251.sql\', \'cp1251\')\n>       formatted = sqlparse.format(sql, reindent=True, encoding=\'cp1251\')\n\nrepos\\sqlparse\\tests\\test_regressions.py:181: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:57: in format\n    stack = formatter.build_filter_stack(stack, options)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nstack = <sqlparse.engine.filter_stack.FilterStack object at 0x00000142B9DEE200>\noptions = {\'reindent\': True}\n\n    def build_filter_stack(stack, options):\n        """"""Setup and return a filter stack.\n    \n        Args:\n          stack: :class:`~sqlparse.filters.FilterStack` instance\n          options: Dictionary with options validated by validate_options.\n        """"""\n        if options.get(\'keyword_case\'):\n            stack.preprocess.append(filters.KeywordCaseFilter(options[\'keyword_case\']))\n        if options.get(\'identifier_case\'):\n            stack.preprocess.append(filters.IdentifierCaseFilter(options[\'identifier_case\']))\n        if options.get(\'truncate_strings\'):\n            stack.preprocess.append(filters.TruncateStringFilter(width=options[\'truncate_strings\'], char=options[\'truncate_char\']))\n        if options.get(\'use_space_around_operators\', False):\n            stack.enable_grouping()\n            stack.stmtprocess.append(filters.SpacesAroundOperatorsFilter())\n        if options.get(\'strip_comments\'):\n            stack.enable_grouping()\n            stack.stmtprocess.append(filters.StripCommentsFilter())\n        if options.get(\'strip_whitespace\') or options.get(\'reindent\'):\n            stack.enable_grouping()\n            stack.stmtprocess.append(filters.StripWhitespaceFilter())\n        if options.get(\'reindent\'):\n            stack.enable_grouping()\n>           stack.stmtprocess.append(filters.ReindentFilter(char=options[\'indent_char\'], width=options[\'indent_width\'], indent_after_first=options[\'indent_after_first\'], indent_columns=options[\'indent_columns\'], wrap_after=options[\'wrap_after\'], comma_first=options[\'comma_first\'], compact=options[\'compact\']))\nE           KeyError: \'indent_char\'\n\nrepos\\sqlparse\\sqlparse\\formatter.py:47: KeyError', 'def test_issue90():\n        sql = (\'UPDATE ""gallery_photo"" SET ""owner_id"" = 4018, ""deleted_at"" = NULL,\'\n               \' ""width"" = NULL, ""height"" = NULL, ""rating_votes"" = 0,\'\n               \' ""rating_score"" = 0, ""thumbnail_width"" = NULL,\'\n               \' ""thumbnail_height"" = NULL, ""price"" = 1, ""description"" = NULL\')\n>       formatted = sqlparse.format(sql, reindent=True)\n\nrepos\\sqlparse\\tests\\test_regressions.py:198: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:57: in format\n    stack = formatter.build_filter_stack(stack, options)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nstack = <sqlparse.engine.filter_stack.FilterStack object at 0x00000142B9D6E5F0>\noptions = {\'reindent\': True}\n\n    def build_filter_stack(stack, options):\n        """"""Setup and return a filter stack.\n    \n        Args:\n          stack: :class:`~sqlparse.filters.FilterStack` instance\n          options: Dictionary with options validated by validate_options.\n        """"""\n        if options.get(\'keyword_case\'):\n            stack.preprocess.append(filters.KeywordCaseFilter(options[\'keyword_case\']))\n        if options.get(\'identifier_case\'):\n            stack.preprocess.append(filters.IdentifierCaseFilter(options[\'identifier_case\']))\n        if options.get(\'truncate_strings\'):\n            stack.preprocess.append(filters.TruncateStringFilter(width=options[\'truncate_strings\'], char=options[\'truncate_char\']))\n        if options.get(\'use_space_around_operators\', False):\n            stack.enable_grouping()\n            stack.stmtprocess.append(filters.SpacesAroundOperatorsFilter())\n        if options.get(\'strip_comments\'):\n            stack.enable_grouping()\n            stack.stmtprocess.append(filters.StripCommentsFilter())\n        if options.get(\'strip_whitespace\') or options.get(\'reindent\'):\n            stack.enable_grouping()\n            stack.stmtprocess.append(filters.StripWhitespaceFilter())\n        if options.get(\'reindent\'):\n            stack.enable_grouping()\n>           stack.stmtprocess.append(filters.ReindentFilter(char=options[\'indent_char\'], width=options[\'indent_width\'], indent_after_first=options[\'indent_after_first\'], indent_columns=options[\'indent_columns\'], wrap_after=options[\'wrap_after\'], comma_first=options[\'comma_first\'], compact=options[\'compact\']))\nE           KeyError: \'indent_char\'\n\nrepos\\sqlparse\\sqlparse\\formatter.py:47: KeyError', 'def test_except_formatting():\n        sql = \'SELECT 1 FROM foo WHERE 2 = 3 EXCEPT SELECT 2 FROM bar WHERE 1 = 2\'\n>       formatted = sqlparse.format(sql, reindent=True)\n\nrepos\\sqlparse\\tests\\test_regressions.py:216: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:57: in format\n    stack = formatter.build_filter_stack(stack, options)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nstack = <sqlparse.engine.filter_stack.FilterStack object at 0x00000142B9D6C520>\noptions = {\'reindent\': True}\n\n    def build_filter_stack(stack, options):\n        """"""Setup and return a filter stack.\n    \n        Args:\n          stack: :class:`~sqlparse.filters.FilterStack` instance\n          options: Dictionary with options validated by validate_options.\n        """"""\n        if options.get(\'keyword_case\'):\n            stack.preprocess.append(filters.KeywordCaseFilter(options[\'keyword_case\']))\n        if options.get(\'identifier_case\'):\n            stack.preprocess.append(filters.IdentifierCaseFilter(options[\'identifier_case\']))\n        if options.get(\'truncate_strings\'):\n            stack.preprocess.append(filters.TruncateStringFilter(width=options[\'truncate_strings\'], char=options[\'truncate_char\']))\n        if options.get(\'use_space_around_operators\', False):\n            stack.enable_grouping()\n            stack.stmtprocess.append(filters.SpacesAroundOperatorsFilter())\n        if options.get(\'strip_comments\'):\n            stack.enable_grouping()\n            stack.stmtprocess.append(filters.StripCommentsFilter())\n        if options.get(\'strip_whitespace\') or options.get(\'reindent\'):\n            stack.enable_grouping()\n            stack.stmtprocess.append(filters.StripWhitespaceFilter())\n        if options.get(\'reindent\'):\n            stack.enable_grouping()\n>           stack.stmtprocess.append(filters.ReindentFilter(char=options[\'indent_char\'], width=options[\'indent_width\'], indent_after_first=options[\'indent_after_first\'], indent_columns=options[\'indent_columns\'], wrap_after=options[\'wrap_after\'], comma_first=options[\'comma_first\'], compact=options[\'compact\']))\nE           KeyError: \'indent_char\'\n\nrepos\\sqlparse\\sqlparse\\formatter.py:47: KeyError', 'def test_null_with_as():\n        sql = \'SELECT NULL AS c1, NULL AS c2 FROM t1\'\n>       formatted = sqlparse.format(sql, reindent=True)\n\nrepos\\sqlparse\\tests\\test_regressions.py:230: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:57: in format\n    stack = formatter.build_filter_stack(stack, options)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nstack = <sqlparse.engine.filter_stack.FilterStack object at 0x00000142B9D6E430>\noptions = {\'reindent\': True}\n\n    def build_filter_stack(stack, options):\n        """"""Setup and return a filter stack.\n    \n        Args:\n          stack: :class:`~sqlparse.filters.FilterStack` instance\n          options: Dictionary with options validated by validate_options.\n        """"""\n        if options.get(\'keyword_case\'):\n            stack.preprocess.append(filters.KeywordCaseFilter(options[\'keyword_case\']))\n        if options.get(\'identifier_case\'):\n            stack.preprocess.append(filters.IdentifierCaseFilter(options[\'identifier_case\']))\n        if options.get(\'truncate_strings\'):\n            stack.preprocess.append(filters.TruncateStringFilter(width=options[\'truncate_strings\'], char=options[\'truncate_char\']))\n        if options.get(\'use_space_around_operators\', False):\n            stack.enable_grouping()\n            stack.stmtprocess.append(filters.SpacesAroundOperatorsFilter())\n        if options.get(\'strip_comments\'):\n            stack.enable_grouping()\n            stack.stmtprocess.append(filters.StripCommentsFilter())\n        if options.get(\'strip_whitespace\') or options.get(\'reindent\'):\n            stack.enable_grouping()\n            stack.stmtprocess.append(filters.StripWhitespaceFilter())\n        if options.get(\'reindent\'):\n            stack.enable_grouping()\n>           stack.stmtprocess.append(filters.ReindentFilter(char=options[\'indent_char\'], width=options[\'indent_width\'], indent_after_first=options[\'indent_after_first\'], indent_columns=options[\'indent_columns\'], wrap_after=options[\'wrap_after\'], comma_first=options[\'comma_first\'], compact=options[\'compact\']))\nE           KeyError: \'indent_char\'\n\nrepos\\sqlparse\\sqlparse\\formatter.py:47: KeyError', 'def test_issue207_runaway_format():\n        sql = \'select 1 from (select 1 as one, 2 as two, 3 from dual) t0\'\n>       p = sqlparse.format(sql, reindent=True)\n\nrepos\\sqlparse\\tests\\test_regressions.py:303: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:57: in format\n    stack = formatter.build_filter_stack(stack, options)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nstack = <sqlparse.engine.filter_stack.FilterStack object at 0x00000142B9E17150>\noptions = {\'reindent\': True}\n\n    def build_filter_stack(stack, options):\n        """"""Setup and return a filter stack.\n    \n        Args:\n          stack: :class:`~sqlparse.filters.FilterStack` instance\n          options: Dictionary with options validated by validate_options.\n        """"""\n        if options.get(\'keyword_case\'):\n            stack.preprocess.append(filters.KeywordCaseFilter(options[\'keyword_case\']))\n        if options.get(\'identifier_case\'):\n            stack.preprocess.append(filters.IdentifierCaseFilter(options[\'identifier_case\']))\n        if options.get(\'truncate_strings\'):\n            stack.preprocess.append(filters.TruncateStringFilter(width=options[\'truncate_strings\'], char=options[\'truncate_char\']))\n        if options.get(\'use_space_around_operators\', False):\n            stack.enable_grouping()\n            stack.stmtprocess.append(filters.SpacesAroundOperatorsFilter())\n        if options.get(\'strip_comments\'):\n            stack.enable_grouping()\n            stack.stmtprocess.append(filters.StripCommentsFilter())\n        if options.get(\'strip_whitespace\') or options.get(\'reindent\'):\n            stack.enable_grouping()\n            stack.stmtprocess.append(filters.StripWhitespaceFilter())\n        if options.get(\'reindent\'):\n            stack.enable_grouping()\n>           stack.stmtprocess.append(filters.ReindentFilter(char=options[\'indent_char\'], width=options[\'indent_width\'], indent_after_first=options[\'indent_after_first\'], indent_columns=options[\'indent_columns\'], wrap_after=options[\'wrap_after\'], comma_first=options[\'comma_first\'], compact=options[\'compact\']))\nE           KeyError: \'indent_char\'\n\nrepos\\sqlparse\\sqlparse\\formatter.py:47: KeyError', 'def test_issue315_utf8_by_default():\n        # Make sure the lexer can handle utf-8 string by default correctly\n        # digest = \'齐天大圣.カラフルな雲.사랑해요\'\n        # The digest contains Chinese, Japanese and Korean characters\n        # All in \'utf-8\' encoding.\n        digest = (\n            \'\\xe9\\xbd\\x90\\xe5\\xa4\\xa9\\xe5\\xa4\\xa7\\xe5\\x9c\\xa3.\'\n            \'\\xe3\\x82\\xab\\xe3\\x83\\xa9\\xe3\\x83\\x95\\xe3\\x83\\xab\\xe3\\x81\\xaa\\xe9\'\n            \'\\x9b\\xb2.\'\n            \'\\xec\\x82\\xac\\xeb\\x9e\\x91\\xed\\x95\\xb4\\xec\\x9a\\x94\'\n        )\n        sql = f""select * from foo where bar = \'{digest}\'""\n>       formatted = sqlparse.format(sql, reindent=True)\n\nrepos\\sqlparse\\tests\\test_regressions.py:340: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:57: in format\n    stack = formatter.build_filter_stack(stack, options)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nstack = <sqlparse.engine.filter_stack.FilterStack object at 0x00000142B9D8E740>\noptions = {\'reindent\': True}\n\n    def build_filter_stack(stack, options):\n        """"""Setup and return a filter stack.\n    \n        Args:\n          stack: :class:`~sqlparse.filters.FilterStack` instance\n          options: Dictionary with options validated by validate_options.\n        """"""\n        if options.get(\'keyword_case\'):\n            stack.preprocess.append(filters.KeywordCaseFilter(options[\'keyword_case\']))\n        if options.get(\'identifier_case\'):\n            stack.preprocess.append(filters.IdentifierCaseFilter(options[\'identifier_case\']))\n        if options.get(\'truncate_strings\'):\n            stack.preprocess.append(filters.TruncateStringFilter(width=options[\'truncate_strings\'], char=options[\'truncate_char\']))\n        if options.get(\'use_space_around_operators\', False):\n            stack.enable_grouping()\n            stack.stmtprocess.append(filters.SpacesAroundOperatorsFilter())\n        if options.get(\'strip_comments\'):\n            stack.enable_grouping()\n            stack.stmtprocess.append(filters.StripCommentsFilter())\n        if options.get(\'strip_whitespace\') or options.get(\'reindent\'):\n            stack.enable_grouping()\n            stack.stmtprocess.append(filters.StripWhitespaceFilter())\n        if options.get(\'reindent\'):\n            stack.enable_grouping()\n>           stack.stmtprocess.append(filters.ReindentFilter(char=options[\'indent_char\'], width=options[\'indent_width\'], indent_after_first=options[\'indent_after_first\'], indent_columns=options[\'indent_columns\'], wrap_after=options[\'wrap_after\'], comma_first=options[\'comma_first\'], compact=options[\'compact\']))\nE           KeyError: \'indent_char\'\n\nrepos\\sqlparse\\sqlparse\\formatter.py:47: KeyError', 'def test_issue469_copy_as_psql_command():\n>       formatted = sqlparse.format(\n            \'\\\\copy select * from foo\',\n            keyword_case=\'upper\', identifier_case=\'capitalize\')\n\nrepos\\sqlparse\\tests\\test_regressions.py:369: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:56: in format\n    options = formatter.validate_options(options)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\noptions = {\'identifier_case\': \'capitalize\', \'keyword_case\': \'upper\'}\n\n    def validate_options(options):\n        for key in options:\n            if key == \'keyword_case\' and options[key] not in [\'upper\', \'lower\']:\n                raise ValueError(""Keyword case must be either \'upper\' or \'lower\'"")\n            elif key == \'identifier_case\' and options[key] not in [\'upper\', \'lower\']:\n>               raise ValueError(""Identifier case must be either \'upper\' or \'lower\'"")\nE               ValueError: Identifier case must be either \'upper\' or \'lower\'\n\nrepos\\sqlparse\\sqlparse\\formatter.py:10: ValueError', 'def test_issue562_tzcasts():\n        # Test that whitespace between \'from\' and \'bar\' is retained\n>       formatted = sqlparse.format(\n            \'SELECT f(HOUR from bar AT TIME ZONE \\\'UTC\\\') from foo\', reindent=True\n        )\n\nrepos\\sqlparse\\tests\\test_regressions.py:410: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:57: in format\n    stack = formatter.build_filter_stack(stack, options)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nstack = <sqlparse.engine.filter_stack.FilterStack object at 0x00000142B9D58D00>\noptions = {\'reindent\': True}\n\n    def build_filter_stack(stack, options):\n        """"""Setup and return a filter stack.\n    \n        Args:\n          stack: :class:`~sqlparse.filters.FilterStack` instance\n          options: Dictionary with options validated by validate_options.\n        """"""\n        if options.get(\'keyword_case\'):\n            stack.preprocess.append(filters.KeywordCaseFilter(options[\'keyword_case\']))\n        if options.get(\'identifier_case\'):\n            stack.preprocess.append(filters.IdentifierCaseFilter(options[\'identifier_case\']))\n        if options.get(\'truncate_strings\'):\n            stack.preprocess.append(filters.TruncateStringFilter(width=options[\'truncate_strings\'], char=options[\'truncate_char\']))\n        if options.get(\'use_space_around_operators\', False):\n            stack.enable_grouping()\n            stack.stmtprocess.append(filters.SpacesAroundOperatorsFilter())\n        if options.get(\'strip_comments\'):\n            stack.enable_grouping()\n            stack.stmtprocess.append(filters.StripCommentsFilter())\n        if options.get(\'strip_whitespace\') or options.get(\'reindent\'):\n            stack.enable_grouping()\n            stack.stmtprocess.append(filters.StripWhitespaceFilter())\n        if options.get(\'reindent\'):\n            stack.enable_grouping()\n>           stack.stmtprocess.append(filters.ReindentFilter(char=options[\'indent_char\'], width=options[\'indent_width\'], indent_after_first=options[\'indent_after_first\'], indent_columns=options[\'indent_columns\'], wrap_after=options[\'wrap_after\'], comma_first=options[\'comma_first\'], compact=options[\'compact\']))\nE           KeyError: \'indent_char\'\n\nrepos\\sqlparse\\sqlparse\\formatter.py:47: KeyError', 'def test_as_in_parentheses_indents():\n        # did raise NoneType has no attribute is_group in _process_parentheses\n>       formatted = sqlparse.format(\'(as foo)\', reindent=True)\n\nrepos\\sqlparse\\tests\\test_regressions.py:419: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:57: in format\n    stack = formatter.build_filter_stack(stack, options)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nstack = <sqlparse.engine.filter_stack.FilterStack object at 0x00000142B9D5B070>\noptions = {\'reindent\': True}\n\n    def build_filter_stack(stack, options):\n        """"""Setup and return a filter stack.\n    \n        Args:\n          stack: :class:`~sqlparse.filters.FilterStack` instance\n          options: Dictionary with options validated by validate_options.\n        """"""\n        if options.get(\'keyword_case\'):\n            stack.preprocess.append(filters.KeywordCaseFilter(options[\'keyword_case\']))\n        if options.get(\'identifier_case\'):\n            stack.preprocess.append(filters.IdentifierCaseFilter(options[\'identifier_case\']))\n        if options.get(\'truncate_strings\'):\n            stack.preprocess.append(filters.TruncateStringFilter(width=options[\'truncate_strings\'], char=options[\'truncate_char\']))\n        if options.get(\'use_space_around_operators\', False):\n            stack.enable_grouping()\n            stack.stmtprocess.append(filters.SpacesAroundOperatorsFilter())\n        if options.get(\'strip_comments\'):\n            stack.enable_grouping()\n            stack.stmtprocess.append(filters.StripCommentsFilter())\n        if options.get(\'strip_whitespace\') or options.get(\'reindent\'):\n            stack.enable_grouping()\n            stack.stmtprocess.append(filters.StripWhitespaceFilter())\n        if options.get(\'reindent\'):\n            stack.enable_grouping()\n>           stack.stmtprocess.append(filters.ReindentFilter(char=options[\'indent_char\'], width=options[\'indent_width\'], indent_after_first=options[\'indent_after_first\'], indent_columns=options[\'indent_columns\'], wrap_after=options[\'wrap_after\'], comma_first=options[\'comma_first\'], compact=options[\'compact\']))\nE           KeyError: \'indent_char\'\n\nrepos\\sqlparse\\sqlparse\\formatter.py:47: KeyError', 'def test_format_invalid_where_clause():\n        # did raise ValueError\n>       formatted = sqlparse.format(\'where, foo\', reindent=True)\n\nrepos\\sqlparse\\tests\\test_regressions.py:425: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nrepos\\sqlparse\\sqlparse\\__init__.py:57: in format\n    stack = formatter.build_filter_stack(stack, options)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nstack = <sqlparse.engine.filter_stack.FilterStack object at 0x00000142B9D5BD20>\noptions = {\'reindent\': True}\n\n    def build_filter_stack(stack, options):\n        """"""Setup and return a filter stack.\n    \n        Args:\n          stack: :class:`~sqlparse.filters.FilterStack` instance\n          options: Dictionary with options validated by validate_options.\n        """"""\n        if options.get(\'keyword_case\'):\n            stack.preprocess.append(filters.KeywordCaseFilter(options[\'keyword_case\']))\n        if options.get(\'identifier_case\'):\n            stack.preprocess.append(filters.IdentifierCaseFilter(options[\'identifier_case\']))\n        if options.get(\'truncate_strings\'):\n            stack.preprocess.append(filters.TruncateStringFilter(width=options[\'truncate_strings\'], char=options[\'truncate_char\']))\n        if options.get(\'use_space_around_operators\', False):\n            stack.enable_grouping()\n            stack.stmtprocess.append(filters.SpacesAroundOperatorsFilter())\n        if options.get(\'strip_comments\'):\n            stack.enable_grouping()\n            stack.stmtprocess.append(filters.StripCommentsFilter())\n        if options.get(\'strip_whitespace\') or options.get(\'reindent\'):\n            stack.enable_grouping()\n            stack.stmtprocess.append(filters.StripWhitespaceFilter())\n        if options.get(\'reindent\'):\n            stack.enable_grouping()\n>           stack.stmtprocess.append(filters.ReindentFilter(char=options[\'indent_char\'], width=options[\'indent_width\'], indent_after_first=options[\'indent_after_first\'], indent_columns=options[\'indent_columns\'], wrap_after=options[\'wrap_after\'], comma_first=options[\'comma_first\'], compact=options[\'compact\']))\nE           KeyError: \'indent_char\'\n\nrepos\\sqlparse\\sqlparse\\formatter.py:47: KeyError']",sqlparse/validate_options,LLM
